// Load environment variables FIRST - before any other initialization
// This ensures all env vars are available for Sentry and other modules
import dotenv from 'dotenv'
import { fileURLToPath } from 'url'
import path from 'path'

// Get __dirname equivalent for ESM
const __filename_early = fileURLToPath(import.meta.url)
const __dirname_early = path.dirname(__filename_early)

// Load .env files in order of priority
dotenv.config() // Default .env in cwd
try {
  dotenv.config({ path: path.resolve(__dirname_early, '.env') }) // .env next to server.js
} catch { }
try {
  dotenv.config({ path: path.resolve(__dirname_early, '.env.server') }) // server-specific secrets
} catch { }

// Sentry error monitoring - must be imported early for error catching
// GDPR Compliance: No PII is sent automatically
// Use @sentry/node for Node.js compatibility (systemd service runs with /usr/bin/node)
// @sentry/bun would only work when running with the Bun runtime
import * as Sentry from '@sentry/node';

const SENTRY_DSN = 'https://758053551e0396eab52314bdbcf57924@o4510783278350336.ingest.de.sentry.io/4510783285821520';

// Server identification: Set PLANTSWIPE_SERVER_NAME to 'DEV' or 'MAIN' on each server
// Now this will correctly read from .env since dotenv was loaded above
const SERVER_NAME = process.env.PLANTSWIPE_SERVER_NAME || process.env.SERVER_NAME || 'unknown';

/**
 * Scrub PII from strings before sending to Sentry
 */
function scrubPII(value) {
  if (!value || typeof value !== 'string') return value;
  // Scrub email addresses
  value = value.replace(/[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/g, '[EMAIL_REDACTED]');
  // Scrub potential passwords in URLs or logs
  value = value.replace(/password[=:][^\s&"']+/gi, 'password=[REDACTED]');
  // Scrub bearer tokens
  value = value.replace(/Bearer\s+[A-Za-z0-9\-_\.]+/g, 'Bearer [REDACTED]');
  // Scrub API keys
  value = value.replace(/[a-f0-9]{32,}/gi, '[TOKEN_REDACTED]');
  return value;
}

// ========================================
// MAINTENANCE MODE - Server-side tracking
// ========================================
// File-based maintenance mode state to coordinate with admin operations
// When enabled, expected HTTP errors (502, 503, 504) during service restarts are suppressed
import fsEarly from 'fs';

const MAINTENANCE_MODE_FILE = '/tmp/plantswipe-maintenance.json';

/**
 * Check if maintenance mode is currently active
 * Returns { active: boolean, expiresAt?: number, reason?: string }
 */
function getMaintenanceMode() {
  try {
    if (!fsEarly.existsSync(MAINTENANCE_MODE_FILE)) {
      return { active: false };
    }
    const content = fsEarly.readFileSync(MAINTENANCE_MODE_FILE, 'utf8');
    const data = JSON.parse(content);
    // Check if maintenance mode has expired
    if (data.expiresAt && Date.now() > data.expiresAt) {
      // Expired - clean up the file
      try { fsEarly.unlinkSync(MAINTENANCE_MODE_FILE); } catch {}
      return { active: false };
    }
    return { active: true, ...data };
  } catch {
    return { active: false };
  }
}

/**
 * Enable maintenance mode for a specified duration
 * @param durationMs - How long to stay in maintenance mode (default: 5 minutes)
 * @param reason - Optional reason for maintenance mode
 */
function enableMaintenanceMode(durationMs = 300000, reason = 'pull-and-build') {
  try {
    const data = {
      active: true,
      enabledAt: Date.now(),
      expiresAt: Date.now() + durationMs,
      reason,
    };
    fsEarly.writeFileSync(MAINTENANCE_MODE_FILE, JSON.stringify(data, null, 2), 'utf8');
    console.log(`[Sentry] Maintenance mode ENABLED - suppressing expected errors for ${durationMs / 1000}s (reason: ${reason})`);
    return true;
  } catch (err) {
    console.error('[Sentry] Failed to enable maintenance mode:', err);
    return false;
  }
}

/**
 * Disable maintenance mode
 */
function disableMaintenanceMode() {
  try {
    if (fsEarly.existsSync(MAINTENANCE_MODE_FILE)) {
      fsEarly.unlinkSync(MAINTENANCE_MODE_FILE);
    }
    console.log('[Sentry] Maintenance mode DISABLED - normal error reporting resumed');
    return true;
  } catch (err) {
    console.error('[Sentry] Failed to disable maintenance mode:', err);
    return false;
  }
}

/**
 * Check if an error should be suppressed during maintenance mode
 * Suppresses 502, 503, 504 errors which are expected during service restarts
 */
function shouldSuppressMaintenanceError(event, hint) {
  const maintenance = getMaintenanceMode();
  if (!maintenance.active) {
    return false;
  }
  
  const error = hint?.originalException;
  
  // Check for HTTP status codes in the error or event
  const statusCodes = [400, 502, 503, 504];
  
  // Check error message for status codes
  if (error instanceof Error) {
    const msg = error.message || '';
    for (const code of statusCodes) {
      if (msg.includes(String(code)) || msg.includes('Bad Gateway') || msg.includes('Service Unavailable') || msg.includes('Gateway Timeout')) {
        console.log(`[Sentry] Suppressing ${code}-related error during maintenance: ${msg.substring(0, 100)}`);
        return true;
      }
    }
    // Also suppress connection-related errors during maintenance
    if (msg.includes('ECONNREFUSED') || msg.includes('ECONNRESET') || msg.includes('ETIMEDOUT') || msg.includes('socket hang up')) {
      console.log(`[Sentry] Suppressing connection error during maintenance: ${msg.substring(0, 100)}`);
      return true;
    }
  }
  
  // Check event tags for status code
  const statusTag = event?.tags?.['http.status_code'] || event?.contexts?.response?.status_code;
  if (statusTag && statusCodes.includes(Number(statusTag))) {
    console.log(`[Sentry] Suppressing HTTP ${statusTag} error during maintenance`);
    return true;
  }
  
  return false;
}

Sentry.init({
  dsn: SENTRY_DSN,
  environment: process.env.NODE_ENV || 'production',
  // Server identification
  serverName: SERVER_NAME,
  // Send structured logs to Sentry
  _experiments: {
    enableLogs: true,
  },
  // GDPR: Sample 20% of transactions in production (cost-effective)
  tracesSampleRate: process.env.NODE_ENV === 'production' ? 0.2 : 1.0,
  // GDPR: Do NOT send PII automatically (IP addresses, cookies, etc.)
  sendDefaultPii: false,
  // Add server tag to all events
  initialScope: {
    tags: {
      server: SERVER_NAME,
      app: 'plant-swipe-server',
    },
  },
  // Filter and scrub events before sending to Sentry
  beforeSend(event, hint) {
    // MAINTENANCE MODE: Suppress expected errors during pull-and-build operations
    if (shouldSuppressMaintenanceError(event, hint)) {
      return null;
    }
    
    const error = hint.originalException;
    if (error instanceof Error) {
      // Ignore connection reset errors (common with load balancers)
      if (error.message?.includes('ECONNRESET')) {
        return null;
      }
      // Ignore socket hang up errors
      if (error.message?.includes('socket hang up')) {
        return null;
      }
      // Ignore cancelled requests
      if (error.name === 'AbortError') {
        return null;
      }
    }
    
    // GDPR: Scrub PII from exception messages
    if (event.exception?.values) {
      event.exception.values = event.exception.values.map(exc => ({
        ...exc,
        value: scrubPII(exc.value),
      }));
    }
    
    // GDPR: Scrub request data
    if (event.request) {
      // Remove IP address
      delete event.request.ip;
      // Remove cookies
      delete event.request.cookies;
      // Only keep safe headers
      if (event.request.headers) {
        const safeHeaders = ['content-type', 'accept', 'user-agent', 'accept-language'];
        event.request.headers = Object.fromEntries(
          Object.entries(event.request.headers)
            .filter(([k]) => safeHeaders.includes(k.toLowerCase()))
        );
      }
      // Scrub URL query params (may contain tokens)
      if (event.request.url && event.request.url.includes('?')) {
        event.request.url = event.request.url.split('?')[0] + '?[PARAMS_REDACTED]';
      }
      // Scrub request body
      if (event.request.data) {
        event.request.data = typeof event.request.data === 'string' 
          ? scrubPII(event.request.data)
          : '[BODY_REDACTED]';
      }
    }
    
    // GDPR: Remove user email if present
    if (event.user) {
      delete event.user.email;
      delete event.user.ip_address;
    }
    
    // Add useful server context
    event.contexts = event.contexts || {};
    event.contexts.server = {
      name: SERVER_NAME,
      node_version: process.version,
      platform: process.platform,
    };
    
    return event;
  },
  // GDPR: Also filter transactions
  beforeSendTransaction(event) {
    // Scrub URL query parameters
    if (event.request?.url && event.request.url.includes('?')) {
      event.request.url = event.request.url.split('?')[0] + '?[PARAMS_REDACTED]';
    }
    // Remove user PII
    if (event.user) {
      delete event.user.email;
      delete event.user.ip_address;
    }
    return event;
  },
});

console.log(`[Sentry] Initialized for server: ${SERVER_NAME} (GDPR-compliant)`);

// Global error handlers for uncaught exceptions and unhandled rejections
process.on('uncaughtException', (error) => {
  console.error('[Server] Uncaught Exception:', error);
  Sentry.captureException(error);
  // Give Sentry time to send the error before exiting
  setTimeout(() => process.exit(1), 2000);
});

process.on('unhandledRejection', (reason, promise) => {
  console.error('[Server] Unhandled Rejection at:', promise, 'reason:', reason);
  Sentry.captureException(reason instanceof Error ? reason : new Error(String(reason)));
});

// ESM server to serve API and static assets
import express from 'express'
import postgres from 'postgres'
// Note: dotenv, path, fileURLToPath already imported at top of file for early env loading
import fs from 'fs/promises'
import fsSync from 'fs'
import { createClient as createSupabaseClient } from '@supabase/supabase-js'
import { exec as execCb, spawn as spawnChild } from 'child_process'
import { promisify } from 'util'

import zlib from 'zlib'
import crypto from 'crypto'
import { pipeline as streamPipeline } from 'stream'
import net from 'net'
import os from 'os'
import OpenAI from 'openai'
import { z } from 'zod'
import { zodResponseFormat } from 'openai/helpers/zod'
import multer from 'multer'
import sharp from 'sharp'
import webpush from 'web-push'
import cron from 'node-cron'

// Note: dotenv already loaded at top of file before Sentry init

// Map common env aliases so deployments can be plugâ€‘andâ€‘play with a single .env
function preferEnv(target, sources) {
  if (!process.env[target]) {
    for (const k of sources) {
      const v = process.env[k]
      if (v && String(v).length > 0) { process.env[target] = v; break }
    }
  }
}
// Allow DB_URL to serve as DATABASE_URL, and other common aliases
preferEnv('DATABASE_URL', ['DB_URL', 'PG_URL', 'POSTGRES_URL', 'POSTGRES_PRISMA_URL', 'SUPABASE_DB_URL'])
// Normalize Supabase envs for server code if only VITE_* are present
preferEnv('SUPABASE_URL', ['VITE_SUPABASE_URL', 'REACT_APP_SUPABASE_URL', 'NEXT_PUBLIC_SUPABASE_URL'])
preferEnv('SUPABASE_ANON_KEY', ['VITE_SUPABASE_ANON_KEY', 'REACT_APP_SUPABASE_ANON_KEY', 'NEXT_PUBLIC_SUPABASE_ANON_KEY'])
preferEnv('SUPABASE_SERVICE_ROLE_KEY', ['SUPABASE_SERVICE_KEY', 'SUPABASE_SERVICE_ROLE', 'SUPABASE_SERVICE_ROLE_TOKEN'])
// Normalize optional admin token from frontend env
preferEnv('ADMIN_STATIC_TOKEN', ['VITE_ADMIN_STATIC_TOKEN'])

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

let aiFieldPromptsTemplate = {}
try {
  const promptPath = path.join(__dirname, 'src', 'lib', 'aiFieldPrompts.json')
  const promptContents = fsSync.readFileSync(promptPath, 'utf-8')
  aiFieldPromptsTemplate = JSON.parse(promptContents)
} catch (err) {
  console.warn('[server] Failed to load AI field prompts JSON:', err?.message || err)
  aiFieldPromptsTemplate = {}
}

// --- Email Compatibility Sanitizer ---
/**
 * Sanitizes HTML content to make it email-client compatible
 * Replaces CSS properties that email clients don't support with compatible alternatives
 */
function sanitizeHtmlForEmail(html) {
  if (!html) return html

  let result = html

  // 1. Replace CSS variables with hardcoded colors (Gmail doesn't support var())
  const cssVarMap = {
    '--tt-color-highlight-yellow': '#fef08a',
    '--tt-color-highlight-red': '#fecaca',
    '--tt-color-highlight-green': '#bbf7d0',
    '--tt-color-highlight-blue': '#bfdbfe',
    '--tt-color-highlight-purple': '#e9d5ff',
    '--tt-color-highlight-pink': '#fbcfe8',
    '--tt-color-highlight-orange': '#fed7aa',
  }
  // Replace var(--variable-name) with actual color
  result = result.replace(/var\(\s*(--tt-color-[a-zA-Z-]+)\s*\)/gi, (match, varName) => {
    return cssVarMap[varName] || '#fef08a' // Default to yellow
  })

  // 2. Replace linear-gradient backgrounds with solid colors
  // Match the full gradient including nested parentheses for rgb/rgba
  result = result.replace(/background:\s*linear-gradient\s*\([^;"}]*\)\s*;?/gi, (match) => {
    // Try to extract a hex color first
    const hexMatch = match.match(/#[a-fA-F0-9]{6}|#[a-fA-F0-9]{3}/)
    if (hexMatch) {
      return `background-color: ${hexMatch[0]};`
    }
    // Try to extract rgb color
    const rgbMatch = match.match(/rgb\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)/)
    if (rgbMatch) {
      const toHex = (n) => {
        const hex = parseInt(n).toString(16)
        return hex.length === 1 ? '0' + hex : hex
      }
      return `background-color: #${toHex(rgbMatch[1])}${toHex(rgbMatch[2])}${toHex(rgbMatch[3])};`
    }
    return 'background-color: #ffffff;'
  })

  // 3. Remove box-shadow properties entirely (not supported in most email clients)
  result = result.replace(/box-shadow:\s*[^;"}]+;?/gi, '')

  // 4. Replace rgba() colors with solid hex (in all contexts, not just background)
  result = result.replace(/rgba\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*[\d.]+\s*\)/gi, (match, r, g, b) => {
    const toHex = (n) => {
      const hex = parseInt(n).toString(16)
      return hex.length === 1 ? '0' + hex : hex
    }
    return `#${toHex(r)}${toHex(g)}${toHex(b)}`
  })

  // 5. Replace display: flex with text-align: center for centering
  result = result.replace(/display:\s*flex\s*;\s*flex-direction:\s*column\s*;\s*align-items:\s*center\s*;?/gi, 'text-align: center;')
  result = result.replace(/display:\s*flex\s*;\s*align-items:\s*center\s*;\s*justify-content:\s*center\s*;?/gi, 'text-align: center;')
  result = result.replace(/display:\s*flex\s*;\s*align-items:\s*center\s*;/gi, '')

  // 6. Remove transition properties (not supported in email)
  result = result.replace(/transition:\s*[^;"}]+;?/gi, '')

  // 7. Remove gap property (not supported in email)
  result = result.replace(/gap:\s*[^;"}]+;?/gi, '')

  // 8. Clean up any double semicolons or empty style artifacts
  result = result.replace(/;\s*;/g, ';')
  result = result.replace(/style="\s*;/g, 'style="')
  result = result.replace(/;\s*"/g, '"')

  return result
}

// --- Email Wrapper ---
// Localized strings for email wrapper
const EMAIL_WRAPPER_STRINGS = {
  en: {
    teamName: 'The Aphylia Team',
    tagline: 'Helping you grow your plant knowledge ðŸŒ±',
    exploreButton: 'Explore Aphylia â†’',
    aboutLink: 'About',
    contactLink: 'Contact',
    copyright: 'Â© {{year}} Aphylia. Made with ðŸ’š for plant enthusiasts everywhere.',
  },
  fr: {
    teamName: "L'Ã©quipe Aphylia",
    tagline: 'Vous aider Ã  dÃ©velopper vos connaissances botaniques ðŸŒ±',
    exploreButton: 'Explorer Aphylia â†’',
    aboutLink: 'Ã€ propos',
    contactLink: 'Contact',
    copyright: 'Â© {{year}} Aphylia. Fait avec ðŸ’š pour les passionnÃ©s de plantes partout.',
  },
}

/**
 * Wraps email body content with a beautiful styled template
 * Matches the Aphylia website aesthetic with gradients and rounded corners
 * @param {string} bodyHtml - The email body content
 * @param {string} subject - The email subject line
 * @param {string} language - The user's preferred language (defaults to 'en')
 */
function wrapEmailHtml(bodyHtml, subject, language = 'en') {
  const currentYear = new Date().getFullYear()
  const websiteUrl = process.env.WEBSITE_URL || 'https://aphylia.app'

  // Get localized strings for the wrapper (fallback to English if language not found)
  const strings = EMAIL_WRAPPER_STRINGS[language] || EMAIL_WRAPPER_STRINGS['en']
  const copyrightText = strings.copyright.replace('{{year}}', String(currentYear))

  // Aphylia logo URL for emails (using PNG for Gmail compatibility - Gmail doesn't support SVG or WebP)
  const logoUrl = 'https://media.aphylia.app/UTILITY/admin/uploads/png/icon-500_transparent_white.png'
  const logoImg = `<img src="${logoUrl}" alt="Aphylia" width="32" height="32" style="display:block;border:0;outline:none;text-decoration:none;" />`
  const logoImgLarge = `<img src="${logoUrl}" alt="Aphylia" width="40" height="40" style="display:block;border:0;outline:none;text-decoration:none;" />`

  return `<!DOCTYPE html>
<html lang="${language}" xmlns="http://www.w3.org/1999/xhtml" xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="x-apple-disable-message-reformatting">
  <meta name="format-detection" content="telephone=no,address=no,email=no,date=no,url=no">
  <meta name="color-scheme" content="light dark">
  <meta name="supported-color-schemes" content="light dark">
  <title>${subject || 'Aphylia'}</title>
  <link href="https://fonts.googleapis.com/css2?family=Quicksand:wght@600;700&display=swap" rel="stylesheet">
  <!--[if mso]>
  <noscript>
    <xml>
      <o:OfficeDocumentSettings>
        <o:PixelsPerInch>96</o:PixelsPerInch>
      </o:OfficeDocumentSettings>
    </xml>
  </noscript>
  <style>
    table, td, div, p, a { font-family: Arial, sans-serif; }
  </style>
  <![endif]-->
  <style>
    /* Reset */
    body, table, td, p, a, li, blockquote { -webkit-text-size-adjust: 100%; -ms-text-size-adjust: 100%; }
    table, td { mso-table-lspace: 0pt; mso-table-rspace: 0pt; }
    img { -ms-interpolation-mode: bicubic; border: 0; height: auto; line-height: 100%; outline: none; text-decoration: none; max-width: 100%; }
    
    /* Base */
    body { margin: 0 !important; padding: 0 !important; width: 100% !important; background: linear-gradient(180deg, #ecfdf5 0%, #ffffff 30%, #ffffff 70%, #fef3c7 100%); min-height: 100vh; }
    
    /* Typography */
    h1 { font-size: 32px; font-weight: 700; color: #111827; margin: 0 0 20px 0; line-height: 1.2; letter-spacing: -0.5px; }
    h2 { font-size: 26px; font-weight: 700; color: #1f2937; margin: 32px 0 16px 0; line-height: 1.3; }
    h3 { font-size: 22px; font-weight: 600; color: #374151; margin: 28px 0 12px 0; line-height: 1.4; }
    h4 { font-size: 18px; font-weight: 600; color: #4b5563; margin: 24px 0 10px 0; }
    p { margin: 0 0 16px 0; line-height: 1.75; color: #374151; }
    
    /* Links */
    a { color: #059669; text-decoration: underline; text-underline-offset: 2px; font-weight: 500; }
    a:hover { color: #047857; }
    
    /* Code */
    code { background: #f3f4f6; color: #dc2626; padding: 3px 8px; border-radius: 6px; font-family: 'SF Mono', Monaco, monospace; font-size: 0.9em; }
    pre { background: linear-gradient(135deg, #1f2937 0%, #111827 100%); color: #e5e7eb; padding: 20px 24px; border-radius: 16px; overflow-x: auto; font-family: 'SF Mono', Monaco, monospace; font-size: 14px; line-height: 1.6; margin: 20px 0; }
    pre code { background: transparent; color: #e5e7eb; padding: 0; border-radius: 0; }
    
    /* Highlight */
    mark { background: linear-gradient(135deg, #fef08a 0%, #fde047 100%); color: #713f12; padding: 2px 6px; border-radius: 4px; }
    
    /* Blockquote */
    blockquote { border-left: 4px solid #10b981; background: rgba(16, 185, 129, 0.08); margin: 20px 0; padding: 16px 24px; border-radius: 0 12px 12px 0; font-style: italic; color: #374151; }
    
    /* Lists */
    ul, ol { margin: 16px 0; padding-left: 28px; }
    li { margin: 8px 0; color: #374151; }
    
    /* Horizontal Rule */
    hr { border: none; height: 2px; background: linear-gradient(90deg, transparent 0%, #10b981 50%, transparent 100%); margin: 32px 0; }
    
    /* Strong/Bold */
    strong, b { font-weight: 600; color: #111827; }
    
    /* Dark mode */
    @media (prefers-color-scheme: dark) {
      body { background: linear-gradient(180deg, #0b1220 0%, #0a0f1a 30%, #0a0f1a 70%, #0f0f0f 100%) !important; }
      .email-wrapper { background: linear-gradient(180deg, #0b1220 0%, #0a0f1a 30%, #0a0f1a 70%, #0f0f0f 100%) !important; }
      .email-container { background: linear-gradient(135deg, rgba(16, 185, 129, 0.06) 0%, rgba(24, 24, 27, 0.98) 50%, rgba(251, 191, 36, 0.03) 100%) !important; border-color: rgba(63, 63, 70, 0.5) !important; }
      .email-body { color: #f4f4f5 !important; }
      .email-body p, .email-body li, .email-body span, .email-body td { color: #e4e4e7 !important; }
      .email-body h1, .email-body h2, .email-body h3, .email-body h4 { color: #ffffff !important; }
      .email-body a { color: #34d399 !important; }
      .email-body code { background: #374151 !important; color: #fca5a5 !important; }
      .email-body mark { background: #854d0e !important; color: #fef08a !important; }
      .signature-section { background: rgba(16, 185, 129, 0.08) !important; border-color: rgba(16, 185, 129, 0.15) !important; }
      .footer-section { border-color: rgba(63, 63, 70, 0.3) !important; }
      .footer-section p { color: #71717a !important; }
    }
    
    /* Responsive */
    @media screen and (max-width: 640px) {
      .email-container { width: 100% !important; margin: 0 !important; border-radius: 0 !important; border-left: none !important; border-right: none !important; }
      .email-body { padding: 32px 24px !important; }
      .signature-section { margin: 24px !important; padding: 24px !important; }
      .footer-section { padding: 24px !important; }
      h1 { font-size: 26px !important; }
      h2 { font-size: 22px !important; }
    }
  </style>
</head>
<body style="margin:0;padding:0;background:linear-gradient(180deg, #ecfdf5 0%, #ffffff 30%, #ffffff 70%, #fef3c7 100%);font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,'Helvetica Neue',Arial,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;">
  <table role="presentation" class="email-wrapper" width="100%" cellpadding="0" cellspacing="0" style="background:linear-gradient(180deg, #ecfdf5 0%, #ffffff 30%, #ffffff 70%, #fef3c7 100%);margin:0;padding:0;min-height:100vh;">
    <tr>
      <td align="center" style="padding:48px 20px;">
        <table role="presentation" class="email-container" width="640" cellpadding="0" cellspacing="0" style="max-width:640px;width:100%;background:linear-gradient(135deg, rgba(16, 185, 129, 0.04) 0%, rgba(255, 255, 255, 0.99) 50%, rgba(251, 191, 36, 0.03) 100%);border-radius:32px;border:1px solid rgba(16, 185, 129, 0.12);box-shadow:0 32px 64px -16px rgba(16, 185, 129, 0.18), 0 0 0 1px rgba(255, 255, 255, 0.8) inset;overflow:hidden;">
          <tr>
            <td class="email-header" style="background:linear-gradient(135deg, #059669 0%, #10b981 50%, #34d399 100%);padding:32px 48px;text-align:center;">
              <table role="presentation" width="100%" cellpadding="0" cellspacing="0">
                <tr>
                  <td align="center">
                    <div style="display:inline-block;background:rgba(255,255,255,0.15);border-radius:20px;padding:14px 28px;">
                      <table role="presentation" cellpadding="0" cellspacing="0">
                        <tr>
                          <td style="vertical-align:middle;padding-right:12px;">
                            ${logoImg}
                          </td>
                          <td style="vertical-align:middle;">
                            <span style="font-size:26px;font-weight:700;color:#ffffff;letter-spacing:-0.5px;font-family:'Quicksand',-apple-system,BlinkMacSystemFont,sans-serif;">Aphylia</span>
                          </td>
                        </tr>
                      </table>
                    </div>
                  </td>
                </tr>
              </table>
            </td>
          </tr>
          <tr>
            <td class="email-body" style="padding:48px 48px 32px 48px;color:#374151;font-size:16px;line-height:1.75;">
              ${bodyHtml}
            </td>
          </tr>
          <tr>
            <td style="padding:0 48px 48px 48px;">
              <table role="presentation" class="signature-section" width="100%" cellpadding="0" cellspacing="0" style="background-color:#f0fdf4;border-radius:20px;border:1px solid rgba(16, 185, 129, 0.1);overflow:hidden;">
                <tr>
                  <td style="padding:28px 32px;">
                    <table role="presentation" width="100%" cellpadding="0" cellspacing="0">
                      <tr>
                        <td width="72" style="vertical-align:middle;padding-right:20px;">
                          <!-- Logo in green square - using table for centering -->
                          <table role="presentation" cellpadding="0" cellspacing="0" border="0" style="background-color:#10b981;border-radius:16px;width:56px;height:56px;">
                            <tr>
                              <td align="center" valign="middle" style="width:56px;height:56px;">
                                ${logoImgLarge}
                              </td>
                            </tr>
                          </table>
                        </td>
                        <td style="vertical-align:middle;">
                          <p style="margin:0 0 4px 0;font-size:18px;font-weight:700;color:#111827;letter-spacing:-0.3px;">
                            ${strings.teamName}
                          </p>
                          <p style="margin:0;font-size:14px;color:#6b7280;">
                            ${strings.tagline}
                          </p>
                        </td>
                      </tr>
                    </table>
                  </td>
                </tr>
              </table>
            </td>
          </tr>
          <tr>
            <td class="footer-section" style="padding:32px 48px;text-align:center;border-top:1px solid rgba(16, 185, 129, 0.08);">
              <table role="presentation" width="100%" cellpadding="0" cellspacing="0">
                <tr>
                  <td align="center">
                    <table role="presentation" cellpadding="0" cellspacing="0" style="margin:0 auto 24px auto;">
                      <tr>
                        <td>
                          <a href="${websiteUrl}" style="display:inline-block;background:linear-gradient(135deg, #059669 0%, #10b981 100%);color:#ffffff;font-weight:600;font-size:14px;padding:12px 28px;border-radius:50px;text-decoration:none;box-shadow:0 8px 24px -6px rgba(16, 185, 129, 0.4);">
                            ${strings.exploreButton}
                          </a>
                        </td>
                      </tr>
                    </table>
                    <p style="margin:0 0 12px 0;font-size:13px;color:#9ca3af;">
                      <a href="${websiteUrl}" style="color:#059669;text-decoration:none;font-weight:500;">aphylia.app</a>
                      <span style="color:#d1d5db;margin:0 8px;">â€¢</span>
                      <a href="${websiteUrl}/about" style="color:#9ca3af;text-decoration:none;">${strings.aboutLink}</a>
                      <span style="color:#d1d5db;margin:0 8px;">â€¢</span>
                      <a href="${websiteUrl}/contact" style="color:#9ca3af;text-decoration:none;">${strings.contactLink}</a>
                    </p>
                    <p style="margin:0;font-size:12px;color:#d1d5db;">
                      ${copyrightText}
                    </p>
                  </td>
                </tr>
              </table>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>
</html>`
}

// --- Scheduled Tasks ---
// Local campaign runner - DISABLED to prevent duplicate sends
// The Edge Function (email-campaign-runner) is the primary runner, invoked via:
// 1. Manual "Send" button click â†’ /api/admin/email-campaigns/:id/run
// 2. Supabase cron job (invoke-email-campaign-runner)
// Keeping this code for reference but disabled to avoid double-sending emails.
// cron.schedule('* * * * *', async () => {
//   if (!sql) return
//   try {
//     await processEmailCampaigns()
//   } catch (err) {
//     console.error('[campaign-runner] Error:', err)
//   }
// })

/**
 * Fetches email template translations for multi-language support
 * @param {string} templateId - The template ID to fetch translations for
 * @returns {Promise<Map<string, {subject: string, bodyHtml: string}>>} Map of language code to translation content
 */
async function fetchEmailTemplateTranslations(templateId) {
  const translations = new Map()
  if (!templateId || !sql) return translations

  try {
    const data = await sql`
      select language, subject, body_html
      from public.admin_email_template_translations
      where template_id = ${templateId}
    `

    for (const row of data || []) {
      if (row?.language) {
        translations.set(row.language, {
          subject: row.subject,
          bodyHtml: row.body_html,
        })
      }
    }
  } catch (err) {
    console.warn('[campaign-runner] failed to load email translations:', err?.message || err)
  }

  return translations
}

async function processEmailCampaigns() {
  const apiKey = process.env.RESEND_API_KEY || process.env.VITE_RESEND_API_KEY
  if (!apiKey) return

  // 0. Auto-migrate tracking table if missing
  try {
    await sql`
       create table if not exists public.admin_campaign_sends (
         id uuid primary key default gen_random_uuid(),
         campaign_id uuid references public.admin_email_campaigns(id) on delete cascade,
         user_id uuid references auth.users(id) on delete cascade,
         sent_at timestamptz default now(),
         status text default 'sent',
         error text
       );
       create index if not exists idx_admin_campaign_sends_campaign_user 
         on public.admin_campaign_sends(campaign_id, user_id);
     `
  } catch (e) { /* ignore */ }

  // 1. Fetch active campaigns (scheduled OR running)
  // We don't lock a single row anymore; we process all valid campaigns in parallel (or sequentially)
  // We check for campaigns that are scheduled in the past OR running within last 48h
  const campaigns = await sql`
    update public.admin_email_campaigns
    set status = 'running', send_started_at = coalesce(send_started_at, now()), send_error = null
    where id in (
      select id from public.admin_email_campaigns
      where (status = 'scheduled' and scheduled_for <= now())
         or (status = 'running' and created_at > now() - interval '3 days')
    )
    returning *
  `

  if (!campaigns || campaigns.length === 0) return

  for (const campaign of campaigns) {
    // console.log('[campaign-runner] Processing:', campaign.title, campaign.id)
    try {
      // Check if this is a test mode campaign
      const isTestMode = campaign.test_mode === true
      const testEmail = campaign.test_email

      // Fetch email template translations for multi-language support
      const emailTranslations = await fetchEmailTemplateTranslations(campaign.template_id)

      // 2. Fetch recipients who have NOT received this campaign yet
      // For test mode, we create a fake recipient with the test email
      let recipients
      if (isTestMode && testEmail) {
        // In test mode, send only to the test email address
        console.log('[campaign-runner] Test mode - sending to:', testEmail)
        recipients = [{
          id: null, // No real user ID for test
          email: testEmail,
          display_name: 'Test User',
          user_timezone: campaign.timezone || 'UTC',
          user_language: 'en'
        }]
      } else {
        // Normal mode: fetch all users who haven't received this campaign
        recipients = await sql`
          select
            au.id,
            au.email,
            coalesce(p.display_name, au.raw_user_meta_data->>'full_name', split_part(au.email, '@', 1)) as display_name,
            coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}) as user_timezone,
            coalesce(p.language, 'en') as user_language
          from auth.users au
          left join public.profiles p on p.id = au.id
          where (au.email_confirmed_at is not null or au.confirmed_at is not null)
          and coalesce(p.notify_email, true) = true
          and not exists (
            select 1 from public.admin_campaign_sends s 
            where s.campaign_id = ${campaign.id} and s.user_id = au.id
          )
          limit 2000
        `
      }

      if (!recipients || recipients.length === 0) {
        // No pending recipients for this campaign. 
        // If it's old enough (e.g. > 30h past schedule), mark as sent? 
        // For now, just leave it running to catch stragglers or manual stop.
        // Optionally verify if we are effectively "done"
        const totalUsers = await sql`select count(*) as count from auth.users where email_confirmed_at is not null`
        const sentCount = await sql`select count(*) as count from public.admin_campaign_sends where campaign_id = ${campaign.id}`
        if (Number(totalUsers[0].count) <= Number(sentCount[0].count)) {
          await sql`update public.admin_email_campaigns set status = 'sent', send_completed_at = now() where id = ${campaign.id}`
        }
        continue
      }

      // 3. Filter by Timezone
      const campaignTz = campaign.timezone || 'UTC'
      const scheduledFor = new Date(campaign.scheduled_for) // This is UTC

      const dueRecipients = recipients.filter(r => {
        // Calculate when the campaign is due for THIS user
        // Formula: Target_Time = Scheduled_UTC - (User_Offset - Camp_Offset)
        // But since we don't have easy offset lookups in JS without a library like date-fns-tz or similar,
        // we rely on Postgres or an approximation. 
        // Alternatively, we can check if the *current local hour* matches.

        // Approximation using Intl (available in Node 18+)
        try {
          // Get "Wall Clock" time of the scheduled event in Campaign TZ
          const schedInCampTzStr = scheduledFor.toLocaleString('en-US', { timeZone: campaignTz })
          const schedInCampTz = new Date(schedInCampTzStr)

          // Get "Wall Clock" time of NOW in User TZ
          const nowInUserTzStr = new Date().toLocaleString('en-US', { timeZone: r.user_timezone })
          const nowInUserTz = new Date(nowInUserTzStr)

          // Compare: Has User's Wall Clock passed the Scheduled Wall Clock?
          // We normalize both to a generic date object to compare times/dates relative to "local"
          // Actually, to handle dates correctly:
          // If Sched is "Oct 25 9:00 AM" (Camp TZ), we want to know if "Oct 25 9:00 AM" has passed in User TZ.
          // So we just compare the ISO strings or millis of these "floating" times?
          // No, `new Date(string)` creates a date in local system time.

          // Let's compare the *absolute* epoch time if we treat them as same TZ.
          // This works because if 9AM passed in JST, it's "later" in absolute terms than 8AM JST.
          return nowInUserTz >= schedInCampTz
        } catch (e) {
          // Fallback: if invalid TZ, assume due
          return true
        }
      })

      if (dueRecipients.length === 0) continue

      // 4. Send Batches
      const batchSize = 40
      const fromEmail = process.env.EMAIL_CAMPAIGN_FROM || process.env.RESEND_FROM || 'Aphylia <info@aphylia.app>'
      let batchSentCount = 0

      for (let i = 0; i < dueRecipients.length; i += batchSize) {
        const batch = dueRecipients.slice(i, i + batchSize)
        const payload = batch.map(r => {
          const userRaw = r.display_name || 'User'
          const userCap = userRaw.charAt(0).toUpperCase() + userRaw.slice(1).toLowerCase()
          const userLang = r.user_language || 'en'

          // Generate random 10-character string (uppercase, lowercase, numbers)
          const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'
          let randomStr = ''
          for (let i = 0; i < 10; i++) {
            randomStr += chars.charAt(Math.floor(Math.random() * chars.length))
          }

          const websiteUrl = process.env.WEBSITE_URL || 'https://aphylia.app'

          // Variables available for replacement in email templates
          const context = {
            user: userCap,                           // User's display name (capitalized)
            email: r.email,                          // User's email address
            random: randomStr,                       // 10 random characters (unique per email)
            url: websiteUrl.replace(/^https?:\/\//, ''), // Website URL without protocol (e.g., "aphylia.app")
            code: 'XXXXXX'                           // Placeholder for campaign emails (real codes are for transactional emails)
          }
          // Get user's language-specific content (fallback to campaign's default content)
          const translation = emailTranslations.get(userLang)
          const rawSubject = translation?.subject || campaign.subject
          const rawBodyHtml = translation?.bodyHtml || campaign.body_html

          // Escape HTML characters in values injected into the body to prevent XSS
          const bodyHtmlRaw = replaceTemplateVariables(rawBodyHtml, context, true)
          // Do not escape values in subject (email clients handle text subjects)
          const subject = replaceTemplateVariables(rawSubject, context, false)
          // Sanitize the body HTML to fix email-incompatible CSS (gradients, flexbox, shadows, etc.)
          const bodyHtml = sanitizeHtmlForEmail(bodyHtmlRaw)
          // Wrap the body HTML with our beautiful styled email template (with localized wrapper)
          const html = wrapEmailHtml(bodyHtml, subject, userLang)
          const text = bodyHtml.replace(/<[^>]+>/g, '').replace(/\s+/g, ' ').trim()

          return {
            from: fromEmail,
            to: r.email,
            subject: subject,
            html: html,
            text: text,
            headers: { 'X-Campaign-Id': campaign.id },
            tags: [{ name: 'campaign_id', value: campaign.id }]
          }
        })

        // Send via Resend
        const res = await fetch('https://api.resend.com/emails/batch', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(payload)
        })

        if (res.ok) {
          batchSentCount += batch.length
          // Record success in tracking table (only for non-test mode with real user IDs)
          if (!isTestMode) {
            const values = batch.map(u => ({
              campaign_id: campaign.id,
              user_id: u.id,
              status: 'sent'
            }))
            await sql`insert into public.admin_campaign_sends ${sql(values, 'campaign_id', 'user_id', 'status')}`
          }
        } else {
          console.error('[campaign-runner] Batch failed:', await res.text())
        }
      }

      // Update total stats
      if (isTestMode) {
        // For test mode, mark as sent immediately
        await sql`
          update public.admin_email_campaigns
          set sent_count = 1,
              total_recipients = 1,
              status = 'sent',
              send_completed_at = now()
          where id = ${campaign.id}
        `
        console.log('[campaign-runner] Test campaign completed:', campaign.id)
      } else {
        await sql`
          update public.admin_email_campaigns
          set sent_count = (select count(*) from public.admin_campaign_sends where campaign_id = ${campaign.id}),
              total_recipients = (select count(*) from auth.users where email_confirmed_at is not null)
          where id = ${campaign.id}
        `
      }

    } catch (err) {
      console.error('[campaign-runner] Exception for campaign ' + campaign.id, err)
    }
  }
}

// Resolve the real Git repository root, even when running under a symlinked
// deployment directory like /var/www/PlantSwipe/plant-swipe.
async function getRepoRoot() {
  // 1) Allow explicit override via env when it actually points at a repo
  try {
    const override = (process.env.PLANTSWIPE_REPO_DIR || '').trim()
    if (override) {
      try {
        const st = await fs.stat(override)
        if (st && st.isDirectory()) {
          const topFromGit = await getTopLevelIfRepo(override)
          if (topFromGit) return topFromGit
          try { await fs.access(path.join(override, '.git')); return override } catch { }
        }
      } catch { }
    }
  } catch { }

  // 2) Prefer the real path of the current directory (handles symlinks)
  let realDir = __dirname
  try { realDir = await fs.realpath(__dirname) } catch { }

  // 3) Try to ask git for the top-level using a safe.directory override
  const topFromGitHere = await getTopLevelIfRepo(realDir)
  if (topFromGitHere) return topFromGitHere

  // 4) Ascend a couple of levels and try common candidates
  const candidates = [
    realDir,
    path.resolve(realDir, '..'),
    path.resolve(realDir, '../..'),
  ]
  for (const dir of candidates) {
    const top = await getTopLevelIfRepo(dir)
    if (top) return top
    try {
      // Also accept git worktree layout where .git is a file
      await fs.access(path.join(dir, '.git'))
      return dir
    } catch { }
  }

  // 5) Fallback: return the real directory (better than an incorrect parent)
  return realDir
}

// Helper: return top-level path if "dir" is a git repo, otherwise null.
async function getTopLevelIfRepo(dir) {
  try {
    const { stdout } = await exec(`git -c "safe.directory=${dir}" -C "${dir}" rev-parse --show-toplevel`)
    const root = (stdout || '').toString().trim()
    return root || null
  } catch {
    return null
  }
}

const exec = promisify(execCb)

function parseEmailTargets(raw, fallback) {
  const source = (typeof raw === 'string' && raw.trim().length > 0) ? raw : (fallback || '')
  if (!source) return []
  return source
    .split(',')
    .map((value) => value.trim())
    .filter(Boolean)
}

const DEFAULT_SUPPORT_EMAIL = 'support@aphylia.app'
const DEFAULT_BUSINESS_EMAIL = 'contact@aphylia.app'

// Utility: wrap a promise with a timeout that rejects when exceeded
function withTimeout(promise, ms, label = 'TIMEOUT') {
  return new Promise((resolve, reject) => {
    const t = setTimeout(() => reject(new Error(label)), Math.max(1, ms || 0))
    Promise.resolve(promise)
      .then((v) => { try { clearTimeout(t) } catch { }; resolve(v) })
      .catch((e) => { try { clearTimeout(t) } catch { }; reject(e) })
  })
}

// Supabase client (server-side) for auth verification
// Support both runtime server env and Vite-style public envs
const supabaseUrlEnv = process.env.SUPABASE_URL || process.env.VITE_SUPABASE_URL || process.env.REACT_APP_SUPABASE_URL || process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseAnonKey = process.env.SUPABASE_ANON_KEY || process.env.VITE_SUPABASE_ANON_KEY || process.env.REACT_APP_SUPABASE_ANON_KEY || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY
const supabaseServer = (supabaseUrlEnv && supabaseAnonKey)
  ? createSupabaseClient(supabaseUrlEnv, supabaseAnonKey, { auth: { persistSession: false, autoRefreshToken: false } })
  : null
const supabaseServiceKey =
  process.env.SUPABASE_SERVICE_ROLE_KEY
  || process.env.SUPABASE_SERVICE_KEY
  || process.env.SUPABASE_SERVICE_ROLE
  || process.env.SUPABASE_SERVICE_ROLE_TOKEN
  || ''
const supabaseServiceClient = (supabaseUrlEnv && supabaseServiceKey)
  ? createSupabaseClient(supabaseUrlEnv, supabaseServiceKey, { auth: { persistSession: false, autoRefreshToken: false } })
  : null

const openaiApiKey = process.env.OPENAI_KEY || process.env.OPENAI_API_KEY || ''
const openaiModel = process.env.OPENAI_MODEL || 'gpt-5.2-2025-12-11'
const openaiModelNano = process.env.OPENAI_MODEL_NANO || 'gpt-5-nano'
let openaiClient = null
let openai = null // Alias for garden advice endpoints
if (openaiApiKey) {
  try {
    openaiClient = new OpenAI({ apiKey: openaiApiKey })
    openai = openaiClient // Use same client for garden advice
  } catch (err) {
    console.error('[server] Failed to initialize OpenAI client:', err)
    openaiClient = null
    openai = null
  }
} else {
  console.warn('[server] OPENAI_KEY not configured â€” AI plant fill endpoint disabled')
}

// Some deployments might lag behind on the latest schema additions for the
// garden_ai_advice table. Track whether advanced context columns (weather,
// journal, avg_completion_time, etc.) are available so queries can gracefully
// fall back instead of failing with "column ... does not exist".
let gardenAdviceContextColumnsSupported = true
function isMissingColumnError(err) {
  const msg = String(err?.message || '').toLowerCase()
  return msg.includes('column') && msg.includes('does not exist')
}
function disableGardenAdviceContextColumns(stage, err) {
  if (!gardenAdviceContextColumnsSupported) return
  gardenAdviceContextColumnsSupported = false
  const label = stage ? ` (${stage})` : ''
  console.warn(`[garden-advice] Context columns unavailable${label}:`, err?.message || err)
}

const supportEmailTargets = parseEmailTargets(process.env.SUPPORT_EMAIL_TO || process.env.SUPPORT_EMAIL, DEFAULT_SUPPORT_EMAIL)
const supportEmailFrom =
  process.env.SUPPORT_EMAIL_FROM
  || process.env.RESEND_FROM
  || (supportEmailTargets[0] ? `Aphylia <${supportEmailTargets[0]}>` : `Aphylia <${DEFAULT_SUPPORT_EMAIL}>`)
const businessEmailTargets = parseEmailTargets(
  process.env.BUSINESS_EMAIL_TO || process.env.BUSINESS_EMAIL || process.env.CONTACT_EMAIL_TO,
  DEFAULT_BUSINESS_EMAIL,
)
const businessEmailFrom =
  process.env.BUSINESS_EMAIL_FROM
  || process.env.RESEND_BUSINESS_FROM
  || (businessEmailTargets[0] ? `Aphylia Partnerships <${businessEmailTargets[0]}>` : supportEmailFrom)
const resendApiKey = process.env.RESEND_API_KEY || process.env.RESEND_KEY || ''
const supportEmailWebhook = process.env.SUPPORT_EMAIL_WEBHOOK_URL || process.env.CONTACT_WEBHOOK_URL || ''
const contactRateLimitStore = new Map()

// =============================================================================
// RATE LIMITING SYSTEM
// Generic rate limiter for various endpoints to prevent abuse
// All rate limits are invisible to users - requests are silently rejected
// =============================================================================

/**
 * Rate limit store for different action types
 * Each store maps identifiers (user ID or IP) to arrays of timestamps
 */
const rateLimitStores = {
  scan: new Map(),           // Plant identification scans
  aiChat: new Map(),         // AI garden chat
  translate: new Map(),      // Translation API
  imageUpload: new Map(),    // Image uploads (messages, gardens, etc.)
  bugReport: new Map(),      // Bug report submissions
  emailVerifySend: new Map(),   // Email verification code sending
  emailVerifyAttempt: new Map(), // Email verification code attempts (brute force protection)
  gardenActivity: new Map(), // Garden activity logging
  gardenJournal: new Map(),  // Journal entries
  pushNotify: new Map(),     // Push notification sending
  authAttempt: new Map(),    // Authentication attempts (brute force protection)
  forgotPassword: new Map(), // Forgot password requests (prevent magic link spam)
}

/**
 * Rate limit configurations for different actions
 * windowMs: Time window in milliseconds
 * maxAttempts: Maximum attempts allowed in the window
 * perUser: If true, limit per user ID; if false, limit per IP
 */
const rateLimitConfig = {
  // Scan: 60 scans per hour per user (AI/API costs - 1 per minute average)
  scan: {
    windowMs: 60 * 60 * 1000,  // 1 hour
    maxAttempts: 60,
    perUser: true,
  },
  // AI Chat: 120 messages per hour per user (OpenAI costs - 2 per minute average)
  aiChat: {
    windowMs: 60 * 60 * 1000,  // 1 hour
    maxAttempts: 120,
    perUser: true,
  },
  // Translation: 500 requests per hour per user (DeepL costs - generous for active translators)
  // Admin users bypass all rate limits entirely (checked in checkRateLimit)
  translate: {
    windowMs: 60 * 60 * 1000,  // 1 hour
    maxAttempts: 500,
    perUser: true,
  },
  // Image uploads: 100 per hour per user (storage costs)
  imageUpload: {
    windowMs: 60 * 60 * 1000,  // 1 hour
    maxAttempts: 100,
    perUser: true,
  },
  // Bug reports: 20 per hour per IP (spam prevention)
  bugReport: {
    windowMs: 60 * 60 * 1000,  // 1 hour
    maxAttempts: 20,
    perUser: false,
  },
  // Garden activity: 300 per hour per user (5 per minute for active gardeners)
  gardenActivity: {
    windowMs: 60 * 60 * 1000,  // 1 hour
    maxAttempts: 300,
    perUser: true,
  },
  // Journal entries: 50 per hour per user (generous for journaling)
  gardenJournal: {
    windowMs: 60 * 60 * 1000,  // 1 hour
    maxAttempts: 50,
    perUser: true,
  },
  // Push notifications: 300 per hour per user (for active social users)
  pushNotify: {
    windowMs: 60 * 60 * 1000,  // 1 hour
    maxAttempts: 300,
    perUser: true,
  },
  // Authentication attempts: 10 per 15 minutes per IP (brute force protection)
  // After 10 failed attempts, IP is blocked for 15 minutes
  authAttempt: {
    windowMs: 15 * 60 * 1000,  // 15 minutes
    maxAttempts: 10,
    perUser: false,  // Per IP to catch credential stuffing
  },
  // Email verification code sending: 5 per 15 minutes per user (prevent email spam)
  emailVerifySend: {
    windowMs: 15 * 60 * 1000,  // 15 minutes
    maxAttempts: 5,
    perUser: true,
  },
  // Email verification attempts: 10 per 15 minutes per user (brute force protection)
  // With 6-char code (32^6 = 1B combinations), 10 attempts is negligible
  emailVerifyAttempt: {
    windowMs: 15 * 60 * 1000,  // 15 minutes
    maxAttempts: 10,
    perUser: true,
  },
  // Forgot password: 5 per 15 minutes per IP (prevent magic link spam)
  forgotPassword: {
    windowMs: 15 * 60 * 1000,  // 15 minutes
    maxAttempts: 5,
    perUser: false,
  },
}

/**
 * Check if an action is rate limited
 * @param {string} action - The action type (scan, aiChat, translate, etc.)
 * @param {string} identifier - User ID or IP address
 * @returns {boolean} - True if rate limited, false if allowed
 */
function isRateLimited(action, identifier) {
  const store = rateLimitStores[action]
  const config = rateLimitConfig[action]
  
  if (!store || !config) {
    console.warn(`[rate-limit] Unknown action type: ${action}`)
    return false
  }
  
  const now = Date.now()
  const { windowMs, maxAttempts } = config
  const history = store.get(identifier) || []
  
  // Filter to only keep timestamps within the window
  const recent = history.filter((ts) => now - ts < windowMs)
  
  if (recent.length >= maxAttempts) {
    store.set(identifier, recent)
    return true
  }
  
  // Add current timestamp and update store
  recent.push(now)
  store.set(identifier, recent)
  return false
}

/**
 * Get rate limit identifier based on action config
 * @param {string} action - The action type
 * @param {object} req - Express request object
 * @param {object|null} user - User object (if authenticated)
 * @returns {string} - Identifier to use for rate limiting
 */
function getRateLimitIdentifier(action, req, user) {
  const config = rateLimitConfig[action]
  if (!config) return getClientIp(req) || 'unknown'
  
  if (config.perUser && user?.id) {
    return `user:${user.id}`
  }
  return `ip:${getClientIp(req) || 'unknown'}`
}

/**
 * Short-lived admin status cache to avoid DB queries on every rate-limit check.
 * Maps userId -> { isAdmin: boolean, expiresAt: number }
 * Entries expire after 60 seconds.
 */
const adminStatusCache = new Map()
const ADMIN_CACHE_TTL_MS = 60_000 // 1 minute

/**
 * Check if a user is an admin (with caching to avoid repeated DB lookups).
 * Returns false if user is null or has no id.
 */
async function isAdminUser(user) {
  if (!user?.id) return false
  
  const cached = adminStatusCache.get(user.id)
  if (cached && Date.now() < cached.expiresAt) {
    return cached.isAdmin
  }
  
  const isAdmin = await isAdminUserId(user.id)
  adminStatusCache.set(user.id, { isAdmin, expiresAt: Date.now() + ADMIN_CACHE_TTL_MS })
  return isAdmin
}

// Clean up expired admin cache entries every 5 minutes
setInterval(() => {
  const now = Date.now()
  for (const [key, entry] of adminStatusCache.entries()) {
    if (now >= entry.expiresAt) adminStatusCache.delete(key)
  }
}, 5 * 60 * 1000)

/**
 * Check rate limit and return 429 if exceeded
 * Returns true if request should be blocked, false if allowed
 * Admin users bypass all rate limits.
 * @param {string} action - The action type
 * @param {object} req - Express request object
 * @param {object} res - Express response object
 * @param {object|null} user - User object (if authenticated)
 * @returns {Promise<boolean>} - True if blocked (429 sent), false if allowed
 */
async function checkRateLimit(action, req, res, user = null) {
  // Admin users are exempt from all rate limits
  if (await isAdminUser(user)) return false
  
  const identifier = getRateLimitIdentifier(action, req, user)
  
  if (isRateLimited(action, identifier)) {
    console.log(`[rate-limit] ${action} rate limit exceeded for ${identifier}`)
    res.status(429).json({ error: 'Too many requests. Please try again later.' })
    return true
  }
  return false
}

/**
 * Check rate limit AND record the attempt
 * Returns true if request should be blocked, false if allowed
 * Unlike checkRateLimit, this also records the current request for future checks
 * Admin users bypass all rate limits.
 * @param {object} req - Express request object
 * @param {object} res - Express response object
 * @param {string} action - The action type
 * @param {object|null} user - User object (if authenticated)
 * @returns {Promise<boolean>} - True if blocked (429 sent), false if allowed
 */
async function checkAndRecordRateLimit(req, res, action, user = null) {
  // Admin users are exempt from all rate limits
  if (await isAdminUser(user)) return false
  
  const store = rateLimitStores[action]
  const config = rateLimitConfig[action]
  
  if (!store || !config) {
    console.warn(`[rate-limit] Unknown action type: ${action}`)
    return false
  }
  
  const identifier = getRateLimitIdentifier(action, req, user)
  const now = Date.now()
  
  // Get existing history and filter to window
  const history = store.get(identifier) || []
  const recent = history.filter((ts) => now - ts < config.windowMs)
  
  // Check if already rate limited
  if (recent.length >= config.maxAttempts) {
    console.log(`[rate-limit] ${action} rate limit exceeded for ${identifier} (${recent.length}/${config.maxAttempts})`)
    res.status(429).json({ error: 'Too many requests. Please try again later.' })
    return true
  }
  
  // Record this attempt
  recent.push(now)
  store.set(identifier, recent)
  
  return false
}

/**
 * Periodically clean up old entries from rate limit stores
 * Runs every 10 minutes to prevent memory bloat
 */
setInterval(() => {
  const now = Date.now()
  let totalCleaned = 0
  
  for (const [action, store] of Object.entries(rateLimitStores)) {
    const config = rateLimitConfig[action]
    if (!config) continue
    
    for (const [key, history] of store.entries()) {
      const recent = history.filter((ts) => now - ts < config.windowMs)
      if (recent.length === 0) {
        store.delete(key)
        totalCleaned++
      } else if (recent.length < history.length) {
        store.set(key, recent)
      }
    }
  }
  
  if (totalCleaned > 0) {
    console.log(`[rate-limit] Cleaned up ${totalCleaned} expired entries`)
  }
}, 10 * 60 * 1000) // Every 10 minutes

// =============================================================================
// END RATE LIMITING SYSTEM
// =============================================================================

const vapidPublicKey =
  process.env.VAPID_PUBLIC_KEY ||
  process.env.WEB_PUSH_PUBLIC_KEY ||
  process.env.VITE_VAPID_PUBLIC_KEY ||
  ''
const vapidPrivateKey =
  process.env.VAPID_PRIVATE_KEY ||
  process.env.WEB_PUSH_PRIVATE_KEY ||
  process.env.VITE_VAPID_PRIVATE_KEY ||
  ''
let pushNotificationsEnabled = false
if (vapidPublicKey && vapidPrivateKey) {
  try {
    webpush.setVapidDetails('mailto:support@aphylia.app', vapidPublicKey, vapidPrivateKey)
    pushNotificationsEnabled = true
    console.log('[notifications] âœ“ VAPID keys configured successfully - push notifications ENABLED')
    console.log('[notifications]   Public key prefix:', vapidPublicKey.slice(0, 20) + '...')
  } catch (err) {
    console.error('[notifications] âœ— Failed to configure VAPID keys:', err)
  }
} else {
  console.warn('[notifications] âœ— VAPID keys not configured â€” push notifications DISABLED')
  if (!vapidPublicKey) console.warn('[notifications]   Missing: VAPID_PUBLIC_KEY')
  if (!vapidPrivateKey) console.warn('[notifications]   Missing: VAPID_PRIVATE_KEY')
}

// Admin bypass configuration
// Support both server-only and Vite-style env variable names
const adminStaticToken = process.env.ADMIN_STATIC_TOKEN || process.env.VITE_ADMIN_STATIC_TOKEN || ''
const adminPublicMode = String(process.env.ADMIN_PUBLIC_MODE || process.env.VITE_ADMIN_PUBLIC_MODE || '').toLowerCase() === 'true'

const adminUploadBucket = 'UTILITY' // Admin uploads go to UTILITY bucket
const adminUploadPrefixRaw = (process.env.ADMIN_UPLOAD_PREFIX || 'admin/uploads').trim()
const adminUploadPrefix = adminUploadPrefixRaw.replace(/^\/+|\/+$/g, '') || 'admin/uploads'
const blogUploadPrefixRaw = (process.env.BLOG_UPLOAD_PREFIX || 'blog').trim()
const blogUploadPrefix = blogUploadPrefixRaw.replace(/^\/+|\/+$/g, '') || 'blog'
const proAdviceUploadPrefixRaw = (process.env.PRO_ADVICE_UPLOAD_PREFIX || 'pro-advice').trim()
const proAdviceUploadPrefix = proAdviceUploadPrefixRaw.replace(/^\/+|\/+$/g, '') || 'pro-advice'
const messagesUploadPrefixRaw = (process.env.MESSAGES_UPLOAD_PREFIX || 'messages').trim()
const messagesUploadPrefix = messagesUploadPrefixRaw.replace(/^\/+|\/+$/g, '') || 'messages'
const mockupsUploadPrefixRaw = (process.env.MOCKUPS_UPLOAD_PREFIX || 'Mockups').trim()
const mockupsUploadPrefix = mockupsUploadPrefixRaw.replace(/^\/+|\/+$/g, '') || 'Mockups'
const adminUploadMaxBytes = (() => {
  const raw = Number(process.env.ADMIN_UPLOAD_MAX_BYTES)
  if (Number.isFinite(raw) && raw > 0) return raw
  return 15 * 1024 * 1024
})()
const adminUploadMaxDimension = (() => {
  const raw = Number(process.env.ADMIN_UPLOAD_MAX_DIMENSION)
  if (Number.isFinite(raw) && raw >= 256 && raw <= 8000) return Math.round(raw)
  return 2000
})()
const adminUploadWebpQuality = 90 // Admin uploads get highest quality (90%)
const adminUploadMulter = multer({
  storage: multer.memoryStorage(),
  limits: { fileSize: adminUploadMaxBytes },
})
const singleAdminImageUpload = adminUploadMulter.single('file')
const adminUploadAllowedMimeTypes = new Set([
  'image/jpeg',
  'image/png',
  'image/webp',
  'image/avif',
  'image/heic',
  'image/heif',
  'image/gif',
  'image/tiff',
  'image/bmp',
  'image/svg+xml',
])

// Media proxy URL configuration
// Transforms Supabase storage URLs to use the nginx reverse proxy
// This prevents exposing the Supabase project URL directly
const mediaProxyBaseUrl = (process.env.MEDIA_PROXY_URL || 'https://media.aphylia.app').replace(/\/+$/, '')

/**
 * Transforms a Supabase storage public URL to use the media proxy
 * Example:
 *   Input:  https://lxnkcguwewrskqnyzjwi.supabase.co/storage/v1/object/public/UTILITY/admin/uploads/svg/file.svg
 *   Output: https://media.aphylia.app/UTILITY/admin/uploads/svg/file.svg
 * 
 * @param {string|null|undefined} url - The Supabase storage public URL
 * @returns {string|null} - The transformed URL using media proxy, or null if input is invalid
 */
function supabaseStorageToMediaProxy(url) {
  if (!url || !supabaseUrlEnv) return url || null
  try {
    const normalizedBase = supabaseUrlEnv.replace(/\/+$/, '')
    const publicPrefix = `${normalizedBase}/storage/v1/object/public/`
    const urlStr = String(url)
    if (!urlStr.startsWith(publicPrefix)) return url
    // Extract the path after /storage/v1/object/public/
    const remainder = urlStr.slice(publicPrefix.length)
    if (!remainder) return url
    // Build the media proxy URL
    return `${mediaProxyBaseUrl}/${remainder}`
  } catch {
    return url
  }
}

const gardenCoverUploadBucket = (() => {
  const fromEnv = (process.env.GARDEN_UPLOAD_BUCKET || '').trim()
  if (fromEnv) return fromEnv
  const preferred = 'PHOTOS'
  if (preferred) return preferred
  return adminUploadBucket
})()
const gardenCoverUploadPrefixRaw = (process.env.GARDEN_UPLOAD_PREFIX || 'gardens/covers').trim()
const gardenCoverUploadPrefix = gardenCoverUploadPrefixRaw.replace(/^\/+|\/+$/g, '') || 'gardens/covers'
const gardenCoverMaxBytes = (() => {
  const raw = Number(process.env.GARDEN_UPLOAD_MAX_BYTES)
  if (Number.isFinite(raw) && raw > 0) return raw
  return adminUploadMaxBytes
})()
const gardenCoverMaxDimension = (() => {
  const raw = Number(process.env.GARDEN_UPLOAD_MAX_DIMENSION)
  if (Number.isFinite(raw) && raw >= 128 && raw <= 4000) return Math.round(raw)
  return 1000
})()
const gardenCoverWebpQuality = 50 // Standard quality for all non-admin uploads (50%)
const gardenCoverMulter = multer({
  storage: multer.memoryStorage(),
  limits: { fileSize: gardenCoverMaxBytes },
})
const singleGardenCoverUpload = gardenCoverMulter.single('file')

// === Messaging Image Upload Settings ===
const messageImageUploadBucket = 'PHOTOS' // All non-admin uploads go to PHOTOS
const messageImageUploadPrefix = 'messages'
const messageImageMaxBytes = 10 * 1024 * 1024 // 10MB
const messageImageMaxDimension = 1200 // Slightly smaller than cover images
const messageImageWebpQuality = 50 // Standard quality for all non-admin uploads (50%)
const messageImageMulter = multer({
  storage: multer.memoryStorage(),
  limits: { fileSize: messageImageMaxBytes },
})
const singleMessageImageUpload = messageImageMulter.single('file')

// === Plant Scan Image Upload Settings ===
const scanImageUploadBucket = 'PHOTOS' // All non-admin uploads go to PHOTOS
const scanImageUploadPrefix = 'scans' // Organize under scans/ folder
const scanImageMaxBytes = 10 * 1024 * 1024 // 10MB
const scanImageMaxDimension = 1920 // Higher resolution for better identification
const scanImageWebpQuality = 50 // Standard quality for all non-admin uploads (50%)
const scanImageMulter = multer({
  storage: multer.memoryStorage(),
  limits: { fileSize: scanImageMaxBytes },
})
const singleScanImageUpload = scanImageMulter.single('file')
// Kindwise API key from environment
const KINDWISE_API_KEY = process.env.KINDWISE || process.env.KINDWISE_API_KEY || ''

// === Bug Screenshot Upload Settings ===
const bugScreenshotUploadBucket = 'PHOTOS' // All non-admin uploads go to PHOTOS
const bugScreenshotUploadPrefix = 'bug-reports' // Organize under bug-reports/ folder
const bugScreenshotMaxBytes = 10 * 1024 * 1024 // 10MB
const bugScreenshotMaxDimension = 1920 // High resolution to capture bug details
const bugScreenshotWebpQuality = 60 // Slightly higher quality to preserve bug details
const bugScreenshotMulter = multer({
  storage: multer.memoryStorage(),
  limits: { fileSize: bugScreenshotMaxBytes },
})
const singleBugScreenshotUpload = bugScreenshotMulter.single('file')

// Mime types that should be optimized and converted to WebP
const optimizableMimeTypes = new Set([
  'image/jpeg',
  'image/png',
  'image/webp',
])

// Standard quality for non-admin uploads
const standardUploadWebpQuality = 50

async function handleScopedImageUpload(req, res, options = {}) {
  const { 
    prefixBuilder, 
    auditLabel = 'admin', 
    actorId = null, 
    uploaderInfo = null,
    // Allow overriding bucket, quality, and dimension per endpoint
    bucket = adminUploadBucket,
    webpQuality = adminUploadWebpQuality,
    maxDimension = adminUploadMaxDimension,
    // Additional metadata to merge with the default metadata (e.g., tag, device)
    extraMetadataBuilder = null,
  } = options

  singleAdminImageUpload(req, res, (err) => {
    if (err) {
      const message =
        err?.code === 'LIMIT_FILE_SIZE'
          ? `File exceeds the maximum size of ${(adminUploadMaxBytes / (1024 * 1024)).toFixed(1)} MB`
          : err?.message || 'Failed to process upload'
      res.status(400).json({ error: message })
      return
    }
    ; (async () => {
      const file = req.file
      if (!file) {
        res.status(400).json({ error: 'Missing image file (expected form field "file")' })
        return
      }
      const mime = (file.mimetype || '').toLowerCase()
      if (!mime.startsWith('image/')) {
        res.status(400).json({ error: 'Only image uploads are supported' })
        return
      }
      if (!adminUploadAllowedMimeTypes.has(mime)) {
        res.status(400).json({ error: `Unsupported image type: ${mime}` })
        return
      }
      if (!file.buffer || file.buffer.length === 0) {
        res.status(400).json({ error: 'Uploaded file is empty' })
        return
      }

      const baseName = sanitizeUploadBaseName(file.originalname)
      const originalTypeSegment = deriveUploadTypeSegment(file.originalname, mime)
      const scopedPrefix =
        typeof prefixBuilder === 'function'
          ? prefixBuilder({ req, file })
          : adminUploadPrefix

      // Check if optimization is requested (defaults to true if not specified)
      const optimizeParam = req.body?.optimize
      const userWantsOptimization = optimizeParam !== 'false'
      
      // Determine if file should be optimized (only JPEG, PNG, WebP when user wants optimization)
      const shouldOptimize = userWantsOptimization && optimizableMimeTypes.has(mime)

      let finalBuffer
      let finalMimeType
      let finalTypeSegment
      let finalExtension = 'webp' // Default to webp for optimized files
      let compressionPercent = 0
      let quality = null

      if (shouldOptimize) {
        // Optimize and convert to WebP
        try {
          finalBuffer = await sharp(file.buffer)
            .rotate()
            .resize({
              width: maxDimension,
              height: maxDimension,
              fit: 'inside',
              withoutEnlargement: true,
              fastShrinkOnLoad: true,
            })
            .webp({
              quality: webpQuality,
              effort: 5,
              smartSubsample: true,
            })
            .toBuffer()
          finalMimeType = 'image/webp'
          finalTypeSegment = sanitizePathSegment('webp', 'webp')
          finalExtension = 'webp'
          quality = webpQuality
          compressionPercent = file.size > 0
            ? Math.max(0, Math.round(100 - (finalBuffer.length / file.size) * 100))
            : 0
        } catch (sharpErr) {
          console.error('[upload-image] failed to convert image to webp', sharpErr)
          res.status(400).json({ error: 'Failed to convert image. Please upload a valid image file.' })
          return
        }
      } else {
        // Upload as-is without optimization (SVG, GIF, AVIF, HEIC, etc., or when user skips optimization)
        finalBuffer = file.buffer
        finalMimeType = mime
        // Derive extension from mime type
        const extMap = {
          'image/jpeg': 'jpg',
          'image/png': 'png',
          'image/webp': 'webp',
          'image/svg+xml': 'svg',
          'image/gif': 'gif',
          'image/avif': 'avif',
          'image/heic': 'heic',
          'image/heif': 'heif',
          'image/tiff': 'tiff',
          'image/bmp': 'bmp',
        }
        const ext = extMap[mime] || originalTypeSegment
        finalTypeSegment = sanitizePathSegment(ext, ext)
        finalExtension = ext // Use original file extension when not optimizing
      }

      const objectPath = buildUploadObjectPath(baseName, finalTypeSegment, scopedPrefix, finalExtension)

      try {
        const { error: uploadError } = await supabaseServiceClient.storage.from(bucket).upload(objectPath, finalBuffer, {
          cacheControl: '31536000',
          contentType: finalMimeType,
          upsert: false,
        })
        if (uploadError) {
          throw new Error(uploadError.message || 'Supabase storage upload failed')
        }
      } catch (storageErr) {
        console.error('[upload-image] supabase storage upload failed', storageErr)
        res.status(500).json({ error: storageErr?.message || 'Failed to store optimized image' })
        return
      }

      const { data: publicData } = supabaseServiceClient.storage.from(bucket).getPublicUrl(objectPath)
      const publicUrl = publicData?.publicUrl || null
      // Transform URL to use media proxy (hides Supabase project URL)
      const proxyUrl = supabaseStorageToMediaProxy(publicUrl)
      const uploadedAt = new Date().toISOString()

      const payload = {
        ok: true,
        bucket: bucket,
        path: objectPath,
        url: proxyUrl,
        mimeType: finalMimeType,
        size: finalBuffer.length,
        originalMimeType: mime,
        originalSize: file.size,
        uploadedAt,
        quality,
        compressionPercent,
        optimized: shouldOptimize,
      }
      if (!proxyUrl) {
        payload.warning = 'Bucket is not public; no public URL is available'
      }

      // Build extra metadata if builder is provided
      const extraMetadata = typeof extraMetadataBuilder === 'function' 
        ? extraMetadataBuilder({ req, file }) 
        : {}

      await recordAdminMediaUpload({
        adminId: uploaderInfo?.id || null,
        adminEmail: uploaderInfo?.email || null,
        adminName: uploaderInfo?.name || null,
        bucket: bucket,
        path: objectPath,
        publicUrl: proxyUrl,
        mimeType: finalMimeType,
        originalMimeType: mime,
        sizeBytes: finalBuffer.length,
        originalSizeBytes: file.size,
        quality,
        compressionPercent,
        metadata: {
          originalName: file.originalname,
          typeSegment: finalTypeSegment,
          originalTypeSegment,
          scope: auditLabel,
          optimized: shouldOptimize,
          ...extraMetadata,
        },
      })

      if (actorId) {
        try {
          const detail = {
            bucket: bucket,
            path: objectPath,
            url: proxyUrl,
            originalMimeType: mime,
            originalSize: file.size,
            finalSize: finalBuffer.length,
            quality,
            scope: auditLabel,
            optimized: shouldOptimize,
          }
          let logged = false
          if (sql) {
            try {
              await sql`
                insert into public.admin_activity_logs (admin_id, action, target, detail)
                values (${actorId}, 'upload_image', ${objectPath}, ${sql.json(detail)})
              `
              logged = true
            } catch (logErr) {
              console.error('[upload-image] failed to log admin activity (db)', logErr)
            }
          }
          if (!logged) {
            try {
              await insertAdminActivityViaRest(req, {
                admin_id: actorId,
                admin_name: null,
                action: 'upload_image',
                target: objectPath,
                detail,
              })
            } catch (restErr) {
              console.error('[upload-image] failed to log admin activity (rest)', restErr)
            }
          }
        } catch { }
      }

      res.json(payload)
    })().catch((unhandled) => {
      console.error('[upload-image] unexpected failure', unhandled)
      if (!res.headersSent) {
        res.status(500).json({ error: 'Unexpected upload failure' })
      }
    })
  })
}
function sanitizeUploadBaseName(name) {
  try {
    const parsed = path.parse(String(name || '')).name || 'upload'
    const normalized = parsed.toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/^-+|-+$/g, '')
    return normalized || 'upload'
  } catch {
    return 'upload'
  }
}

function normalizeJsonArray(input, fallback = []) {
  if (!input) return Array.isArray(fallback) ? fallback : []
  if (Array.isArray(input)) return input
  if (typeof input === 'string') {
    try {
      const parsed = JSON.parse(input)
      return Array.isArray(parsed) ? parsed : Array.isArray(fallback) ? fallback : []
    } catch {
      return Array.isArray(fallback) ? fallback : []
    }
  }
  return Array.isArray(fallback) ? fallback : []
}

function sanitizePathSegment(value, fallback = 'unknown') {
  try {
    const normalized = String(value || '')
      .toLowerCase()
      .replace(/[^a-z0-9]+/g, '-')
      .replace(/^-+|-+$/g, '')
    return normalized || fallback
  } catch {
    return fallback
  }
}

function deriveUploadTypeSegment(originalName, mimeType) {
  try {
    const ext = path.extname(String(originalName || ''))
    if (ext && ext.length > 1) {
      return sanitizePathSegment(ext.slice(1))
    }
  } catch { }
  try {
    if (mimeType && mimeType.includes('/')) {
      const subtype = mimeType.split('/')[1]
      if (subtype) return sanitizePathSegment(subtype)
    }
  } catch { }
  return 'unknown'
}

function buildUploadObjectPath(baseName, typeSegment, prefix = adminUploadPrefix, extension = 'webp') {
  const unique =
    (typeof crypto.randomUUID === 'function'
      ? crypto.randomUUID()
      : crypto.randomBytes(10).toString('hex'))
  const cleanPrefix = typeof prefix === 'string' ? prefix.replace(/^\/+|\/+$/g, '') : ''
  // Use provided extension (without leading dot if present)
  const ext = (extension || 'webp').replace(/^\./, '')
  const segments = [
    cleanPrefix,
    sanitizePathSegment(typeSegment, 'unknown'),
    `${baseName}-${unique}.${ext}`,
  ].filter(Boolean)
  return segments.join('/').replace(/\/{2,}/g, '/')
}

function sanitizeFolderInput(value) {
  if (!value) return ''
  return String(value)
    .split('/')
    .map((segment) => sanitizePathSegment(segment))
    .filter(Boolean)
    .join('/')
}

function parseStoragePublicUrl(url) {
  try {
    if (!url) return null
    const urlStr = String(url)

    // Try to parse as a Supabase storage URL
    if (supabaseUrlEnv) {
      const normalizedBase = supabaseUrlEnv.replace(/\/+$/, '')
      const publicPrefix = `${normalizedBase}/storage/v1/object/public/`
      if (urlStr.startsWith(publicPrefix)) {
        const remainder = urlStr.slice(publicPrefix.length)
        const parts = remainder.split('/').filter(Boolean)
        if (parts.length >= 2) {
          const bucket = parts.shift()
          const path = parts.join('/')
          if (bucket && path) return { bucket, path }
        }
      }
    }

    // Try to parse as a media proxy URL (e.g., https://media.aphylia.app/BUCKET/path)
    const proxyPrefix = `${mediaProxyBaseUrl}/`
    if (urlStr.startsWith(proxyPrefix)) {
      const remainder = urlStr.slice(proxyPrefix.length)
      const parts = remainder.split('/').filter(Boolean)
      if (parts.length >= 2) {
        const bucket = parts.shift()
        const path = parts.join('/')
        if (bucket && path) return { bucket, path }
      }
    }

    return null
  } catch {
    return null
  }
}

function extractPlainText(html, limit = 4000) {
  if (!html) return ''
  const cleaned = String(html)
    .replace(/<style[\s\S]*?<\/style>/gi, ' ')
    .replace(/<script[\s\S]*?<\/script>/gi, ' ')
    .replace(/<\/?(?:p|div|br|li|h\d)[^>]*>/gi, '\n')
    .replace(/<[^>]+>/g, ' ')
    .replace(/\s+/g, ' ')
    .trim()
  if (!cleaned) return ''
  if (cleaned.length <= limit) return cleaned
  return cleaned.slice(0, limit)
}

async function deleteGardenCoverObject(publicUrl) {
  if (!publicUrl || !supabaseServiceClient) return { deleted: false, reason: 'unavailable' }
  const info = parseStoragePublicUrl(publicUrl)
  if (!info) return { deleted: false, reason: 'not_managed' }
  if (info.bucket !== gardenCoverUploadBucket) return { deleted: false, reason: 'different_bucket' }
  if (gardenCoverUploadPrefix && !info.path.startsWith(`${gardenCoverUploadPrefix}/`)) {
    return { deleted: false, reason: 'different_prefix' }
  }
  try {
    const { error } = await supabaseServiceClient.storage.from(info.bucket).remove([info.path])
    if (error) throw error
    return { deleted: true }
  } catch (err) {
    console.error('[garden-cover] failed to delete storage object', err)
    return { deleted: false, reason: err?.message || 'delete_failed' }
  }
}

// Extract Supabase user id and email from Authorization header. Falls back to
// decoding the JWT locally when the server anon client isn't configured.
async function getUserIdFromRequest(req) {
  try {
    const header = req.get('authorization') || req.get('Authorization') || ''
    const prefix = 'bearer '
    if (!header || header.length < 10) return null
    const low = header.toLowerCase()
    if (!low.startsWith(prefix)) return null
    const token = header.slice(prefix.length).trim()
    if (!token) return null
    // Preferred: ask Supabase to resolve the token (works with anon key)
    if (supabaseServer) {
      try {
        const { data, error } = await supabaseServer.auth.getUser(token)
        if (!error && data?.user?.id) return data.user.id
      } catch { }
    }
    // Fallback: decode JWT payload locally to grab the subject (sub)
    try {
      const parts = token.split('.')
      if (parts.length >= 2) {
        const b64 = parts[1]
        const norm = (b64 + '==='.slice((b64.length + 3) % 4)).replace(/-/g, '+').replace(/_/g, '/')
        const json = Buffer.from(norm, 'base64').toString('utf8')
        const payload = JSON.parse(json)
        const sub = (payload && (payload.sub || payload.user_id))
        if (typeof sub === 'string' && sub.length > 0) return sub
      }
    } catch { }
    return null
  } catch {
    return null
  }
}

async function isAdminUserId(userId) {
  if (!userId || !sql) return false
  try {
    const rows = await sql`select is_admin from public.profiles where id = ${userId} limit 1`
    if (Array.isArray(rows) && rows.length > 0) {
      const val = rows[0]?.is_admin
      return val === true
    }
  } catch { }
  return false
}

// Resolve user (id/email) from request. Uses Supabase if available, otherwise
// decodes the JWT locally. Returns null if no valid bearer token.
async function getUserFromRequest(req) {
  try {
    const header = req.get('authorization') || req.get('Authorization') || ''
    const prefix = 'bearer '
    if (!header || header.length < 10) return null
    const low = header.toLowerCase()
    if (!low.startsWith(prefix)) return null
    const token = header.slice(prefix.length).trim()
    if (!token) return null
    if (supabaseServer) {
      try {
        const { data, error } = await supabaseServer.auth.getUser(token)
        if (!error && data?.user?.id) {
          return { id: data.user.id, email: data.user.email || null }
        }
      } catch { }
    }
    try {
      const parts = token.split('.')
      if (parts.length >= 2) {
        const b64 = parts[1]
        const norm = (b64 + '==='.slice((b64.length + 3) % 4)).replace(/-/g, '+').replace(/_/g, '/')
        const json = Buffer.from(norm, 'base64').toString('utf8')
        const payload = JSON.parse(json)
        const id = (payload && (payload.sub || payload.user_id)) || null
        const email = (payload && (payload.email || payload.user_email)) || null
        if (id) return { id, email }
      }
    } catch { }
    return null
  } catch {
    return null
  }
}

function getTokenFromQuery(req) {
  try {
    const qToken = req.query?.token || req.query?.access_token
    return qToken ? String(qToken) : null
  } catch {
    return null
  }
}

async function getUserFromRequestOrToken(req) {
  const direct = await getUserFromRequest(req)
  if (direct?.id) return direct
  const qToken = getTokenFromQuery(req)
  if (qToken && supabaseServer) {
    try {
      const { data, error } = await supabaseServer.auth.getUser(qToken)
      if (!error && data?.user?.id) {
        return { id: data.user.id, email: data.user.email || null }
      }
    } catch { }
  }
  return null
}

// Determine whether a user (from Authorization) has admin privileges. Checks
// profiles.is_admin when DB is configured, and falls back to Supabase REST and environment allowlists.
function getBearerTokenFromRequest(req) {
  try {
    const header = req.get('authorization') || req.get('Authorization') || ''
    const prefix = 'bearer '
    if (!header || header.length < 10) return null
    const low = header.toLowerCase()
    if (!low.startsWith(prefix)) return null
    const token = header.slice(prefix.length).trim()
    return token || null
  } catch { return null }
}

function getAuthTokenFromRequest(req) {
  return getBearerTokenFromRequest(req) || getTokenFromQuery(req)
}
async function isAdminFromRequest(req) {
  try {
    // Allow explicit public mode for maintenance
    if (adminPublicMode === true) return true
    // Static header token support for non-authenticated admin actions (CI/ops)
    const headerToken = req.get('X-Admin-Token') || req.get('x-admin-token') || ''
    if (adminStaticToken && headerToken && headerToken === adminStaticToken) return true

    // Bearer token path: resolve user and check admin
    const user = await getUserFromRequest(req)
    if (!user?.id) return false
    let isAdmin = false
    // Prefer DB flag
    if (sql) {
      try {
        const exists = await sql`select 1 from information_schema.tables where table_schema='public' and table_name='profiles'`
        if (exists?.length) {
          const rows = await sql`select is_admin from public.profiles where id = ${user.id} limit 1`
          isAdmin = !!(rows?.[0]?.is_admin)
        }
      } catch { }
    }
    // Supabase REST fallback: allow any authenticated user whose profile row has is_admin = true
    if (!isAdmin && supabaseUrlEnv && supabaseAnonKey) {
      try {
        const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
        const bearer = getBearerTokenFromRequest(req)
        if (bearer) Object.assign(headers, { 'Authorization': `Bearer ${bearer}` })
        const url = `${supabaseUrlEnv}/rest/v1/profiles?id=eq.${encodeURIComponent(user.id)}&select=is_admin&limit=1`
        const resp = await fetch(url, { headers })
        if (resp.ok) {
          const arr = await resp.json().catch(() => [])
          const flag = Array.isArray(arr) && arr[0] ? (arr[0].is_admin === true) : false
          if (flag) isAdmin = true
        }
      } catch { }
    }
    // Environment allowlists as fallback
    if (!isAdmin) {
      const allowedEmails = (process.env.ADMIN_EMAILS || '').split(',').map(s => s.trim().toLowerCase()).filter(Boolean)
      const allowedUserIds = (process.env.ADMIN_USER_IDS || '').split(',').map(s => s.trim()).filter(Boolean)
      const email = (user.email || '').toLowerCase()
      if ((email && allowedEmails.includes(email)) || allowedUserIds.includes(user.id)) {
        isAdmin = true
      }
    }
    return isAdmin
  } catch {
    return false
  }
}

// Determine whether a user has editor access (admin OR editor role)
// This allows editors to access plant creation, blog, notifications, emails, and requests
async function isEditorFromRequest(req) {
  try {
    // Allow explicit public mode for maintenance
    if (adminPublicMode === true) return true
    // Static header token support for non-authenticated admin actions (CI/ops)
    const headerToken = req.get('X-Admin-Token') || req.get('x-admin-token') || ''
    if (adminStaticToken && headerToken && headerToken === adminStaticToken) return true

    // Bearer token path: resolve user and check admin or editor role
    const user = await getUserFromRequest(req)
    if (!user?.id) return false
    let hasAccess = false
    // Prefer DB flag
    if (sql) {
      try {
        const exists = await sql`select 1 from information_schema.tables where table_schema='public' and table_name='profiles'`
        if (exists?.length) {
          const rows = await sql`select is_admin, roles from public.profiles where id = ${user.id} limit 1`
          if (rows?.[0]) {
            // Check is_admin flag
            if (rows[0].is_admin === true) hasAccess = true
            // Check roles array for admin or editor
            const roles = Array.isArray(rows[0].roles) ? rows[0].roles : []
            if (roles.includes('admin') || roles.includes('editor')) hasAccess = true
          }
        }
      } catch { }
    }
    // Supabase REST fallback
    if (!hasAccess && supabaseUrlEnv && supabaseAnonKey) {
      try {
        const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
        const bearer = getBearerTokenFromRequest(req)
        if (bearer) Object.assign(headers, { 'Authorization': `Bearer ${bearer}` })
        const url = `${supabaseUrlEnv}/rest/v1/profiles?id=eq.${encodeURIComponent(user.id)}&select=is_admin,roles&limit=1`
        const resp = await fetch(url, { headers })
        if (resp.ok) {
          const arr = await resp.json().catch(() => [])
          if (Array.isArray(arr) && arr[0]) {
            if (arr[0].is_admin === true) hasAccess = true
            const roles = Array.isArray(arr[0].roles) ? arr[0].roles : []
            if (roles.includes('admin') || roles.includes('editor')) hasAccess = true
          }
        }
      } catch { }
    }
    // Environment allowlists as fallback (for admin only, not editor)
    if (!hasAccess) {
      const allowedEmails = (process.env.ADMIN_EMAILS || '').split(',').map(s => s.trim().toLowerCase()).filter(Boolean)
      const allowedUserIds = (process.env.ADMIN_USER_IDS || '').split(',').map(s => s.trim()).filter(Boolean)
      const email = (user.email || '').toLowerCase()
      if ((email && allowedEmails.includes(email)) || allowedUserIds.includes(user.id)) {
        hasAccess = true
      }
    }
    return hasAccess
  } catch {
    return false
  }
}

// Determine whether a user has pro-level access (pro, editor, or admin)
async function isProOrEditorFromRequest(req) {
  try {
    // Editors/admins are already allowed
    if (await isEditorFromRequest(req)) return true
    if (adminPublicMode === true) return true
    const headerToken = req.get('X-Admin-Token') || req.get('x-admin-token') || ''
    if (adminStaticToken && headerToken && headerToken === adminStaticToken) return true

    const user = await getUserFromRequest(req)
    if (!user?.id) return false
    let hasAccess = false

    if (sql) {
      try {
        const exists = await sql`select 1 from information_schema.tables where table_schema='public' and table_name='profiles'`
        if (exists?.length) {
          const rows = await sql`select is_admin, roles from public.profiles where id = ${user.id} limit 1`
          if (rows?.[0]) {
            if (rows[0].is_admin === true) hasAccess = true
            const roles = Array.isArray(rows[0].roles) ? rows[0].roles : []
            if (roles.includes('admin') || roles.includes('editor') || roles.includes('pro')) hasAccess = true
          }
        }
      } catch { }
    }

    if (!hasAccess && supabaseUrlEnv && supabaseAnonKey) {
      try {
        const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
        const bearer = getBearerTokenFromRequest(req)
        if (bearer) Object.assign(headers, { 'Authorization': `Bearer ${bearer}` })
        const url = `${supabaseUrlEnv}/rest/v1/profiles?id=eq.${encodeURIComponent(user.id)}&select=is_admin,roles&limit=1`
        const resp = await fetch(url, { headers })
        if (resp.ok) {
          const arr = await resp.json().catch(() => [])
          if (Array.isArray(arr) && arr[0]) {
            if (arr[0].is_admin === true) hasAccess = true
            const roles = Array.isArray(arr[0].roles) ? arr[0].roles : []
            if (roles.includes('admin') || roles.includes('editor') || roles.includes('pro')) hasAccess = true
          }
        }
      } catch { }
    }

    if (!hasAccess) {
      const allowedEmails = (process.env.ADMIN_EMAILS || '').split(',').map(s => s.trim().toLowerCase()).filter(Boolean)
      const allowedUserIds = (process.env.ADMIN_USER_IDS || '').split(',').map(s => s.trim()).filter(Boolean)
      const email = (user.email || '').toLowerCase()
      if ((email && allowedEmails.includes(email)) || allowedUserIds.includes(user.id)) {
        hasAccess = true
      }
    }

    return hasAccess
  } catch {
    return false
  }
}

// Helper function to ensure editor access (admin OR editor role)
async function ensureEditor(req, res) {
  try {
    // Public mode or static token
    if (adminPublicMode === true) return 'public'
    const headerToken = req.get('X-Admin-Token') || req.get('x-admin-token') || ''
    if (adminStaticToken && headerToken && headerToken === adminStaticToken) return 'static-admin'

    // Bearer token path
    const user = await getUserFromRequest(req)
    if (!user?.id) {
      res.status(401).json({ error: 'Unauthorized' })
      return null
    }

    const hasAccess = await isEditorFromRequest(req)
    if (!hasAccess) {
      res.status(403).json({ error: 'Editor privileges required' })
      return null
    }
    return user.id
  } catch (err) {
    res.status(500).json({ error: err?.message || 'Authorization check failed' })
    return null
  }
}

// Helper to ensure pro/editor/admin access (used for professional advice uploads)
async function ensureProOrEditor(req, res) {
  try {
    if (adminPublicMode === true) return 'public'
    const headerToken = req.get('X-Admin-Token') || req.get('x-admin-token') || ''
    if (adminStaticToken && headerToken && headerToken === adminStaticToken) return 'static-admin'

    const user = await getUserFromRequest(req)
    if (!user?.id) {
      res.status(401).json({ error: 'Unauthorized' })
      return null
    }

    const hasAccess = await isProOrEditorFromRequest(req)
    if (!hasAccess) {
      res.status(403).json({ error: 'Pro, editor, or admin privileges required' })
      return null
    }
    return user.id
  } catch (err) {
    res.status(500).json({ error: err?.message || 'Authorization check failed' })
    return null
  }
}

// Helper: insert admin_activity_logs row via Supabase REST when DB is unavailable
async function insertAdminActivityViaRest(req, row) {
  try {
    if (!(supabaseUrlEnv && supabaseAnonKey)) return false
    const headers = { apikey: supabaseAnonKey, Accept: 'application/json', 'Content-Type': 'application/json' }
    const bearer = getBearerTokenFromRequest(req)
    if (bearer) headers['Authorization'] = `Bearer ${bearer}`
    const resp = await fetch(`${supabaseUrlEnv}/rest/v1/admin_activity_logs`, { method: 'POST', headers, body: JSON.stringify(row) })
    return resp.ok
  } catch {
    return false
  }
}

async function ensureAdmin(req, res) {
  try {
    // Public mode or static token
    if (adminPublicMode === true) return 'public'
    const headerToken = req.get('X-Admin-Token') || req.get('x-admin-token') || ''
    if (adminStaticToken && headerToken && headerToken === adminStaticToken) return 'static-admin'

    // Bearer token path
    const user = await getUserFromRequest(req)
    if (!user?.id) {
      res.status(401).json({ error: 'Unauthorized' })
      return null
    }
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return null
    }
    return user.id
  } catch {
    res.status(500).json({ error: 'Failed to authorize request' })
    return null
  }
}

/**
 * Converts admin identifier to a valid UUID for database storage.
 * Returns null for non-UUID identifiers like 'static-admin' or 'public'.
 * @param {string} adminId - The admin identifier from ensureAdmin()
 * @returns {string|null} - Valid UUID string or null
 */
function toAdminUuid(adminId) {
  if (!adminId || adminId === 'static-admin' || adminId === 'public') {
    return null
  }
  // Basic UUID format check
  const uuidRegex = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i
  return uuidRegex.test(adminId) ? adminId : null
}

const disallowedImageKeys = new Set(['image', 'imageurl', 'image_url', 'imageURL', 'thumbnail', 'photo', 'picture'])
const disallowedFieldKeys = new Set(['externalids'])
const metadataKeys = new Set(['type', 'description', 'options', 'items', 'additionalProperties', 'examples', 'format'])

function pickPrimaryPhotoUrlFromArray(photos, fallback) {
  if (Array.isArray(photos)) {
    const normalized = []
    for (const entry of photos) {
      if (!entry || typeof entry !== 'object') continue
      const url = typeof entry.url === 'string' ? entry.url.trim() : ''
      if (!url) continue
      normalized.push({ url, isPrimary: entry.isPrimary === true })
    }
    if (normalized.length > 0) {
      const primary = normalized.find((photo) => photo.isPrimary && photo.url)
      if (primary && primary.url) return primary.url
      return normalized[0].url
    }
  }
  return typeof fallback === 'string' && fallback ? fallback : ''
}

const EMAIL_VARIABLE_REGEX = /\{\{\s*([a-zA-Z0-9_]+)\s*\}\}/g

function extractEmailTemplateVariables(...inputs) {
  const result = new Set()
  for (const input of inputs) {
    if (!input || typeof input !== 'string') continue
    let match
    while ((match = EMAIL_VARIABLE_REGEX.exec(input)) !== null) {
      const key = (match[1] || '').trim().toLowerCase()
      if (key) result.add(key)
    }
  }
  return Array.from(result).sort()
}

function stripHtmlToPlainText(html = '', maxLength = 240) {
  if (!html || typeof html !== 'string') return ''
  const withoutTags = html
    .replace(/<style[\s\S]*?<\/style>/gi, '')
    .replace(/<script[\s\S]*?<\/script>/gi, '')
    .replace(/<br\s*\/?>/gi, '\n')
    .replace(/<\/p>/gi, '\n\n')
    .replace(/<[^>]+>/g, ' ')
    .replace(/\s+/g, ' ')
    .trim()
  if (withoutTags.length <= maxLength) return withoutTags
  return `${withoutTags.slice(0, maxLength - 1).trim()}â€¦`
}

function coerceJsonValue(value, fallback = null) {
  if (value === null || value === undefined) return fallback
  if (typeof value === 'object') return value
  if (typeof value === 'string') {
    try {
      return JSON.parse(value)
    } catch {
      return fallback
    }
  }
  return fallback
}

function normalizeScheduledDate(value) {
  if (!value || typeof value !== 'string') return null
  const date = new Date(value)
  if (Number.isNaN(date.getTime())) return null
  return date.toISOString()
}

function resolvePreviewText(previewText, bodyHtml) {
  if (previewText && typeof previewText === 'string' && previewText.trim().length > 0) {
    return previewText.trim()
  }
  return stripHtmlToPlainText(bodyHtml || '', 200)
}

function coerceVariableArray(value) {
  const raw = coerceJsonValue(value, [])
  if (!Array.isArray(raw)) return []
  const set = new Set()
  for (const entry of raw) {
    if (entry === null || entry === undefined) continue
    const key = String(entry).trim().toLowerCase()
    if (key) set.add(key)
  }
  return Array.from(set).sort()
}

const JsonValueSchema = z.lazy(() =>
  z.union([
    z.string(),
    z.number(),
    z.boolean(),
    z.null(),
    z.array(JsonValueSchema),
    z.object({}).catchall(JsonValueSchema)
  ])
)
const PlantFillSchema = z.object({}).catchall(JsonValueSchema)

function sanitizeTemplate(node, path = []) {
  if (Array.isArray(node)) {
    return node.map((item) => sanitizeTemplate(item, path))
  }
  if (node && typeof node === 'object') {
    const result = {}
    for (const [key, value] of Object.entries(node)) {
      const lowerKey = key.toLowerCase()
      if (disallowedImageKeys.has(lowerKey)) continue
      if (disallowedFieldKeys.has(lowerKey)) continue
      if (lowerKey === 'name' && path.length === 0) continue
      result[key] = sanitizeTemplate(value, [...path, key])
    }
    return result
  }
  return node
}

function ensureStructure(template, target) {
  if (Array.isArray(template)) {
    return Array.isArray(target) ? target : []
  }
  if (template && typeof template === 'object' && !Array.isArray(template)) {
    const result =
      target && typeof target === 'object' && !Array.isArray(target)
        ? { ...target }
        : {}
    for (const [key, templateValue] of Object.entries(template)) {
      if (!(key in result)) {
        if (Array.isArray(templateValue)) {
          result[key] = []
        } else if (templateValue && typeof templateValue === 'object') {
          result[key] = ensureStructure(templateValue, {})
        } else {
          result[key] = null
        }
      } else if (templateValue && typeof templateValue === 'object') {
        result[key] = ensureStructure(templateValue, result[key])
      }
    }
    return result
  }
  return target !== undefined ? target : null
}

function stripDisallowedKeys(node, path = []) {
  if (Array.isArray(node)) {
    return node.map((item) => stripDisallowedKeys(item, path))
  }
  if (node && typeof node === 'object') {
    const result = {}
    for (const [key, value] of Object.entries(node)) {
      const lowerKey = key.toLowerCase()
      if (disallowedImageKeys.has(lowerKey)) continue
      if (disallowedFieldKeys.has(lowerKey)) continue
      if (lowerKey === 'name' && path.length === 0) continue
      result[key] = stripDisallowedKeys(value, [...path, key])
    }
    return result
  }
  return node
}

function schemaToBlueprint(node) {
  if (Array.isArray(node)) {
    if (node.length === 0) return []
    return node.map((item) => schemaToBlueprint(item))
  }
  if (!node || typeof node !== 'object') {
    return null
  }
  const obj = node
  if (typeof obj.type === 'string') {
    const typeValue = obj.type.toLowerCase()
    if (typeValue === 'array') {
      const items = obj.items
      if (!items) return []
      const blueprintItem = schemaToBlueprint(items)
      return Array.isArray(blueprintItem) ? blueprintItem : [blueprintItem]
    }
    if (typeValue === 'object') {
      const result = {}
      const source =
        typeof obj.properties === 'object' && obj.properties !== null && !Array.isArray(obj.properties)
          ? obj.properties
          : Object.fromEntries(
            Object.entries(obj).filter(([key]) => !metadataKeys.has(key))
          )
      for (const [key, value] of Object.entries(source)) {
        result[key] = schemaToBlueprint(value)
      }
      return result
    }
    return null
  }

  const result = {}
  for (const [key, value] of Object.entries(obj)) {
    if (metadataKeys.has(key)) continue
    result[key] = schemaToBlueprint(value)
  }
  return result
}

function pruneEmpty(node) {
  if (Array.isArray(node)) {
    const pruned = node
      .map((item) => pruneEmpty(item))
      .filter((item) => item !== undefined)
    return pruned.length > 0 ? pruned : undefined
  }
  if (node && typeof node === 'object') {
    const result = {}
    for (const [key, value] of Object.entries(node)) {
      const prunedValue = pruneEmpty(value)
      if (prunedValue !== undefined) result[key] = prunedValue
    }
    return Object.keys(result).length > 0 ? result : undefined
  }
  if (node === null || node === undefined) return undefined
  if (typeof node === 'string') {
    return node.trim().length > 0 ? node : undefined
  }
  return node
}

function mergePreferExisting(aiValue, existingValue) {
  if (existingValue === undefined) return aiValue
  if (existingValue === null) return aiValue
  if (Array.isArray(existingValue)) {
    if (existingValue.length === 0) {
      return Array.isArray(aiValue) ? aiValue : []
    }
    return existingValue
  }
  if (existingValue && typeof existingValue === 'object') {
    const aiObj = aiValue && typeof aiValue === 'object' && !Array.isArray(aiValue) ? aiValue : {}
    const result = { ...aiObj }
    for (const [key, existingChild] of Object.entries(existingValue)) {
      result[key] = mergePreferExisting(aiObj[key], existingChild)
    }
    return result
  }
  if (typeof existingValue === 'string') {
    const trimmed = existingValue.trim()
    if (trimmed.length > 0) return existingValue
    if (typeof aiValue === 'string') return aiValue
    return trimmed
  }
  return existingValue
}

function removeNullValues(node) {
  if (node === null || node === undefined) {
    return undefined
  }
  if (Array.isArray(node)) {
    const cleaned = node
      .map((item) => removeNullValues(item))
      .filter((item) => item !== undefined)
    return cleaned
  }
  if (node && typeof node === 'object') {
    const result = {}
    for (const [key, value] of Object.entries(node)) {
      const cleanedValue = removeNullValues(value)
      if (cleanedValue !== undefined) {
        result[key] = cleanedValue
      }
    }
    return Object.keys(result).length > 0 ? result : undefined
  }
  return node
}

function collectFieldHints(node, path, hints = new Set()) {
  if (!node || typeof node !== 'object') {
    return hints
  }

  const type = typeof node.type === 'string' ? node.type.toLowerCase() : null
  if (Array.isArray(node.options) && node.options.length > 0) {
    hints.add(`${path}: choose only from [${node.options.join(', ')}]`)
  }
  if (type === 'number' || type === 'integer') {
    hints.add(`${path}: answer with numbers only.`)
  }
  if (type === 'boolean') {
    hints.add(`${path}: answer with "true" or "false".`)
  }
  if (type === 'array') {
    const items = node.items
    if (typeof items === 'string') {
      const itemType = items.toLowerCase()
      if (itemType === 'number' || itemType === 'integer') {
        hints.add(`${path}: provide an array of numbers.`)
      } else if (itemType === 'boolean') {
        hints.add(`${path}: provide an array of true/false values.`)
      }
    } else if (items && typeof items === 'object') {
      collectFieldHints(items, `${path}[]`, hints)
    }
  }
  if (node.additionalProperties && typeof node.additionalProperties === 'object') {
    collectFieldHints(node.additionalProperties, `${path}.*`, hints)
  }

  const skipKeys = new Set([
    'type',
    'description',
    'options',
    'items',
    'additionalProperties',
    'min',
    'max',
    'minCm',
    'maxCm',
    'rowCm',
    'plantCm',
    'minF',
    'maxF',
    'minC',
    'maxC',
    'units',
    'unit',
    'example',
    'default',
  ])

  for (const [key, value] of Object.entries(node)) {
    if (skipKeys.has(key)) continue
    if (value && typeof value === 'object') {
      collectFieldHints(value, `${path}.${key}`, hints)
    }
  }

  return hints
}

function renderFieldPromptFromTemplate(fieldKey, plantName) {
  const template = aiFieldPromptsTemplate?.[fieldKey]
  if (!template) return null

  let segments = []
  if (Array.isArray(template)) {
    segments = template
  } else if (typeof template === 'string') {
    segments = [template]
  } else if (template && Array.isArray(template.instructions)) {
    segments = template.instructions
  }

  if (!segments.length) return null
  const compiled = segments.join('\n')
  return compiled.replace(/\{\{\s*plantName\s*\}\}/gi, plantName)
}

function inferExpectedKind(node) {
  if (Array.isArray(node)) return 'array'
  if (!node || typeof node !== 'object') {
    return typeof node
  }
  if (typeof node.type === 'string') {
    return node.type.toLowerCase()
  }
  return 'object'
}

function inferArrayItemKind(node) {
  if (!node || typeof node !== 'object') return 'unknown'
  const items = node.items
  if (typeof items === 'string') {
    return items.toLowerCase()
  }
  if (items && typeof items === 'object') {
    if (typeof items.type === 'string') {
      return items.type.toLowerCase()
    }
    return 'object'
  }
  return 'unknown'
}

function coerceValueForSchema(schemaNode, value, existingValue) {
  const kind = inferExpectedKind(schemaNode)
  if (value === undefined || value === null) {
    return value
  }

  if (kind === 'number' || kind === 'integer') {
    if (typeof value === 'number') {
      return kind === 'integer' ? Math.round(value) : value
    }
    if (typeof value === 'string') {
      const numericText = value.trim().match(/[-+]?\d+(\.\d+)?/g)
      if (numericText && numericText.length > 0) {
        const num = Number(numericText[0])
        if (!Number.isNaN(num)) {
          return kind === 'integer' ? Math.round(num) : num
        }
      }
    }
    return existingValue !== undefined ? existingValue : undefined
  }

  if (kind === 'boolean') {
    if (typeof value === 'boolean') return value
    if (typeof value === 'string') {
      const lowered = value.trim().toLowerCase()
      if (lowered === 'true') return true
      if (lowered === 'false') return false
    }
    return existingValue !== undefined ? existingValue : undefined
  }

  if (kind === 'array') {
    if (Array.isArray(value)) {
      return value
    }
    if (typeof value === 'string') {
      const itemKind = inferArrayItemKind(schemaNode)
      const parts = value
        .split(/[,;\n]+/)
        .map((part) => part.trim())
        .filter((part) => part.length > 0)
      if (itemKind === 'number' || itemKind === 'integer') {
        const numbers = parts
          .map((part) => Number(part))
          .filter((num) => !Number.isNaN(num))
        return numbers
      }
      if (itemKind === 'boolean') {
        const bools = parts
          .map((part) => {
            const lowered = part.toLowerCase()
            if (lowered === 'true') return true
            if (lowered === 'false') return false
            return null
          })
          .filter((item) => item !== null)
        return bools
      }
      return parts
    }
    return existingValue !== undefined ? existingValue : []
  }

  if (kind === 'object') {
    if (value && typeof value === 'object' && !Array.isArray(value)) {
      return value
    }
    if (typeof value === 'string') {
      try {
        const parsed = JSON.parse(value)
        if (parsed && typeof parsed === 'object' && !Array.isArray(parsed)) {
          return parsed
        }
      } catch { }
    }
    if (existingValue && typeof existingValue === 'object') {
      return existingValue
    }
    return {}
  }

  if (kind === 'string') {
    if (typeof value === 'string') {
      return value
    }
    if (value != null) {
      return String(value)
    }
    return existingValue !== undefined ? existingValue : ''
  }

  return value
}

// Fields that are simple enum selections - use lower reasoning effort for faster processing
const SIMPLE_ENUM_FIELDS = new Set([
  'plantType',    // Single enum selection
  'utility',      // Array of enum values
  'comestiblePart', // Array of enum values  
  'fruitType',    // Array of enum values
  'seasons',      // Array of enum values
])

// Fields that require more complex analysis - use medium reasoning effort
const COMPLEX_FIELDS = new Set([
  'description',
  'identity',
  'plantCare',
  'growth',
  'usage',
  'ecology',
  'danger',
  'miscellaneous',
])

async function generateFieldData(options) {
  const { plantName, fieldKey, fieldSchema, existingField } = options || {}
  if (!openaiClient) {
    throw new Error('OpenAI client not configured')
  }

  // Determine reasoning effort based on field complexity
  // Simple enum fields use 'low' effort (faster), complex fields use 'medium' effort (more accurate)
  const reasoningEffort = SIMPLE_ENUM_FIELDS.has(fieldKey) ? 'low' : 'medium'

  const hintList = Array.from(collectFieldHints(fieldSchema, fieldKey)).slice(0, 50)
  const commonInstructions = [
    `Act as a horticulture researcher filling structured data for the plant named "${plantName}".`,
    'Work only in concise English and rely on reputable botanical sources.',
    'Respond strictly with valid JSON containing the requested field and nothing else.',
    'Populate every possible sub-value; if data is missing, return an empty string or array instead of null.',
    'Reuse suitable existing data and never fabricate meta/status/image information.',
  ].join('\n')

  const promptSections = [
    `Plant name: ${plantName}`,
    `Field key: ${fieldKey}`,
    `Field definition (for reference):\n${JSON.stringify(fieldSchema, null, 2)}`,
  ]

  const templatePrompt = renderFieldPromptFromTemplate(fieldKey, plantName)
  if (templatePrompt) {
    promptSections.push(templatePrompt)
  }

  if (hintList.length > 0) {
    promptSections.push(`Constraints:\n- ${hintList.join('\n- ')}`)
  }

  if (existingField !== undefined) {
    promptSections.push(`Existing data (prefer and expand when correct):\n${JSON.stringify(existingField, null, 2)}`)
  }

  promptSections.push(
    `Respond with JSON shaped exactly like:\n{"${fieldKey}": ...}\nDo not include any other keys or commentary.`
  )

  // Use shorter timeout for simple fields (2 min) vs complex fields (10 min)
  const defaultTimeout = SIMPLE_ENUM_FIELDS.has(fieldKey) ? 120000 : 600000
  const timeout = Number(process.env.OPENAI_TIMEOUT_MS) || defaultTimeout

  const response = await openaiClient.responses.create(
    {
      model: openaiModel,
      reasoning: { effort: reasoningEffort },
      instructions: commonInstructions,
      input: promptSections.join('\n\n'),
    },
    { timeout }
  )

  const outputText = typeof response?.output_text === 'string' ? response.output_text.trim() : ''
  if (!outputText) {
    throw new Error(`AI returned empty output for "${fieldKey}"`)
  }

  let parsedField
  try {
    parsedField = JSON.parse(outputText)
  } catch (parseError) {
    const jsonMatch = outputText.match(/\{[\s\S]*\}/)
    if (jsonMatch) {
      try {
        parsedField = JSON.parse(jsonMatch[0])
      } catch (innerError) {
        console.error('[server] Failed to parse extracted AI field response:', innerError, outputText)
      }
    } else {
      console.error('[server] Failed to parse AI field response:', parseError, outputText)
    }
  }

  const rawValue =
    parsedField && typeof parsedField === 'object' && !Array.isArray(parsedField) && fieldKey in parsedField
      ? parsedField[fieldKey]
      : parsedField && typeof parsedField === 'object' && !Array.isArray(parsedField)
        ? parsedField
        : outputText
  const coercedValue = coerceValueForSchema(
    fieldSchema,
    typeof rawValue === 'string' ? rawValue.trim() : rawValue,
    existingField
  )

  const cleanedValue = removeNullValues(coercedValue)
  return cleanedValue !== undefined ? cleanedValue : undefined
}

async function verifyPlantNameCandidate(plantName) {
  if (!openaiClient) {
    throw new Error('OpenAI client not configured')
  }

  const instructions = [
    'You verify whether a provided term clearly refers to a plant species, cultivar, or commonly recognized plant.',
    'Respond strictly with compact JSON: {"isPlant": true|false, "reason": "very short explanation"}',
    'Return isPlant = true only when the name primarily identifies a plant (botanical or common).',
    'Return false for people, companies, fictional characters, generic objects, or ambiguous inputs.',
    'Do not include markdown or prose outside the JSON.',
  ].join('\n')

  const prompt = [`Name to classify: ${plantName}`].join('\n')

  const response = await openaiClient.responses.create(
    {
      model: openaiModelNano,
      reasoning: { effort: 'low' },
      instructions,
      input: prompt,
    },
    { timeout: Number(process.env.OPENAI_TIMEOUT_MS || 300000) },
  )

  const outputText = typeof response?.output_text === 'string' ? response.output_text.trim() : ''
  if (!outputText) {
    throw new Error('AI returned empty verification output')
  }

  let parsed
  try {
    parsed = JSON.parse(outputText)
  } catch {
    const jsonMatch = outputText.match(/\{[\s\S]*\}/)
    if (jsonMatch) {
      try {
        parsed = JSON.parse(jsonMatch[0])
      } catch { }
    }
  }

  const normalized =
    parsed && typeof parsed === 'object' && !Array.isArray(parsed) ? parsed : {}

  let isPlant = false
  if (typeof normalized.isPlant === 'boolean') {
    isPlant = normalized.isPlant
  } else if (typeof normalized.result === 'string') {
    const lowered = normalized.result.trim().toLowerCase()
    isPlant = lowered.startsWith('y') || lowered.includes('plant')
  } else if (/"isPlant"\s*:\s*true/i.test(outputText)) {
    isPlant = true
  }

  const reason =
    typeof normalized.reason === 'string'
      ? normalized.reason
      : typeof normalized.explanation === 'string'
        ? normalized.explanation
        : outputText

  return { isPlant: Boolean(isPlant), reason: reason.trim() }
}

function removeExternalIds(node) {
  if (!node || typeof node !== 'object') return node
  if (Array.isArray(node)) {
    return node.map((item) => removeExternalIds(item))
  }
  const result = {}
  for (const [key, value] of Object.entries(node)) {
    if (key.toLowerCase() === 'externalids') continue
    result[key] = removeExternalIds(value)
  }
  return result
}


function buildConnectionString() {
  let cs = process.env.DATABASE_URL || process.env.POSTGRES_URL || process.env.POSTGRES_PRISMA_URL || process.env.SUPABASE_DB_URL
  if (!cs) {
    const host = process.env.PGHOST || process.env.POSTGRES_HOST
    const user = process.env.PGUSER || process.env.POSTGRES_USER
    const password = process.env.PGPASSWORD || process.env.POSTGRES_PASSWORD
    const port = process.env.PGPORT || process.env.POSTGRES_PORT || '5432'
    const database = process.env.PGDATABASE || process.env.POSTGRES_DB || 'postgres'
    if (host && user) {
      const encUser = encodeURIComponent(user)
      const encPass = password ? encodeURIComponent(password) : ''
      const auth = encPass ? `${encUser}:${encPass}` : encUser
      cs = `postgresql://${auth}@${host}:${port}/${database}`
    }
  }
  // Fallback: support explicit Supabase DB host credentials if provided
  if (!cs) {
    const sbHost = process.env.SUPABASE_DB_HOST
    const sbUser = process.env.SUPABASE_DB_USER || process.env.PGUSER || process.env.POSTGRES_USER || 'postgres'
    const sbPass = process.env.SUPABASE_DB_PASSWORD || process.env.PGPASSWORD || process.env.POSTGRES_PASSWORD
    const sbPort = process.env.SUPABASE_DB_PORT || process.env.PGPORT || process.env.POSTGRES_PORT || '5432'
    const sbDb = process.env.SUPABASE_DB_NAME || process.env.PGDATABASE || process.env.POSTGRES_DB || 'postgres'
    if (sbHost && sbPass) {
      const encUser = encodeURIComponent(sbUser)
      const encPass = encodeURIComponent(sbPass)
      cs = `postgresql://${encUser}:${encPass}@${sbHost}:${sbPort}/${sbDb}`
    }
  }
  // Auto-derive Supabase DB host when only project URL and DB password are provided
  if (!cs && supabaseUrlEnv && (process.env.SUPABASE_DB_PASSWORD || process.env.PGPASSWORD || process.env.POSTGRES_PASSWORD)) {
    try {
      const u = new URL(supabaseUrlEnv)
      const projectRef = u.hostname.split('.')[0] // e.g., lxnkcguwewrskqnyzjwi
      const host = `db.${projectRef}.supabase.co`
      const user = process.env.SUPABASE_DB_USER || process.env.PGUSER || process.env.POSTGRES_USER || 'postgres'
      const pass = process.env.SUPABASE_DB_PASSWORD || process.env.PGPASSWORD || process.env.POSTGRES_PASSWORD || ''
      const port = process.env.SUPABASE_DB_PORT || process.env.PGPORT || process.env.POSTGRES_PORT || '5432'
      const database = process.env.SUPABASE_DB_NAME || process.env.PGDATABASE || process.env.POSTGRES_DB || 'postgres'
      if (host && pass) {
        const encUser = encodeURIComponent(user)
        const encPass = encodeURIComponent(pass)
        cs = `postgresql://${encUser}:${encPass}@${host}:${port}/${database}`
      }
    } catch { }
  }
  // Intentionally avoid deriving connection string from Supabase-specific envs
  if (cs) {
    try {
      const url = new URL(cs)
      const isLocal = url.hostname === 'localhost' || url.hostname === '127.0.0.1'
      if (!isLocal && !url.searchParams.has('sslmode')) url.searchParams.set('sslmode', 'require')
      if (!url.searchParams.has('connect_timeout')) url.searchParams.set('connect_timeout', '5')
      cs = url.toString()
    } catch { }
  }
  return cs
}

const connectionString = buildConnectionString()
if (!connectionString) {
  console.warn('[server] DATABASE_URL not configured â€” API will error on queries')
}

// Prefer SSL for non-local databases even if URL lacks sslmode; honor custom CA
let postgresOptions = {}
try {
  if (connectionString) {
    const u = new URL(connectionString)
    const isLocal = u.hostname === 'localhost' || u.hostname === '127.0.0.1'
    if (!isLocal) {
      const allowInsecure = String(process.env.ALLOW_INSECURE_DB_TLS || 'false').toLowerCase() === 'true'
      if (allowInsecure) {
        postgresOptions = { ssl: { rejectUnauthorized: false } }
      } else {
        const candidates = [
          process.env.PGSSLROOTCERT,
          process.env.NODE_EXTRA_CA_CERTS,
          '/etc/ssl/certs/aws-rds-global.pem',
          '/etc/ssl/certs/ca-certificates.crt',
        ].filter(Boolean)
        let ssl = undefined
        for (const p of candidates) {
          try {
            if (p && fsSync.existsSync(p)) {
              const ca = fsSync.readFileSync(p, 'utf8')
              if (ca && ca.length > 0) { ssl = { rejectUnauthorized: true, ca }; break }
            }
          } catch { }
        }
        if (!ssl) ssl = true
        postgresOptions = { ssl }
      }
    }
  }
} catch { }
const sql = connectionString ? postgres(connectionString, postgresOptions) : null

let adminMediaUploadsEnsured = false
async function ensureAdminMediaUploadsTable() {
  if (!sql) return
  if (adminMediaUploadsEnsured) return
  const ddl = `
    create table if not exists public.admin_media_uploads (
      id uuid primary key default gen_random_uuid(),
      admin_id uuid,
      admin_email text,
      admin_name text,
      bucket text not null,
      path text not null,
      public_url text,
      mime_type text,
      original_mime_type text,
      size_bytes integer,
      original_size_bytes integer,
      quality integer,
      compression_percent integer,
      metadata jsonb,
      upload_source text,
      created_at timestamptz not null default now()
    );
    create index if not exists admin_media_uploads_created_idx on public.admin_media_uploads (created_at desc);
    create index if not exists admin_media_uploads_admin_idx on public.admin_media_uploads (admin_id);
    create unique index if not exists admin_media_uploads_bucket_path_idx on public.admin_media_uploads (bucket, path);
    create index if not exists admin_media_uploads_source_idx on public.admin_media_uploads (upload_source);
  `
  // Add column if it doesn't exist (for existing installations)
  const addColumnDdl = `
    alter table public.admin_media_uploads add column if not exists upload_source text;
    create index if not exists admin_media_uploads_source_idx on public.admin_media_uploads (upload_source);
  `
  try {
    await sql.unsafe(ddl, [], { simple: true })
    await sql.unsafe(addColumnDdl, [], { simple: true })
    adminMediaUploadsEnsured = true
  } catch (err) {
    console.error('[schema] failed to ensure admin_media_uploads table', err)
  }
}

async function getAdminProfileName(userId) {
  if (!userId) return null
  if (sql) {
    try {
      const rows = await sql`select display_name from public.profiles where id = ${userId} limit 1`
      if (Array.isArray(rows) && rows[0]?.display_name) return rows[0].display_name
    } catch { }
  }
  if (supabaseServiceClient) {
    try {
      const { data, error } = await supabaseServiceClient
        .from('profiles')
        .select('display_name')
        .eq('id', userId)
        .limit(1)
        .maybeSingle()
      if (!error && data?.display_name) return data.display_name
    } catch { }
  }
  return null
}

function extractStorageName(path) {
  try {
    if (!path) return null
    const parts = String(path).split('/').filter(Boolean)
    if (parts.length === 0) return String(path)
    return parts[parts.length - 1]
  } catch {
    return path || null
  }
}

function normalizeAdminMediaRow(row) {
  if (!row) return null
  // Transform any Supabase URLs to proxy URLs for backward compatibility
  const rawUrl = row.public_url || row.publicUrl || null
  const url = rawUrl ? supabaseStorageToMediaProxy(rawUrl) : null
  // Derive upload source from column, metadata.scope, or metadata.source
  const uploadSource = 
    row.upload_source || 
    row.uploadSource || 
    row.metadata?.scope || 
    row.metadata?.source || 
    'admin'
  return {
    id: row.id || null,
    adminId: row.admin_id || row.adminId || null,
    adminEmail: row.admin_email || row.adminEmail || null,
    adminName: row.admin_name || row.adminName || null,
    bucket: row.bucket || null,
    path: row.path || null,
    url,
    mimeType: row.mime_type || row.mimeType || null,
    originalMimeType: row.original_mime_type || row.originalMimeType || null,
    sizeBytes:
      typeof row.size_bytes === 'number' ? row.size_bytes : row.sizeBytes ?? null,
    originalSizeBytes:
      typeof row.original_size_bytes === 'number'
        ? row.original_size_bytes
        : row.originalSizeBytes ?? null,
    quality: typeof row.quality === 'number' ? row.quality : row.quality ?? null,
    compressionPercent:
      typeof row.compression_percent === 'number'
        ? row.compression_percent
        : row.compressionPercent ?? null,
    metadata: row.metadata || null,
    uploadSource,
    createdAt: row.created_at || row.createdAt || null,
  }
}

async function recordAdminMediaUpload(row) {
  if (!row) return null
  try {
    const createdAt = (() => {
      try {
        return row.createdAt ? new Date(row.createdAt).toISOString() : null
      } catch {
        return null
      }
    })()
    const createdAtValue = createdAt || new Date().toISOString()
    const storageName =
      row.metadata?.storageName ||
      row.metadata?.displayName ||
      extractStorageName(row.path)
    const metadataPayload = (() => {
      const base =
        row.metadata && typeof row.metadata === 'object' ? { ...row.metadata } : {}
      if (base.originalName && !base.originalUploadName) {
        base.originalUploadName = base.originalName
      }
      if (storageName) {
        base.storageName = storageName
        if (!base.displayName) base.displayName = storageName
        base.originalName = storageName
      } else if (!base.originalName && base.storageName) {
        base.originalName = base.storageName
      }
      return base
    })()
    // Derive upload_source from metadata.scope, metadata.source, or row.uploadSource
    const uploadSource = row.uploadSource || row.metadata?.scope || row.metadata?.source || 'admin'

    if (sql) {
      const inserted = await sql`
        insert into public.admin_media_uploads
          (admin_id, admin_email, admin_name, bucket, path, public_url, mime_type, original_mime_type, size_bytes, original_size_bytes, quality, compression_percent, metadata, upload_source, created_at)
        values
          (${row.adminId}, ${row.adminEmail}, ${row.adminName}, ${row.bucket}, ${row.path}, ${row.publicUrl}, ${row.mimeType}, ${row.originalMimeType}, ${row.sizeBytes}, ${row.originalSizeBytes}, ${row.quality}, ${row.compressionPercent}, ${sql.json(metadataPayload || null)}, ${uploadSource}, ${createdAtValue})
        on conflict (bucket, path) do update set
          admin_id = excluded.admin_id,
          admin_email = excluded.admin_email,
          admin_name = excluded.admin_name,
          public_url = excluded.public_url,
          mime_type = excluded.mime_type,
          original_mime_type = excluded.original_mime_type,
          size_bytes = excluded.size_bytes,
          original_size_bytes = excluded.original_size_bytes,
          quality = excluded.quality,
          compression_percent = excluded.compression_percent,
          metadata = excluded.metadata,
          upload_source = excluded.upload_source,
          created_at = excluded.created_at
        returning id, admin_id, admin_email, admin_name, bucket, path, public_url, mime_type, original_mime_type, size_bytes, original_size_bytes, quality, compression_percent, metadata, upload_source, created_at
      `
      return Array.isArray(inserted) && inserted.length > 0
        ? normalizeAdminMediaRow(inserted[0])
        : null
    }
    if (supabaseServiceClient) {
      const { data, error } = await supabaseServiceClient
        .from('admin_media_uploads')
        .upsert(
          {
            admin_id: row.adminId,
            admin_email: row.adminEmail,
            admin_name: row.adminName,
            bucket: row.bucket,
            path: row.path,
            public_url: row.publicUrl,
            mime_type: row.mimeType,
            original_mime_type: row.originalMimeType,
            size_bytes: row.sizeBytes,
            original_size_bytes: row.originalSizeBytes,
            quality: row.quality,
            compression_percent: row.compressionPercent,
            metadata: metadataPayload || null,
            upload_source: uploadSource,
            created_at: createdAtValue,
          },
          { onConflict: 'bucket,path' }
        )
        .select(
          'id, admin_id, admin_email, admin_name, bucket, path, public_url, mime_type, original_mime_type, size_bytes, original_size_bytes, quality, compression_percent, metadata, upload_source, created_at'
        )
        .maybeSingle()
      if (error) throw error
      return data ? normalizeAdminMediaRow(data) : null
    }
  } catch (err) {
    console.error('[upload] failed to record admin media upload', err)
  }
  return null
}

async function syncGardenCoverMedia(existingKeys, limit = 200) {
  if (!gardenCoverUploadBucket) return []
  const inserted = []
  let rows = []
  try {
    if (sql) {
      rows = await sql`
        select
          g.id::text as id,
          g.name,
          g.created_by::text as owner_id,
          g.cover_image_url,
          coalesce(g.updated_at, g.created_at, now()) as updated_at,
          p.display_name as owner_name
        from public.gardens g
        left join public.profiles p on p.id = g.created_by
        where g.cover_image_url is not null
        order by coalesce(g.updated_at, g.created_at, now()) desc
        limit ${limit}
      `
    } else if (supabaseServiceClient) {
      const { data, error } = await supabaseServiceClient
        .from('gardens')
        .select(
          'id, name, created_by, cover_image_url, updated_at, created_at, owner:profiles(display_name)'
        )
        .not('cover_image_url', 'is', null)
        .order('created_at', { ascending: false })
        .limit(limit)
      if (error) throw error
      rows = data || []
    } else {
      return inserted
    }
  } catch (err) {
    console.error('[media] failed to load garden cover entries', err)
    return inserted
  }

  for (const row of rows) {
    const publicUrl = row.cover_image_url || row.coverImageUrl
    if (!publicUrl) continue
    const parsed = parseStoragePublicUrl(publicUrl)
    if (!parsed) continue
    if (parsed.bucket !== gardenCoverUploadBucket) continue
    if (
      gardenCoverUploadPrefix &&
      !parsed.path.startsWith(`${gardenCoverUploadPrefix}/`)
    ) {
      continue
    }
    const key = parsed.bucket && parsed.path ? `${parsed.bucket}/${parsed.path}`.toLowerCase() : null
    if (!key || existingKeys.has(key)) continue
    const ownerId =
      row.owner_id ||
      row.ownerId ||
      row.created_by ||
      row.createdBy ||
      null
    const ownerName =
      row.owner_name ||
      (row.owner && (row.owner.display_name || row.owner.displayName)) ||
      null
    const createdAt =
      row.updated_at ||
      row.updatedAt ||
      row.created_at ||
      row.createdAt ||
      null
    // Transform URL to use media proxy for consistency
    const proxyUrl = supabaseStorageToMediaProxy(publicUrl) || publicUrl
    const recorded = await recordAdminMediaUpload({
      adminId: ownerId,
      adminEmail: null,
      adminName: ownerName,
      bucket: parsed.bucket,
      path: parsed.path,
      publicUrl: proxyUrl,
      mimeType: 'image/webp',
      originalMimeType: 'image/webp',
      sizeBytes: null,
      originalSizeBytes: null,
      quality: gardenCoverWebpQuality,
      compressionPercent: null,
      uploadSource: 'garden_cover',
      metadata: {
        source: 'garden_cover',
        gardenId: row.id || null,
        gardenName: row.name || null,
      },
      createdAt,
    })
    if (recorded) {
      existingKeys.add(key)
      inserted.push(recorded)
    }
  }
  return inserted
}

if (sql) {
  ensureAdminMediaUploadsTable().catch((err) =>
    console.error('[schema] admin_media_uploads ensure failed', err),
  )
}

// Resolve visits table name (default: public.web_visits). Supports alternate names like visit-web.
const VISITS_TABLE_ENV =
  (process.env.VISITS_TABLE ||
    process.env.VISIT_TABLE ||
    process.env.WEB_VISITS_TABLE ||
    'web_visits').trim()

function buildVisitsTableIdentifier() {
  try {
    const t = VISITS_TABLE_ENV || 'web_visits'
    // Allow letters, digits, underscore or hyphen
    if (/^[a-zA-Z0-9_]+$/.test(t)) return `public.${t}`
    if (/^[a-zA-Z0-9_-]+$/.test(t)) return `public."${t}"`
  } catch { }
  return 'public.web_visits'
}
const VISITS_TABLE_SQL_IDENT = buildVisitsTableIdentifier()

// Helper function to get visits table identifier parts for use with sql.identifier()
// Returns [schema, table] array that can be safely used with sql.identifier()
function getVisitsTableIdentifierParts() {
  try {
    const t = VISITS_TABLE_ENV || 'web_visits'
    // Validate table name: allow letters, digits, underscore or hyphen
    if (/^[a-zA-Z0-9_-]+$/.test(t)) {
      return ['public', t]
    }
  } catch { }
  return ['public', 'web_visits']
}

const app = express()
// Trust proxy headers so req.secure and x-forwarded-proto reflect real scheme
try { app.set('trust proxy', true) } catch { }
// Limit JSON body size to 100kb to prevent DoS (large uploads use multer/multipart)
// Was previously 15mb for legacy base64 uploads which are now deprecated
app.use(express.json({ limit: '100kb' }))

// =============================================================================
// CSRF (Cross-Site Request Forgery) Protection
// Used for high-risk operations like password/email changes
// =============================================================================

// CSRF token store: Map of token -> { userId, createdAt, used }
// Tokens expire after 15 minutes and can only be used once
const csrfTokenStore = new Map()
const CSRF_TOKEN_EXPIRY_MS = 15 * 60 * 1000 // 15 minutes
const CSRF_CLEANUP_INTERVAL_MS = 5 * 60 * 1000 // Clean up every 5 minutes

// Cleanup expired tokens periodically
setInterval(() => {
  const now = Date.now()
  for (const [token, data] of csrfTokenStore.entries()) {
    if (now - data.createdAt > CSRF_TOKEN_EXPIRY_MS) {
      csrfTokenStore.delete(token)
    }
  }
}, CSRF_CLEANUP_INTERVAL_MS)

/**
 * Generate a new CSRF token for a user
 * @param userId - The user ID to associate with the token
 * @returns The generated token
 */
function generateCsrfToken(userId) {
  const token = crypto.randomBytes(32).toString('hex')
  csrfTokenStore.set(token, {
    userId: userId || 'anonymous',
    createdAt: Date.now(),
    used: false
  })
  return token
}

/**
 * Validate a CSRF token
 * @param token - The token to validate
 * @param userId - The user ID to match against (optional)
 * @returns { valid: boolean, reason?: string }
 */
function validateCsrfToken(token, userId = null) {
  if (!token) {
    return { valid: false, reason: 'No CSRF token provided' }
  }

  const tokenData = csrfTokenStore.get(token)
  
  if (!tokenData) {
    return { valid: false, reason: 'Invalid or expired CSRF token' }
  }

  // Check if token has expired
  if (Date.now() - tokenData.createdAt > CSRF_TOKEN_EXPIRY_MS) {
    csrfTokenStore.delete(token)
    return { valid: false, reason: 'CSRF token has expired' }
  }

  // Check if token was already used (prevent replay attacks)
  if (tokenData.used) {
    return { valid: false, reason: 'CSRF token has already been used' }
  }

  // If userId provided, verify it matches
  if (userId && tokenData.userId !== 'anonymous' && tokenData.userId !== userId) {
    return { valid: false, reason: 'CSRF token user mismatch' }
  }

  // Mark token as used (one-time use)
  tokenData.used = true
  
  return { valid: true }
}

/**
 * Middleware to require CSRF token validation
 * Expects token in X-CSRF-Token header
 */
function requireCsrfToken(req, res, next) {
  const csrfToken = req.headers['x-csrf-token']
  
  // Get user ID from Authorization header if present
  let userId = null
  const authHeader = req.headers.authorization
  if (authHeader && authHeader.startsWith('Bearer ')) {
    try {
      // Decode JWT to get user ID (without verification - Supabase handles that)
      const token = authHeader.split(' ')[1]
      const payload = JSON.parse(Buffer.from(token.split('.')[1], 'base64').toString())
      userId = payload.sub
    } catch { }
  }

  const validation = validateCsrfToken(csrfToken, userId)
  
  if (!validation.valid) {
    console.warn(`[CSRF] Validation failed: ${validation.reason}`, { 
      path: req.path, 
      ip: req.ip || req.headers['x-forwarded-for'],
      userId 
    })
    return res.status(403).json({ 
      error: 'CSRF validation failed', 
      reason: validation.reason,
      code: 'CSRF_INVALID'
    })
  }

  next()
}

// Global CORS and preflight handling for API routes
app.use((req, res, next) => {
  try {
    const origin = req.headers.origin
    // Allow all origins by default; optionally restrict via CORS_ALLOW_ORIGINS
    const allowList = (process.env.CORS_ALLOW_ORIGINS || '').split(',').map(s => s.trim()).filter(Boolean)
    if (origin) {
      if (allowList.length === 0 || allowList.includes(origin)) {
        res.setHeader('Access-Control-Allow-Origin', allowList.length ? origin : '*')
        res.setHeader('Vary', 'Origin')
      }
    } else {
      res.setHeader('Access-Control-Allow-Origin', '*')
    }
    if (req.path && req.path.startsWith('/api/')) {
      res.setHeader('Access-Control-Allow-Methods', 'GET,POST,PUT,DELETE,OPTIONS')
      res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token, X-CSRF-Token')
      res.setHeader('Access-Control-Expose-Headers', 'X-CSRF-Token')
      if (req.method === 'OPTIONS') {
        res.status(204).end()
        return
      }
    }
  } catch { }
  next()
})

// Catch-all OPTIONS for any /api/* route (defense-in-depth)
app.options('/api/*', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'GET,POST,PUT,DELETE,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token, X-CSRF-Token')
  res.setHeader('Access-Control-Expose-Headers', 'X-CSRF-Token')
  res.setHeader('Access-Control-Allow-Origin', '*')
  res.status(204).end()
})

// Content Security Policy - Allow all *.aphylia.app subdomains EXCEPT for images
// img-src and media-src allow all sources; other directives restrict to aphylia.app domains
const CSP_POLICY = [
  "default-src 'self' *.aphylia.app",
  "script-src 'self' 'unsafe-inline' 'unsafe-eval' *.aphylia.app https://www.googletagmanager.com https://www.google.com https://www.gstatic.com https://recaptchaenterprise.googleapis.com",
  "style-src 'self' 'unsafe-inline' *.aphylia.app https://fonts.googleapis.com",
  "connect-src 'self' *.aphylia.app wss://*.aphylia.app https://*.supabase.co wss://*.supabase.co https://www.google-analytics.com https://analytics.google.com https://region1.google-analytics.com https://recaptchaenterprise.googleapis.com https://www.google.com https://*.sentry.io https://fonts.googleapis.com https://fonts.gstatic.com https://ipapi.co https://geocoding-api.open-meteo.com https://nominatim.openstreetmap.org",
  "font-src 'self' *.aphylia.app https://fonts.gstatic.com data:",
  "frame-src 'self' *.aphylia.app https://www.google.com https://recaptcha.google.com",
  "img-src * data: blob:",
  "media-src * data: blob:",
  "object-src 'none'",
  "base-uri 'self'",
  "form-action 'self' *.aphylia.app",
  "worker-src 'self' *.aphylia.app blob:",
  "manifest-src 'self' *.aphylia.app"
].join('; ')

// Security headers middleware
app.use((_req, res, next) => {
  // Content Security Policy
  res.setHeader('Content-Security-Policy', CSP_POLICY)
  
  // Prevent MIME type sniffing
  res.setHeader('X-Content-Type-Options', 'nosniff')
  
  // Prevent clickjacking (in addition to CSP frame-ancestors)
  res.setHeader('X-Frame-Options', 'SAMEORIGIN')
  
  // XSS protection (legacy browsers)
  res.setHeader('X-XSS-Protection', '1; mode=block')
  
  // Referrer policy - don't leak URLs to external sites
  res.setHeader('Referrer-Policy', 'strict-origin-when-cross-origin')
  
  // Permissions policy - disable unnecessary browser features
  res.setHeader('Permissions-Policy', 'geolocation=(self), camera=(self), microphone=()')
  
  // HSTS - enforce HTTPS (only in production)
  if (process.env.NODE_ENV === 'production') {
    // max-age=31536000 (1 year), includeSubDomains
    res.setHeader('Strict-Transport-Security', 'max-age=31536000; includeSubDomains')
  }
  
  next()
})

// Supabase service client disabled to avoid using service-role env vars
const supabaseAdmin = null

// Composite health: reflect DB status so UI doesn't show green on failures
app.get('/api/health', async (_req, res) => {
  const started = Date.now()
  try {
    let dbOk = false
    let err = null
    if (sql) {
      try {
        const rows = await withTimeout(sql`select 1 as one`, 1000, 'DB_TIMEOUT')
        dbOk = Array.isArray(rows) && rows[0] && Number(rows[0].one) === 1
      } catch (e) {
        err = e?.message || 'query failed'
      }
    }
    res.status(200).json({
      ok: true,
      db: {
        ok: dbOk,
        latencyMs: Date.now() - started,
        error: dbOk ? null : (err || (connectionString ? 'DB_QUERY_FAILED' : 'DB_NOT_CONFIGURED')),
      },
    })
  } catch {
    res.status(200).json({
      ok: true,
      db: { ok: false, latencyMs: Date.now() - started, error: 'HEALTH_CHECK_FAILED' },
    })
  }
})

// =============================================================================
// PWA Manifest Screenshots - Public endpoint for dynamic manifest screenshots
// =============================================================================
// Returns screenshots tagged for PWA manifest use (tag: screenshot)
// Format follows Web App Manifest spec: https://www.w3.org/TR/appmanifest/#screenshots-member
app.get('/api/manifest/screenshots', async (_req, res) => {
  try {
    let rows = []
    if (sql) {
      // Fetch screenshots (tag = 'screenshot') ordered by device type for proper form_factor grouping
      rows = await sql`
        select 
          id, 
          public_url, 
          metadata
        from public.admin_media_uploads 
        where upload_source = 'mockups' 
          and metadata->>'tag' = 'screenshot'
          and public_url is not null
        order by 
          case metadata->>'device'
            when 'phone' then 1
            when 'tablet' then 2
            when 'computer' then 3
            else 4
          end,
          created_at desc
        limit 8
      `
    }
    
    // Transform to PWA manifest screenshot format
    const screenshots = rows.map(row => {
      const device = row.metadata?.device || 'phone'
      // Map device to form_factor (wide for computer/tablet, narrow for phone)
      const formFactor = device === 'phone' ? 'narrow' : 'wide'
      // Default sizes based on device type
      const sizes = device === 'phone' 
        ? '1080x1920' 
        : device === 'tablet'
        ? '2048x1536'
        : '1920x1080'
      
      return {
        src: row.public_url,
        sizes,
        type: 'image/webp',
        form_factor: formFactor,
        label: row.metadata?.displayName || row.metadata?.storageName || 'App Screenshot',
      }
    })
    
    res.json({ screenshots })
  } catch (err) {
    console.error('[manifest/screenshots] failed to fetch screenshots', err)
    res.json({ screenshots: [] })
  }
})

// Full dynamic manifest endpoint - merges static config with dynamic screenshots
app.get('/api/manifest.webmanifest', async (_req, res) => {
  try {
    // Base manifest (matches vite.config.ts)
    const baseManifest = {
      id: 'aphylia',
      name: 'Aphylia',
      short_name: 'Aphylia',
      description: 'Discover, swipe and manage the perfect plants for every garden.',
      lang: 'en',
      theme_color: '#052e16',
      background_color: '#03120c',
      display: 'standalone',
      display_override: ['window-controls-overlay', 'standalone'],
      scope: '/',
      start_url: '/discovery',
      orientation: 'portrait-primary',
      categories: ['productivity', 'lifestyle', 'utilities'],
      iarc_rating_id: 'IARC21-00000000-0000000000000000',
      icons: [
        { src: '/icons/icon-192x192.png', sizes: '192x192', type: 'image/png', purpose: 'any' },
        { src: '/icons/icon-512x512.png', sizes: '512x512', type: 'image/png', purpose: 'any' },
        { src: '/icons/icon-maskable-512.png', sizes: '512x512', type: 'image/png', purpose: 'maskable any' },
        { src: '/icons/plant-swipe-icon.svg', sizes: '512x512', type: 'image/svg+xml', purpose: 'any' },
        { src: '/icons/plant-swipe-icon-outline.svg', sizes: '512x512', type: 'image/svg+xml', purpose: 'any' },
      ],
      shortcuts: [
        { name: 'Swipe plants', url: '/swipe', description: 'Jump directly into swipe mode' },
        { name: 'My gardens', url: '/gardens', description: 'Open your garden dashboard' },
      ],
    }
    
    // Fetch screenshots from database
    let screenshots = []
    if (sql) {
      try {
        const rows = await sql`
          select 
            public_url, 
            metadata
          from public.admin_media_uploads 
          where upload_source = 'mockups' 
            and metadata->>'tag' = 'screenshot'
            and public_url is not null
          order by 
            case metadata->>'device'
              when 'phone' then 1
              when 'tablet' then 2
              when 'computer' then 3
              else 4
            end,
            created_at desc
          limit 8
        `
        screenshots = rows.map(row => {
          const device = row.metadata?.device || 'phone'
          const formFactor = device === 'phone' ? 'narrow' : 'wide'
          const sizes = device === 'phone' 
            ? '1080x1920' 
            : device === 'tablet'
            ? '2048x1536'
            : '1920x1080'
          
          return {
            src: row.public_url,
            sizes,
            type: 'image/webp',
            form_factor: formFactor,
            label: row.metadata?.displayName || row.metadata?.storageName || 'App Screenshot',
          }
        })
      } catch (err) {
        console.error('[manifest] failed to fetch screenshots', err)
      }
    }
    
    // Only add screenshots if we have some
    if (screenshots.length > 0) {
      baseManifest.screenshots = screenshots
    }
    
    res.setHeader('Content-Type', 'application/manifest+json')
    res.setHeader('Cache-Control', 'public, max-age=3600') // Cache for 1 hour
    res.json(baseManifest)
  } catch (err) {
    console.error('[manifest] failed to generate manifest', err)
    res.status(500).json({ error: 'Failed to generate manifest' })
  }
})

// =============================================================================
// CSRF Token Endpoint - Get a fresh CSRF token for security-sensitive operations
// =============================================================================
app.get('/api/csrf-token', (req, res) => {
  // Extract user ID from Authorization header if present
  let userId = null
  const authHeader = req.headers.authorization
  if (authHeader && authHeader.startsWith('Bearer ')) {
    try {
      const token = authHeader.split(' ')[1]
      const payload = JSON.parse(Buffer.from(token.split('.')[1], 'base64').toString())
      userId = payload.sub
    } catch { }
  }

  const csrfToken = generateCsrfToken(userId)
  
  // Also set as a cookie for additional security layer
  res.cookie('csrf_token', csrfToken, {
    httpOnly: false, // Must be readable by JS
    secure: process.env.NODE_ENV === 'production',
    sameSite: 'strict',
    maxAge: CSRF_TOKEN_EXPIRY_MS,
    path: '/'
  })

  res.json({ 
    token: csrfToken,
    expiresIn: CSRF_TOKEN_EXPIRY_MS / 1000 // seconds
  })
})

// Admin: System health stats (CPU, memory, disk, uptime, connections)
app.get('/api/admin/system-health', async (req, res) => {
  try {
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }

    // Get CPU usage (averaged over cores)
    const cpus = os.cpus()
    const cpuCount = cpus.length
    let totalIdle = 0, totalTick = 0
    for (const cpu of cpus) {
      for (const type in cpu.times) {
        totalTick += cpu.times[type]
      }
      totalIdle += cpu.times.idle
    }
    const cpuPercent = 100 - (100 * totalIdle / totalTick)

    // Memory stats
    const totalMem = os.totalmem()
    const freeMem = os.freemem()
    const usedMem = totalMem - freeMem
    const memPercent = (usedMem / totalMem) * 100

    // Disk stats (for root or /home depending on platform)
    let diskStats = null
    try {
      const { promisify } = await import('util')
      const execAsync = promisify(execCb)
      // Try df command for disk usage
      const diskPath = process.platform === 'win32' ? 'C:' : '/'
      const dfResult = await execAsync(`df -B1 ${diskPath} 2>/dev/null || df -k ${diskPath} 2>/dev/null`).catch(() => null)
      if (dfResult && dfResult.stdout) {
        const lines = dfResult.stdout.trim().split('\n')
        if (lines.length >= 2) {
          const parts = lines[1].split(/\s+/)
          if (parts.length >= 4) {
            // df -B1 output: Filesystem 1B-blocks Used Available Use% Mounted
            // df -k output: Filesystem 1K-blocks Used Available Use% Mounted
            const multiplier = dfResult.stdout.includes('1B-blocks') ? 1 : 1024
            const total = parseInt(parts[1], 10) * multiplier
            const used = parseInt(parts[2], 10) * multiplier
            if (!isNaN(total) && !isNaN(used) && total > 0) {
              diskStats = {
                total,
                used,
                percent: (used / total) * 100,
                path: diskPath
              }
            }
          }
        }
      }
    } catch { }

    // Count active HTTP connections (approximation via server connections)
    let activeConnections = 0
    try {
      if (app._httpServer && typeof app._httpServer.getConnections === 'function') {
        activeConnections = await new Promise((resolve) => {
          app._httpServer.getConnections((err, count) => resolve(err ? 0 : count))
        })
      }
    } catch { }

    // Load average (1, 5, 15 min)
    const loadAvg = os.loadavg()

    res.json({
      ok: true,
      uptime: Math.floor(os.uptime()),
      memory: {
        total: totalMem,
        used: usedMem,
        free: freeMem,
        percent: Math.round(memPercent * 10) / 10
      },
      cpu: {
        percent: Math.round(cpuPercent * 10) / 10,
        cores: cpuCount
      },
      disk: diskStats,
      connections: activeConnections,
      loadAvg: loadAvg.map(l => Math.round(l * 100) / 100),
      platform: `${os.platform()} ${os.release()}`,
      nodeVersion: process.version,
      hostname: os.hostname()
    })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to get system health' })
  }
})

// =============================================================================
// MAINTENANCE MODE API - Coordinate Sentry error suppression during restarts
// =============================================================================

// Admin: Get current maintenance mode status
app.get('/api/admin/maintenance-mode', async (req, res) => {
  try {
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    const status = getMaintenanceMode()
    res.json({
      ok: true,
      ...status,
      remainingMs: status.active && status.expiresAt ? Math.max(0, status.expiresAt - Date.now()) : 0
    })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to get maintenance mode status' })
  }
})

// Admin: Enable maintenance mode (suppresses 502/503/504 errors in Sentry)
app.post('/api/admin/maintenance-mode/enable', async (req, res) => {
  try {
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    // Duration in milliseconds (default: 5 minutes, max: 30 minutes)
    const durationMs = Math.min(
      Math.max(Number(req.body?.durationMs) || 300000, 60000), // At least 1 minute
      30 * 60 * 1000 // Max 30 minutes
    )
    const reason = String(req.body?.reason || 'admin-request').slice(0, 100)
    
    const success = enableMaintenanceMode(durationMs, reason)
    if (success) {
      res.json({
        ok: true,
        message: `Maintenance mode enabled for ${durationMs / 1000} seconds`,
        expiresAt: Date.now() + durationMs,
        reason
      })
    } else {
      res.status(500).json({ error: 'Failed to enable maintenance mode' })
    }
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to enable maintenance mode' })
  }
})

// Admin: Disable maintenance mode
app.post('/api/admin/maintenance-mode/disable', async (req, res) => {
  try {
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    
    const success = disableMaintenanceMode()
    if (success) {
      res.json({
        ok: true,
        message: 'Maintenance mode disabled'
      })
    } else {
      res.status(500).json({ error: 'Failed to disable maintenance mode' })
    }
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to disable maintenance mode' })
  }
})

app.options('/api/admin/maintenance-mode', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'GET,OPTIONS')
  res.status(204).end()
})

app.options('/api/admin/maintenance-mode/enable', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.status(204).end()
})

app.options('/api/admin/maintenance-mode/disable', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.status(204).end()
})

// Admin: Get sitemap info (last update time, file size)
app.get('/api/admin/sitemap-info', async (req, res) => {
  try {
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }

    // Check multiple possible sitemap locations
    const sitemapPaths = [
      path.resolve(__dirname, 'public', 'sitemap.xml'),
      path.resolve(__dirname, 'dist', 'sitemap.xml'),
    ]

    let sitemapInfo = null
    for (const sitemapPath of sitemapPaths) {
      try {
        const stats = await fs.stat(sitemapPath)
        if (stats.isFile()) {
          sitemapInfo = {
            path: sitemapPath,
            lastModified: stats.mtime.toISOString(),
            lastModifiedUnix: Math.floor(stats.mtime.getTime() / 1000),
            size: stats.size,
            source: sitemapPath.includes('/dist/') ? 'dist' : 'public'
          }
          break
        }
      } catch {
        // File doesn't exist, try next
      }
    }

    if (!sitemapInfo) {
      res.json({
        ok: true,
        exists: false,
        message: 'Sitemap not found. Run "Regenerate Sitemap" to create it.'
      })
      return
    }

    // Try to count URLs in the sitemap
    let urlCount = null
    try {
      const content = await fs.readFile(sitemapInfo.path, 'utf-8')
      const matches = content.match(/<url>/g)
      urlCount = matches ? matches.length : 0
    } catch {
      // Ignore read errors
    }

    res.json({
      ok: true,
      exists: true,
      lastModified: sitemapInfo.lastModified,
      lastModifiedUnix: sitemapInfo.lastModifiedUnix,
      size: sitemapInfo.size,
      source: sitemapInfo.source,
      urlCount
    })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to get sitemap info' })
  }
})

// Admin: fetch admin activity logs for the last N days (default 30)
app.get('/api/admin/admin-logs', async (req, res) => {
  try {
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    const daysParam = Number(req.query.days || 30)
    const days = (Number.isFinite(daysParam) && daysParam > 0) ? Math.min(90, Math.floor(daysParam)) : 30
    if (!sql) {
      // Supabase REST fallback
      if (!(supabaseUrlEnv && supabaseAnonKey)) {
        res.status(500).json({ error: 'Database not configured' })
        return
      }
      const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
      const token = getBearerTokenFromRequest(req)
      if (token) headers['Authorization'] = `Bearer ${token}`
      const sinceIso = new Date(Date.now() - days * 24 * 60 * 60 * 1000).toISOString()
      const url = `${supabaseUrlEnv}/rest/v1/admin_activity_logs?occurred_at=gte.${encodeURIComponent(sinceIso)}&select=occurred_at,admin_id,admin_name,action,target,detail&order=occurred_at.desc&limit=1000`
      const r = await fetch(url, { headers })
      if (!r.ok) {
        const body = await r.text().catch(() => '')
        res.status(r.status).json({ error: body || 'Failed to load logs' })
        return
      }
      const arr = await r.json().catch(() => [])
      res.json({ ok: true, logs: Array.isArray(arr) ? arr : [], via: 'supabase' })
      return
    }
    const rows = await sql`
      select occurred_at, admin_id, admin_name, action, target, detail
      from public.admin_activity_logs
      where occurred_at >= (now() - make_interval(days => ${days}))
      order by occurred_at desc
      limit 2000
    `
    res.json({ ok: true, logs: Array.isArray(rows) ? rows : [], via: 'database' })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to load admin logs' })
  }
})

// Admin/Editor: AI plant name verification
app.post('/api/admin/ai/plant-fill/verify-name', async (req, res) => {
  try {
    const caller = await ensureEditor(req, res)
    if (!caller) return
    if (!openaiClient) {
      res.status(503).json({ error: 'AI plant fill is not configured' })
      return
    }
    const body = req.body || {}
    const plantName = typeof body.plantName === 'string' ? body.plantName.trim() : ''
    if (!plantName) {
      res.status(400).json({ error: 'Plant name is required' })
      return
    }
    const result = await verifyPlantNameCandidate(plantName)
    res.json({ success: true, isPlant: result.isPlant, reason: result.reason })
  } catch (err) {
    console.error('[server] AI plant name verification failed:', err)
    if (!res.headersSent) {
      res.status(500).json({ error: err?.message || 'Failed to verify plant name' })
    }
  }
})
app.options('/api/admin/ai/plant-fill/verify-name', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

// Admin/Editor: Get English plant name from any language
app.post('/api/admin/ai/plant-fill/english-name', async (req, res) => {
  try {
    const caller = await ensureEditor(req, res)
    if (!caller) return
    if (!openaiClient) {
      res.status(503).json({ error: 'AI plant fill is not configured' })
      return
    }
    const body = req.body || {}
    const plantName = typeof body.plantName === 'string' ? body.plantName.trim() : ''
    if (!plantName) {
      res.status(400).json({ error: 'Plant name is required' })
      return
    }
    
    // Ask AI to identify the English common name of the plant
    // IMPORTANT: Preserve cultivar names, subspecies, and variety information
    const instructions = `You are a botanist expert. Your task is to identify plants and provide their English name while PRESERVING all botanical specificity.

Given a plant name in ANY language (scientific name, common name in French, Spanish, German, etc.), 
return the ENGLISH name for that plant, keeping ALL specific details like cultivar names, subspecies, and varieties.

Rules:
1. PRESERVE cultivar names (e.g., 'Monstera deliciosa Thai Constellation' stays as 'Monstera Thai Constellation', NOT simplified to 'Monstera')
2. PRESERVE subspecies and variety names (e.g., 'Rosa gallica var. officinalis' becomes 'Apothecary Rose' or 'Rosa gallica officinalis', NOT just 'Rose')
3. If the input is already a specific English name with cultivar/variety, return it as-is (possibly corrected for spelling)
4. If the input is a scientific/Latin name with subspecies/cultivar, translate to English equivalent BUT KEEP the specific cultivar/variety name
5. If the input is a name in another language, translate/identify the English equivalent while keeping specificity
6. DO NOT simplify to the most common/generic name - keep the EXACT variety/cultivar specified
7. If you cannot identify the specific variety, return the original name unchanged
8. Return ONLY the plant name, nothing else - no explanations, no quotes, no JSON

Examples:
- "Monstera deliciosa Thai Constellation" â†’ "Monstera Thai Constellation" (NOT "Monstera" or "Swiss Cheese Plant")
- "Philodendron Pink Princess" â†’ "Philodendron Pink Princess" (NOT "Philodendron")
- "Rosa 'Peace'" â†’ "Peace Rose" (NOT "Rose")
- "Lavandula angustifolia 'Hidcote'" â†’ "Hidcote Lavender" (NOT "Lavender")
- "Tomate cerise" â†’ "Cherry Tomato" (translating but not simplifying)`

    const prompt = `What is the English name for this plant, preserving any cultivar or variety specificity: "${plantName}"?`
    
    const response = await openaiClient.responses.create({
      model: openaiModelNano,
      reasoning: { effort: 'low' },
      instructions,
      input: prompt,
    })
    
    const englishName = (response.output_text || plantName).trim()
    
    // Clean up the response - remove quotes, periods, etc.
    const cleanedName = englishName
      .replace(/^["']|["']$/g, '')  // Remove surrounding quotes
      .replace(/\.$/, '')           // Remove trailing period
      .trim()
    
    console.log(`[server] English name lookup: "${plantName}" -> "${cleanedName}"`)
    
    res.json({ 
      success: true, 
      originalName: plantName,
      englishName: cleanedName,
      wasTranslated: plantName.toLowerCase() !== cleanedName.toLowerCase()
    })
  } catch (err) {
    console.error('[server] AI English name lookup failed:', err)
    if (!res.headersSent) {
      res.status(500).json({ error: err?.message || 'Failed to get English plant name' })
    }
  }
})
app.options('/api/admin/ai/plant-fill/english-name', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

// Admin/Editor: AI-assisted plant data fill
app.post('/api/admin/ai/plant-fill', async (req, res) => {
  try {
    const caller = await ensureEditor(req, res)
    if (!caller) return
    if (!openaiClient) {
      res.status(503).json({ error: 'AI plant fill is not configured' })
      return
    }

    const body = req.body || {}
    const plantName = typeof body.plantName === 'string' ? body.plantName.trim() : ''
    if (!plantName) {
      res.status(400).json({ error: 'Plant name is required' })
      return
    }

    const schema = body.schema
    if (!schema || typeof schema !== 'object' || Array.isArray(schema)) {
      res.status(400).json({ error: 'Valid schema object is required' })
      return
    }

    const sanitizedSchemaRaw = sanitizeTemplate(schema)
    if (!sanitizedSchemaRaw || Array.isArray(sanitizedSchemaRaw) || typeof sanitizedSchemaRaw !== 'object') {
      res.status(400).json({ error: 'Invalid schema provided' })
      return
    }
    const sanitizedSchema = sanitizedSchemaRaw
    const schemaBlueprint = schemaToBlueprint(sanitizedSchema)

    const canUseExisting = body.existingData && typeof body.existingData === 'object' && !Array.isArray(body.existingData)
    const existingDataRaw = canUseExisting ? stripDisallowedKeys(body.existingData) || {} : {}

    const aggregated = {}

    // Prepare all field tasks
    const fieldTasks = Object.keys(schemaBlueprint)
      .filter((fieldKey) => sanitizedSchema[fieldKey])
      .map((fieldKey) => {
        const fieldSchema = sanitizedSchema[fieldKey]
        const existingFieldRaw =
          existingDataRaw && typeof existingDataRaw === 'object'
            ? existingDataRaw[fieldKey]
            : undefined
        const existingFieldClean =
          existingFieldRaw !== undefined ? removeNullValues(existingFieldRaw) : undefined
        return { fieldKey, fieldSchema, existingFieldClean }
      })

    // Process fields one by one (sequential)
    for (const { fieldKey, fieldSchema, existingFieldClean } of fieldTasks) {
      try {
        const fieldValue = await generateFieldData({
          plantName,
          fieldKey,
          fieldSchema,
          existingField: existingFieldClean,
        })

        const cleanedField =
          fieldValue !== undefined ? removeNullValues(fieldValue) : undefined
        if (cleanedField !== undefined) {
          aggregated[fieldKey] = removeExternalIds(cleanedField)
        } else {
          delete aggregated[fieldKey]
        }
      } catch (err) {
        console.error(`[server] AI fill failed for field "${fieldKey}":`, err?.message || err)
        // Continue with next field on error
      }
    }

    let plantData = ensureStructure(schemaBlueprint, aggregated)
    plantData = stripDisallowedKeys(plantData)
    plantData = mergePreferExisting(plantData, existingDataRaw)
    plantData = ensureStructure(schemaBlueprint, plantData)
    plantData = stripDisallowedKeys(plantData)
    const cleanedPlantData = removeNullValues(plantData)
    if (cleanedPlantData && typeof cleanedPlantData === 'object' && !Array.isArray(cleanedPlantData)) {
      plantData = cleanedPlantData
    }

    if (!plantData || typeof plantData !== 'object' || Array.isArray(plantData)) {
      throw new Error('AI output could not be transformed into a plant record')
    }

    const plantObject = removeExternalIds(plantData)
    if (!('meta' in plantObject) || typeof plantObject.meta !== 'object' || plantObject.meta === null || Array.isArray(plantObject.meta)) {
      plantObject.meta = {}
    }
    const metaObject = plantObject.meta
    if (!metaObject.funFact || (typeof metaObject.funFact === 'string' && metaObject.funFact.trim().length === 0)) {
      metaObject.funFact = `Symbolic meaning information for ${plantName} is currently not well documented; please supplement this entry with future research.`
    }

    res.json({ success: true, data: plantObject, model: openaiModel })
  } catch (err) {
    console.error('[server] AI plant fill failed:', err)
    if (!res.headersSent) {
      res.status(500).json({ error: err?.message || 'Failed to fill plant data' })
    }
  }
})
app.options('/api/admin/ai/plant-fill', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})
app.options('/api/admin/ai/plant-fill/field', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

app.post('/api/admin/ai/plant-fill/field', async (req, res) => {
  try {
    const caller = await ensureEditor(req, res)
    if (!caller) return
    if (!openaiClient) {
      res.status(503).json({ error: 'AI plant fill is not configured' })
      return
    }

    const body = req.body || {}
    const plantName = typeof body.plantName === 'string' ? body.plantName.trim() : ''
    const fieldKey = typeof body.fieldKey === 'string' ? body.fieldKey.trim() : ''
    if (!plantName || !fieldKey) {
      res.status(400).json({ error: 'Plant name and field key are required' })
      return
    }

    const schema = body.schema
    if (!schema || typeof schema !== 'object' || Array.isArray(schema)) {
      res.status(400).json({ error: 'Valid schema object is required' })
      return
    }

    const sanitizedSchemaRaw = sanitizeTemplate(schema)
    if (!sanitizedSchemaRaw || Array.isArray(sanitizedSchemaRaw) || typeof sanitizedSchemaRaw !== 'object') {
      res.status(400).json({ error: 'Invalid schema provided' })
      return
    }

    const sanitizedSchema = sanitizedSchemaRaw
    const fieldSchema = sanitizedSchema[fieldKey]
    if (!fieldSchema) {
      res.status(400).json({ error: `Schema for field "${fieldKey}" not found` })
      return
    }

    const existingFieldRaw = body.existingField
    let existingField = existingFieldRaw
    if (existingFieldRaw && typeof existingFieldRaw === 'object') {
      existingField = stripDisallowedKeys({ [fieldKey]: existingFieldRaw })?.[fieldKey]
    }
    const existingFieldClean =
      existingField !== undefined ? removeNullValues(existingField) : undefined

    const fieldValue = await generateFieldData({
      plantName,
      fieldKey,
      fieldSchema,
      existingField: existingFieldClean,
    })

    const cleanedValue = fieldValue !== undefined ? removeNullValues(fieldValue) : undefined
    const sanitizedValue = cleanedValue !== undefined ? removeExternalIds(cleanedValue) : undefined

    res.json({
      success: true,
      field: fieldKey,
      data: sanitizedValue ?? null,
    })
  } catch (err) {
    console.error('[server] AI plant field fill failed:', err)
    if (!res.headersSent) {
      res.status(500).json({ error: err?.message || 'Failed to fill field' })
    }
  }
})

// Admin/Editor: Batch AI plant field fill - process multiple fields in parallel
app.options('/api/admin/ai/plant-fill/batch', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

app.post('/api/admin/ai/plant-fill/batch', async (req, res) => {
  try {
    const caller = await ensureEditor(req, res)
    if (!caller) return
    if (!openaiClient) {
      res.status(503).json({ error: 'AI plant fill is not configured' })
      return
    }

    const body = req.body || {}
    const plantName = typeof body.plantName === 'string' ? body.plantName.trim() : ''
    const fieldKeys = Array.isArray(body.fieldKeys) ? body.fieldKeys.filter(k => typeof k === 'string' && k.trim()) : []
    
    if (!plantName) {
      res.status(400).json({ error: 'Plant name is required' })
      return
    }
    if (!fieldKeys.length) {
      res.status(400).json({ error: 'At least one field key is required' })
      return
    }
    if (fieldKeys.length > 6) {
      res.status(400).json({ error: 'Maximum 6 fields per batch request' })
      return
    }

    const schema = body.schema
    if (!schema || typeof schema !== 'object' || Array.isArray(schema)) {
      res.status(400).json({ error: 'Valid schema object is required' })
      return
    }

    const sanitizedSchemaRaw = sanitizeTemplate(schema)
    if (!sanitizedSchemaRaw || Array.isArray(sanitizedSchemaRaw) || typeof sanitizedSchemaRaw !== 'object') {
      res.status(400).json({ error: 'Invalid schema provided' })
      return
    }

    const sanitizedSchema = sanitizedSchemaRaw
    const existingDataRaw = body.existingData && typeof body.existingData === 'object' && !Array.isArray(body.existingData)
      ? stripDisallowedKeys(body.existingData) || {}
      : {}

    // Process all fields in parallel
    const results = await Promise.allSettled(
      fieldKeys.map(async (fieldKey) => {
        const fieldSchema = sanitizedSchema[fieldKey]
        if (!fieldSchema) {
          throw new Error(`Schema for field "${fieldKey}" not found`)
        }

        const existingFieldRaw = existingDataRaw[fieldKey]
        let existingField = existingFieldRaw
        if (existingFieldRaw && typeof existingFieldRaw === 'object') {
          existingField = stripDisallowedKeys({ [fieldKey]: existingFieldRaw })?.[fieldKey]
        }
        const existingFieldClean = existingField !== undefined ? removeNullValues(existingField) : undefined

        const fieldValue = await generateFieldData({
          plantName,
          fieldKey,
          fieldSchema,
          existingField: existingFieldClean,
        })

        const cleanedValue = fieldValue !== undefined ? removeNullValues(fieldValue) : undefined
        const sanitizedValue = cleanedValue !== undefined ? removeExternalIds(cleanedValue) : undefined

        return { fieldKey, data: sanitizedValue ?? null }
      })
    )

    // Aggregate results
    const fieldsData = {}
    const errors = {}
    
    for (let i = 0; i < fieldKeys.length; i++) {
      const fieldKey = fieldKeys[i]
      const result = results[i]
      
      if (result.status === 'fulfilled') {
        fieldsData[fieldKey] = result.value.data
      } else {
        errors[fieldKey] = result.reason?.message || 'Unknown error'
        console.error(`[server] AI batch fill failed for field "${fieldKey}":`, result.reason?.message || result.reason)
      }
    }

    res.json({
      success: true,
      data: fieldsData,
      errors: Object.keys(errors).length > 0 ? errors : undefined,
    })
  } catch (err) {
    console.error('[server] AI plant batch fill failed:', err)
    if (!res.headersSent) {
      res.status(500).json({ error: err?.message || 'Failed to fill fields' })
    }
  }
})

// Admin: generic log endpoint to record an action from admin_api or UI
app.post('/api/admin/log-action', async (req, res) => {
  try {
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    const body = req.body || {}
    const action = typeof body.action === 'string' ? body.action.trim() : ''
    if (!action) {
      res.status(400).json({ error: 'action required' })
      return
    }
    const target = (body.target == null || typeof body.target === 'string') ? body.target : String(body.target)
    const detail = (body.detail && typeof body.detail === 'object') ? body.detail : {}

    let adminId = null
    let adminName = null
    try {
      const caller = await getUserFromRequest(req)
      adminId = caller?.id || null
      // Resolve admin display name for clearer logs
      if (sql && adminId) {
        try {
          const rows = await sql`select coalesce(display_name, '') as name from public.profiles where id = ${adminId} limit 1`
          adminName = (rows?.[0]?.name || '').trim() || null
        } catch { }
      }
      if (!adminName && supabaseUrlEnv && supabaseAnonKey && adminId) {
        try {
          const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
          const bearer = getBearerTokenFromRequest(req)
          if (bearer) headers['Authorization'] = `Bearer ${bearer}`
          const url = `${supabaseUrlEnv}/rest/v1/profiles?id=eq.${encodeURIComponent(adminId)}&select=display_name&limit=1`
          const r = await fetch(url, { headers })
          if (r.ok) {
            const arr = await r.json().catch(() => [])
            adminName = Array.isArray(arr) && arr[0] ? (arr[0].display_name || null) : null
          }
        } catch { }
      }
    } catch { }

    let ok = false
    if (sql) {
      try {
        // Cast to expected types to avoid parameter type ambiguity
        await sql`
          insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail)
          values (${adminId || null}::uuid, ${adminName || null}::text, ${action}::text, ${target || null}::text, ${sql.json(detail)})
        `
        ok = true
      } catch { }
    }
    if (!ok) {
      try {
        const row = { admin_id: adminId, admin_name: adminName, action, target: target || null, detail }
        ok = await insertAdminActivityViaRest(req, row)
      } catch { }
    }
    if (!ok) {
      res.status(500).json({ error: 'Failed to log action' })
      return
    }
    res.json({ ok: true })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to log action' })
  }
})
app.options('/api/admin/log-action', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

const contactScreenshotUploadMulter = multer({
  storage: multer.memoryStorage(),
  limits: { fileSize: 5 * 1024 * 1024 }, // 5MB
})
const singleContactScreenshotUpload = contactScreenshotUploadMulter.single('file')
const contactScreenshotPrefix = 'contact/screenshots'

app.post('/api/contact/upload-screenshot', async (req, res) => {
  try {
    const user = await getUserFromRequest(req)
    if (!user?.id) {
      res.status(401).json({ error: 'Unauthorized' })
      return
    }

    singleContactScreenshotUpload(req, res, (err) => {
      if (err) {
        const message = err.code === 'LIMIT_FILE_SIZE'
          ? 'File too large. Max 5MB.'
          : err.message || 'Upload failed'
        res.status(400).json({ error: message })
        return
      }

      ;(async () => {
        const file = req.file
        if (!file) {
          res.status(400).json({ error: 'Missing file' })
          return
        }

        // Optimize - use standard 50% quality for non-admin uploads
        const contactScreenshotQuality = 50
        let buffer
        try {
          buffer = await sharp(file.buffer)
            .resize({ width: 1920, height: 1080, fit: 'inside', withoutEnlargement: true })
            .webp({ quality: contactScreenshotQuality })
            .toBuffer()
        } catch (e) {
          res.status(400).json({ error: 'Invalid image file' })
          return
        }

        const unique = crypto.randomUUID()
        const path = `${contactScreenshotPrefix}/${user.id}/${unique}.webp`

        try {
          // Contact screenshots go to PHOTOS bucket (not UTILITY)
          const { error: uploadError } = await supabaseServiceClient.storage
            .from('PHOTOS')
            .upload(path, buffer, {
              contentType: 'image/webp',
              cacheControl: '3600',
              upsert: false
            })

          if (uploadError) throw uploadError

          const { data: publicData } = supabaseServiceClient.storage
            .from('PHOTOS')
            .getPublicUrl(path)

          // Use media proxy
          const proxyUrl = supabaseStorageToMediaProxy(publicData.publicUrl)

          // Record to global image database
          let uploaderDisplayName = null
          try {
            uploaderDisplayName = await getAdminProfileName(user.id)
          } catch { }
          
          try {
            await recordAdminMediaUpload({
              adminId: user.id,
              adminEmail: user.email || null,
              adminName: uploaderDisplayName,
              bucket: 'PHOTOS',
              path: path,
              publicUrl: proxyUrl,
              mimeType: 'image/webp',
              originalMimeType: file.mimetype || 'image/unknown',
              sizeBytes: buffer.length,
              originalSizeBytes: file.size,
              quality: contactScreenshotQuality,
              compressionPercent: file.size > 0 ? Math.max(0, Math.round(100 - (buffer.length / file.size) * 100)) : 0,
              uploadSource: 'contact_screenshot',
              metadata: {
                source: 'contact_screenshot',
                originalName: file.originalname,
                userId: user.id,
              },
              createdAt: new Date().toISOString(),
            })
          } catch (recordErr) {
            console.error('[contact-upload] failed to record media upload', recordErr)
          }

          res.json({ url: proxyUrl })
        } catch (e) {
          console.error('[contact-upload] upload failed', e)
          res.status(500).json({ error: 'Storage upload failed' })
        }
      })().catch(e => {
        console.error('[contact-upload] unexpected error', e)
        res.status(500).json({ error: 'Unexpected error' })
      })
    })
  } catch (e) {
    res.status(500).json({ error: 'Server error' })
  }
})

app.post('/api/contact/delete-screenshot', async (req, res) => {
  try {
    const user = await getUserFromRequest(req)
    if (!user?.id) {
      res.status(401).json({ error: 'Unauthorized' })
      return
    }

    const { url } = req.body
    if (!url) {
      res.status(400).json({ error: 'URL required' })
      return
    }

    const info = parseStoragePublicUrl(url)
    if (!info || info.bucket !== 'PHOTOS') {
      // Just ignore if it doesn't match our bucket, claim success
      res.json({ ok: true })
      return
    }

    // Check path prefix to ensure user can only delete their own screenshots
    if (!info.path.startsWith(`${contactScreenshotPrefix}/${user.id}/`)) {
      res.status(403).json({ error: 'Permission denied for this file' })
      return
    }

    const { error } = await supabaseServiceClient.storage
      .from('PHOTOS')
      .remove([info.path])

    if (error) {
      console.error('[contact-delete] delete failed', error)
      // Don't fail the request if delete fails, it's just cleanup
    }

    res.json({ ok: true })

  } catch (e) {
    res.status(500).json({ error: 'Server error' })
  }
})

// Database health: returns ok along with latency; always 200 for easier probes
app.get('/api/health/db', async (_req, res) => {
  const started = Date.now()
  try {
    if (!sql) {
      // Fallback: try Supabase reachability via anon client
      if (supabaseServer) {
        try {
          const { error } = await supabaseServer.from('plants').select('id', { head: true, count: 'exact' }).limit(1)
          const ok = !error
          res.status(200).json({ ok, latencyMs: Date.now() - started, via: 'supabase' })
          return
        } catch { }
      }
      res.status(200).json({
        ok: false,
        error: 'Database not configured',
        errorCode: 'DB_NOT_CONFIGURED',
        latencyMs: Date.now() - started,
      })
      return
    }
    const rows = await sql`select 1 as one`
    const ok = Array.isArray(rows) && rows[0] && Number(rows[0].one) === 1
    res.status(200).json({ ok, latencyMs: Date.now() - started })
  } catch (e) {
    res.status(200).json({
      ok: false,
      latencyMs: Date.now() - started,
      error: e?.message || 'query failed',
      errorCode: 'DB_QUERY_FAILED',
    })

  }
})

// Runtime environment injector for client (exposes safe VITE_* only)
// Serve on both /api/env.js and /env.js to be resilient to proxy rules.
// Some static hosts might hijack /env.js and serve index.html; prefer /api/env.js in index.html.
app.get(['/api/env.js', '/env.js'], (_req, res) => {
  try {
    const disablePwaEnv = String(process.env.VITE_DISABLE_PWA || process.env.DISABLE_PWA || process.env.PWA_DISABLED || '').trim()
    const env = {
      VITE_SUPABASE_URL: process.env.VITE_SUPABASE_URL || process.env.REACT_APP_SUPABASE_URL || process.env.NEXT_PUBLIC_SUPABASE_URL || '',
      VITE_SUPABASE_ANON_KEY: process.env.VITE_SUPABASE_ANON_KEY || process.env.REACT_APP_SUPABASE_ANON_KEY || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY || process.env.SUPABASE_ANON_KEY || '',
      VITE_ADMIN_STATIC_TOKEN: process.env.VITE_ADMIN_STATIC_TOKEN || process.env.ADMIN_STATIC_TOKEN || '',
      VITE_ADMIN_PUBLIC_MODE: String(process.env.VITE_ADMIN_PUBLIC_MODE || process.env.ADMIN_PUBLIC_MODE || '').toLowerCase() === 'true',
      VITE_DISABLE_PWA: disablePwaEnv,
      VITE_VAPID_PUBLIC_KEY: process.env.VITE_VAPID_PUBLIC_KEY || process.env.VAPID_PUBLIC_KEY || '',
    }
    const js = `window.__ENV__ = ${JSON.stringify(env).replace(/</g, '\\u003c')};\n`
    res.setHeader('Content-Type', 'application/javascript; charset=utf-8')
    res.setHeader('Cache-Control', 'no-store')
    res.send(js)
  } catch (e) {
    res.setHeader('Content-Type', 'application/javascript; charset=utf-8')
    res.setHeader('Cache-Control', 'no-store')
    res.send('window.__ENV__ = {}')
  }
})

// ==== Helpers: cookie/session/ip/geo ====
function parseCookies(headerValue) {
  const cookies = {}
  if (!headerValue) return cookies
  const parts = headerValue.split(';')
  for (const part of parts) {
    const idx = part.indexOf('=')
    if (idx > -1) {
      const k = part.slice(0, idx).trim()
      const v = part.slice(idx + 1).trim()
      if (k) cookies[k] = decodeURIComponent(v)
    }
  }
  return cookies
}

function getOrSetSessionId(req, res) {
  const COOKIE_NAME = 'ps_sid'
  const cookies = parseCookies(req.headers.cookie || '')
  let sid = cookies[COOKIE_NAME]
  if (!sid || sid.length < 8) {
    sid = crypto.randomBytes(16).toString('hex')
    // Mark cookie Secure only when the original request is HTTPS
    const xfProto = (req.headers['x-forwarded-proto'] || '').toString().toLowerCase()
    const isHttps = xfProto.includes('https') || (req.secure === true) || (req.protocol === 'https')
    const forceSecure = String(process.env.FORCE_SECURE_COOKIES || '').toLowerCase() === 'true'
    const secure = forceSecure || isHttps
    const attrs = [
      `${COOKIE_NAME}=${encodeURIComponent(sid)}`,
      'Path=/',
      'SameSite=Lax',
      `Max-Age=${60 * 60 * 24 * 180}`,
      secure ? 'Secure' : '',
    ].filter(Boolean)
    res.append('Set-Cookie', attrs.join('; '))
  }
  return sid
}

// Normalize various proxy/IP header formats into a canonical representation
function normalizeIp(ip) {
  try {
    if (!ip) return ''
    let out = String(ip).trim()
    // Remove square brackets around IPv6 literals if present
    if (out.startsWith('[') && out.endsWith(']')) {
      out = out.slice(1, -1)
    }
    // Strip port suffix from IPv4 "a.b.c.d:port" or IPv6 ":port"
    // Do not naively split on ':' because IPv6 uses ':' as part of the address
    const lastColon = out.lastIndexOf(':')
    const lastRightBracket = out.lastIndexOf(']')
    if (lastColon > -1 && lastRightBracket === -1 && out.indexOf('.') > -1) {
      // Looks like IPv4 with port
      const maybePort = out.slice(lastColon + 1)
      if (/^\d{1,5}$/.test(maybePort)) {
        out = out.slice(0, lastColon)
      }
    }
    // Handle IPv6-mapped IPv4 addresses like ::ffff:127.0.0.1
    const v4mapped = out.match(/::ffff:(\d{1,3}(?:\.\d{1,3}){3})/i)
    if (v4mapped) out = v4mapped[1]
    const lower = out.toLowerCase()
    return net.isIP(lower) ? lower : ''
  } catch {
    return ''
  }
}

function getClientIp(req) {
  const h = req.headers
  // Prefer the first IP in X-Forwarded-For when present (left-most is original client)
  const xff = (h['x-forwarded-for'] || h['X-Forwarded-For'] || '').toString()
  if (xff) return normalizeIp(xff.split(',')[0].trim())
  // Common CDN / proxy specific headers
  const cf = (h['cf-connecting-ip'] || h['CF-Connecting-IP'] || '').toString()
  if (cf) return normalizeIp(cf)
  const trueClient = (h['true-client-ip'] || h['True-Client-IP'] || '').toString()
  if (trueClient) return normalizeIp(trueClient)
  const fastly = (h['fastly-client-ip'] || h['Fastly-Client-IP'] || '').toString()
  if (fastly) return normalizeIp(fastly)
  const xClientIp = (h['x-client-ip'] || h['X-Client-IP'] || '').toString()
  if (xClientIp) return normalizeIp(xClientIp)
  // Finally, fall back to X-Real-IP set by upstream (e.g., nginx) or the socket address
  const real = (h['x-real-ip'] || h['X-Real-IP'] || '').toString()
  if (real) return normalizeIp(real)
  return normalizeIp(req.ip || req.connection?.remoteAddress || '')
}

const htmlEscapeMap = {
  '&': '&amp;',
  '<': '&lt;',
  '>': '&gt;',
  '"': '&quot;',
  "'": '&#39;',
}

function escapeHtml(value) {
  if (value === null || value === undefined) return ''
  return String(value).replace(/[&<>"']/g, (ch) => htmlEscapeMap[ch] || ch)
}

/**
 * Replaces {{variables}} in a string with values from a context object.
 * @param {string} str - The template string
 * @param {object} context - Map of variable names to values
 * @param {boolean} escape - Whether to HTML-escape the values (default: false)
 */
function replaceTemplateVariables(str, context, escape = false) {
  return (str || '').replace(/\{\{\s*([a-zA-Z0-9_]+)\s*\}\}/g, (_, k) => {
    const val = context[k.toLowerCase()]
    if (val === undefined || val === null) return `{{${k}}}`
    return escape ? escapeHtml(String(val)) : String(val)
  })
}

function isContactRateLimited(key) {
  const now = Date.now()
  const windowMs = Number(process.env.CONTACT_FORM_WINDOW_MS || 5 * 60 * 1000)
  const limit = Number(process.env.CONTACT_FORM_MAX_ATTEMPTS || 5)
  const history = contactRateLimitStore.get(key) || []
  const recent = history.filter((ts) => now - ts < windowMs)
  if (recent.length >= limit) {
    contactRateLimitStore.set(key, recent)
    return true
  }
  recent.push(now)
  contactRateLimitStore.set(key, recent)
  return false
}

const CONTACT_AUDIENCES = new Set(['support', 'business'])

function normalizeContactAudience(value) {
  if (typeof value !== 'string') return 'support'
  const normalized = value.trim().toLowerCase()
  return CONTACT_AUDIENCES.has(normalized) ? normalized : 'support'
}

async function dispatchSupportEmail({ name, email, subject, message, audience = 'support' }) {
  const normalizedAudience = normalizeContactAudience(audience)
  const targets = normalizedAudience === 'business'
    ? (businessEmailTargets.length ? businessEmailTargets : [DEFAULT_BUSINESS_EMAIL])
    : (supportEmailTargets.length ? supportEmailTargets : [DEFAULT_SUPPORT_EMAIL])
  const fromAddress = normalizedAudience === 'business' ? businessEmailFrom : supportEmailFrom
  const safeName = name ? name.slice(0, 200) : ''
  const safeSubject = subject && subject.trim() ? subject.trim().slice(0, 180) : null
  const sanitizedMessage = (message || '').replace(/\r\n/g, '\n').slice(0, 5000)
  const plainText = [
    `New ${normalizedAudience} contact form submission`,
    '',
    `Name: ${safeName || 'N/A'}`,
    `Email: ${email || 'N/A'}`,
    `Audience: ${normalizedAudience}`,
    `Delivered to: ${targets.join(', ')}`,
    '',
    sanitizedMessage || 'No additional message provided.',
  ].join('\n')
  const htmlBody = [
    `<h2 style="font-family:system-ui,sans-serif;margin:0 0 12px;">New ${normalizedAudience} contact form submission</h2>`,
    `<p style="font-family:system-ui,sans-serif;margin:0 0 8px;"><strong>Name:</strong> ${escapeHtml(safeName) || 'N/A'}</p>`,
    `<p style="font-family:system-ui,sans-serif;margin:0 0 16px;"><strong>Email:</strong> ${escapeHtml(email || '') || 'N/A'}</p>`,
    `<p style="font-family:system-ui,sans-serif;margin:0 0 8px;"><strong>Audience:</strong> ${escapeHtml(normalizedAudience)}</p>`,
    `<p style="font-family:system-ui,sans-serif;margin:0 0 16px;"><strong>Delivered to:</strong> ${escapeHtml(targets.join(', '))}</p>`,
    `<p style="font-family:system-ui,sans-serif;margin:0;">${escapeHtml(sanitizedMessage || 'No additional message provided.').replace(/\n/g, '<br />')}</p>`,
  ].join('')
  const finalSubject = safeSubject || `Contact form message from ${safeName || email || 'Aphylia user'}`

  if (resendApiKey) {
    const payload = {
      from: fromAddress,
      to: targets,
      subject: finalSubject,
      text: plainText,
      html: htmlBody,
    }
    if (email) payload.reply_to = email
    const resp = await fetch('https://api.resend.com/emails', {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${resendApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(payload),
    })
    if (!resp.ok) {
      const text = await resp.text().catch(() => '')
      throw new Error(text || `Resend API error (${resp.status})`)
    }
    return
  }

  if (supportEmailWebhook) {
    const resp = await fetch(supportEmailWebhook, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        to: targets,
        subject: finalSubject,
        text: plainText,
        html: htmlBody,
        replyTo: email || null,
        audience: normalizedAudience,
      }),
    })
    if (!resp.ok) {
      const text = await resp.text().catch(() => '')
      throw new Error(text || `Webhook delivery failed (${resp.status})`)
    }
    return
  }

  throw new Error('Email delivery not configured')
}

function getGeoFromHeaders(req) {
  const h = req.headers
  // Country detection from common providers (normalize to upper-case when likely a code)
  const vercelCountry = (h['x-vercel-ip-country'] || '').toString()
  const cfCountry = (h['cf-ipcountry'] || '').toString()
  const geoCountry = (h['x-geo-country'] || '').toString()
  const cfViewerCountry = (h['cloudfront-viewer-country'] || h['CloudFront-Viewer-Country'] || '').toString()
  const appEngineCountry = (h['x-appengine-country'] || h['X-AppEngine-Country'] || '').toString()
  const fastlyCountry = (h['x-fastly-geoip-country-code'] || h['fastly-geoip-country-code'] || '').toString()
  const genericCountry = (h['x-country-code'] || '').toString()

  const countryRaw = vercelCountry || cfCountry || geoCountry || cfViewerCountry || appEngineCountry || fastlyCountry || genericCountry || ''
  const country = countryRaw && /^[a-z]{2}$/i.test(countryRaw) ? countryRaw.toUpperCase() : (countryRaw || null)

  // Region/state detection
  const vercelRegion = (h['x-vercel-ip-region'] || '').toString()
  const geoRegion = (h['x-geo-region'] || '').toString()
  const appEngineRegion = (h['x-appengine-region'] || h['X-AppEngine-Region'] || '').toString()
  const region = vercelRegion || geoRegion || appEngineRegion || ''

  // City detection
  const vercelCity = (h['x-vercel-ip-city'] || '').toString()
  const geoCity = (h['x-geo-city'] || '').toString()
  const appEngineCity = (h['x-appengine-city'] || h['X-AppEngine-City'] || '').toString()
  const city = vercelCity || geoCity || appEngineCity || ''

  return {
    geo_country: country || null,
    geo_region: region || null,
    geo_city: city || null,
  }
}

// In-memory cache for IP -> geo lookups to avoid repeated external calls
const geoCache = new Map()

function isPrivateIp(ip) {
  try {
    const s = String(ip || '').toLowerCase()
    if (!s) return true
    if (s === '127.0.0.1' || s === '::1') return true
    if (s.startsWith('10.')) return true
    if (s.startsWith('192.168.')) return true
    const first = s.split('.')
    const a = Number(first[0]); const b = Number(first[1])
    if (a === 172 && b >= 16 && b <= 31) return true
    if (s.startsWith('fc') || s.startsWith('fd')) return true // IPv6 unique local
    if (s.startsWith('fe80:')) return true // IPv6 link-local
  } catch { }
  return false
}

function geoDebugLog(...args) {
  try {
    const enabled = String(process.env.GEO_LOG_DEBUG || '').toLowerCase() === 'true'
    if (enabled) console.log('[geo]', ...args)
  } catch { }
}

async function lookupGeoForIp(ip) {
  const key = `ip:${ip}`
  const now = Date.now()
  const ttlMs = 24 * 60 * 60 * 1000 // 24h
  const cached = geoCache.get(key)
  if (cached && (now - cached.ts < ttlMs)) {
    return cached.val
  }

  if (!ip || isPrivateIp(ip)) {
    const val = { geo_country: null, geo_region: null, geo_city: null }
    geoCache.set(key, { ts: now, val })
    return val
  }

  // Provider 1: ipapi.co (HTTPS, no key required for basic usage)
  try {
    const r = await fetch(`https://ipapi.co/${encodeURIComponent(ip)}/json/`, { method: 'GET', headers: { 'Accept': 'application/json' }, redirect: 'follow' })
    if (r.ok) {
      const j = await r.json().catch(() => null)
      if (j && (j.country || j.region || j.city)) {
        const val = {
          geo_country: j.country ? String(j.country).toUpperCase() : null, // ISO code
          geo_region: j.region || null,
          geo_city: j.city || null,
        }
        geoCache.set(key, { ts: now, val })
        geoDebugLog('ipapi.co resolved', ip, val)
        return val
      }
    }
  } catch (e) {
    geoDebugLog('ipapi.co failed', ip, e?.message || String(e))
  }

  // Provider 2: ip-api.com (HTTP; keep as last resort)
  try {
    const r2 = await fetch(`http://ip-api.com/json/${encodeURIComponent(ip)}?fields=status,message,country,countryCode,regionName,city`, { method: 'GET', headers: { 'Accept': 'application/json' } })
    if (r2.ok) {
      const j2 = await r2.json().catch(() => null)
      if (j2 && j2.status === 'success') {
        const val = {
          geo_country: j2.countryCode ? String(j2.countryCode).toUpperCase() : (j2.country || null),
          geo_region: j2.regionName || null,
          geo_city: j2.city || null,
        }
        geoCache.set(key, { ts: now, val })
        geoDebugLog('ip-api.com resolved', ip, val)
        return val
      }
    }
  } catch (e) {
    geoDebugLog('ip-api.com failed', ip, e?.message || String(e))
  }

  const val = { geo_country: null, geo_region: null, geo_city: null }
  geoCache.set(key, { ts: now, val })
  return val
}

async function resolveGeo(req, ipAddress) {
  const headerGeo = getGeoFromHeaders(req)
  const hasHeaderCountry = !!headerGeo.geo_country
  const hasHeaderRegion = !!headerGeo.geo_region
  const needsLookup = !hasHeaderCountry || !hasHeaderRegion

  if (!needsLookup) return headerGeo

  try {
    const fromIp = await lookupGeoForIp(ipAddress)
    return {
      geo_country: headerGeo.geo_country || fromIp.geo_country || null,
      geo_region: headerGeo.geo_region || fromIp.geo_region || null,
      geo_city: headerGeo.geo_city || fromIp.geo_city || null,
    }
  } catch {
    return headerGeo
  }
}

function extractHostname(url) {
  try {
    const u = new URL(url)
    return u.hostname || null
  } catch {
    try {
      // Attempt to handle bare domains like "example.com/path"
      const withProto = new URL(`http://${String(url || '').replace(/^\/+/, '')}`)
      return withProto.hostname || null
    } catch { return null }
  }
}

function deriveTrafficSource(referrer) {
  const domain = extractHostname(referrer || '')
  if (domain) {
    return { traffic_source: 'referral', traffic_details: { domain } }
  }
  return { traffic_source: 'direct', traffic_details: {} }
}

// Basic device categorization from a User-Agent string for admin analytics
function categorizeDeviceFromUa(userAgent) {
  try {
    const ua = String(userAgent || '')
    if (!ua) return 'Other'
    const uaLower = ua.toLowerCase()
    if (/(bot|spider|crawler|bingpreview|googlebot|duckduckbot|facebookexternalhit|slackbot|twitterbot)/i.test(ua)) return 'Bot'
    if (/iphone/i.test(ua)) return 'iPhone'
    if (/ipad/i.test(ua)) return 'iPad'
    if (/android/i.test(ua)) {
      if (/mobile/i.test(ua)) return 'Android Phone'
      return 'Android Tablet'
    }
    if (/cros/i.test(ua)) return 'ChromeOS'
    if (/windows nt/i.test(ua)) return 'Windows'
    if (/macintosh|mac os x/i.test(ua)) return 'Mac'
    if (/linux/i.test(ua)) return 'Linux'
    return 'Other'
  } catch { return 'Other' }
}

// Lightweight in-memory analytics as a resilient fallback when DB is unavailable
class MemoryAnalytics {
  constructor() {
    this.minuteToUniqueIps = new Map()
    this.minuteToVisitCount = new Map()
    this.dayToUniqueIps = new Map()
  }

  recordVisit(ipAddress, occurredAtMs) {
    const ip = typeof ipAddress === 'string' ? ipAddress.trim() : ''
    if (!ip) return
    const ts = Number.isFinite(occurredAtMs) ? occurredAtMs : Date.now()
    const minuteKey = Math.floor(ts / 60000) // epoch minutes
    const dayKey = new Date(ts).toISOString().slice(0, 10) // YYYY-MM-DD UTC

    if (!this.minuteToUniqueIps.has(minuteKey)) this.minuteToUniqueIps.set(minuteKey, new Set())
    this.minuteToUniqueIps.get(minuteKey).add(ip)
    this.minuteToVisitCount.set(minuteKey, (this.minuteToVisitCount.get(minuteKey) || 0) + 1)

    if (!this.dayToUniqueIps.has(dayKey)) this.dayToUniqueIps.set(dayKey, new Set())
    this.dayToUniqueIps.get(dayKey).add(ip)

    this.prune()
  }

  getUniqueIpCountInLastMinutes(windowMinutes) {
    const nowMin = Math.floor(Date.now() / 60000)
    const start = nowMin - Math.max(0, Number(windowMinutes) || 0) + 1
    let uniq = new Set()
    for (let m = start; m <= nowMin; m++) {
      const set = this.minuteToUniqueIps.get(m)
      if (set && set.size) {
        for (const ip of set) uniq.add(ip)
      }
    }
    return uniq.size
  }

  getVisitCountInLastMinutes(windowMinutes) {
    const nowMin = Math.floor(Date.now() / 60000)
    const start = nowMin - Math.max(0, Number(windowMinutes) || 0) + 1
    let total = 0
    for (let m = start; m <= nowMin; m++) {
      total += this.minuteToVisitCount.get(m) || 0
    }
    return total
  }

  getDailySeries(days) {
    const n = Math.max(1, Number(days) || 7)
    const out = []
    const today = new Date()
    const start = new Date(Date.UTC(today.getUTCFullYear(), today.getUTCMonth(), today.getUTCDate()))
    start.setUTCDate(start.getUTCDate() - (n - 1))
    for (let i = 0; i < n; i++) {
      const d = new Date(start)
      d.setUTCDate(start.getUTCDate() + i)
      const key = d.toISOString().slice(0, 10)
      const set = this.dayToUniqueIps.get(key)
      out.push({ date: key, uniqueVisitors: set ? set.size : 0 })
    }
    return out
  }

  // Return count of unique IPs across the last N calendar days (UTC)
  getUniqueIpCountInLastDays(days) {
    const n = Math.max(1, Number(days) || 7)
    const today = new Date()
    const start = new Date(Date.UTC(
      today.getUTCFullYear(),
      today.getUTCMonth(),
      today.getUTCDate()
    ))
    start.setUTCDate(start.getUTCDate() - (n - 1))
    const uniq = new Set()
    for (let i = 0; i < n; i++) {
      const d = new Date(start)
      d.setUTCDate(start.getUTCDate() + i)
      const key = d.toISOString().slice(0, 10)
      const set = this.dayToUniqueIps.get(key)
      if (set && set.size) {
        for (const ip of set) uniq.add(ip)
      }
    }
    return uniq.size
  }

  prune() {
    // Keep last 180 minutes of minute buckets, last 30 days of day sets
    const cutoffMin = Math.floor(Date.now() / 60000) - 180
    for (const k of Array.from(this.minuteToUniqueIps.keys())) {
      if (k < cutoffMin) this.minuteToUniqueIps.delete(k)
    }
    for (const k of Array.from(this.minuteToVisitCount.keys())) {
      if (k < cutoffMin) this.minuteToVisitCount.delete(k)
    }
    const cutoffDay = new Date()
    cutoffDay.setUTCDate(cutoffDay.getUTCDate() - 30)
    const cutoffKey = cutoffDay.toISOString().slice(0, 10)
    for (const k of Array.from(this.dayToUniqueIps.keys())) {
      if (k < cutoffKey) this.dayToUniqueIps.delete(k)
    }
  }
}
const memAnalytics = new MemoryAnalytics()

async function computeNextVisitNum(sessionId) {
  if (!sql || !sessionId) return null
  try {
    const rows = await sql.unsafe(`select count(*)::int as c from ${VISITS_TABLE_SQL_IDENT} where session_id = $1`, [sessionId])
    const c = Array.isArray(rows) && rows[0] ? Number(rows[0].c) : 0
    return c + 1
  } catch {
    return null
  }
}

async function insertWebVisitViaSupabaseRest(payload, req) {
  try {
    if (!supabaseUrlEnv || !supabaseAnonKey) return false
    const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json', 'Content-Type': 'application/json', 'Prefer': 'return=minimal' }
    const token = getBearerTokenFromRequest(req)
    if (token) Object.assign(headers, { 'Authorization': `Bearer ${token}` })
    // First try full payload (new schema)
    const tablePath = (process.env.VISITS_TABLE_REST || VISITS_TABLE_ENV || 'web_visits')
    const fullResp = await fetch(`${supabaseUrlEnv}/rest/v1/${tablePath}`, {
      method: 'POST',
      headers,
      body: JSON.stringify(payload),
    })
    if (fullResp.ok) return true
    // Retry with minimal legacy-compatible columns if schema is older
    const minimal = {
      session_id: payload.session_id,
      user_id: payload.user_id ?? null,
      page_path: payload.page_path,
      referrer: payload.referrer ?? null,
      user_agent: payload.user_agent ?? null,
      ip_address: payload.ip_address ?? null,
      geo_country: payload.geo_country ?? null,
      geo_region: payload.geo_region ?? null,
      geo_city: payload.geo_city ?? null,
      extra: payload.extra ?? {},
    }
    const minResp = await fetch(`${supabaseUrlEnv}/rest/v1/${tablePath}`, {
      method: 'POST',
      headers,
      body: JSON.stringify(minimal),
    })
    return minResp.ok
  } catch {
    return false
  }
}

async function insertWebVisit({ sessionId, userId, pagePath, referrer, userAgent, ipAddress, geo, extra, pageTitle, language, visitNum }, req) {
  // Always record into in-memory analytics, regardless of DB availability
  try { memAnalytics.recordVisit(String(ipAddress || ''), Date.now()) } catch { }

  // Prepare common fields
  const parsedUtm = null
  const lang = language || null

  // If no direct DB, try Supabase REST immediately
  if (!sql) {
    const restPayload = {
      session_id: sessionId,
      user_id: userId || null,
      page_path: pagePath,
      referrer: referrer || null,
      user_agent: userAgent || null,
      ip_address: ipAddress || null,
      geo_country: (geo?.geo_country && /^[a-z]{2}$/i.test(String(geo.geo_country))) ? String(geo.geo_country).toUpperCase() : (geo?.geo_country || null),
      geo_region: geo?.geo_region || null,
      geo_city: geo?.geo_city || null,
      extra: (() => { try { const { traffic_source, traffic_details } = deriveTrafficSource(referrer); return { ...(extra || {}), traffic_source, traffic_details } } catch { return (extra || {}) } })(),
      visit_num: null,
      page_title: pageTitle || null,
      language: lang,
    }
    await insertWebVisitViaSupabaseRest(restPayload, req)
    return
  }

  try {
    const computedVisitNum = Number.isFinite(visitNum) ? visitNum : await computeNextVisitNum(sessionId)
    const trafficAugmentedExtra = (() => { try { const { traffic_source, traffic_details } = deriveTrafficSource(referrer); return { ...(extra || {}), traffic_source, traffic_details } } catch { return (extra || {}) } })()
    const geoCountry = (geo?.geo_country && /^[a-z]{2}$/i.test(String(geo.geo_country))) ? String(geo.geo_country).toUpperCase() : (geo?.geo_country || null)
    await sql.unsafe(
      `insert into ${VISITS_TABLE_SQL_IDENT}
         (session_id, user_id, page_path, referrer, user_agent, ip_address, geo_country, geo_region, geo_city, extra, visit_num, page_title, language)
       values ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10::jsonb, $11, $12, $13)`,
      [sessionId, userId || null, pagePath, referrer || null, userAgent || null, ipAddress || null, geoCountry, geo?.geo_region || null, geo?.geo_city || null, JSON.stringify(trafficAugmentedExtra), computedVisitNum, pageTitle || null, lang]
    )
  } catch (e) {
    // On DB failure, attempt Supabase REST fallback (handles older schemas too)
    const restPayload = {
      session_id: sessionId,
      user_id: userId || null,
      page_path: pagePath,
      referrer: referrer || null,
      user_agent: userAgent || null,
      ip_address: ipAddress || null,
      geo_country: (geo?.geo_country && /^[a-z]{2}$/i.test(String(geo.geo_country))) ? String(geo.geo_country).toUpperCase() : (geo?.geo_country || null),
      geo_region: geo?.geo_region || null,
      geo_city: geo?.geo_city || null,
      extra: (() => { try { const { traffic_source, traffic_details } = deriveTrafficSource(referrer); return { ...(extra || {}), traffic_source, traffic_details } } catch { return (extra || {}) } })(),
      // Avoid computing visit_num via REST; leave null when falling back
      visit_num: null,
      page_title: pageTitle || null,
      language: lang,
    }
    await insertWebVisitViaSupabaseRest(restPayload, req)
  }
}

// Admin: restart server via systemd; always exit so systemd restarts us
async function handleRestartServer(req, res) {
  try {
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }

    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      let adminName = null
      if (sql && adminId) {
        try {
          const rows = await sql`select coalesce(display_name, '') as name from public.profiles where id = ${adminId} limit 1`
          adminName = (rows?.[0]?.name || '').trim() || null
        } catch { }
      }
      if (!adminName && supabaseUrlEnv && supabaseAnonKey && adminId) {
        try {
          const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
          const bearer = getBearerTokenFromRequest(req)
          if (bearer) headers['Authorization'] = `Bearer ${bearer}`
          const url = `${supabaseUrlEnv}/rest/v1/profiles?id=eq.${encodeURIComponent(adminId)}&select=display_name&limit=1`
          const r = await fetch(url, { headers })
          if (r.ok) {
            const arr = await r.json().catch(() => [])
            adminName = Array.isArray(arr) && arr[0] ? (arr[0].display_name || null) : null
          }
        } catch { }
      }
      let ok = false
      if (sql) {
        try { await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${adminName}, 'restart_server', null, ${sql.json({})})`; ok = true } catch { }
      }
      if (!ok) {
        try { await insertAdminActivityViaRest(req, { admin_id: adminId, admin_name: adminName, action: 'restart_server', target: null, detail: {} }) } catch { }
      }
    } catch { }
    res.json({ ok: true, message: 'Restarting server' })
    // Give time for response to flush, then request systemd to restart the service.
    setTimeout(() => {
      let restartedViaSystemd = false
      try {
        const serviceName = process.env.NODE_SYSTEMD_SERVICE || process.env.SELF_SYSTEMD_SERVICE || 'plant-swipe-node'
        const child = spawnChild('sudo', ['-n', 'systemctl', 'restart', serviceName], { detached: true, stdio: 'ignore' })
        try { child.unref() } catch { }
        restartedViaSystemd = true
      } catch { }
      // Exit in all cases so the systemd unit can take over.
      // If systemd call failed to spawn, exit non-zero to trigger Restart=on-failure.
      try { process.exit(restartedViaSystemd ? 0 : 1) } catch { }
    }, 150)
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to restart server' })
  }
}

app.post('/api/admin/restart-server', handleRestartServer)
app.get('/api/admin/restart-server', handleRestartServer)
app.options('/api/admin/restart-server', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'GET,POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

function scheduleRestartAllServices(trigger = 'manual') {
  const serviceNode = process.env.NODE_SYSTEMD_SERVICE || process.env.SELF_SYSTEMD_SERVICE || 'plant-swipe-node'
  const serviceAdmin = process.env.ADMIN_SYSTEMD_SERVICE || 'admin-api'
  const serviceNginx = process.env.NGINX_SYSTEMD_SERVICE || 'nginx'
  const label = trigger || 'manual'
  setTimeout(() => {
    console.log(`[restart] Scheduling service restart (trigger=${label})`)
      ; (async () => {
        try { await exec('sudo -n nginx -t', { timeout: 15000 }) } catch { }
        try { await exec(`sudo -n systemctl reload ${serviceNginx}`, { timeout: 20000 }) } catch { }
        try {
          const admin = spawnChild('sudo', ['-n', 'systemctl', 'restart', serviceAdmin], { detached: true, stdio: 'ignore' })
          try { admin.unref() } catch { }
        } catch { }
        try {
          const node = spawnChild('sudo', ['-n', 'systemctl', 'restart', serviceNode], { detached: true, stdio: 'ignore' })
          try { node.unref() } catch { }
        } catch { }
      })()
        .catch(() => { })
        .finally(() => {
          try { process.exit(0) } catch { }
        })
  }, 150)
}

// Admin: reload nginx and restart admin + node services in sequence, then exit self
app.post('/api/admin/restart-all', async (req, res) => {
  try {
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }

    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      let adminName = null
      if (sql && adminId) {
        try {
          const rows = await sql`select coalesce(display_name, '') as name from public.profiles where id = ${adminId} limit 1`
          adminName = (rows?.[0]?.name || '').trim() || null
        } catch { }
      }
      if (!adminName && supabaseUrlEnv && supabaseAnonKey && adminId) {
        try {
          const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
          const bearer = getBearerTokenFromRequest(req)
          if (bearer) headers['Authorization'] = `Bearer ${bearer}`
          const url = `${supabaseUrlEnv}/rest/v1/profiles?id=eq.${encodeURIComponent(adminId)}&select=display_name&limit=1`
          const r = await fetch(url, { headers })
          if (r.ok) {
            const arr = await r.json().catch(() => [])
            adminName = Array.isArray(arr) && arr[0] ? (arr[0].display_name || null) : null
          }
        } catch { }
      }
      let ok = false
      if (sql) {
        try { await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${adminName}, 'restart_all', null, ${sql.json({})})`; ok = true } catch { }
      }
      if (!ok) {
        try { await insertAdminActivityViaRest(req, { admin_id: adminId, admin_name: adminName, action: 'restart_all', target: null, detail: {} }) } catch { }
      }
    } catch { }
    res.json({ ok: true, message: 'Reloading nginx and restarting services' })

    scheduleRestartAllServices('api_endpoint')
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to restart all services' })
  }
})

app.options('/api/admin/restart-all', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

// Ensure ban tables exist (idempotent)
async function ensureBanTables() {
  if (!sql) return
  try {
    await sql`
      create table if not exists public.banned_accounts (
        id uuid primary key default gen_random_uuid(),
        user_id uuid,
        email text not null,
        ip_addresses text[] not null default '{}',
        reason text,
        banned_by uuid,
        banned_at timestamptz not null default now()
      );
    `
    await sql`create index if not exists banned_accounts_email_idx on public.banned_accounts (lower(email));`
    await sql`create index if not exists banned_accounts_user_idx on public.banned_accounts (user_id);`
    await sql`
      create table if not exists public.banned_ips (
        ip_address inet primary key,
        reason text,
        banned_by uuid,
        banned_at timestamptz not null default now(),
        user_id uuid,
        email text
      );
    `
    await sql`create index if not exists banned_ips_banned_at_idx on public.banned_ips (banned_at desc);`
  } catch { }
}

// Ensure broadcast table exists (idempotent)
async function ensureBroadcastTable() {
  if (!sql) return
  try {
    await sql`
      create table if not exists public.broadcast_messages (
        id uuid primary key default gen_random_uuid(),
        message text not null,
        severity text not null default 'info',
        created_at timestamptz not null default now(),
        expires_at timestamptz null,
        removed_at timestamptz null,
        created_by uuid null
      );
    `
    // Backfill/ensure severity column and constraint for older deployments
    try { await sql`alter table if exists public.broadcast_messages add column if not exists severity text;` } catch { }
    try { await sql`update public.broadcast_messages set severity = 'info' where severity is null;` } catch { }
    try {
      await sql`
        do $$ begin
          if not exists (
            select 1 from pg_constraint where conname = 'broadcast_messages_severity_chk'
          ) then
            alter table public.broadcast_messages
            add constraint broadcast_messages_severity_chk check (severity in ('info','warning','danger'));
          end if;
        end $$;
      `
    } catch { }
    await sql`create index if not exists broadcast_messages_created_at_idx on public.broadcast_messages (created_at desc);`
    await sql`create index if not exists broadcast_messages_active_idx on public.broadcast_messages (expires_at) where removed_at is null;`
  } catch { }
}

let notificationTablesEnsured = false

// Default timezone for notifications and users - MUST be defined before notification API routes
const DEFAULT_TIMEZONE = 'Europe/London'

async function ensureNotificationTables() {
  if (!sql) {
    console.log('[ensureNotificationTables] No SQL connection')
    return
  }
  if (notificationTablesEnsured) {
    console.log('[ensureNotificationTables] Already ensured, skipping')
    return
  }
  console.log('[ensureNotificationTables] Starting table creation...')
  try {
    // Notification Templates
    console.log('[ensureNotificationTables] Creating notification_templates...')
    await sql`
      create table if not exists public.notification_templates (
        id uuid primary key default gen_random_uuid(),
        title text not null,
        description text,
        message_variants text[] not null default '{}'::text[],
        randomize boolean not null default true,
        is_active boolean not null default true,
        usage_count integer not null default 0,
        created_by uuid,
        updated_by uuid,
        created_at timestamptz not null default now(),
        updated_at timestamptz not null default now()
      );
    `
    await sql`create index if not exists notification_templates_active_idx on public.notification_templates (is_active) where is_active = true;`

    // Notification Template Translations
    await sql`
      create table if not exists public.notification_template_translations (
        id uuid primary key default gen_random_uuid(),
        template_id uuid not null references public.notification_templates(id) on delete cascade,
        language text not null,
        message_variants text[] not null default '{}'::text[],
        created_at timestamptz default now(),
        updated_at timestamptz default now(),
        unique(template_id, language)
      );
    `
    await sql`create index if not exists ntt_template_lang_idx on public.notification_template_translations (template_id, language);`

    // Notification Campaigns
    await sql`
      create table if not exists public.notification_campaigns (
        id uuid primary key default gen_random_uuid(),
        title text not null,
        description text,
        delivery_mode text not null default 'send_now' check (delivery_mode in ('send_now','planned','scheduled')),
        state text not null default 'draft' check (state in ('draft','scheduled','processing','paused','completed','cancelled')),
        audience text not null default 'all' check (audience in ('all','tasks_open','inactive_week','admins','custom')),
        filters jsonb not null default '{}'::jsonb,
        message_variants text[] not null default '{}'::text[],
        randomize boolean not null default true,
        timezone text default 'Europe/London',
        planned_for timestamptz,
        schedule_start_at timestamptz,
        schedule_interval text check (schedule_interval in ('daily','weekly','monthly')),
        cta_url text,
        custom_user_ids uuid[] not null default '{}'::uuid[],
        template_id uuid references public.notification_templates(id) on delete set null,
        run_count integer not null default 0,
        created_by uuid,
        updated_by uuid,
        last_run_at timestamptz,
        next_run_at timestamptz,
        last_run_summary jsonb,
        created_at timestamptz not null default now(),
        updated_at timestamptz not null default now(),
        deleted_at timestamptz
      );
    `
    // Add template_id column if it doesn't exist (for existing tables)
    try {
      await sql`alter table public.notification_campaigns add column if not exists template_id uuid references public.notification_templates(id) on delete set null;`
    } catch (alterErr) {
      // Column might already exist, ignore error
    }
    await sql`create index if not exists notification_campaigns_next_run_idx on public.notification_campaigns (next_run_at) where deleted_at is null;`
    await sql`create index if not exists notification_campaigns_state_idx on public.notification_campaigns (state);`

    // Notification Automations
    await sql`
      create table if not exists public.notification_automations (
        id uuid primary key default gen_random_uuid(),
        trigger_type text not null unique,
        display_name text not null,
        description text,
        is_enabled boolean not null default false,
        template_id uuid references public.notification_templates(id) on delete set null,
        send_hour integer not null default 9,
        cta_url text,
        last_run_at timestamptz,
        last_run_summary jsonb,
        created_by uuid,
        updated_by uuid,
        created_at timestamptz not null default now(),
        updated_at timestamptz not null default now()
      );
    `
    await sql`create index if not exists notification_automations_enabled_idx on public.notification_automations (is_enabled) where is_enabled = true;`

    // User Notifications
    await sql`
      create table if not exists public.user_notifications (
        id uuid primary key default gen_random_uuid(),
        campaign_id uuid references public.notification_campaigns(id) on delete set null,
        automation_id uuid references public.notification_automations(id) on delete set null,
        iteration integer not null default 1,
        user_id uuid not null references auth.users(id) on delete cascade,
        title text,
        message text not null,
        payload jsonb not null default '{}'::jsonb,
        cta_url text,
        scheduled_for timestamptz not null default now(),
        delivered_at timestamptz,
        delivery_status text not null default 'pending' check (delivery_status in ('pending','sent','failed','cancelled')),
        delivery_attempts integer not null default 0,
        delivery_error text,
        seen_at timestamptz,
        cancelled_at timestamptz,
        created_at timestamptz not null default now()
      );
    `
    // Add automation_id column if it doesn't exist (for existing tables)
    try {
      await sql`alter table public.user_notifications add column if not exists automation_id uuid references public.notification_automations(id) on delete set null;`
    } catch (alterErr) {
      // Column might already exist, ignore error
    }
    await sql`create index if not exists user_notifications_user_idx on public.user_notifications (user_id, scheduled_for desc);`
    await sql`create index if not exists user_notifications_campaign_idx on public.user_notifications (campaign_id);`
    await sql`create index if not exists user_notifications_automation_idx on public.user_notifications (automation_id);`
    await sql`create unique index if not exists user_notifications_unique_delivery on public.user_notifications (campaign_id, iteration, user_id);`
    // Unique constraint for automation notifications: one notification per automation per user per day (in user's timezone)
    // Using scheduled_for::date since the automation inserts with scheduled_for = now()
    await sql`create unique index if not exists user_notifications_unique_automation on public.user_notifications (automation_id, user_id, (scheduled_for::date)) where automation_id is not null;`

    // User Push Subscriptions
    await sql`
      create table if not exists public.user_push_subscriptions (
        id uuid primary key default gen_random_uuid(),
        user_id uuid not null references auth.users(id) on delete cascade,
        endpoint text not null,
        auth_key text,
        p256dh_key text,
        user_agent text,
        subscription jsonb not null,
        created_at timestamptz not null default now(),
        updated_at timestamptz not null default now(),
        last_used_at timestamptz
      );
    `
    await sql`create unique index if not exists user_push_subscriptions_endpoint_idx on public.user_push_subscriptions (endpoint);`
    await sql`create index if not exists user_push_subscriptions_user_idx on public.user_push_subscriptions (user_id);`
    notificationTablesEnsured = true
    console.log('[ensureNotificationTables] All tables created successfully')
  } catch (err) {
    console.error('[ensureNotificationTables] Failed:', err?.message || err)
  }
}

const notificationAudienceValues = ['all', 'tasks_open', 'inactive_week', 'admins', 'custom']
const notificationModeValues = ['send_now', 'planned', 'scheduled']
const notificationIntervalValues = ['daily', 'weekly', 'monthly']
const notificationInputSchema = z.object({
  title: z.string().min(3).max(160),
  description: z
    .string()
    .max(2000)
    .optional()
    .nullable()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  deliveryMode: z.enum(notificationModeValues),
  audience: z.enum(notificationAudienceValues),
  messageVariants: z.array(z.string().min(1).max(400)).min(1),
  randomize: z.boolean().optional(),
  templateId: z
    .string()
    .uuid()
    .optional()
    .nullable()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  timezone: z
    .string()
    .max(64)
    .optional()
    .nullable()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  plannedFor: z
    .string()
    .optional()
    .nullable()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  scheduleStartAt: z
    .string()
    .optional()
    .nullable()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  scheduleInterval: z
    .enum(notificationIntervalValues)
    .optional()
    .nullable()
    .transform((value) => (value && value.trim().length > 0 ? value : null)),
  ctaUrl: z
    .string()
    .url()
    .optional()
    .nullable()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  customUserIds: z.array(z.string().uuid()).optional(),
})
const notificationStateSchema = z.object({
  state: z.enum(['paused', 'scheduled']),
})

// Notification template schema
const notificationTemplateInputSchema = z.object({
  title: z.string().trim().min(3).max(160),
  description: z
    .string()
    .max(2000)
    .optional()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  messageVariants: z.array(z.string().min(1).max(400)).min(1),
  randomize: z.boolean().optional(),
  isActive: z.boolean().optional(),
})

// Notification automation schema
const notificationAutomationTriggerTypes = ['weekly_inactive_reminder', 'daily_task_reminder', 'journal_continue_reminder']
const notificationAutomationUpdateSchema = z.object({
  isEnabled: z.boolean().optional(),
  templateId: z.string().uuid().nullable().optional(),
  sendHour: z.number().int().min(0).max(23).optional(),
  ctaUrl: z
    .string()
    .url()
    .optional()
    .nullable()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
})

// Campaign input schema (updated to support template_id)
const notificationCampaignInputSchema = z.object({
  title: z.string().min(3).max(160),
  description: z
    .string()
    .max(2000)
    .optional()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  deliveryMode: z.enum(notificationModeValues),
  audience: z.enum(notificationAudienceValues),
  templateId: z.string().uuid().optional().nullable(),
  messageVariants: z.array(z.string().min(1).max(400)).optional(),
  randomize: z.boolean().optional(),
  timezone: z
    .string()
    .max(64)
    .optional()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  plannedFor: z
    .string()
    .optional()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  scheduleStartAt: z
    .string()
    .optional()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  scheduleInterval: z
    .enum(notificationIntervalValues)
    .optional()
    .transform((value) => (value && value.trim().length > 0 ? value : null)),
  ctaUrl: z
    .string()
    .url()
    .optional()
    .transform((value) => (value && value.trim().length > 0 ? value.trim() : null)),
  customUserIds: z.array(z.string().uuid()).optional(),
})

const emailTemplateInputSchema = z.object({
  title: z.string().trim().min(3).max(120),
  subject: z.string().trim().min(3).max(240),
  description: z
    .string()
    .trim()
    .max(600)
    .optional()
    .nullable(),
  previewText: z
    .string()
    .trim()
    .max(240)
    .optional()
    .nullable(),
  bodyHtml: z.string().min(1),
  bodyJson: JsonValueSchema.optional().nullable(),
  isActive: z.boolean().optional(),
})

const emailCampaignInputSchema = z.object({
  title: z.string().trim().min(3).max(160),
  description: z
    .string()
    .trim()
    .max(600)
    .optional()
    .nullable(),
  templateId: z.string().uuid(),
  scheduledFor: z.string().trim().min(6),
  timezone: z
    .string()
    .trim()
    .max(64)
    .optional()
    .nullable(),
  previewText: z
    .string()
    .trim()
    .max(240)
    .optional()
    .nullable(),
  testMode: z.boolean().optional().default(false),
  testEmail: z.string().email().optional().nullable(),
  isMarketing: z.boolean().optional().default(false), // If true, only send to users with marketing_consent=true
})

const emailCampaignUpdateSchema = z.object({
  title: z.string().trim().min(3).max(160).optional(),
  description: z
    .string()
    .trim()
    .max(600)
    .optional()
    .nullable(),
  templateId: z.string().uuid().optional(),
  scheduledFor: z
    .string()
    .trim()
    .min(6)
    .optional()
    .nullable(),
  timezone: z
    .string()
    .trim()
    .max(64)
    .optional()
    .nullable(),
  previewText: z
    .string()
    .trim()
    .max(240)
    .optional()
    .nullable(),
  refreshTemplate: z.boolean().optional(),
})

const emailCampaignRunSchema = z
  .object({
    recipientLimit: z.number().int().min(1).max(5000).optional(),
  })
  .optional()

async function ensureRequestedPlantsSchema() {
  if (!sql) return
  const ddl = `
create table if not exists public.requested_plants (
  id uuid primary key default gen_random_uuid(),
  plant_name text not null,
  plant_name_normalized text not null,
  requested_by uuid not null references auth.users(id) on delete cascade,
  request_count integer not null default 1 check (request_count > 0),
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now(),
  completed_at timestamptz,
  completed_by uuid references auth.users(id) on delete set null
);

alter table if exists public.requested_plants add column if not exists plant_name text;
alter table if exists public.requested_plants add column if not exists plant_name_normalized text;
alter table if exists public.requested_plants add column if not exists requested_by uuid references auth.users(id) on delete cascade;
alter table if exists public.requested_plants add column if not exists request_count integer not null default 1;
alter table if exists public.requested_plants add column if not exists created_at timestamptz not null default now();
alter table if exists public.requested_plants add column if not exists updated_at timestamptz not null default now();
alter table if exists public.requested_plants add column if not exists completed_at timestamptz;
alter table if exists public.requested_plants add column if not exists completed_by uuid;

do $do$
begin
  if not exists (select 1 from pg_constraint where conname = 'requested_plants_request_count_check') then
    alter table public.requested_plants add constraint requested_plants_request_count_check check (request_count > 0);
  end if;
  if not exists (select 1 from pg_constraint where conname = 'requested_plants_requested_by_fkey') then
    alter table public.requested_plants add constraint requested_plants_requested_by_fkey
      foreign key (requested_by) references auth.users(id) on delete cascade;
  end if;
  if not exists (select 1 from pg_constraint where conname = 'requested_plants_completed_by_fkey') then
    alter table public.requested_plants add constraint requested_plants_completed_by_fkey
      foreign key (completed_by) references auth.users(id) on delete set null;
  end if;
end
$do$;

create index if not exists requested_plants_plant_name_normalized_idx on public.requested_plants(plant_name_normalized);
create unique index if not exists requested_plants_active_name_unique_idx on public.requested_plants(plant_name_normalized) where completed_at is null;
create index if not exists requested_plants_completed_at_idx on public.requested_plants(completed_at);
create index if not exists requested_plants_requested_by_idx on public.requested_plants(requested_by);
create index if not exists requested_plants_created_at_idx on public.requested_plants(created_at desc);
`
  try {
    await sql.unsafe(ddl, [], { simple: true })
    await sql`update public.requested_plants set plant_name_normalized = lower(trim(plant_name)) where plant_name_normalized is null and plant_name is not null`
    await sql`alter table public.requested_plants alter column plant_name_normalized set not null`
  } catch (err) {
    console.error('[sync] failed to ensure requested_plants schema', err)
  }
}

async function ensurePlantTranslationsSchema() {
  if (!sql) return
  const ddl = `
create table if not exists public.plant_translations (
  id uuid primary key default gen_random_uuid(),
  plant_id text not null references public.plants(id) on delete cascade,
  language text not null check (language in ('en', 'fr')),
  name text not null,
  scientific_name text,
  meaning text,
    description text,
  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now(),
  unique(plant_id, language)
);

create index if not exists plant_translations_plant_id_idx on public.plant_translations(plant_id);
create index if not exists plant_translations_language_idx on public.plant_translations(language);

alter table public.plant_translations enable row level security;

do $do$ begin
  if exists (
    select 1 from pg_policies
    where schemaname = 'public'
      and tablename = 'plant_translations'
      and policyname = 'plant_translations_select_all'
  ) then
    drop policy plant_translations_select_all on public.plant_translations;
  end if;
  create policy plant_translations_select_all on public.plant_translations for select to authenticated, anon using (true);
end $do$;

do $do$ begin
  if exists (
    select 1 from pg_policies
    where schemaname = 'public'
      and tablename = 'plant_translations'
      and policyname = 'plant_translations_insert'
  ) then
    drop policy plant_translations_insert on public.plant_translations;
  end if;
  create policy plant_translations_insert on public.plant_translations for insert to authenticated with check (true);
end $do$;

do $do$ begin
  if exists (
    select 1 from pg_policies
    where schemaname = 'public'
      and tablename = 'plant_translations'
      and policyname = 'plant_translations_update'
  ) then
    drop policy plant_translations_update on public.plant_translations;
  end if;
  create policy plant_translations_update on public.plant_translations for update to authenticated using (true) with check (true);
end $do$;

do $do$ begin
  if exists (
    select 1 from pg_policies
    where schemaname = 'public'
      and tablename = 'plant_translations'
      and policyname = 'plant_translations_delete'
  ) then
    drop policy plant_translations_delete on public.plant_translations;
  end if;
  create policy plant_translations_delete on public.plant_translations for delete to authenticated using (true);
end $do$;
`
  try {
    await sql.unsafe(ddl, [], { simple: true })
  } catch (err) {
    console.error('[sync] failed to ensure plant_translations schema', err)
  }
}

// Helper: verify key schema objects exist after sync for operator assurance
async function verifySchemaAfterSync() {
  if (!sql) return null
  const requiredTables = [
    'profiles',
    'plants',
    'gardens',
    'garden_members',
    'garden_plants',
    'garden_plant_tasks',
    'garden_task_user_completions',
    'garden_watering_schedule',
    'web_visits',
    'requested_plants',
  ]
  const requiredFunctions = [
    'get_profile_public_by_display_name',
    'compute_user_current_streak',
    'get_user_profile_public_stats',
    'count_unique_ips_last_minutes',
    'count_unique_ips_last_days',
  ]
  const requiredExtensions = [
    'pgcrypto',
    'pg_cron',
  ]

  const [tableRows, funcRows, extRows] = await Promise.all([
    sql`select table_name from information_schema.tables where table_schema='public' and table_name = any(${sql.array(requiredTables)})`,
    sql`select p.proname as name from pg_proc p join pg_namespace n on n.oid = p.pronamespace where n.nspname = 'public' and p.proname = any(${sql.array(requiredFunctions)})`,
    sql`select extname from pg_extension where extname = any(${sql.array(requiredExtensions)})`,
  ])

  const presentTables = new Set((tableRows || []).map(r => r.table_name))
  const presentFunctions = new Set((funcRows || []).map(r => r.name))
  const presentExtensions = new Set((extRows || []).map(r => r.extname))

  const missingTables = requiredTables.filter(n => !presentTables.has(n))
  const missingFunctions = requiredFunctions.filter(n => !presentFunctions.has(n))
  const missingExtensions = requiredExtensions.filter(n => !presentExtensions.has(n))

  return {
    tables: { required: requiredTables, present: Array.from(presentTables), missing: missingTables },
    functions: { required: requiredFunctions, present: Array.from(presentFunctions), missing: missingFunctions },
    extensions: { required: requiredExtensions, present: Array.from(presentExtensions), missing: missingExtensions },
  }
}

// Support both POST and GET (some environments may block POST from admin UI)
async function handleSyncSchema(req, res) {
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  try {
    // Require admin (robust detection; currently permissive via isAdminFromRequest)
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }

    // Read all SQL files from sync_parts folder and execute them in order
    const syncPartsDir = path.resolve(__dirname, 'supabase', 'sync_parts')
    let sqlFiles = []
    
    console.log(`[sync-schema] Looking for SQL files in: ${syncPartsDir}`)
    
    try {
      const files = await fs.readdir(syncPartsDir)
      sqlFiles = files
        .filter(f => f.endsWith('.sql'))
        .sort() // Sort alphabetically to ensure correct order (01_, 02_, etc.)
      console.log(`[sync-schema] Found ${sqlFiles.length} SQL files: ${sqlFiles.join(', ')}`)
    } catch (dirErr) {
      console.error(`[sync-schema] ERROR: sync_parts folder not found at ${syncPartsDir}`)
      console.error(`[sync-schema] Directory error: ${dirErr?.message}`)
      res.status(500).json({ 
        ok: false,
        error: `sync_parts folder not found at ${syncPartsDir}`,
        detail: 'The schema sync files are missing. Please ensure the supabase/sync_parts/ folder exists with SQL files.',
        path: syncPartsDir
      })
      return
    }

    if (sqlFiles.length === 0) {
      console.error(`[sync-schema] ERROR: No SQL files found in ${syncPartsDir}`)
      res.status(500).json({ 
        ok: false,
        error: 'No SQL files found in sync_parts folder',
        detail: 'The sync_parts folder exists but contains no .sql files.',
        path: syncPartsDir
      })
      return
    }

    // Execute each file and track results
    const results = []
    let hasError = false
    let failedFile = null
    let failedError = null

    console.log(`[sync-schema] Starting schema sync with ${sqlFiles.length} files...`)

    for (const file of sqlFiles) {
      const filePath = path.join(syncPartsDir, file)
      const startTime = Date.now()
      
      try {
        console.log(`[sync-schema] Executing: ${file}`)
        const sqlText = await fs.readFile(filePath, 'utf8')
        await sql.unsafe(sqlText, [], { simple: true })
        const duration = Date.now() - startTime
        results.push({ file, status: 'success', duration: `${duration}ms` })
        console.log(`[sync-schema] âœ“ ${file} completed in ${duration}ms`)
      } catch (fileErr) {
        const duration = Date.now() - startTime
        const errorMessage = fileErr?.message || String(fileErr)
        // Extract PostgreSQL error details if available
        const errorDetail = fileErr?.detail || null
        const errorHint = fileErr?.hint || null
        const errorPosition = fileErr?.position || null
        
        results.push({ 
          file, 
          status: 'error', 
          duration: `${duration}ms`,
          error: errorMessage,
          detail: errorDetail,
          hint: errorHint,
          position: errorPosition
        })
        
        console.error(`[sync-schema] âœ— ${file} FAILED after ${duration}ms:`)
        console.error(`[sync-schema]   Error: ${errorMessage}`)
        if (errorDetail) console.error(`[sync-schema]   Detail: ${errorDetail}`)
        if (errorHint) console.error(`[sync-schema]   Hint: ${errorHint}`)
        if (errorPosition) console.error(`[sync-schema]   Position: ${errorPosition}`)
        
        hasError = true
        failedFile = file
        failedError = errorMessage
        // Continue with remaining files to see if they have errors too
      }
    }

    // Ensure critical tables exist even if some scripts failed
    try {
      await ensureRequestedPlantsSchema()
      await ensurePlantTranslationsSchema()
    } catch (ensureErr) {
      console.error('[sync-schema] Failed to ensure critical schemas:', ensureErr?.message)
    }

    // Verify important objects exist after sync
    let summary = null
    try { summary = await verifySchemaAfterSync() } catch { }

    // Log admin action
    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      const detail = { 
        results, 
        summary, 
        hasError, 
        failedFile,
        totalFiles: sqlFiles.length,
        successCount: results.filter(r => r.status === 'success').length,
        errorCount: results.filter(r => r.status === 'error').length
      }
      const action = hasError ? 'sync_schema_partial' : 'sync_schema'
      if (sql) {
        try {
          await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${null}, ${action}, null, ${sql.json(detail)})`
        } catch { }
      }
    } catch { }

    // Return detailed results
    if (hasError) {
      console.log(`[sync-schema] Completed with errors. ${results.filter(r => r.status === 'success').length}/${sqlFiles.length} files succeeded.`)
      res.status(500).json({ 
        ok: false, 
        message: `Schema sync failed at: ${failedFile}`,
        error: failedError,
        results,
        summary,
        totalFiles: sqlFiles.length,
        successCount: results.filter(r => r.status === 'success').length,
        errorCount: results.filter(r => r.status === 'error').length
      })
    } else {
      console.log(`[sync-schema] All ${sqlFiles.length} files executed successfully.`)
      res.json({ 
        ok: true, 
        message: `Schema synchronized successfully (${sqlFiles.length} files)`,
        results,
        summary,
        totalFiles: sqlFiles.length,
        successCount: sqlFiles.length,
        errorCount: 0
      })
    }
  } catch (e) {
    // Log failure
    console.error('[sync-schema] Critical error:', e?.message || e)
    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      const detail = { error: e?.message || String(e) }
      if (sql) {
        try { await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${null}, 'sync_schema_failed', null, ${sql.json(detail)})` } catch { }
      } else {
        try { await insertAdminActivityViaRest(req, { admin_id: adminId, admin_name: null, action: 'sync_schema_failed', target: null, detail }) } catch { }
      }
    } catch { }
    res.status(500).json({ error: e?.message || 'Failed to sync schema' })
  }
}

app.post('/api/admin/sync-schema', handleSyncSchema)
app.get('/api/admin/sync-schema', handleSyncSchema)
app.options('/api/admin/sync-schema', (_req, res) => {
  // Allow standard headers for admin calls
  res.setHeader('Access-Control-Allow-Methods', 'GET,POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

async function runSupabaseEdgeDeploy() {
  const repoRoot = await getRepoRoot()
  const scriptPath = path.join(repoRoot, 'scripts', 'deploy-supabase-functions.sh')
  try {
    await fs.access(scriptPath)
  } catch {
    throw new Error(`deploy script not found at ${scriptPath}`)
  }
  try { await fs.chmod(scriptPath, 0o755) } catch { }

  const env = {
    ...process.env,
    CI: process.env.CI || 'true',
    PLANTSWIPE_REPO_DIR: repoRoot,
  }

  return await new Promise((resolve, reject) => {
    const child = spawnChild(scriptPath, {
      cwd: repoRoot,
      env,
      shell: false,
    })
    let stdout = ''
    let stderr = ''
    child.stdout?.on('data', (buf) => { stdout += buf.toString() })
    child.stderr?.on('data', (buf) => { stderr += buf.toString() })
    child.on('error', (err) => reject(err))
    child.on('close', (code) => resolve({ code, stdout, stderr }))
  })
}

function tailLines(text, limit) {
  if (!text) return ''
  const lines = String(text).split(/\r?\n/)
  return lines.slice(-limit).join('\n')
}

async function handleDeployEdgeFunctions(req, res) {
  const caller = await ensureAdmin(req, res)
  if (!caller) return
  try {
    const result = await runSupabaseEdgeDeploy()
    const stdoutTail = tailLines(result.stdout, 200)
    const stderrTail = tailLines(result.stderr, 100)

    if (result.code !== 0) {
      console.error('[server] Supabase deployment failed', { code: result.code })
      res.status(500).json({
        ok: false,
        error: 'Supabase deployment failed',
        returncode: result.code,
        stdout: stdoutTail,
        stderr: stderrTail,
      })
      return
    }

    res.json({
      ok: true,
      message: 'Supabase Edge Functions deployed successfully',
      returncode: result.code,
      stdout: stdoutTail,
      stderr: stderrTail,
    })
  } catch (err) {
    console.error('[server] deploy-edge-functions failed', err)
    res.status(500).json({
      ok: false,
      error: 'Failed to trigger Supabase deployment',
      detail: err?.message || String(err),
    })
  }
}

app.post('/api/admin/deploy-edge-functions', handleDeployEdgeFunctions)
app.get('/api/admin/deploy-edge-functions', handleDeployEdgeFunctions)

app.options('/api/admin/deploy-edge-functions', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'GET,POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

app.post('/api/admin/upload-image', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service role key not configured for uploads' })
    return
  }
  const adminPrincipal = await ensureEditor(req, res)
  if (!adminPrincipal) return

  try {
    await ensureAdminMediaUploadsTable()
  } catch { }

  let adminUser = null
  try {
    adminUser = await getUserFromRequest(req)
  } catch { }
  let adminDisplayName = null
  if (adminUser?.id) {
    adminDisplayName = await getAdminProfileName(adminUser.id)
  }

  await handleScopedImageUpload(req, res, {
    actorId: adminPrincipal,
    auditLabel: 'admin',
    uploaderInfo: {
      id: adminUser?.id || null,
      email: adminUser?.email || null,
      name: adminDisplayName || null,
    },
    prefixBuilder: ({ req }) => {
      const folder = sanitizeFolderInput(req.body?.folder || req.query?.folder)
      return [adminUploadPrefix, folder].filter(Boolean).join('/')
    },
    // Admin uploads: UTILITY bucket, 90% quality (highest)
    bucket: 'UTILITY',
    webpQuality: 90,
  })
})

// Mockups upload - for PWA screenshots and app mockup images
app.post('/api/admin/upload-mockup', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service role key not configured for uploads' })
    return
  }
  const adminPrincipal = await ensureEditor(req, res)
  if (!adminPrincipal) return

  try {
    await ensureAdminMediaUploadsTable()
  } catch { }

  let adminUser = null
  try {
    adminUser = await getUserFromRequest(req)
  } catch { }
  let adminDisplayName = null
  if (adminUser?.id) {
    adminDisplayName = await getAdminProfileName(adminUser.id)
  }

  await handleScopedImageUpload(req, res, {
    actorId: adminPrincipal,
    auditLabel: 'mockups',
    uploaderInfo: {
      id: adminUser?.id || null,
      email: adminUser?.email || null,
      name: adminDisplayName || null,
    },
    prefixBuilder: () => {
      // Always store in the Mockups folder
      return mockupsUploadPrefix
    },
    // Mockups uploads: UTILITY bucket, 90% quality (highest for marketing materials)
    bucket: 'UTILITY',
    webpQuality: 90,
    // Extract tag and device from request body for mockup metadata
    extraMetadataBuilder: ({ req }) => {
      const validTags = ['screenshot', 'mockup']
      const validDevices = ['phone', 'computer', 'tablet']
      const tag = validTags.includes(req.body?.tag) ? req.body.tag : null
      const device = validDevices.includes(req.body?.device) ? req.body.device : null
      return { tag, device }
    },
  })
})

app.post('/api/blog/upload-image', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service role key not configured for uploads' })
    return
  }
  const adminPrincipal = await ensureEditor(req, res)
  if (!adminPrincipal) return

  try {
    await ensureAdminMediaUploadsTable()
  } catch { }

  let adminUser = null
  try {
    adminUser = await getUserFromRequest(req)
  } catch { }
  let adminDisplayName = null
  if (adminUser?.id) {
    adminDisplayName = await getAdminProfileName(adminUser.id)
  }

  await handleScopedImageUpload(req, res, {
    actorId: adminPrincipal,
    auditLabel: 'blog',
    uploaderInfo: {
      id: adminUser?.id || null,
      email: adminUser?.email || null,
      name: adminDisplayName || null,
    },
    prefixBuilder: ({ req }) => {
      const folder = sanitizeFolderInput(req.body?.folder || req.query?.folder)
      return [blogUploadPrefix, folder].filter(Boolean).join('/')
    },
    // Blog uploads: UTILITY bucket, 90% quality (same as admin)
    bucket: 'UTILITY',
    webpQuality: 90,
  })
})

app.post('/api/pro-advice/upload-image', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service role key not configured for uploads' })
    return
  }
  const principal = await ensureProOrEditor(req, res)
  if (!principal) return

  try {
    await ensureAdminMediaUploadsTable()
  } catch { }

  let uploader = null
  try {
    uploader = await getUserFromRequest(req)
  } catch { }
  let uploaderDisplayName = null
  if (uploader?.id) {
    uploaderDisplayName = await getAdminProfileName(uploader.id)
  }

  await handleScopedImageUpload(req, res, {
    actorId: principal,
    auditLabel: 'pro-advice',
    uploaderInfo: {
      id: uploader?.id || null,
      email: uploader?.email || null,
      name: uploaderDisplayName || null,
    },
    prefixBuilder: ({ req }) => {
      const folder = sanitizeFolderInput(req.body?.folder || req.query?.folder)
      return [proAdviceUploadPrefix, folder].filter(Boolean).join('/')
    },
    // Pro advice uploads: PHOTOS bucket, 50% quality (standard)
    bucket: 'PHOTOS',
    webpQuality: 50,
  })
})

// Messages image upload - for chat images
app.post('/api/messages/upload-image', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service role key not configured for uploads' })
    return
  }
  
  // Require authenticated user
  let uploader = null
  try {
    uploader = await getUserFromRequest(req)
  } catch { }
  
  if (!uploader?.id) {
    res.status(401).json({ error: 'You must be signed in to upload images' })
    return
  }

  // Rate limit: 50 image uploads per hour per user
  if (await checkRateLimit('imageUpload', req, res, uploader)) {
    return
  }

  try {
    await ensureAdminMediaUploadsTable()
  } catch { }

  let uploaderDisplayName = null
  try {
    uploaderDisplayName = await getAdminProfileName(uploader.id)
  } catch { }

  await handleScopedImageUpload(req, res, {
    actorId: uploader.id,
    auditLabel: 'messages',
    uploaderInfo: {
      id: uploader.id,
      email: uploader.email || null,
      name: uploaderDisplayName || null,
    },
    prefixBuilder: ({ req }) => {
      // Organize by user ID for easier management
      const userId = uploader?.id || 'anonymous'
      return `${messagesUploadPrefix}/${userId}`
    },
    // Messages uploads: PHOTOS bucket, 50% quality (standard)
    bucket: 'PHOTOS',
    webpQuality: 50,
  })
})

app.post('/api/blog/summarize', async (req, res) => {
  if (!openaiClient) {
    res.status(503).json({ error: 'OpenAI client not configured' })
    return
  }
  const adminPrincipal = await ensureEditor(req, res)
  if (!adminPrincipal) return

  const html = typeof req.body?.html === 'string' ? req.body.html : ''
  const title = typeof req.body?.title === 'string' ? req.body.title : ''
  // Check if full metadata generation is requested (new feature)
  const generateFullMetadata = req.body?.generateMetadata === true

  if (!html.trim()) {
    res.status(400).json({ error: 'Missing html content to summarize' })
    return
  }

  const bodyText = extractPlainText(html, 6000)
  if (!bodyText) {
    res.json({ summary: '', seoTitle: null, seoDescription: null, tags: [] })
    return
  }

  // If full metadata generation is requested, generate all fields at once
  if (generateFullMetadata) {
    const instructions = [
      'You are an SEO expert. Generate metadata for this blog article from Aphylia (a plant care app).',
      '',
      'Return a JSON object with exactly these fields:',
      '',
      '- "teaser": A compelling 1-sentence summary under 240 characters. Capture the SPECIFIC topic/insight of THIS article. Active voice, no emojis.',
      '',
      '- "seoTitle": An SEO-optimized title under 60 characters that is SPECIFIC to this article\'s unique content. Do NOT use generic titles. Include the main subject/plant/technique discussed.',
      '',
      '- "seoDescription": An SEO meta description between 120-155 characters. Be SPECIFIC about what readers will learn from THIS article.',
      '',
      '- "tags": An array of 5-7 lowercase tags. IMPORTANT: Tags must be SPECIFIC to the article content:',
      '  * Include specific plant names mentioned (e.g., "monstera", "tomatoes", "succulents")',
      '  * Include specific techniques discussed (e.g., "propagation", "repotting", "pruning")',
      '  * Include specific problems/solutions (e.g., "yellow-leaves", "overwatering", "pest-control")',
      '  * Include seasonal relevance if applicable (e.g., "spring-planting", "winter-care")',
      '  * Avoid generic tags like "plants", "gardening", "tips" unless the article is truly general',
      '  * Use hyphens for multi-word tags (e.g., "indoor-plants", "soil-mix")',
      '',
      'Respond ONLY with valid JSON, no markdown formatting.',
    ].join('\n')
    const promptSections = [
      title ? `Article Title: ${title}` : null,
      `Article Body:\n${bodyText}`,
    ].filter(Boolean)

    try {
      // Use same model and timeout as AI Plant Fill for best quality metadata
      const response = await openaiClient.responses.create(
        {
          model: openaiModel,
          reasoning: { effort: 'medium' },
          instructions,
          input: promptSections.join('\n\n'),
          max_output_tokens: 500,
        },
        { timeout: Number(process.env.OPENAI_TIMEOUT_MS || 600000) },
      )
      const rawOutput = typeof response?.output_text === 'string' ? response.output_text.trim() : '{}'
      // Parse the JSON response, handling potential markdown code blocks
      let parsed = {}
      try {
        const cleanJson = rawOutput.replace(/^```json\s*/i, '').replace(/```\s*$/i, '').trim()
        parsed = JSON.parse(cleanJson)
      } catch (parseErr) {
        console.warn('[blog] Failed to parse AI metadata JSON, falling back to empty', parseErr)
      }
      // Validate and normalize the response
      const teaser = typeof parsed.teaser === 'string' ? parsed.teaser.slice(0, 240).trim() : ''
      const seoTitle = typeof parsed.seoTitle === 'string' ? parsed.seoTitle.slice(0, 60).trim() : null
      const seoDescription = typeof parsed.seoDescription === 'string' ? parsed.seoDescription.slice(0, 160).trim() : null
      const tags = Array.isArray(parsed.tags) 
        ? parsed.tags.filter(t => typeof t === 'string').map(t => t.toLowerCase().trim()).slice(0, 7)
        : []
      res.json({ summary: teaser, seoTitle, seoDescription, tags })
    } catch (err) {
      console.error('[blog] full metadata generation failed', err)
      res.status(500).json({ error: err?.message || 'Failed to generate metadata' })
    }
    return
  }

  // Legacy mode: just generate summary/teaser
  const instructions = [
    'Summarize the provided Aphylia blog article into a single compelling sentence under 240 characters.',
    'Write in active voice and avoid emojis or hashtags.',
    'Mention the core outcome or insight so it can be shown on cards.',
  ].join('\n')
  const promptSections = [
    title ? `Title: ${title}` : null,
    `Body:\n${bodyText}`,
  ].filter(Boolean)

  try {
    const response = await openaiClient.responses.create(
      {
        model: openaiModel,
        reasoning: { effort: 'low' },
        instructions,
        input: promptSections.join('\n\n'),
        max_output_tokens: 150,
      },
      { timeout: Number(process.env.OPENAI_TIMEOUT_MS || 300000) },
    )
    const summary = typeof response?.output_text === 'string' ? response.output_text.trim() : ''
    res.json({ summary })
  } catch (err) {
    console.error('[blog] summary generation failed', err)
    res.status(500).json({ error: err?.message || 'Failed to generate summary' })
  }
})

app.post('/api/admin/plant-translations/ensure-schema', async (req, res) => {
  const caller = await ensureEditor(req, res)
  if (!caller) return
  try {
    await ensurePlantTranslationsSchema()
    res.json({ ok: true })
  } catch (err) {
    console.error('[server] ensure plant_translations schema failed', err)
    res.status(500).json({ error: err?.message || 'Failed to ensure plant translation schema' })
  }
})
app.options('/api/admin/plant-translations/ensure-schema', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

app.get('/api/admin/media', async (req, res) => {
  const admin = await ensureEditor(req, res)
  if (!admin) return

  // Ensure table schema is up to date (adds upload_source column if missing)
  try {
    await ensureAdminMediaUploadsTable()
  } catch { }

  const limitParam = Number.parseInt(String(req.query?.limit || ''), 10)
  const limit = Number.isFinite(limitParam) ? Math.min(Math.max(limitParam, 1), 500) : 100
  const bucketParamRaw =
    typeof req.query?.bucket === 'string'
      ? String(req.query.bucket).trim().toLowerCase()
      : null
  const sourceParam =
    typeof req.query?.source === 'string'
      ? String(req.query.source).trim().toLowerCase()
      : null
  const userIdParam =
    typeof req.query?.userId === 'string'
      ? String(req.query.userId).trim()
      : null
  const gardenBucketName = gardenCoverUploadBucket
    ? gardenCoverUploadBucket.toLowerCase()
    : null
  const includeGardenCovers =
    !bucketParamRaw || (gardenBucketName && bucketParamRaw === gardenBucketName)

  try {
    let rows = []
    if (sql) {
      rows =
        await sql`select id, admin_id, admin_email, admin_name, bucket, path, public_url, mime_type, original_mime_type, size_bytes, original_size_bytes, quality, compression_percent, metadata, upload_source, created_at from public.admin_media_uploads order by created_at desc limit ${limit * 2}`
    } else if (supabaseServiceClient) {
      const { data, error } = await supabaseServiceClient
        .from('admin_media_uploads')
        .select(
          'id, admin_id, admin_email, admin_name, bucket, path, public_url, mime_type, original_mime_type, size_bytes, original_size_bytes, quality, compression_percent, metadata, upload_source, created_at',
        )
        .order('created_at', { ascending: false })
        .limit(limit * 2)
      if (error) throw error
      rows = data || []
    } else {
      res.status(500).json({ error: 'Storage backend not configured' })
      return
    }

    let media = (rows || [])
      .map((row) => normalizeAdminMediaRow(row))
      .filter(Boolean)
    
    // Filter by bucket if specified
    if (bucketParamRaw) {
      media = media.filter(
        (item) => (item?.bucket || '').toLowerCase() === bucketParamRaw,
      )
    }
    
    // Filter by source/function if specified
    if (sourceParam) {
      media = media.filter(
        (item) => (item?.uploadSource || '').toLowerCase() === sourceParam,
      )
    }
    
    // Filter by user ID if specified
    if (userIdParam) {
      media = media.filter(
        (item) => item?.adminId === userIdParam,
      )
    }

    const seenKeys = new Set(
      media
        .filter((item) => item?.bucket && item?.path)
        .map((item) => `${item.bucket}/${item.path}`.toLowerCase()),
    )

    let combined = [...media]
    if (includeGardenCovers && !sourceParam) {
      try {
        const gardenMedia = await syncGardenCoverMedia(seenKeys, limit)
        combined = combined.concat(gardenMedia.filter(Boolean))
      } catch (coverErr) {
        console.error('[media] failed to sync garden cover uploads', coverErr)
      }
    }
    combined = combined.filter(Boolean)

    combined.sort((a, b) => {
      const aTime = a?.createdAt ? Date.parse(a.createdAt) : 0
      const bTime = b?.createdAt ? Date.parse(b.createdAt) : 0
      if (!Number.isFinite(aTime) && !Number.isFinite(bTime)) return 0
      return (Number.isFinite(bTime) ? bTime : 0) - (Number.isFinite(aTime) ? aTime : 0)
    })

    // Collect unique sources for filter dropdown
    const availableSources = [...new Set(combined.map(item => item?.uploadSource).filter(Boolean))].sort()
    
    // Collect stats
    const totalSize = combined.reduce((sum, item) => sum + (item?.sizeBytes || 0), 0)
    const stats = {
      totalCount: combined.length,
      totalSize,
      bySource: availableSources.reduce((acc, src) => {
        const items = combined.filter(item => item?.uploadSource === src)
        acc[src] = {
          count: items.length,
          size: items.reduce((sum, item) => sum + (item?.sizeBytes || 0), 0),
        }
        return acc
      }, {}),
    }

    res.json({ 
      ok: true, 
      media: combined.slice(0, limit),
      availableSources,
      stats,
    })
  } catch (err) {
    console.error('[media] failed to load admin media uploads', err)
    res.status(500).json({ error: 'Failed to load media uploads' })
  }
})
app.options('/api/admin/media', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'GET,DELETE,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

app.delete('/api/admin/media/:id', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service role key not configured for media deletion' })
    return
  }
  const admin = await ensureEditor(req, res)
  if (!admin) return

  try {
    await ensureAdminMediaUploadsTable()
  } catch { }

  const mediaId = String(req.params?.id || '').trim()
  if (!mediaId) {
    res.status(400).json({ error: 'Missing media id' })
    return
  }

  let mediaRow = null
  try {
    if (sql) {
      const rows =
        await sql`select id, bucket, path from public.admin_media_uploads where id = ${mediaId} limit 1`
      mediaRow = rows?.[0] || null
    } else {
      const { data, error } = await supabaseServiceClient
        .from('admin_media_uploads')
        .select('id, bucket, path')
        .eq('id', mediaId)
        .maybeSingle()
      if (error) {
        res.status(500).json({ error: error.message || 'Failed to load media record' })
        return
      }
      mediaRow = data || null
    }
  } catch (err) {
    res.status(500).json({ error: err?.message || 'Failed to load media record' })
    return
  }

  if (!mediaRow) {
    res.status(404).json({ error: 'Media not found' })
    return
  }

  let storageWarning = null
  try {
    const { error } = await supabaseServiceClient
      .storage
      .from(mediaRow.bucket)
      .remove([mediaRow.path])
    if (error) storageWarning = error.message || 'Failed to delete storage object'
  } catch (err) {
    storageWarning = err?.message || 'Failed to delete storage object'
  }

  try {
    if (sql) {
      await sql`delete from public.admin_media_uploads where id = ${mediaId}`
    } else {
      const { error } = await supabaseServiceClient
        .from('admin_media_uploads')
        .delete()
        .eq('id', mediaId)
      if (error) throw error
    }
  } catch (err) {
    res.status(500).json({ error: err?.message || 'Failed to delete media record', storageWarning })
    return
  }

  res.json({ ok: true, id: mediaId, storageWarning })
})
app.options('/api/admin/media/:id', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'DELETE,PATCH,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type, X-Admin-Token')
  res.status(204).end()
})

// Update media metadata (tag, device)
app.patch('/api/admin/media/:id', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service role key not configured' })
    return
  }
  const admin = await ensureEditor(req, res)
  if (!admin) return

  try {
    await ensureAdminMediaUploadsTable()
  } catch { }

  const mediaId = String(req.params?.id || '').trim()
  if (!mediaId) {
    res.status(400).json({ error: 'Missing media id' })
    return
  }

  // Validate and extract tag/device from body
  const validTags = ['screenshot', 'mockup']
  const validDevices = ['phone', 'computer', 'tablet']
  const body = req.body || {}
  
  // Only allow updating tag and device, and validate values
  const updates = {}
  if (body.tag !== undefined) {
    if (body.tag === null || validTags.includes(body.tag)) {
      updates.tag = body.tag
    } else {
      res.status(400).json({ error: `Invalid tag value. Must be one of: ${validTags.join(', ')}` })
      return
    }
  }
  if (body.device !== undefined) {
    if (body.device === null || validDevices.includes(body.device)) {
      updates.device = body.device
    } else {
      res.status(400).json({ error: `Invalid device value. Must be one of: ${validDevices.join(', ')}` })
      return
    }
  }

  if (Object.keys(updates).length === 0) {
    res.status(400).json({ error: 'No valid fields to update. Provide tag and/or device.' })
    return
  }

  try {
    let updatedRow = null
    if (sql) {
      // Fetch current metadata, merge updates, and save
      const rows = await sql`
        select id, metadata from public.admin_media_uploads where id = ${mediaId} limit 1
      `
      if (!rows || rows.length === 0) {
        res.status(404).json({ error: 'Media not found' })
        return
      }
      const currentMetadata = rows[0].metadata || {}
      const newMetadata = { ...currentMetadata, ...updates }
      
      const updated = await sql`
        update public.admin_media_uploads
        set metadata = ${sql.json(newMetadata)}
        where id = ${mediaId}
        returning id, admin_id, admin_email, admin_name, bucket, path, public_url, mime_type, original_mime_type, size_bytes, original_size_bytes, quality, compression_percent, metadata, upload_source, created_at
      `
      updatedRow = updated?.[0] || null
    } else {
      // Fetch current record
      const { data: current, error: fetchError } = await supabaseServiceClient
        .from('admin_media_uploads')
        .select('id, metadata')
        .eq('id', mediaId)
        .maybeSingle()
      
      if (fetchError) {
        res.status(500).json({ error: fetchError.message || 'Failed to load media record' })
        return
      }
      if (!current) {
        res.status(404).json({ error: 'Media not found' })
        return
      }
      
      const currentMetadata = current.metadata || {}
      const newMetadata = { ...currentMetadata, ...updates }
      
      const { data, error } = await supabaseServiceClient
        .from('admin_media_uploads')
        .update({ metadata: newMetadata })
        .eq('id', mediaId)
        .select('id, admin_id, admin_email, admin_name, bucket, path, public_url, mime_type, original_mime_type, size_bytes, original_size_bytes, quality, compression_percent, metadata, upload_source, created_at')
        .maybeSingle()
      
      if (error) {
        res.status(500).json({ error: error.message || 'Failed to update media record' })
        return
      }
      updatedRow = data
    }

    if (!updatedRow) {
      res.status(404).json({ error: 'Media not found' })
      return
    }

    res.json({ ok: true, media: normalizeAdminMediaRow(updatedRow) })
  } catch (err) {
    console.error('[media-update] failed to update media metadata', err)
    res.status(500).json({ error: err?.message || 'Failed to update media record' })
  }
})

app.get('/api/env.js', (req, res) => {
  res.setHeader('Content-Type', 'application/javascript')
  const token = process.env.ADMIN_STATIC_TOKEN || process.env.VITE_ADMIN_STATIC_TOKEN || ''
  res.send(`window.__ENV__ = window.__ENV__ || {}; window.__ENV__.VITE_ADMIN_STATIC_TOKEN = "${token}";`)
})

app.get('/api/admin/notifications', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  try {
    const rows = await sql`
      select n.*, 
             stats.total_recipients, stats.sent_count, stats.failed_count, stats.pending_count,
             creator.display_name as created_by_name,
             t.title as template_title,
             rc.recipient_count as estimated_recipients
      from public.notification_campaigns n
      left join lateral (
        select
          count(*)::bigint as total_recipients,
          count(*) filter (where delivery_status = 'sent')::bigint as sent_count,
          count(*) filter (where delivery_status = 'failed')::bigint as failed_count,
          count(*) filter (where delivery_status = 'pending')::bigint as pending_count
        from public.user_notifications un
        where un.campaign_id = n.id
      ) stats on true
      left join public.profiles creator on creator.id = n.created_by
      left join public.notification_templates t on t.id = n.template_id
      left join lateral (
        select case 
          when n.audience = 'all' then (
            select count(*)::bigint from public.profiles p 
            where (p.notify_push is null or p.notify_push = true)
          )
          when n.audience = 'tasks_open' then (
            select count(distinct p.id)::bigint
            from public.profiles p
            join public.garden_members gm on gm.user_id = p.id
            join public.garden_plant_tasks t on t.garden_id = gm.garden_id
            join public.garden_plant_task_occurrences occ on occ.task_id = t.id
            where (p.notify_push is null or p.notify_push = true)
              and occ.due_at::date = current_date
              and (occ.completed_count < occ.required_count or occ.completed_count = 0)
          )
          when n.audience = 'inactive_week' then (
            select count(*)::bigint
            from public.profiles p
            left join auth.users u on u.id = p.id
            where (p.notify_push is null or p.notify_push = true)
              and coalesce(u.last_sign_in_at, u.created_at, now() - interval '30 days') < now() - interval '7 days'
          )
          when n.audience = 'admins' then (
            select count(*)::bigint from public.profiles p 
            where p.is_admin = true and (p.notify_push is null or p.notify_push = true)
          )
          when n.audience = 'custom' then (
            select count(*)::bigint from unnest(n.custom_user_ids) as uid
            join public.profiles p on p.id = uid
            where (p.notify_push is null or p.notify_push = true)
          )
          else 0
        end as recipient_count
      ) rc on true
      where n.deleted_at is null
      order by coalesce(n.next_run_at, n.created_at) desc
      limit 200
    `
    const notifications = (rows || [])
      .map((row) => normalizeNotificationCampaign(row))
      .filter(Boolean)
    res.json({ notifications, pushConfigured: pushNotificationsEnabled })
  } catch (err) {
    console.error('[notifications] failed to load campaigns', err)
    res.status(500).json({ error: err?.message || 'Failed to load notifications' })
  }
})

app.post('/api/admin/notifications', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  let parsed
  try {
    parsed = notificationInputSchema.parse(req.body || {})
  } catch (err) {
    res.status(400).json({ error: err?.errors?.[0]?.message || 'Invalid payload' })
    return
  }
  const messageVariants = (parsed.messageVariants || [])
    .map((value) => value.trim())
    .filter((value) => value.length > 0)
  if (!messageVariants.length) {
    res.status(400).json({ error: 'At least one message variant is required' })
    return
  }
  const deliveryMode = parsed.deliveryMode
  const campaignTimezone = parsed.timezone || DEFAULT_TIMEZONE

  // Convert datetime-local input to UTC timestamp in campaign timezone
  const convertDatetimeLocalToUTC = (datetimeLocal, tz) => {
    if (!datetimeLocal || !datetimeLocal.length) return null
    try {
      const match = datetimeLocal.match(/^(\d{4})-(\d{2})-(\d{2})T(\d{2}):(\d{2})$/)
      if (!match) {
        const fallback = new Date(datetimeLocal)
        return Number.isNaN(fallback.getTime()) ? null : fallback.toISOString()
      }

      const [, year, month, day, hour, minute] = match
      const y = parseInt(year)
      const m = parseInt(month) - 1
      const d = parseInt(day)
      const h = parseInt(hour)
      const min = parseInt(minute)

      let candidateUtc = new Date(Date.UTC(y, m, d, h, min, 0))

      for (let iteration = 0; iteration < 10; iteration++) {
        const formatter = new Intl.DateTimeFormat('en-US', {
          timeZone: tz,
          year: 'numeric',
          month: '2-digit',
          day: '2-digit',
          hour: '2-digit',
          minute: '2-digit',
          second: '2-digit',
          hour12: false
        })

        const parts = formatter.formatToParts(candidateUtc)
        const getPart = (type) => parseInt(parts.find(p => p.type === type)?.value || '0')

        const tzYear = getPart('year')
        const tzMonth = getPart('month') - 1
        const tzDay = getPart('day')
        const tzHour = getPart('hour')
        const tzMinute = getPart('minute')
        const tzSecond = getPart('second')

        if (tzYear === y && tzMonth === m && tzDay === d &&
          tzHour === h && tzMinute === min && tzSecond === 0) {
          return candidateUtc.toISOString()
        }

        const desiredLocal = new Date(y, m, d, h, min, 0)
        const actualLocal = new Date(tzYear, tzMonth, tzDay, tzHour, tzMinute, tzSecond)
        const diffMs = desiredLocal.getTime() - actualLocal.getTime()

        if (Math.abs(diffMs) < 1000) {
          return candidateUtc.toISOString()
        }

        candidateUtc = new Date(candidateUtc.getTime() + diffMs)
      }

      return candidateUtc.toISOString()
    } catch (err) {
      console.error('[notifications] Error converting datetime-local:', err)
      const fallback = new Date(datetimeLocal)
      return Number.isNaN(fallback.getTime()) ? null : fallback.toISOString()
    }
  }

  const plannedFor = deliveryMode === 'planned' && parsed.plannedFor
    ? convertDatetimeLocalToUTC(parsed.plannedFor, campaignTimezone)
    : null
  const scheduleStartAt = deliveryMode === 'scheduled' && parsed.scheduleStartAt
    ? convertDatetimeLocalToUTC(parsed.scheduleStartAt, campaignTimezone)
    : null
  const nextRunAt = determineInitialNextRunAt({
    deliveryMode,
    plannedFor,
    scheduleStartAt,
  })
  const audience = parsed.audience
  const customIds = audience === 'custom' ? parsed.customUserIds || [] : []
  const scheduleInterval = deliveryMode === 'scheduled' ? parsed.scheduleInterval || 'daily' : null
  const timezone = campaignTimezone
  const state = deliveryMode === 'scheduled' ? 'scheduled' : 'draft'
  const templateId = parsed.templateId || null
  const adminUuid = toAdminUuid(adminId)
  try {
    const rows = await sql`
      insert into public.notification_campaigns (
        title, description, delivery_mode, state, audience, filters, message_variants,
        randomize, timezone, planned_for, schedule_start_at, schedule_interval, cta_url,
        custom_user_ids, template_id, run_count, created_by, updated_by, next_run_at, created_at, updated_at
      )
      values (
        ${parsed.title.trim()},
        ${parsed.description},
        ${deliveryMode},
        ${state},
        ${audience},
        '{}'::jsonb,
        ${sql.array(messageVariants)},
        ${parsed.randomize !== false},
        ${timezone},
        ${deliveryMode === 'planned' ? plannedFor : null},
        ${deliveryMode === 'scheduled' ? (scheduleStartAt || nextRunAt) : null},
        ${scheduleInterval},
        ${parsed.ctaUrl || null},
        ${customIds.length ? sql.array(customIds) : sql.array([])},
        ${templateId},
        0,
        ${adminUuid},
        ${adminUuid},
        ${nextRunAt},
        now(),
        now()
      )
      returning *
    `
    const notification = normalizeNotificationCampaign(rows?.[0])
    res.json({ notification, pushConfigured: pushNotificationsEnabled })
    runNotificationWorkerTick().catch(() => { })
  } catch (err) {
    console.error('[notifications] failed to create campaign', err)
    res.status(500).json({ error: err?.message || 'Failed to create notification' })
  }
})

app.put('/api/admin/notifications/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  const notificationId = String(req.params?.id || '').trim()
  if (!notificationId) {
    res.status(400).json({ error: 'Missing notification id' })
    return
  }
  let parsed
  try {
    parsed = notificationInputSchema.parse(req.body || {})
  } catch (err) {
    res.status(400).json({ error: err?.errors?.[0]?.message || 'Invalid payload' })
    return
  }
  const messageVariants = (parsed.messageVariants || [])
    .map((value) => value.trim())
    .filter((value) => value.length > 0)
  if (!messageVariants.length) {
    res.status(400).json({ error: 'At least one message variant is required' })
    return
  }
  const existingRows = await sql`
    select * from public.notification_campaigns where id = ${notificationId} and deleted_at is null limit 1
  `
  if (!existingRows || !existingRows.length) {
    res.status(404).json({ error: 'Notification not found' })
    return
  }
  const deliveryMode = parsed.deliveryMode
  const campaignTimezone = parsed.timezone || DEFAULT_TIMEZONE

  // Convert datetime-local input to UTC timestamp in campaign timezone (same logic as create)
  const convertDatetimeLocalToUTC = (datetimeLocal, tz) => {
    if (!datetimeLocal || !datetimeLocal.length) return null
    try {
      const match = datetimeLocal.match(/^(\d{4})-(\d{2})-(\d{2})T(\d{2}):(\d{2})$/)
      if (!match) {
        const fallback = new Date(datetimeLocal)
        return Number.isNaN(fallback.getTime()) ? null : fallback.toISOString()
      }

      const [, year, month, day, hour, minute] = match
      const y = parseInt(year)
      const m = parseInt(month) - 1
      const d = parseInt(day)
      const h = parseInt(hour)
      const min = parseInt(minute)

      let candidateUtc = new Date(Date.UTC(y, m, d, h, min, 0))

      for (let iteration = 0; iteration < 10; iteration++) {
        const formatter = new Intl.DateTimeFormat('en-US', {
          timeZone: tz,
          year: 'numeric',
          month: '2-digit',
          day: '2-digit',
          hour: '2-digit',
          minute: '2-digit',
          second: '2-digit',
          hour12: false
        })

        const parts = formatter.formatToParts(candidateUtc)
        const getPart = (type) => parseInt(parts.find(p => p.type === type)?.value || '0')

        const tzYear = getPart('year')
        const tzMonth = getPart('month') - 1
        const tzDay = getPart('day')
        const tzHour = getPart('hour')
        const tzMinute = getPart('minute')
        const tzSecond = getPart('second')

        if (tzYear === y && tzMonth === m && tzDay === d &&
          tzHour === h && tzMinute === min && tzSecond === 0) {
          return candidateUtc.toISOString()
        }

        const desiredLocal = new Date(y, m, d, h, min, 0)
        const actualLocal = new Date(tzYear, tzMonth, tzDay, tzHour, tzMinute, tzSecond)
        const diffMs = desiredLocal.getTime() - actualLocal.getTime()

        if (Math.abs(diffMs) < 1000) {
          return candidateUtc.toISOString()
        }

        candidateUtc = new Date(candidateUtc.getTime() + diffMs)
      }

      return candidateUtc.toISOString()
    } catch (err) {
      console.error('[notifications] Error converting datetime-local:', err)
      const fallback = new Date(datetimeLocal)
      return Number.isNaN(fallback.getTime()) ? null : fallback.toISOString()
    }
  }

  const plannedFor = deliveryMode === 'planned' && parsed.plannedFor
    ? convertDatetimeLocalToUTC(parsed.plannedFor, campaignTimezone)
    : null
  const scheduleStartAt = deliveryMode === 'scheduled' && parsed.scheduleStartAt
    ? convertDatetimeLocalToUTC(parsed.scheduleStartAt, campaignTimezone)
    : null
  const nextRunAt = determineInitialNextRunAt({
    deliveryMode,
    plannedFor,
    scheduleStartAt,
  })
  const audience = parsed.audience
  const customIds = audience === 'custom' ? parsed.customUserIds || [] : []
  const scheduleInterval = deliveryMode === 'scheduled' ? parsed.scheduleInterval || 'daily' : null
  const timezone = campaignTimezone
  const nextState = deliveryMode === 'scheduled' ? (existingRows[0].state === 'paused' ? 'paused' : 'scheduled') : 'draft'
  const templateId = parsed.templateId || null
  const adminUuid = toAdminUuid(adminId)
  try {
    const rows = await sql`
      update public.notification_campaigns
      set title = ${parsed.title.trim()},
          description = ${parsed.description},
          delivery_mode = ${deliveryMode},
          state = ${nextState},
          audience = ${audience},
          message_variants = ${sql.array(messageVariants)},
          randomize = ${parsed.randomize !== false},
          timezone = ${timezone},
          planned_for = ${deliveryMode === 'planned' ? plannedFor : null},
          schedule_start_at = ${deliveryMode === 'scheduled' ? (scheduleStartAt || nextRunAt) : null},
          schedule_interval = ${scheduleInterval},
          cta_url = ${parsed.ctaUrl || null},
          custom_user_ids = ${customIds.length ? sql.array(customIds) : sql.array([])},
          template_id = ${templateId},
          updated_by = ${adminUuid},
          next_run_at = ${nextRunAt},
          updated_at = now()
      where id = ${notificationId}
      returning *
    `
    const notification = normalizeNotificationCampaign(rows?.[0])
    res.json({ notification })
  } catch (err) {
    console.error('[notifications] failed to update campaign', err)
    res.status(500).json({ error: err?.message || 'Failed to update notification' })
  }
})

app.delete('/api/admin/notifications/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  const notificationId = String(req.params?.id || '').trim()
  if (!notificationId) {
    res.status(400).json({ error: 'Missing notification id' })
    return
  }
  const adminUuid = toAdminUuid(adminId)
  try {
    const rows = await sql`
      update public.notification_campaigns
      set deleted_at = now(),
          state = 'cancelled',
          updated_by = ${adminUuid},
          updated_at = now()
      where id = ${notificationId}
      returning *
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Notification not found' })
      return
    }
    const notification = normalizeNotificationCampaign(rows[0])
    res.json({ notification })
  } catch (err) {
    console.error('[notifications] failed to delete campaign', err)
    res.status(500).json({ error: err?.message || 'Failed to delete notification' })
  }
})

app.post('/api/admin/notifications/:id/trigger', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  const notificationId = String(req.params?.id || '').trim()
  if (!notificationId) {
    res.status(400).json({ error: 'Missing notification id' })
    return
  }
  const adminUuid = toAdminUuid(adminId)
  try {
    const rows = await sql`
      update public.notification_campaigns
      set next_run_at = now(),
          state = case when delivery_mode = 'scheduled' then 'scheduled' else 'draft' end,
          updated_by = ${adminUuid},
          updated_at = now()
      where id = ${notificationId} and deleted_at is null
      returning *
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Notification not found' })
      return
    }
    const notification = normalizeNotificationCampaign(rows[0])
    res.json({ notification })
    runNotificationWorkerTick().catch(() => { })
  } catch (err) {
    console.error('[notifications] failed to trigger campaign', err)
    res.status(500).json({ error: err?.message || 'Failed to trigger notification' })
  }
})

app.post('/api/admin/notifications/:id/state', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  const notificationId = String(req.params?.id || '').trim()
  if (!notificationId) {
    res.status(400).json({ error: 'Missing notification id' })
    return
  }
  let parsed
  try {
    parsed = notificationStateSchema.parse(req.body || {})
  } catch (err) {
    res.status(400).json({ error: err?.errors?.[0]?.message || 'Invalid payload' })
    return
  }
  const adminUuid = toAdminUuid(adminId)
  try {
    const rows = await sql`
      update public.notification_campaigns
      set state = ${parsed.state},
          next_run_at = case when ${parsed.state} = 'scheduled' and next_run_at is null then now() else next_run_at end,
          updated_by = ${adminUuid},
          updated_at = now()
      where id = ${notificationId} and deleted_at is null
      returning *
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Notification not found' })
      return
    }
    const notification = normalizeNotificationCampaign(rows[0])
    res.json({ notification })
  } catch (err) {
    console.error('[notifications] failed to update state', err)
    res.status(500).json({ error: err?.message || 'Failed to update notification state' })
  }
})

// Debug endpoint for notification diagnostics
app.get('/api/admin/notifications/debug', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  try {
    // Get pending campaigns (including those stuck in processing)
    const pendingCampaigns = await sql`
      select id, title, state, delivery_mode, next_run_at, planned_for, schedule_start_at, timezone, updated_at, last_run_summary
      from public.notification_campaigns
      where deleted_at is null
        and state not in ('cancelled','completed')
      order by 
        case when state = 'processing' then 0 else 1 end,
        next_run_at asc nulls last
      limit 10
    `

    // Get recent user notifications with error breakdown
    const recentNotifications = await sql`
      select un.id, un.user_id, un.title, un.delivery_status, un.scheduled_for, un.delivered_at, un.delivery_error, un.campaign_id, un.delivery_attempts
      from public.user_notifications un
      order by un.scheduled_for desc
      limit 30
    `

    // Get subscription counts
    const subscriptionStats = await sql`
      select 
        count(distinct user_id) as users_with_subscriptions,
        count(*) as total_subscriptions
      from public.user_push_subscriptions
    `

    // Get notification delivery stats
    const deliveryStats = await sql`
      select 
        delivery_status,
        count(*) as count
      from public.user_notifications
      where scheduled_for >= now() - interval '24 hours'
      group by delivery_status
    `

    // Get failure reason breakdown (last 24 hours)
    const failureReasons = await sql`
      select 
        delivery_error,
        count(*) as count
      from public.user_notifications
      where scheduled_for >= now() - interval '24 hours'
        and delivery_status = 'failed'
        and delivery_error is not null
      group by delivery_error
      order by count desc
      limit 10
    `

    // Get count of users who have push enabled in profile but no subscription registered
    const usersWithoutSubscription = await sql`
      select count(*) as count
      from public.profiles p
      where (p.notify_push is null or p.notify_push = true)
        and not exists (
          select 1 from public.user_push_subscriptions ups
          where ups.user_id = p.id
        )
    `

    // Check for stuck campaigns
    const stuckCampaigns = await sql`
      select id, title, state, updated_at
      from public.notification_campaigns
      where deleted_at is null
        and state = 'processing'
        and updated_at < now() - interval '5 minutes'
    `

    res.json({
      pushEnabled: pushNotificationsEnabled,
      vapidConfigured: Boolean(vapidPublicKey && vapidPrivateKey),
      workerIntervalMs: notificationWorkerIntervalMs,
      serverTime: new Date().toISOString(),
      pendingCampaigns: pendingCampaigns || [],
      recentNotifications: recentNotifications || [],
      subscriptionStats: subscriptionStats?.[0] || { users_with_subscriptions: 0, total_subscriptions: 0 },
      deliveryStats: deliveryStats || [],
      failureReasons: failureReasons || [],
      usersWithoutPushSubscription: Number(usersWithoutSubscription?.[0]?.count || 0),
      stuckCampaigns: stuckCampaigns || [],
      troubleshooting: {
        vapidKeysConfigured: Boolean(vapidPublicKey && vapidPrivateKey),
        pushEnabled: pushNotificationsEnabled,
        commonIssues: [
          'NO_PUSH_SUBSCRIPTION: User authorized notifications but subscription was not synced to server',
          'SUBSCRIPTION_EXPIRED: Browser subscription expired, user needs to re-enable notifications',
          'PUSH_DISABLED: VAPID keys not configured on server',
          'Processing stuck: Campaign error occurred, state was reset after 5 minutes',
        ],
      },
    })
  } catch (err) {
    console.error('[notifications] debug endpoint failed', err)
    res.status(500).json({ error: err?.message || 'Failed to get debug info' })
  }
})

// ---- Recipient Count Endpoint ----
app.get('/api/admin/notifications/recipient-count', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const audience = String(req.query?.audience || 'all').trim()
  try {
    let count = 0
    if (audience === 'all') {
      const rows = await sql`
        select count(*)::bigint as count
        from public.profiles p
        where (p.notify_push is null or p.notify_push = true)
      `
      count = Number(rows?.[0]?.count || 0)
    } else if (audience === 'tasks_open') {
      // Users with incomplete tasks today
      const rows = await sql`
        select count(distinct p.id)::bigint as count
        from public.profiles p
        join public.garden_members gm on gm.user_id = p.id
        join public.garden_plant_tasks t on t.garden_id = gm.garden_id
        join public.garden_plant_task_occurrences occ on occ.task_id = t.id
        where (p.notify_push is null or p.notify_push = true)
          and occ.due_at::date = current_date
          and (occ.completed_count < occ.required_count or occ.completed_count = 0)
      `
      count = Number(rows?.[0]?.count || 0)
    } else if (audience === 'inactive_week') {
      // Users inactive for 7+ days (based on last_seen_at or updated_at)
      const rows = await sql`
        select count(*)::bigint as count
        from public.profiles p
        left join auth.users u on u.id = p.id
        where (p.notify_push is null or p.notify_push = true)
          and coalesce(u.last_sign_in_at, u.created_at, now() - interval '30 days') < now() - interval '7 days'
      `
      count = Number(rows?.[0]?.count || 0)
    } else if (audience === 'admins') {
      const rows = await sql`
        select count(*)::bigint as count
        from public.profiles p
        where p.is_admin = true
          and (p.notify_push is null or p.notify_push = true)
      `
      count = Number(rows?.[0]?.count || 0)
    } else if (audience === 'journal_yesterday') {
      // Users who wrote in journal/note yesterday (for journal continue automation)
      const rows = await sql`
        select count(distinct p.id)::bigint as count
        from public.profiles p
        join public.garden_members gm on gm.user_id = p.id
        join public.garden_activity_logs gal on gal.garden_id = gm.garden_id
        where (p.notify_push is null or p.notify_push = true)
          and gal.kind = 'note'
          and gal.occurred_at::date = current_date - interval '1 day'
      `
      count = Number(rows?.[0]?.count || 0)
    }
    res.json({ count, audience })
  } catch (err) {
    console.error('[notifications] failed to count recipients', err)
    res.status(500).json({ error: err?.message || 'Failed to count recipients' })
  }
})

// ---- Notification Templates ----
app.get('/api/admin/notification-templates', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  try {
    await ensureNotificationTables()
    const rows = await sql`
      select t.*,
             stats.campaign_count,
             auto_stats.automation_count,
             trans.translations
      from public.notification_templates t
      left join lateral (
        select count(*)::bigint as campaign_count
        from public.notification_campaigns c
        where c.template_id = t.id and c.deleted_at is null
      ) stats on true
      left join lateral (
        select count(*)::bigint as automation_count
        from public.notification_automations a
        where a.template_id = t.id
      ) auto_stats on true
      left join lateral (
        select jsonb_object_agg(ntt.language, ntt.message_variants) as translations
        from public.notification_template_translations ntt
        where ntt.template_id = t.id
      ) trans on true
      order by t.updated_at desc
      limit 200
    `
    const templates = (rows || []).map((row) => normalizeNotificationTemplate(row)).filter(Boolean)
    res.json({ templates })
  } catch (err) {
    console.error('[notification-templates] failed to load templates', err)
    res.status(500).json({ error: err?.message || 'Failed to load templates' })
  }
})

app.post('/api/admin/notification-templates', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  let parsed
  try {
    parsed = notificationTemplateInputSchema.parse(req.body || {})
  } catch (err) {
    res.status(400).json({ error: err?.errors?.[0]?.message || 'Invalid payload' })
    return
  }
  const messageVariants = (parsed.messageVariants || [])
    .map((value) => value.trim())
    .filter((value) => value.length > 0)
  if (!messageVariants.length) {
    res.status(400).json({ error: 'At least one message variant is required' })
    return
  }
  const adminUuid = toAdminUuid(adminId)
  try {
    const rows = await sql`
      insert into public.notification_templates (
        title, description, message_variants, randomize, is_active,
        created_by, updated_by, created_at, updated_at
      )
      values (
        ${parsed.title.trim()},
        ${parsed.description || null},
        ${sql.array(messageVariants)},
        ${parsed.randomize !== false},
        ${parsed.isActive !== false},
        ${adminUuid},
        ${adminUuid},
        now(),
        now()
      )
      returning *
    `
    const template = normalizeNotificationTemplate(rows?.[0])
    res.json({ template })
  } catch (err) {
    console.error('[notification-templates] failed to create template', err)
    res.status(500).json({ error: err?.message || 'Failed to create template' })
  }
})

app.put('/api/admin/notification-templates/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const templateId = String(req.params?.id || '').trim()
  if (!templateId) {
    res.status(400).json({ error: 'Missing template id' })
    return
  }
  let parsed
  try {
    parsed = notificationTemplateInputSchema.parse(req.body || {})
  } catch (err) {
    res.status(400).json({ error: err?.errors?.[0]?.message || 'Invalid payload' })
    return
  }
  const messageVariants = (parsed.messageVariants || [])
    .map((value) => value.trim())
    .filter((value) => value.length > 0)
  if (!messageVariants.length) {
    res.status(400).json({ error: 'At least one message variant is required' })
    return
  }
  const adminUuid = toAdminUuid(adminId)
  try {
    const rows = await sql`
      update public.notification_templates
      set title = ${parsed.title.trim()},
          description = ${parsed.description || null},
          message_variants = ${sql.array(messageVariants)},
          randomize = ${parsed.randomize !== false},
          is_active = ${parsed.isActive !== false},
          updated_by = ${adminUuid},
          updated_at = now()
      where id = ${templateId}
      returning *
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Template not found' })
      return
    }
    const template = normalizeNotificationTemplate(rows[0])
    res.json({ template })
  } catch (err) {
    console.error('[notification-templates] failed to update template', err)
    res.status(500).json({ error: err?.message || 'Failed to update template' })
  }
})

app.delete('/api/admin/notification-templates/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const templateId = String(req.params?.id || '').trim()
  if (!templateId) {
    res.status(400).json({ error: 'Missing template id' })
    return
  }
  try {
    // Check if template is in use by campaigns or automations
    const usageCheck = await sql`
      select 
        (select count(*) from public.notification_campaigns where template_id = ${templateId} and deleted_at is null) as campaign_count,
        (select count(*) from public.notification_automations where template_id = ${templateId}) as automation_count
    `
    const campaignCount = Number(usageCheck?.[0]?.campaign_count || 0)
    const automationCount = Number(usageCheck?.[0]?.automation_count || 0)
    if (campaignCount > 0 || automationCount > 0) {
      res.status(400).json({
        error: `Template is in use by ${campaignCount} campaign(s) and ${automationCount} automation(s). Remove references first.`
      })
      return
    }
    const rows = await sql`
      delete from public.notification_templates
      where id = ${templateId}
      returning id
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Template not found' })
      return
    }
    res.json({ deleted: true, id: templateId })
  } catch (err) {
    console.error('[notification-templates] failed to delete template', err)
    res.status(500).json({ error: err?.message || 'Failed to delete template' })
  }
})

// ---- Notification Template Translations ----
app.get('/api/admin/notification-templates/:id/translations', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const templateId = String(req.params?.id || '').trim()
  if (!templateId) {
    res.status(400).json({ error: 'Missing template id' })
    return
  }
  try {
    const rows = await sql`
      select language, message_variants, updated_at
      from public.notification_template_translations
      where template_id = ${templateId}
      order by language
    `
    const translations = {}
    for (const row of rows || []) {
      translations[row.language] = {
        messageVariants: toStringArray(row.message_variants),
        updatedAt: isoOrNull(row.updated_at),
      }
    }
    res.json({ templateId, translations })
  } catch (err) {
    console.error('[notification-templates] failed to load translations', err)
    res.status(500).json({ error: err?.message || 'Failed to load translations' })
  }
})

app.put('/api/admin/notification-templates/:id/translations/:lang', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const templateId = String(req.params?.id || '').trim()
  const language = String(req.params?.lang || '').trim().toLowerCase()
  if (!templateId) {
    res.status(400).json({ error: 'Missing template id' })
    return
  }
  if (!language || language.length > 10) {
    res.status(400).json({ error: 'Invalid language code' })
    return
  }
  const body = req.body || {}
  const messageVariants = toStringArray(body.messageVariants || [])
    .map(v => v.trim())
    .filter(v => v.length > 0)

  if (!messageVariants.length) {
    // Delete translation if no variants
    try {
      await sql`
        delete from public.notification_template_translations
        where template_id = ${templateId} and language = ${language}
      `
      res.json({ deleted: true, templateId, language })
    } catch (err) {
      console.error('[notification-templates] failed to delete translation', err)
      res.status(500).json({ error: err?.message || 'Failed to delete translation' })
    }
    return
  }

  try {
    const rows = await sql`
      insert into public.notification_template_translations (template_id, language, message_variants, updated_at)
      values (${templateId}, ${language}, ${sql.array(messageVariants)}, now())
      on conflict (template_id, language)
      do update set message_variants = ${sql.array(messageVariants)}, updated_at = now()
      returning *
    `
    res.json({
      templateId,
      language,
      messageVariants: toStringArray(rows?.[0]?.message_variants),
      updatedAt: isoOrNull(rows?.[0]?.updated_at),
    })
  } catch (err) {
    console.error('[notification-templates] failed to save translation', err)
    res.status(500).json({ error: err?.message || 'Failed to save translation' })
  }
})

// Batch save all translations for a template
app.put('/api/admin/notification-templates/:id/translations', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const templateId = String(req.params?.id || '').trim()
  if (!templateId) {
    res.status(400).json({ error: 'Missing template id' })
    return
  }
  const body = req.body || {}
  const translationsInput = body.translations || {}

  try {
    // Delete all existing translations first
    await sql`delete from public.notification_template_translations where template_id = ${templateId}`

    // Insert new translations
    const savedTranslations = {}
    for (const [language, variants] of Object.entries(translationsInput)) {
      const lang = String(language).trim().toLowerCase()
      if (!lang || lang.length > 10) continue
      const messageVariants = toStringArray(variants)
        .map(v => v.trim())
        .filter(v => v.length > 0)
      if (!messageVariants.length) continue

      await sql`
        insert into public.notification_template_translations (template_id, language, message_variants, updated_at)
        values (${templateId}, ${lang}, ${sql.array(messageVariants)}, now())
      `
      savedTranslations[lang] = messageVariants
    }

    res.json({ templateId, translations: savedTranslations })
  } catch (err) {
    console.error('[notification-templates] failed to save translations', err)
    res.status(500).json({ error: err?.message || 'Failed to save translations' })
  }
})

// ---- Notification Automations ----
// Ensure default automations exist in database
async function ensureDefaultAutomations() {
  if (!sql) {
    console.log('[notification-automations] No SQL connection, skipping')
    return
  }

  console.log('[notification-automations] Starting to ensure default automations...')

  try {
    // First check if the table exists
    const tableCheck = await sql`
      select exists (
        select from information_schema.tables 
        where table_schema = 'public' 
        and table_name = 'notification_automations'
      ) as table_exists
    `
    console.log('[notification-automations] Table exists:', tableCheck?.[0]?.table_exists)

    if (!tableCheck?.[0]?.table_exists) {
      console.log('[notification-automations] Table does not exist, skipping seeding')
      return
    }

    const defaultAutomations = [
      {
        trigger_type: 'weekly_inactive_reminder',
        display_name: 'Weekly Inactive User Reminder',
        description: 'Sends a reminder to users who have been inactive for 7+ days',
        send_hour: 10,
      },
      {
        trigger_type: 'daily_task_reminder',
        display_name: 'Daily Remaining Task Reminder',
        description: 'Sends a reminder about incomplete tasks for today',
        send_hour: 18,
      },
      {
        trigger_type: 'journal_continue_reminder',
        display_name: 'Journal Continue Reminder',
        description: 'Encourages users who wrote in their journal yesterday to continue',
        send_hour: 9,
      },
    ]

    // Valid automation types (cron-based only)
    const validTriggerTypes = defaultAutomations.map(a => a.trigger_type)
    
    // First, delete any invalid automation types (action-based notifications that shouldn't be here)
    try {
      const deleted = await sql`
        delete from public.notification_automations
        where trigger_type not in ${sql(validTriggerTypes)}
        returning trigger_type
      `
      if (deleted && deleted.length > 0) {
        console.log(`[notification-automations] Cleaned up invalid automation types:`, deleted.map(d => d.trigger_type))
      }
    } catch (deleteErr) {
      console.warn('[notification-automations] Could not clean up invalid types:', deleteErr?.message)
    }

    // Then ensure the valid automations exist
    for (const auto of defaultAutomations) {
      try {
        // First check if it exists
        const existing = await sql`
          select id from public.notification_automations where trigger_type = ${auto.trigger_type} limit 1
        `
        console.log(`[notification-automations] Checking ${auto.trigger_type}: exists=${existing?.length > 0}`)

        if (!existing || existing.length === 0) {
          await sql`
            insert into public.notification_automations (trigger_type, display_name, description, send_hour)
            values (${auto.trigger_type}, ${auto.display_name}, ${auto.description}, ${auto.send_hour})
          `
          console.log(`[notification-automations] Created automation: ${auto.trigger_type}`)
        }
      } catch (insertErr) {
        console.error(`[notification-automations] Failed to create ${auto.trigger_type}:`, insertErr?.message || insertErr)
      }
    }

    // Verify what we have
    const allAutomations = await sql`select trigger_type from public.notification_automations`
    console.log('[notification-automations] All automations in DB:', allAutomations?.map(a => a.trigger_type))

  } catch (err) {
    console.error('[notification-automations] failed to ensure defaults:', err?.message || err)
  }
}

app.get('/api/admin/notification-automations', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  try {
    // Ensure notification tables exist first
    console.log('[notification-automations] Ensuring tables exist...')
    await ensureNotificationTables()
    // Ensure default automations exist
    console.log('[notification-automations] Ensuring default automations exist...')
    await ensureDefaultAutomations()

    // First, get basic automations
    const rows = await sql`
      select a.*,
             t.title as template_title
      from public.notification_automations a
      left join public.notification_templates t on t.id = a.template_id
      order by a.created_at asc
    `
    console.log('[notification-automations] Query returned:', rows?.length || 0, 'rows')

    // Calculate recipient counts separately to avoid query failures
    // NOTE: These counts show users who will receive notifications TODAY (in their local timezone)
    // The actual delivery happens when the user's local time matches the send_hour
    const automationsWithCounts = await Promise.all((rows || []).map(async (row) => {
      let recipientCount = 0
      const sendHour = typeof row.send_hour === 'number' ? row.send_hour : 9
      try {
        if (row.trigger_type === 'weekly_inactive_reminder') {
          // Count users who are inactive 7+ days, haven't received this notification today,
          // and have push notifications enabled
          const countResult = await sql`
            select count(*)::bigint as cnt
            from public.profiles p
            left join auth.users u on u.id = p.id
            where (p.notify_push is null or p.notify_push = true)
              and coalesce(u.last_sign_in_at, u.created_at, now() - interval '30 days') < now() - interval '7 days'
              and not exists (
                select 1 from public.user_notifications un
                where un.automation_id = ${row.id}
                  and un.user_id = p.id
                  and (un.scheduled_for at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date
              )
          `
          recipientCount = Number(countResult?.[0]?.cnt || 0)
        } else if (row.trigger_type === 'daily_task_reminder') {
          try {
            // Count users with incomplete tasks TODAY (in their local timezone),
            // who haven't received this notification today
            // This matches the actual delivery query logic
            const countResult = await sql`
              select count(distinct p.id)::bigint as cnt
              from public.profiles p
              join public.garden_members gm on gm.user_id = p.id
              join public.garden_plant_tasks t on t.garden_id = gm.garden_id
              join public.garden_plant_task_occurrences occ on occ.task_id = t.id
              where (p.notify_push is null or p.notify_push = true)
                and (p.push_task_reminders is null or p.push_task_reminders = true)
                and (occ.due_at at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date
                and coalesce(occ.completed_count, 0) < coalesce(occ.required_count, 1)
                and not exists (
                  select 1 from public.user_notifications un
                  where un.automation_id = ${row.id}
                    and un.user_id = p.id
                    and (un.scheduled_for at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date
                )
            `
            recipientCount = Number(countResult?.[0]?.cnt || 0)
          } catch (e) {
            // Table might not exist
            console.warn('[notification-automations] daily_task_reminder count error:', e?.message)
            recipientCount = 0
          }
        } else if (row.trigger_type === 'journal_continue_reminder') {
          try {
            // Count users who wrote in their journal yesterday (in their local timezone)
            const countResult = await sql`
              select count(distinct p.id)::bigint as cnt
              from public.profiles p
              join public.garden_members gm on gm.user_id = p.id
              join public.garden_activity_logs gal on gal.garden_id = gm.garden_id
              where (p.notify_push is null or p.notify_push = true)
                and gal.kind = 'note'
                and (gal.occurred_at at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date - interval '1 day'
                and not exists (
                  select 1 from public.user_notifications un
                  where un.automation_id = ${row.id}
                    and un.user_id = p.id
                    and (un.scheduled_for at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date
                )
            `
            recipientCount = Number(countResult?.[0]?.cnt || 0)
          } catch (e) {
            // Table might not exist
            console.warn('[notification-automations] journal_continue_reminder count error:', e?.message)
            recipientCount = 0
          }
        }
      } catch (countErr) {
        console.error('[notification-automations] Error counting recipients for', row.trigger_type, countErr)
      }
      
      // Count how many notifications were sent today for this automation
      let sentTodayCount = 0
      try {
        const sentTodayResult = await sql`
          select count(*)::bigint as cnt
          from public.user_notifications un
          where un.automation_id = ${row.id}
            and un.scheduled_for::date = current_date
            and un.delivery_status in ('sent', 'pending')
        `
        sentTodayCount = Number(sentTodayResult?.[0]?.cnt || 0)
      } catch (sentErr) {
        // Ignore errors counting sent notifications
      }
      
      return { ...row, recipient_count: recipientCount, sent_today_count: sentTodayCount }
    }))

    const automations = automationsWithCounts.map((row) => normalizeNotificationAutomation(row)).filter(Boolean)
    console.log('[notification-automations] Returning:', automations.length, 'automations')
    res.json({ automations })
  } catch (err) {
    console.error('[notification-automations] failed to load automations', err)
    res.status(500).json({ error: err?.message || 'Failed to load automations' })
  }
})

app.get('/api/admin/notification-automations/monitoring', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  const windowHours = 24
  try {
    const totalsRows = await sql`
      select
        count(un.id)::bigint as total,
        count(un.id) filter (where un.delivery_status = 'sent')::bigint as sent,
        count(un.id) filter (where un.delivery_status = 'failed')::bigint as failed,
        count(un.id) filter (where un.delivery_status = 'pending')::bigint as pending,
        count(un.id) filter (where un.delivery_error = 'NO_PUSH_SUBSCRIPTION')::bigint as no_subscription,
        max(un.scheduled_for) as last_queued_at
      from public.user_notifications un
      where un.automation_id is not null
        and un.scheduled_for >= now() - interval '24 hours'
    `

    const failureRows = await sql`
      select
        coalesce(un.delivery_error, 'UNKNOWN') as reason,
        count(un.id)::bigint as count
      from public.user_notifications un
      where un.automation_id is not null
        and un.scheduled_for >= now() - interval '24 hours'
        and un.delivery_status = 'failed'
      group by reason
      order by count desc
      limit 6
    `

    const automationRows = await sql`
      select
        a.id::text as id,
        a.display_name,
        count(un.id)::bigint as total,
        count(un.id) filter (where un.delivery_status = 'sent')::bigint as sent,
        count(un.id) filter (where un.delivery_status = 'failed')::bigint as failed,
        count(un.id) filter (where un.delivery_status = 'pending')::bigint as pending,
        count(un.id) filter (where un.delivery_error = 'NO_PUSH_SUBSCRIPTION')::bigint as no_subscription,
        max(un.scheduled_for) as last_queued_at
      from public.notification_automations a
      left join public.user_notifications un
        on un.automation_id = a.id
        and un.scheduled_for >= now() - interval '24 hours'
      group by a.id, a.display_name
      order by total desc nulls last, a.display_name
    `

    const totalsRow = totalsRows?.[0] || {}
    const recentRows = await sql`
      select
        un.id::text as id,
        un.user_id::text as user_id,
        un.automation_id::text as automation_id,
        un.delivery_status,
        un.delivery_error,
        un.scheduled_for,
        un.delivered_at,
        a.display_name as automation_name
      from public.user_notifications un
      left join public.notification_automations a on a.id = un.automation_id
      where un.automation_id is not null
        and un.scheduled_for >= now() - interval '3 days'
      order by un.scheduled_for desc nulls last
      limit 60
    `

    const monitoring = {
      windowHours,
      pushConfigured: pushNotificationsEnabled,
      serverTime: new Date().toISOString(),
      workerIntervalMs: notificationWorkerIntervalMs,
      defaultTimezone: DEFAULT_USER_TIMEZONE,
      totals: {
        queued: Number(totalsRow.total || 0),
        sent: Number(totalsRow.sent || 0),
        failed: Number(totalsRow.failed || 0),
        pending: Number(totalsRow.pending || 0),
        noSubscription: Number(totalsRow.no_subscription || 0),
      },
      lastQueuedAt: isoOrNull(totalsRow.last_queued_at),
      failureReasons: (failureRows || []).map((row) => ({
        reason: row.reason || 'UNKNOWN',
        count: Number(row.count || 0),
      })),
      automations: (automationRows || []).map((row) => ({
        id: row.id,
        displayName: row.display_name || null,
        total: Number(row.total || 0),
        sent: Number(row.sent || 0),
        failed: Number(row.failed || 0),
        pending: Number(row.pending || 0),
        noSubscription: Number(row.no_subscription || 0),
        lastQueuedAt: isoOrNull(row.last_queued_at),
      })),
      recentNotifications: (recentRows || []).map((row) => ({
        id: row.id,
        userId: row.user_id,
        automationId: row.automation_id,
        automationName: row.automation_name || null,
        status: row.delivery_status || 'pending',
        error: row.delivery_error || null,
        scheduledFor: isoOrNull(row.scheduled_for),
        deliveredAt: isoOrNull(row.delivered_at),
      })),
    }

    res.json({ monitoring })
  } catch (err) {
    console.error('[notification-automations] failed to load monitoring summary', err)
    res.status(500).json({ error: err?.message || 'Failed to load monitoring summary' })
  }
})

app.put('/api/admin/notification-automations/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const automationId = String(req.params?.id || '').trim()
  if (!automationId) {
    res.status(400).json({ error: 'Missing automation id' })
    return
  }
  let parsed
  try {
    parsed = notificationAutomationUpdateSchema.parse(req.body || {})
  } catch (err) {
    res.status(400).json({ error: err?.errors?.[0]?.message || 'Invalid payload' })
    return
  }
  const adminUuid = toAdminUuid(adminId)
  try {
    // Convert undefined to null for SQL compatibility
    const isEnabled = typeof parsed.isEnabled === 'boolean' ? parsed.isEnabled : null
    const templateId = parsed.templateId !== undefined ? (parsed.templateId || null) : null
    const sendHour = typeof parsed.sendHour === 'number' ? parsed.sendHour : null
    const ctaUrl = parsed.ctaUrl !== undefined ? (parsed.ctaUrl || null) : null

    // Track which fields to update
    const hasIsEnabled = typeof parsed.isEnabled === 'boolean'
    const hasTemplateId = parsed.templateId !== undefined
    const hasSendHour = typeof parsed.sendHour === 'number'
    const hasCtaUrl = parsed.ctaUrl !== undefined

    const rows = await sql`
      update public.notification_automations
      set is_enabled = case when ${hasIsEnabled} then ${isEnabled} else is_enabled end,
          template_id = case when ${hasTemplateId} then ${templateId} else template_id end,
          send_hour = case when ${hasSendHour} then ${sendHour} else send_hour end,
          cta_url = case when ${hasCtaUrl} then ${ctaUrl} else cta_url end,
          updated_by = ${adminUuid},
          updated_at = now()
      where id = ${automationId}
      returning *
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Automation not found' })
      return
    }
    // Fetch with template info
    const enriched = await sql`
      select a.*, t.title as template_title
      from public.notification_automations a
      left join public.notification_templates t on t.id = a.template_id
      where a.id = ${automationId}
    `
    const automation = normalizeNotificationAutomation(enriched?.[0] || rows[0])
    res.json({ automation })
  } catch (err) {
    console.error('[notification-automations] failed to update automation', err)
    res.status(500).json({ error: err?.message || 'Failed to update automation' })
  }
})

// Trigger automation manually (for testing)
app.post('/api/admin/notification-automations/:id/trigger', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const automationId = String(req.params?.id || '').trim()
  if (!automationId) {
    res.status(400).json({ error: 'Missing automation id' })
    return
  }
  try {
    const rows = await sql`
      select a.*, t.message_variants, t.randomize, t.title as template_title
      from public.notification_automations a
      left join public.notification_templates t on t.id = a.template_id
      where a.id = ${automationId}
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Automation not found' })
      return
    }
    const automation = rows[0]
    if (!automation.template_id || !automation.message_variants?.length) {
      res.status(400).json({ error: 'Automation has no template configured' })
      return
    }
    // Trigger automation run
    const result = await runAutomation(automation)
    // Update last_run_at
    await sql`
      update public.notification_automations
      set last_run_at = now(),
          last_run_summary = ${sql.json(result)}
      where id = ${automationId}
    `
    res.json({ triggered: true, result })
  } catch (err) {
    console.error('[notification-automations] failed to trigger automation', err)
    res.status(500).json({ error: err?.message || 'Failed to trigger automation' })
  }
})

// Helper function to run an automation
async function runAutomation(automation) {
  if (!sql) return { error: 'Database not configured' }

  const defaultVariants = toStringArray(automation.message_variants)
  if (!defaultVariants.length) return { error: 'No message variants' }

  // Get the notification title from template (fallback to automation display_name)
  const notificationTitle = automation.template_title || automation.display_name || 'Reminder'

  // Load translations for the template
  let translations = {}
  if (automation.template_id) {
    try {
      const transRows = await sql`
        select language, message_variants
        from public.notification_template_translations
        where template_id = ${automation.template_id}
      `
      for (const row of transRows || []) {
        translations[row.language] = toStringArray(row.message_variants)
      }
    } catch (err) {
      console.error('[automation] failed to load translations', err)
    }
  }
  const normalizedTranslations = normalizeTranslationMap(translations)

  const triggerType = automation.trigger_type
  let recipientQuery

  if (triggerType === 'weekly_inactive_reminder') {
    recipientQuery = sql`
      select p.id as user_id, p.display_name, p.language
      from public.profiles p
      left join auth.users u on u.id = p.id
      where (p.notify_push is null or p.notify_push = true)
        and coalesce(u.last_sign_in_at, u.created_at, now() - interval '30 days') < now() - interval '7 days'
      limit 5000
    `
  } else if (triggerType === 'daily_task_reminder') {
    // Find users with incomplete tasks for today (in their local timezone)
    // Join through garden_plant_tasks to get the correct garden association
    recipientQuery = sql`
      select distinct p.id as user_id, p.display_name, p.language, p.timezone
      from public.profiles p
      join public.garden_members gm on gm.user_id = p.id
      join public.garden_plant_tasks t on t.garden_id = gm.garden_id
      join public.garden_plant_task_occurrences occ on occ.task_id = t.id
      where (p.notify_push is null or p.notify_push = true)
        and (p.push_task_reminders is null or p.push_task_reminders = true)
        and (occ.due_at at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date
        and coalesce(occ.completed_count, 0) < coalesce(occ.required_count, 1)
      limit 5000
    `
  } else if (triggerType === 'journal_continue_reminder') {
    recipientQuery = sql`
      select distinct p.id as user_id, p.display_name, p.language
      from public.profiles p
      join public.garden_members gm on gm.user_id = p.id
      join public.garden_activity_logs gal on gal.garden_id = gm.garden_id
      where (p.notify_push is null or p.notify_push = true)
        and gal.kind = 'note'
        and gal.occurred_at::date = current_date - interval '1 day'
      limit 5000
    `
  } else {
    return { error: 'Unknown trigger type' }
  }

  const recipients = await recipientQuery
  if (!recipients || !recipients.length) {
    return { recipients: 0, sent: 0, message: 'No recipients found' }
  }

  // Create user_notifications entries
  let insertedCount = 0
  for (const recipient of recipients) {
    // Get message variants for user's language (with fallback to default)
    const messageVariants = resolveMessageVariants(defaultVariants, normalizedTranslations, recipient.language)
    const shouldRandomize = automation.randomize !== false
    const messageIndex = shouldRandomize
      ? Math.floor(Math.random() * messageVariants.length)
      : 0
    const message = messageVariants[messageIndex]
      .replace(/\{\{user\}\}/gi, recipient.display_name || 'there')
    const personalizedTitle = notificationTitle.replace(/\{\{user\}\}/gi, recipient.display_name || 'there')

    try {
      // Check if notification already exists for this automation + user today
      const existing = await sql`
        select id from public.user_notifications 
        where automation_id = ${automation.id} 
          and user_id = ${recipient.user_id}
          and scheduled_for::date = current_date
        limit 1
      `
      if (existing && existing.length > 0) {
        continue // Skip, already sent today
      }

      await sql`
        insert into public.user_notifications (
          automation_id, user_id, title, message, cta_url, scheduled_for, delivery_status
        )
        values (
          ${automation.id},
          ${recipient.user_id},
          ${personalizedTitle},
          ${message},
          ${automation.cta_url || null},
          now(),
          'pending'
        )
      `
      insertedCount++
    } catch (insertErr) {
      console.error('[automation] insert error', insertErr)
    }
  }

  return { recipients: recipients.length, queued: insertedCount }
}

// ---- Admin email templates ----
app.get('/api/admin/email-templates', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const limitParam = Number(req.query?.limit) || 100
  const limit = Math.min(Math.max(limitParam, 1), 200)
  try {
    const rows = await sql`
      select t.*, stats.campaign_count, stats.last_campaign_at
      from public.admin_email_templates t
      left join lateral (
        select count(*)::bigint as campaign_count,
               max(created_at) as last_campaign_at
        from public.admin_email_campaigns c
        where c.template_id = t.id
      ) stats on true
      order by t.updated_at desc
      limit ${limit}
    `
    const templates = (rows || []).map((row) => normalizeEmailTemplateRow(row)).filter(Boolean)
    res.json({ templates })
  } catch (err) {
    console.error('[email-templates] failed to load templates', err)
    res.status(500).json({ error: err?.message || 'Failed to load templates' })
  }
})

app.get('/api/admin/email-templates/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const templateId = String(req.params?.id || '').trim()
  if (!templateId) {
    res.status(400).json({ error: 'Missing template id' })
    return
  }
  try {
    const rows = await sql`
      select t.*, stats.campaign_count, stats.last_campaign_at
      from public.admin_email_templates t
      left join lateral (
        select count(*)::bigint as campaign_count,
               max(created_at) as last_campaign_at
        from public.admin_email_campaigns c
        where c.template_id = t.id
      ) stats on true
      where t.id = ${templateId}
      limit 1
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Template not found' })
      return
    }
    const template = normalizeEmailTemplateRow(rows[0])
    res.json({ template })
  } catch (err) {
    console.error('[email-templates] failed to load template', err)
    res.status(500).json({ error: err?.message || 'Failed to load template' })
  }
})

app.post('/api/admin/email-templates', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  let parsed
  try {
    parsed = emailTemplateInputSchema.parse(req.body || {})
  } catch (err) {
    res.status(400).json({ error: err?.errors?.[0]?.message || 'Invalid payload' })
    return
  }
  const description = parsed.description && parsed.description.length ? parsed.description : null
  const previewText = resolvePreviewText(parsed.previewText, parsed.bodyHtml)
  const bodyJsonFragment =
    parsed.bodyJson === null || parsed.bodyJson === undefined ? null : sql.json(parsed.bodyJson)
  const variables = extractEmailTemplateVariables(parsed.subject, parsed.bodyHtml)
  const isActive = parsed.isActive !== false
  const adminUuid = toAdminUuid(adminId)
  try {
    const rows = await sql`
      insert into public.admin_email_templates (
        title, subject, description, preview_text, body_html, body_json, variables,
        is_active, created_by, updated_by, created_at, updated_at
      )
      values (
        ${parsed.title},
        ${parsed.subject},
        ${description},
        ${previewText},
        ${parsed.bodyHtml},
        ${bodyJsonFragment},
        ${variables},
        ${isActive},
        ${adminUuid},
        ${adminUuid},
        now(),
        now()
      )
      returning *
    `
    const template = normalizeEmailTemplateRow(rows?.[0])
    res.json({ template })
  } catch (err) {
    console.error('[email-templates] failed to create template', err)
    res.status(500).json({ error: err?.message || 'Failed to create template' })
  }
})

app.put('/api/admin/email-templates/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const templateId = String(req.params?.id || '').trim()
  if (!templateId) {
    res.status(400).json({ error: 'Missing template id' })
    return
  }
  let parsed
  try {
    parsed = emailTemplateInputSchema.parse(req.body || {})
  } catch (err) {
    res.status(400).json({ error: err?.errors?.[0]?.message || 'Invalid payload' })
    return
  }
  try {
    const existing = await sql`
      select * from public.admin_email_templates
      where id = ${templateId}
      limit 1
    `
    if (!existing || !existing.length) {
      res.status(404).json({ error: 'Template not found' })
      return
    }
    const current = existing[0]
    const description = parsed.description && parsed.description.length ? parsed.description : null
    const previewText = resolvePreviewText(parsed.previewText, parsed.bodyHtml)
    const bodyJsonFragment =
      parsed.bodyJson === null || parsed.bodyJson === undefined ? null : sql.json(parsed.bodyJson)
    const variables = extractEmailTemplateVariables(parsed.subject, parsed.bodyHtml)
    const isActive =
      parsed.isActive === undefined ? current.is_active !== false : parsed.isActive
    const adminUuid = toAdminUuid(adminId)

    const rows = await sql`
      update public.admin_email_templates
      set title = ${parsed.title},
          subject = ${parsed.subject},
          description = ${description},
          preview_text = ${previewText},
          body_html = ${parsed.bodyHtml},
          body_json = ${bodyJsonFragment},
          variables = ${variables},
          is_active = ${isActive},
          updated_by = ${adminUuid},
          updated_at = now()
      where id = ${templateId}
      returning *
    `
    const template = normalizeEmailTemplateRow(rows?.[0])
    res.json({ template })
  } catch (err) {
    console.error('[email-templates] failed to update template', err)
    res.status(500).json({ error: err?.message || 'Failed to update template' })
  }
})

app.delete('/api/admin/email-templates/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const templateId = String(req.params?.id || '').trim()
  if (!templateId) {
    res.status(400).json({ error: 'Missing template id' })
    return
  }
  try {
    const usage = await sql`
      select count(*)::bigint as cnt
      from public.admin_email_campaigns
      where template_id = ${templateId}
        and status in ('draft','scheduled','running')
    `
    const activeCount = usage && usage[0] ? Number(usage[0].cnt) : 0
    if (activeCount > 0) {
      res.status(409).json({ error: 'Template is used by active campaigns' })
      return
    }
    const rows = await sql`
      delete from public.admin_email_templates
      where id = ${templateId}
      returning *
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Template not found' })
      return
    }
    const template = normalizeEmailTemplateRow(rows[0])
    res.json({ template })
  } catch (err) {
    console.error('[email-templates] failed to delete template', err)
    res.status(500).json({ error: err?.message || 'Failed to delete template' })
  }
})

// ---- Admin email campaigns ----
app.get('/api/admin/email-campaigns', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const limitParam = Number(req.query?.limit) || 100
  const limit = Math.min(Math.max(limitParam, 1), 200)
  try {
    const rows = await sql`
      select c.*, t.title as template_title
      from public.admin_email_campaigns c
      left join public.admin_email_templates t on t.id = c.template_id
      order by coalesce(c.scheduled_for, c.created_at) desc
      limit ${limit}
    `
    const campaigns = (rows || []).map((row) => normalizeEmailCampaignRow(row)).filter(Boolean)
    res.json({ campaigns })
  } catch (err) {
    console.error('[email-campaigns] failed to load campaigns', err)
    res.status(500).json({ error: err?.message || 'Failed to load campaigns' })
  }
})

app.get('/api/admin/email-campaigns/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const campaignId = String(req.params?.id || '').trim()
  if (!campaignId) {
    res.status(400).json({ error: 'Missing campaign id' })
    return
  }
  try {
    const rows = await sql`
      select c.*, t.title as template_title
      from public.admin_email_campaigns c
      left join public.admin_email_templates t on t.id = c.template_id
      where c.id = ${campaignId}
      limit 1
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Campaign not found' })
      return
    }
    const campaign = normalizeEmailCampaignRow(rows[0])
    res.json({ campaign })
  } catch (err) {
    console.error('[email-campaigns] failed to load campaign', err)
    res.status(500).json({ error: err?.message || 'Failed to load campaign' })
  }
})

app.post('/api/admin/email-campaigns', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  let parsed
  try {
    parsed = emailCampaignInputSchema.parse(req.body || {})
  } catch (err) {
    res.status(400).json({ error: err?.errors?.[0]?.message || 'Invalid payload' })
    return
  }
  const scheduledFor = normalizeScheduledDate(parsed.scheduledFor)
  if (!scheduledFor) {
    res.status(400).json({ error: 'scheduledFor must be a valid ISO date' })
    return
  }
  try {
    const templateRows = await sql`
      select * from public.admin_email_templates
      where id = ${parsed.templateId}
      limit 1
    `
    if (!templateRows || !templateRows.length) {
      res.status(404).json({ error: 'Template not found' })
      return
    }
    const template = templateRows[0]
    if (!template.body_html || !template.subject) {
      res.status(400).json({ error: 'Template is missing subject or body' })
      return
    }
    const description = parsed.description && parsed.description.length ? parsed.description : null
    const previewText = resolvePreviewText(parsed.previewText || template.preview_text, template.body_html)
    const bodyJsonSnapshot = coerceJsonValue(template.body_json, null)
    const bodyJsonFragment = bodyJsonSnapshot == null ? null : sql.json(bodyJsonSnapshot)
    const variables = extractEmailTemplateVariables(template.subject, template.body_html)
    const timezone = parsed.timezone && parsed.timezone.length ? parsed.timezone : 'UTC'

    const testMode = parsed.testMode === true
    const testEmail = testMode && parsed.testEmail ? parsed.testEmail : null
    const isMarketing = parsed.isMarketing === true
    const adminUuid = toAdminUuid(adminId)

    const rows = await sql`
      insert into public.admin_email_campaigns (
        template_id,
        template_version,
        title,
        description,
        subject,
        preview_text,
        body_html,
        body_json,
        variables,
        timezone,
        scheduled_for,
        status,
        total_recipients,
        sent_count,
        failed_count,
        test_mode,
        test_email,
        is_marketing,
        created_by,
        updated_by,
        created_at,
        updated_at
      )
      values (
        ${template.id},
        ${template.version || 1},
        ${parsed.title},
        ${description},
        ${template.subject},
        ${previewText},
        ${template.body_html},
        ${bodyJsonFragment},
        ${variables},
        ${timezone || 'UTC'},
        ${scheduledFor},
        'scheduled',
        ${testMode ? 1 : 0},
        0,
        0,
        ${testMode},
        ${testEmail},
        ${isMarketing},
        ${adminUuid},
        ${adminUuid},
        now(),
        now()
      )
      returning *
    `
    const campaign = normalizeEmailCampaignRow({ ...rows[0], template_title: template.title })
    res.json({ campaign })
  } catch (err) {
    console.error('[email-campaigns] failed to create campaign', err)
    res.status(500).json({ error: err?.message || 'Failed to create campaign' })
  }
})

app.put('/api/admin/email-campaigns/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const campaignId = String(req.params?.id || '').trim()
  if (!campaignId) {
    res.status(400).json({ error: 'Missing campaign id' })
    return
  }
  let parsed
  try {
    parsed = emailCampaignUpdateSchema.parse(req.body || {})
  } catch (err) {
    res.status(400).json({ error: err?.errors?.[0]?.message || 'Invalid payload' })
    return
  }
  if (!parsed || Object.keys(parsed).length === 0) {
    res.status(400).json({ error: 'No changes provided' })
    return
  }
  try {
    const rows = await sql`
      select c.*, t.title as template_title
      from public.admin_email_campaigns c
      left join public.admin_email_templates t on t.id = c.template_id
      where c.id = ${campaignId}
      limit 1
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Campaign not found' })
      return
    }
    const current = rows[0]
    if (!['draft', 'scheduled', 'cancelled'].includes(current.status)) {
      res.status(400).json({ error: 'Campaign can no longer be edited' })
      return
    }
    let templateId = current.template_id
    let templateVersion = current.template_version || 1
    let subject = current.subject
    let bodyHtml = current.body_html || ''
    let bodyJsonSnapshot = coerceJsonValue(current.body_json, null)
    let variablesSnapshot = coerceVariableArray(current.variables)
    let previewText = current.preview_text || resolvePreviewText(null, bodyHtml)
    let templateTitle = current.template_title || null

    const wantsRefresh =
      parsed.refreshTemplate === true ||
      (parsed.templateId && parsed.templateId !== current.template_id)

    if (wantsRefresh) {
      templateId = parsed.templateId || current.template_id
      const templateRows = await sql`
        select * from public.admin_email_templates
        where id = ${templateId}
        limit 1
      `
      if (!templateRows || !templateRows.length) {
        res.status(404).json({ error: 'Template not found' })
        return
      }
      const template = templateRows[0]
      if (!template.body_html || !template.subject) {
        res.status(400).json({ error: 'Template is missing subject or body' })
        return
      }
      subject = template.subject
      bodyHtml = template.body_html
      bodyJsonSnapshot = coerceJsonValue(template.body_json, null)
      variablesSnapshot = extractEmailTemplateVariables(subject, bodyHtml)
      previewText = resolvePreviewText(parsed.previewText || template.preview_text, bodyHtml)
      templateVersion = template.version || 1
      templateTitle = template.title || null
    } else if (parsed.previewText !== undefined) {
      previewText = resolvePreviewText(parsed.previewText, bodyHtml)
    }

    const description =
      parsed.description === undefined
        ? current.description
        : parsed.description && parsed.description.length
          ? parsed.description
          : null
    const title = parsed.title || current.title
    const scheduledFor =
      parsed.scheduledFor === undefined || parsed.scheduledFor === null
        ? current.scheduled_for
        : normalizeScheduledDate(parsed.scheduledFor)
    if (!scheduledFor) {
      res.status(400).json({ error: 'scheduledFor must be a valid ISO date' })
      return
    }
    const timezone =
      parsed.timezone === undefined || parsed.timezone === null
        ? current.timezone || 'UTC'
        : parsed.timezone.length
          ? parsed.timezone
          : 'UTC'
    let status = current.status
    if (['draft', 'cancelled'].includes(status)) {
      status = 'scheduled'
    }
    const bodyJsonFragment = bodyJsonSnapshot == null ? null : sql.json(bodyJsonSnapshot)
    const adminUuid = toAdminUuid(adminId)

    const updated = await sql`
      update public.admin_email_campaigns
      set title = ${title},
          description = ${description},
          subject = ${subject},
          preview_text = ${previewText},
          body_html = ${bodyHtml},
          body_json = ${bodyJsonFragment},
          variables = ${variablesSnapshot},
          template_id = ${templateId},
          template_version = ${templateVersion},
          timezone = ${timezone},
          scheduled_for = ${scheduledFor},
          status = ${status},
          updated_by = ${adminUuid},
          updated_at = now()
      where id = ${campaignId}
      returning *
    `
    const campaign = normalizeEmailCampaignRow({
      ...updated[0],
      template_title: templateTitle,
    })
    res.json({ campaign })
  } catch (err) {
    console.error('[email-campaigns] failed to update campaign', err)
    res.status(500).json({ error: err?.message || 'Failed to update campaign' })
  }
})

app.delete('/api/admin/email-campaigns/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const campaignId = String(req.params?.id || '').trim()
  if (!campaignId) {
    res.status(400).json({ error: 'Missing campaign id' })
    return
  }
  try {
    // First, delete any campaign sends records (in case cascade doesn't work)
    await sql`delete from public.admin_campaign_sends where campaign_id = ${campaignId}`

    // Allow deletion of campaigns in any status (including sent, partial, failed, running)
    const rows = await sql`
      delete from public.admin_email_campaigns
      where id = ${campaignId}
      returning *
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Campaign not found' })
      return
    }
    const campaign = normalizeEmailCampaignRow(rows[0])
    console.log('[email-campaigns] deleted campaign:', campaign.id, campaign.title, 'status:', campaign.status)
    res.json({ campaign })
  } catch (err) {
    console.error('[email-campaigns] failed to delete campaign', err)
    res.status(500).json({ error: err?.message || 'Failed to delete campaign' })
  }
})

app.post('/api/admin/email-campaigns/:id/cancel', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const campaignId = String(req.params?.id || '').trim()
  if (!campaignId) {
    res.status(400).json({ error: 'Missing campaign id' })
    return
  }
  const adminUuid = toAdminUuid(adminId)
  try {
    const rows = await sql`
      update public.admin_email_campaigns
      set status = 'cancelled',
          send_error = 'Cancelled by admin',
          updated_by = ${adminUuid},
          updated_at = now()
      where id = ${campaignId}
        and status in ('draft','scheduled')
      returning *
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Campaign not found or already in progress' })
      return
    }
    const campaign = normalizeEmailCampaignRow(rows[0])
    res.json({ campaign })
  } catch (err) {
    console.error('[email-campaigns] failed to cancel campaign', err)
    res.status(500).json({ error: err?.message || 'Failed to cancel campaign' })
  }
})

app.post('/api/admin/email-campaigns/:id/run', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service client not configured' })
    return
  }
  const campaignId = String(req.params?.id || '').trim()
  if (!campaignId) {
    res.status(400).json({ error: 'Missing campaign id' })
    return
  }
  let params
  try {
    params = emailCampaignRunSchema.parse(req.body || {})
  } catch (err) {
    res.status(400).json({ error: err?.errors?.[0]?.message || 'Invalid payload' })
    return
  }
  try {
    const existing = await sql`
      select c.*, t.title as template_title
      from public.admin_email_campaigns c
      left join public.admin_email_templates t on t.id = c.template_id
      where c.id = ${campaignId}
      limit 1
    `
    if (!existing || !existing.length) {
      res.status(404).json({ error: 'Campaign not found' })
      return
    }
    const invokePayload = {
      campaignId,
      ...(params?.recipientLimit ? { recipientLimit: params.recipientLimit } : {}),
    }
    const invocation = await supabaseServiceClient.functions.invoke('email-campaign-runner', {
      body: invokePayload,
    })
    if (invocation.error) {
      throw new Error(invocation.error.message || 'Edge function failed')
    }
    if (invocation.data) {
      console.log('[email-campaigns] runner completed:', JSON.stringify(invocation.data))
    }
    const refreshed = await sql`
      select c.*, t.title as template_title
      from public.admin_email_campaigns c
      left join public.admin_email_templates t on t.id = c.template_id
      where c.id = ${campaignId}
      limit 1
    `
    const campaign = refreshed && refreshed.length ? normalizeEmailCampaignRow(refreshed[0]) : null
    res.json({ campaign, runner: invocation.data })
  } catch (err) {
    console.error('[email-campaigns] failed to trigger run', err)
    res.status(500).json({ error: err?.message || 'Failed to trigger campaign run' })
  }
})

function normalizeEmailTemplateRow(row) {
  if (!row) return null
  const bodyJson = coerceJsonValue(row.body_json, null)
  const variables = coerceVariableArray(row.variables)
  const campaignCount =
    row && Object.prototype.hasOwnProperty.call(row, 'campaign_count')
      ? Number(row.campaign_count || 0)
      : 0
  return {
    id: row.id,
    title: row.title,
    subject: row.subject,
    description: row.description || null,
    previewText: row.preview_text || resolvePreviewText(null, row.body_html),
    bodyHtml: row.body_html || '',
    bodyJson,
    variables,
    isActive: row.is_active !== false,
    version: Number(row.version || 1),
    lastUsedAt: row.last_used_at || null,
    createdAt: row.created_at,
    updatedAt: row.updated_at,
    campaignCount: Number.isFinite(campaignCount) ? campaignCount : 0,
    lastCampaignAt: row.last_campaign_at || null,
  }
}

function normalizeEmailCampaignRow(row) {
  if (!row) return null
  const bodyJson = coerceJsonValue(row.body_json, null)
  const variables = coerceVariableArray(row.variables)
  const sendSummary = coerceJsonValue(row.send_summary, null)
  return {
    id: row.id,
    title: row.title,
    description: row.description || null,
    status: row.status,
    templateId: row.template_id,
    templateTitle: row.template_title || null,
    templateVersion: Number(row.template_version || 1),
    subject: row.subject,
    previewText: row.preview_text || resolvePreviewText(null, row.body_html),
    bodyHtml: row.body_html || '',
    bodyJson,
    variables,
    timezone: row.timezone || 'UTC',
    scheduledFor: row.scheduled_for,
    totalRecipients: Number(row.total_recipients || 0),
    sentCount: Number(row.sent_count || 0),
    failedCount: Number(row.failed_count || 0),
    sendSummary,
    sendError: row.send_error || null,
    sendStartedAt: row.send_started_at || null,
    sendCompletedAt: row.send_completed_at || null,
    testMode: row.test_mode === true,
    testEmail: row.test_email || null,
    isMarketing: row.is_marketing === true, // If true, only users with marketing_consent receive this
    createdAt: row.created_at,
    updatedAt: row.updated_at,
  }
}

// ---- Admin email triggers (automatic emails) ----
const DEFAULT_EMAIL_TRIGGERS = [
  {
    triggerType: 'WELCOME_EMAIL',
    displayName: 'New User Welcome Email',
    description: 'Automatically sent when a new user creates an account',
  },
  {
    triggerType: 'BAN_USER',
    displayName: 'User Ban Notification',
    description: 'Sent when a user is marked as threat level 3 (ban)',
  },
  // Security Emails - Email Change
  {
    triggerType: 'EMAIL_CHANGE_NOTIFICATION',
    displayName: 'Email Changed Notification',
    description: 'Sent to the OLD email address to inform that the email has been changed. Variables: {{new_email}}, {{old_email}}, {{time}}',
  },
  // Security Emails - Password
  {
    triggerType: 'PASSWORD_RESET_REQUEST',
    displayName: 'Password Reset Request',
    description: 'Sent when user requests a password reset. Contains a secure reset link. Variables: {{url}}, {{time}}',
  },
  {
    triggerType: 'PASSWORD_CHANGE_CONFIRMATION',
    displayName: 'Password Changed Confirmation',
    description: 'Sent after password has been successfully changed. Variables: {{time}}, {{device}}, {{location}}',
  },
  // Security Emails - Login Security
  {
    triggerType: 'SUSPICIOUS_LOGIN_ALERT',
    displayName: 'Suspicious Login Alert',
    description: 'Sent when a login is detected from an unusual location or device. Variables: {{location}}, {{device}}, {{ip_address}}, {{time}}',
  },
  {
    triggerType: 'NEW_DEVICE_LOGIN',
    displayName: 'New Device Login',
    description: 'Sent when user logs in from a new device. Variables: {{device}}, {{location}}, {{ip_address}}, {{time}}',
  },
  // Email Verification
  {
    triggerType: 'EMAIL_VERIFICATION',
    displayName: 'Email Verification Code',
    description: 'Sent when user needs to verify their email address (after setup). Contains a 6-character verification code. Variables: {{code}}, {{user}}, {{email}}',
  },
  // Forgot Password (Magic Link)
  {
    triggerType: 'FORGOT_PASSWORD',
    displayName: 'Forgot Password Magic Link',
    description: 'Sent when a user requests a password reset via magic link. The link logs the user in and redirects to the password change page. Variables: {{url}}, {{user}}, {{email}}',
  },
]

// Cache to prevent running ensureDefaultEmailTriggers on every request
let defaultTriggersEnsured = false

async function ensureDefaultEmailTriggers() {
  // Only run once per server lifetime - triggers are seeded, not dynamic
  if (defaultTriggersEnsured) return
  if (!sql) return
  
  try {
    // Use a single batch insert for better performance
    const values = DEFAULT_EMAIL_TRIGGERS.map(t => 
      `('${t.triggerType}', '${t.displayName.replace(/'/g, "''")}', '${(t.description || '').replace(/'/g, "''")}')`
    ).join(',\n')
    
    await sql.unsafe(`
      INSERT INTO public.admin_email_triggers (trigger_type, display_name, description)
      VALUES ${values}
      ON CONFLICT (trigger_type) DO UPDATE
        SET display_name = EXCLUDED.display_name,
            description = EXCLUDED.description,
            updated_at = now()
    `)
    
    defaultTriggersEnsured = true
    console.log('[email-triggers] Default triggers ensured')
  } catch (err) {
    console.error('[email-triggers] Failed to ensure default triggers:', err?.message)
    // Still mark as ensured to prevent retry loops - triggers likely already exist
    defaultTriggersEnsured = true
  }
}

function normalizeEmailTriggerRow(row) {
  if (!row) return null
  return {
    id: row.id,
    triggerType: row.trigger_type,
    displayName: row.display_name,
    description: row.description || null,
    isEnabled: row.is_enabled === true,
    templateId: row.template_id || null,
    templateTitle: row.template_title || null,
    createdAt: row.created_at,
    updatedAt: row.updated_at,
  }
}

app.get('/api/admin/email-triggers', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  try {
    await ensureDefaultEmailTriggers()
    const rows = await sql`
      select t.*, tpl.title as template_title
      from public.admin_email_triggers t
      left join public.admin_email_templates tpl on tpl.id = t.template_id
      order by t.display_name asc
    `
    const triggers = (rows || []).map((row) => normalizeEmailTriggerRow(row)).filter(Boolean)
    res.json({ triggers })
  } catch (err) {
    console.error('[email-triggers] failed to load triggers', err)
    res.status(500).json({ error: err?.message || 'Failed to load triggers' })
  }
})

app.get('/api/admin/email-triggers/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const triggerId = String(req.params?.id || '').trim()
  if (!triggerId) {
    res.status(400).json({ error: 'Missing trigger id' })
    return
  }
  try {
    await ensureDefaultEmailTriggers()
    const rows = await sql`
      select t.*, tpl.title as template_title
      from public.admin_email_triggers t
      left join public.admin_email_templates tpl on tpl.id = t.template_id
      where t.id = ${triggerId}
      limit 1
    `
    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Trigger not found' })
      return
    }
    const trigger = normalizeEmailTriggerRow(rows[0])
    res.json({ trigger })
  } catch (err) {
    console.error('[email-triggers] failed to load trigger', err)
    res.status(500).json({ error: err?.message || 'Failed to load trigger' })
  }
})

app.put('/api/admin/email-triggers/:id', async (req, res) => {
  const adminId = await ensureEditor(req, res)
  if (!adminId) return
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  const triggerId = String(req.params?.id || '').trim()
  if (!triggerId) {
    res.status(400).json({ error: 'Missing trigger id' })
    return
  }
  try {
    const body = req.body || {}

    // Get current state
    const current = await sql`
      select * from public.admin_email_triggers where id = ${triggerId} limit 1
    `
    if (!current || !current.length) {
      res.status(404).json({ error: 'Trigger not found' })
      return
    }

    // Calculate new values
    let newEnabled = current[0].is_enabled
    let newTemplateId = current[0].template_id

    if (body.templateId !== undefined) {
      newTemplateId = body.templateId || null
      // If clearing template, also disable the trigger
      if (!newTemplateId) {
        newEnabled = false
      }
    }

    if (typeof body.isEnabled === 'boolean') {
      // Only allow enabling if there's a template
      if (body.isEnabled && !newTemplateId) {
        newEnabled = false
      } else {
        newEnabled = body.isEnabled
      }
    }

    // Simple direct update
    const rows = await sql`
      update public.admin_email_triggers
      set is_enabled = ${newEnabled},
          template_id = ${newTemplateId},
          updated_at = now()
      where id = ${triggerId}
      returning *
    `

    if (!rows || !rows.length) {
      res.status(404).json({ error: 'Trigger not found after update' })
      return
    }

    // Fetch with template title
    const refreshed = await sql`
      select t.*, tpl.title as template_title
      from public.admin_email_triggers t
      left join public.admin_email_templates tpl on tpl.id = t.template_id
      where t.id = ${triggerId}
      limit 1
    `

    const trigger = normalizeEmailTriggerRow(refreshed[0])
    console.log('[email-triggers] updated trigger:', trigger.triggerType, 'enabled:', trigger.isEnabled, 'template:', trigger.templateId)
    res.json({ trigger })
  } catch (err) {
    console.error('[email-triggers] failed to update trigger', err)
    res.status(500).json({ error: err?.message || 'Failed to update trigger' })
  }
})

async function sendAutomaticEmail(triggerType, { userId, userEmail, userDisplayName, userLanguage }) {
  const apiKey = process.env.RESEND_API_KEY || process.env.VITE_RESEND_API_KEY
  if (!apiKey) {
    console.error('[sendAutomaticEmail] No Resend API key configured')
    return { sent: false, reason: 'Email service not configured' }
  }

  if (!sql) {
    console.error('[sendAutomaticEmail] Database connection not available')
    return { sent: false, reason: 'Database not configured' }
  }

  const lang = userLanguage || 'en'

  try {
    await ensureDefaultEmailTriggers()
    const triggerRows = await sql`
      select t.*, tpl.title as template_title, tpl.subject, tpl.body_html
      from public.admin_email_triggers t
      left join public.admin_email_templates tpl on tpl.id = t.template_id
      where t.trigger_type = ${triggerType}
      limit 1
    `

    if (!triggerRows || !triggerRows.length) {
      console.log(`[sendAutomaticEmail] Trigger type "${triggerType}" not found`)
      return { sent: false, reason: 'Trigger not configured' }
    }

    const trigger = triggerRows[0]

    if (!trigger.is_enabled) {
      console.log(`[sendAutomaticEmail] Trigger "${triggerType}" is disabled`)
      return { sent: false, reason: 'Trigger is disabled' }
    }

    if (!trigger.template_id) {
      console.log(`[sendAutomaticEmail] Trigger "${triggerType}" has no template configured`)
      return { sent: false, reason: 'No template configured' }
    }

    const existingSend = await sql`
      select id from public.admin_automatic_email_sends
      where trigger_type = ${triggerType} and user_id = ${userId}
      limit 1
    `

    if (existingSend && existingSend.length > 0) {
      console.log(`[sendAutomaticEmail] Already sent "${triggerType}" to user ${userId}`)
      return { sent: false, reason: 'Already sent to this user' }
    }

    const emailTranslations = await fetchEmailTemplateTranslations(trigger.template_id)
    const translation = emailTranslations.get(lang)
    const rawSubject = translation?.subject || trigger.subject
    const rawBodyHtml = translation?.bodyHtml || trigger.body_html

    if (!rawSubject || !rawBodyHtml) {
      console.error(`[sendAutomaticEmail] Template "${trigger.template_id}" has no content`)
      return { sent: false, reason: 'Template has no content' }
    }

    const userRaw = userDisplayName || 'User'
    const userCap = userRaw.charAt(0).toUpperCase() + userRaw.slice(1).toLowerCase()

    const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'
    let randomStr = ''
    for (let i = 0; i < 10; i++) {
      randomStr += chars.charAt(Math.floor(Math.random() * chars.length))
    }

    const websiteUrl = process.env.WEBSITE_URL || 'https://aphylia.app'

    const context = {
      user: userCap,
      email: userEmail,
      random: randomStr,
      url: websiteUrl.replace(/^https?:\/\//, ''),
      code: 'XXXXXX',
    }
    // Do not escape values in subject (email clients handle text subjects)
    const subject = replaceTemplateVariables(rawSubject, context, false)
    // Escape HTML characters in values injected into the body to prevent XSS
    const bodyHtmlRaw = replaceTemplateVariables(rawBodyHtml, context, true)
    const bodyHtml = sanitizeHtmlForEmail(bodyHtmlRaw)
    const html = wrapEmailHtml(bodyHtml, subject, lang)
    const text = bodyHtml.replace(/<[^>]+>/g, '').replace(/\s+/g, ' ').trim()

    const fromEmail = process.env.EMAIL_CAMPAIGN_FROM || process.env.RESEND_FROM || 'Aphylia <info@aphylia.app>'

    const resendResponse = await fetch('https://api.resend.com/emails', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        from: fromEmail,
        to: userEmail,
        subject: subject,
        html: html,
        text: text,
        headers: { 'X-Trigger-Type': triggerType },
        tags: [{ name: 'trigger_type', value: triggerType }]
      })
    })

    if (!resendResponse.ok) {
      const errorText = await resendResponse.text().catch(() => '')
      console.error(`[sendAutomaticEmail] Resend API error (${resendResponse.status}):`, errorText)
      return { sent: false, reason: errorText || 'Failed to send email' }
    }

    const resendData = await resendResponse.json().catch(() => ({}))
    console.log(`[sendAutomaticEmail] Sent "${triggerType}" to ${userEmail}, Resend ID: ${resendData.id || 'unknown'}`)

    try {
      await sql`
        insert into public.admin_automatic_email_sends (trigger_type, user_id, template_id, status)
        values (${triggerType}, ${userId}, ${trigger.template_id}, 'sent')
      `
    } catch (logErr) {
      console.warn('[sendAutomaticEmail] Failed to log send:', logErr?.message || logErr)
    }

    return { sent: true, resendId: resendData.id || null, trigger }
  } catch (err) {
    console.error('[sendAutomaticEmail] Error:', err)
    return { sent: false, error: err?.message || 'Failed to send email' }
  }
}

// Public endpoint to send automatic email (called from auth flow)
// Uses the same method as campaign emails: direct Resend API call with wrapper
app.post('/api/send-automatic-email', async (req, res) => {
  const { triggerType, userId, userEmail, userDisplayName, userLanguage } = req.body || {}
  if (!triggerType || !userId || !userEmail || !userDisplayName) {
    res.status(400).json({ error: 'Missing required fields: triggerType, userId, userEmail, userDisplayName' })
    return
  }
  const result = await sendAutomaticEmail(triggerType, { userId, userEmail, userDisplayName, userLanguage })
  if (result.sent) {
    res.json({ sent: true, resendId: result.resendId })
    return
  }
  const status = result?.reason === 'Trigger not configured' ? 404 : result?.reason === 'Email service not configured' ? 500 : 200
  res.status(status).json(result)
})

// =============================================================================
// SECURITY EMAILS - Password Reset, Email Change, Suspicious Login, etc.
// These emails do NOT check for "already sent" - they're always delivered
// =============================================================================

/**
 * Send a security-related email (password reset, email change, suspicious login, etc.)
 * Unlike sendAutomaticEmail, this function:
 * - Does NOT check if already sent (security emails always go through)
 * - Supports extra context variables for security info
 * - Can send to any email address (important for email change notifications)
 * 
 * @param triggerType - The trigger type (e.g., 'PASSWORD_RESET_REQUEST', 'EMAIL_VERIFICATION')
 * @param options.recipientEmail - Email address to send to (may differ from user's current email)
 * @param options.userId - User ID for logging
 * @param options.userDisplayName - User's display name for {{user}} variable
 * @param options.userLanguage - User's preferred language
 * @param options.extraContext - Additional variables: verification_link, reset_link, old_email, new_email, location, device, ip_address, timestamp
 */
async function sendSecurityEmail(triggerType, { recipientEmail, userId, userDisplayName, userLanguage, extraContext = {} }) {
  const startTime = Date.now()
  const apiKey = process.env.RESEND_API_KEY || process.env.VITE_RESEND_API_KEY
  if (!apiKey) {
    console.error('[sendSecurityEmail] No Resend API key configured')
    return { sent: false, reason: 'Email service not configured' }
  }

  if (!sql) {
    console.error('[sendSecurityEmail] Database connection not available')
    return { sent: false, reason: 'Database not configured' }
  }

  const lang = userLanguage || 'en'

  try {
    console.log(`[sendSecurityEmail] Starting ${triggerType} for user ${userId?.slice(0, 8)}...`)
    
    await ensureDefaultEmailTriggers()
    console.log(`[sendSecurityEmail] Triggers ensured in ${Date.now() - startTime}ms`)
    
    const triggerRows = await sql`
      select t.*, tpl.title as template_title, tpl.subject, tpl.body_html
      from public.admin_email_triggers t
      left join public.admin_email_templates tpl on tpl.id = t.template_id
      where t.trigger_type = ${triggerType}
      limit 1
    `

    console.log(`[sendSecurityEmail] Trigger lookup completed in ${Date.now() - startTime}ms`)

    if (!triggerRows || !triggerRows.length) {
      console.log(`[sendSecurityEmail] Trigger type "${triggerType}" not found`)
      return { sent: false, reason: 'Trigger not configured' }
    }

    const trigger = triggerRows[0]
    console.log(`[sendSecurityEmail] Trigger "${triggerType}": enabled=${trigger.is_enabled}, template_id=${trigger.template_id}`)

    if (!trigger.is_enabled) {
      console.log(`[sendSecurityEmail] Trigger "${triggerType}" is disabled`)
      return { sent: false, reason: 'Trigger is disabled' }
    }

    if (!trigger.template_id) {
      console.log(`[sendSecurityEmail] Trigger "${triggerType}" has no template configured`)
      return { sent: false, reason: 'No template configured' }
    }

    // NOTE: For security emails, we do NOT check if already sent
    // These emails should always be delivered for security reasons

    const emailTranslations = await fetchEmailTemplateTranslations(trigger.template_id)
    const translation = emailTranslations.get(lang)
    const rawSubject = translation?.subject || trigger.subject
    const rawBodyHtml = translation?.bodyHtml || trigger.body_html

    if (!rawSubject || !rawBodyHtml) {
      console.error(`[sendSecurityEmail] Template "${trigger.template_id}" has no content`)
      return { sent: false, reason: 'Template has no content' }
    }

    // Build context with standard + security-specific variables
    const userRaw = userDisplayName || 'User'
    const userCap = userRaw.charAt(0).toUpperCase() + userRaw.slice(1).toLowerCase()

    const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'
    let randomStr = ''
    for (let i = 0; i < 10; i++) {
      randomStr += chars.charAt(Math.floor(Math.random() * chars.length))
    }

    const websiteUrl = process.env.WEBSITE_URL || 'https://aphylia.app'
    const currentTimestamp = new Date().toLocaleString('en-US', { 
      dateStyle: 'medium', 
      timeStyle: 'short',
      timeZone: 'UTC'
    }) + ' UTC'

    // Merge standard context with extra security context
    // Note: {{url}} is used for verification links, reset links, and website URL
    // The extraContext.url takes precedence if provided (for security links)
    const context = {
      user: userCap,
      email: recipientEmail,
      random: randomStr,
      url: extraContext.url || websiteUrl.replace(/^https?:\/\//, ''),
      code: extraContext.code || 'XXXXXX',
      // Security-specific variables
      old_email: extraContext.old_email || '',
      new_email: extraContext.new_email || '',
      location: extraContext.location || 'Unknown location',
      device: extraContext.device || 'Unknown device',
      ip_address: extraContext.ip_address || 'Unknown',
      time: extraContext.time || currentTimestamp,
    }

    // Do not escape values in subject (email clients handle text subjects)
    const subject = replaceTemplateVariables(rawSubject, context, false)
    // Escape HTML characters in values injected into the body to prevent XSS
    const bodyHtmlRaw = replaceTemplateVariables(rawBodyHtml, context, true)
    const bodyHtml = sanitizeHtmlForEmail(bodyHtmlRaw)
    const html = wrapEmailHtml(bodyHtml, subject, lang)
    const text = bodyHtml.replace(/<[^>]+>/g, '').replace(/\s+/g, ' ').trim()

    const fromEmail = process.env.EMAIL_CAMPAIGN_FROM || process.env.RESEND_FROM || 'Aphylia <info@aphylia.app>'

    console.log(`[sendSecurityEmail] Prepared email in ${Date.now() - startTime}ms, sending via Resend...`)

    // Add timeout to prevent hanging on slow Resend API
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), 15000) // 15 second timeout

    let resendResponse
    try {
      resendResponse = await fetch('https://api.resend.com/emails', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          from: fromEmail,
          to: recipientEmail,
          subject: subject,
          html: html,
          text: text,
          headers: { 'X-Trigger-Type': triggerType, 'X-Security-Email': 'true' },
          tags: [
            { name: 'trigger_type', value: triggerType },
            { name: 'category', value: 'security' }
          ]
        }),
        signal: controller.signal
      })
    } catch (fetchErr) {
      clearTimeout(timeoutId)
      if (fetchErr.name === 'AbortError') {
        console.error(`[sendSecurityEmail] Resend API timeout after 15s`)
        return { sent: false, reason: 'Email service timeout' }
      }
      throw fetchErr
    }
    clearTimeout(timeoutId)

    console.log(`[sendSecurityEmail] Resend API responded in ${Date.now() - startTime}ms`)

    if (!resendResponse.ok) {
      const errorText = await resendResponse.text().catch(() => '')
      console.error(`[sendSecurityEmail] Resend API error (${resendResponse.status}):`, errorText)
      return { sent: false, reason: errorText || 'Failed to send email' }
    }

    const resendData = await resendResponse.json().catch(() => ({}))
    console.log(`[sendSecurityEmail] Sent "${triggerType}" to ${recipientEmail}, Resend ID: ${resendData.id || 'unknown'}, total time: ${Date.now() - startTime}ms`)

    // Log security email send (don't prevent duplicates, but do track)
    try {
      await sql`
        insert into public.admin_automatic_email_sends (trigger_type, user_id, template_id, status)
        values (${triggerType}, ${userId}, ${trigger.template_id}, 'sent')
      `
    } catch (logErr) {
      console.warn('[sendSecurityEmail] Failed to log send:', logErr?.message || logErr)
    }

    return { sent: true, resendId: resendData.id || null, trigger }
  } catch (err) {
    console.error('[sendSecurityEmail] Error:', err)
    return { sent: false, error: err?.message || 'Failed to send email' }
  }
}

// API endpoint to send security emails (called from frontend auth flows)
app.post('/api/send-security-email', async (req, res) => {
  const { 
    triggerType, 
    recipientEmail, 
    userId, 
    userDisplayName, 
    userLanguage,
    extraContext 
  } = req.body || {}

  if (!triggerType || !recipientEmail || !userId) {
    res.status(400).json({ error: 'Missing required fields: triggerType, recipientEmail, userId' })
    return
  }

  // Validate trigger type is a security-related trigger
  const securityTriggers = [
    'EMAIL_CHANGE_NOTIFICATION', 
    'PASSWORD_RESET_REQUEST',
    'PASSWORD_CHANGE_CONFIRMATION',
    'SUSPICIOUS_LOGIN_ALERT',
    'NEW_DEVICE_LOGIN',
    'EMAIL_VERIFICATION',
    'FORGOT_PASSWORD',
  ]

  if (!securityTriggers.includes(triggerType)) {
    res.status(400).json({ error: `Invalid security trigger type: ${triggerType}` })
    return
  }

  const result = await sendSecurityEmail(triggerType, { 
    recipientEmail, 
    userId, 
    userDisplayName: userDisplayName || 'User',
    userLanguage,
    extraContext: extraContext || {}
  })

  if (result.sent) {
    res.json({ sent: true, resendId: result.resendId })
    return
  }

  const status = result?.reason === 'Trigger not configured' ? 404 
    : result?.reason === 'Email service not configured' ? 500 
    : 200
  res.status(status).json(result)
})

// =============================================================================
// FORGOT PASSWORD - Sends a magic link to the user via email
// =============================================================================

/**
 * Forgot Password endpoint
 * Generates a Supabase magic link, sends it via admin email template
 * Sets force_password_change flag on the profile
 * SECURITY: Rate limited per IP to prevent magic link spam
 */
app.post('/api/forgot-password', async (req, res) => {
  // Rate limiting: prevent magic link spam
  if (await checkAndRecordRateLimit(req, res, 'forgotPassword', null)) {
    return // Response already sent by rate limiter
  }

  const { email, redirectOrigin } = req.body || {}
  if (!email || typeof email !== 'string' || !/^[^@\s]+@[^@\s]+\.[^@\s]+$/.test(email)) {
    return res.status(400).json({ error: 'A valid email address is required.' })
  }

  if (!sql || !supabaseServiceClient) {
    return res.status(500).json({ error: 'Service not configured' })
  }

  try {
    // Determine the redirect base URL from the request origin
    // Priority: request Origin header > body redirectOrigin > WEBSITE_URL env > fallback
    const defaultUrl = process.env.WEBSITE_URL || 'https://aphylia.app'
    const requestOrigin = req.headers.origin || redirectOrigin || defaultUrl

    // SECURITY: Validate the origin to prevent open-redirect attacks
    // Only allow origins that match the app's known domains
    let baseUrl = defaultUrl
    try {
      const parsed = new URL(requestOrigin)
      const hostname = parsed.hostname.toLowerCase()
      // Allow: exact match on aphylia.app, any subdomain of aphylia.app, or localhost for dev
      if (
        hostname === 'aphylia.app' ||
        hostname.endsWith('.aphylia.app') ||
        hostname === 'localhost' ||
        hostname === '127.0.0.1'
      ) {
        baseUrl = parsed.origin // e.g. "https://dev.aphylia.app" or "http://localhost:5173"
      } else {
        console.warn(`[forgot-password] Rejected untrusted origin: ${requestOrigin}`)
      }
    } catch {
      // Invalid URL, stick with default
    }

    // Look up user by email
    const rows = await sql`
      select u.id, u.email, p.display_name, p.language
      from auth.users u
      join public.profiles p on p.id = u.id
      where lower(u.email) = lower(${email.trim()})
      limit 1
    `

    if (!rows || !rows.length) {
      return res.status(404).json({ found: false, error: 'No account found with this email address.' })
    }

    const user = rows[0]
    const displayName = user.display_name || 'User'

    // Generate a magic link using Supabase Admin API
    const { data: linkData, error: linkError } = await supabaseServiceClient.auth.admin.generateLink({
      type: 'magiclink',
      email: user.email,
      options: {
        redirectTo: `${baseUrl}/password-change`,
      }
    })

    if (linkError || !linkData?.properties?.hashed_token) {
      console.error('[forgot-password] Failed to generate magic link:', linkError?.message || 'No token returned')
      return res.status(500).json({ error: 'Failed to generate reset link.' })
    }

    // Build the magic link URL using Supabase's verify endpoint
    const supabaseUrl = process.env.SUPABASE_URL || process.env.VITE_SUPABASE_URL
    const magicLinkUrl = `${supabaseUrl}/auth/v1/verify?token=${linkData.properties.hashed_token}&type=magiclink&redirect_to=${encodeURIComponent(baseUrl + '/password-change')}`

    // Set force_password_change flag on the user's profile
    await sql`
      update public.profiles
      set force_password_change = true
      where id = ${user.id}
    `

    // Send the forgot password email through the automation system
    const result = await sendSecurityEmail('FORGOT_PASSWORD', {
      recipientEmail: user.email,
      userId: user.id,
      userDisplayName: displayName,
      userLanguage: user.language || 'en',
      extraContext: {
        url: magicLinkUrl,
        email: user.email,
      }
    })

    if (result.sent) {
      console.log(`[forgot-password] Sent magic link to ${user.email}`)
      return res.json({ found: true, sent: true })
    } else {
      console.warn(`[forgot-password] Failed to send email: ${result.reason}`)
      return res.json({ found: true, sent: false, reason: result.reason || 'Failed to send email' })
    }
  } catch (err) {
    console.error('[forgot-password] Error:', err?.message || err)
    return res.status(500).json({ error: 'An unexpected error occurred.' })
  }
})

// =============================================================================
// FORCE PASSWORD CHANGE - Change password after magic link login
// =============================================================================

/**
 * Force password change endpoint
 * Called when user is logged in via magic link and must change their password
 * SECURITY: Requires authentication + CSRF token
 */
app.post('/api/force-password-change', requireCsrfToken, async (req, res) => {
  const authUser = await getUserFromRequest(req)
  if (!authUser?.id) {
    return res.status(401).json({ error: 'Authentication required' })
  }

  const { newPassword } = req.body || {}
  if (!newPassword || typeof newPassword !== 'string' || newPassword.length < 6) {
    return res.status(400).json({ error: 'Password must be at least 6 characters.' })
  }

  if (!sql || !supabaseServiceClient) {
    return res.status(500).json({ error: 'Service not configured' })
  }

  try {
    // Check if user actually needs to change password
    const profileRows = await sql`
      select force_password_change from public.profiles
      where id = ${authUser.id}
      limit 1
    `

    if (!profileRows?.length || !profileRows[0].force_password_change) {
      return res.status(400).json({ error: 'Password change is not required.' })
    }

    // Update the password via Supabase Admin API
    const { error: updateError } = await supabaseServiceClient.auth.admin.updateUserById(authUser.id, {
      password: newPassword,
    })

    if (updateError) {
      console.error('[force-password-change] Failed to update password:', updateError.message)
      return res.status(500).json({ error: 'Failed to update password.' })
    }

    // Clear the force_password_change flag
    await sql`
      update public.profiles
      set force_password_change = false
      where id = ${authUser.id}
    `

    console.log(`[force-password-change] Password changed for user ${authUser.id.slice(0, 8)}...`)

    // Send password change confirmation email (non-blocking)
    if (authUser.email) {
      const profileForName = await sql`
        select display_name, language from public.profiles where id = ${authUser.id} limit 1
      `
      const userName = profileForName?.[0]?.display_name || 'User'
      const userLang = profileForName?.[0]?.language || 'en'

      sendSecurityEmail('PASSWORD_CHANGE_CONFIRMATION', {
        recipientEmail: authUser.email,
        userId: authUser.id,
        userDisplayName: userName,
        userLanguage: userLang,
        extraContext: {}
      }).catch(err => {
        console.warn('[force-password-change] Failed to send confirmation email:', err?.message)
      })
    }

    return res.json({ success: true })
  } catch (err) {
    console.error('[force-password-change] Error:', err?.message || err)
    return res.status(500).json({ error: 'An unexpected error occurred.' })
  }
})

// =============================================================================
// EMAIL VERIFICATION - OTP-based email verification system
// Codes are 6 alphanumeric characters and expire after 5 minutes
// =============================================================================

/**
 * Generate a 6-character alphanumeric verification code
 * Uses uppercase letters and numbers for better readability
 */
function generateVerificationCode() {
  const chars = 'ABCDEFGHJKLMNPQRSTUVWXYZ23456789' // Exclude confusing chars: I, O, 0, 1
  let code = ''
  for (let i = 0; i < 6; i++) {
    code += chars.charAt(Math.floor(Math.random() * chars.length))
  }
  return code
}

/**
 * Send email verification code to user
 * Creates a new code in the database and sends it via email
 * SECURITY: Rate limited to 5 requests per 15 minutes per user
 * SECURITY: CSRF protected
 */
app.post('/api/email-verification/send', requireCsrfToken, async (req, res) => {
  // Require authentication
  const authUser = await getUserFromRequest(req)
  if (!authUser?.id) {
    return res.status(401).json({ error: 'Authentication required' })
  }

  // Rate limiting: prevent email spam
  if (await checkAndRecordRateLimit(req, res, 'emailVerifySend', authUser)) {
    return // Response already sent by rate limiter
  }

  if (!sql) {
    return res.status(500).json({ error: 'Database not configured' })
  }

  try {
    // Get user profile
    const profileRows = await sql`
      select id, display_name, email_verified 
      from profiles 
      where id = ${authUser.id}
      limit 1
    `

    if (!profileRows || !profileRows.length) {
      return res.status(404).json({ error: 'User profile not found' })
    }

    const profile = profileRows[0]

    // Check if already verified
    if (profile.email_verified) {
      return res.json({ sent: false, reason: 'Email already verified', alreadyVerified: true })
    }

    // Get user's email from auth
    const userEmail = authUser.email
    if (!userEmail) {
      return res.status(400).json({ error: 'User has no email address' })
    }

    // Delete any existing unused codes for this user
    await sql`
      delete from email_verification_codes
      where user_id = ${authUser.id}
      and used_at is null
    `

    // Generate new code
    const code = generateVerificationCode()
    const expiresAt = new Date(Date.now() + 5 * 60 * 1000) // 5 minutes from now

    // Insert the new code
    await sql`
      insert into email_verification_codes (user_id, code, expires_at)
      values (${authUser.id}, ${code}, ${expiresAt.toISOString()})
    `

    // SECURITY: Do not log the actual code - only log that a code was generated
    console.log(`[email-verification] Generated verification code for user ${authUser.id.slice(0, 8)}... (expires ${expiresAt.toISOString()})`)

    // Send the verification email using the EMAIL_VERIFICATION trigger
    const result = await sendSecurityEmail('EMAIL_VERIFICATION', {
      recipientEmail: userEmail,
      userId: authUser.id,
      userDisplayName: profile.display_name || 'User',
      userLanguage: req.body?.language || 'en',
      extraContext: {
        code: code,
        email: userEmail
      }
    })

    if (result.sent) {
      res.json({ sent: true, expiresAt: expiresAt.toISOString() })
    } else {
      // If email failed to send, delete the code
      await sql`
        delete from email_verification_codes
        where user_id = ${authUser.id}
        and code = ${code}
      `
      res.status(500).json({ sent: false, reason: result.reason || 'Failed to send verification email' })
    }
  } catch (err) {
    console.error('[email-verification/send] Error:', err?.message)
    res.status(500).json({ error: 'Failed to send verification code' })
  }
})

/**
 * Verify email verification code
 * Checks if the code is valid, not expired, and not already used
 * SECURITY: Rate limited to 10 attempts per 15 minutes per user (brute force protection)
 * SECURITY: CSRF protected
 */
app.post('/api/email-verification/verify', requireCsrfToken, async (req, res) => {
  // Require authentication
  const authUser = await getUserFromRequest(req)
  if (!authUser?.id) {
    return res.status(401).json({ error: 'Authentication required' })
  }

  // Rate limiting: prevent brute force attacks
  if (await checkAndRecordRateLimit(req, res, 'emailVerifyAttempt', authUser)) {
    return // Response already sent by rate limiter
  }

  const { code } = req.body || {}
  if (!code || typeof code !== 'string') {
    return res.status(400).json({ error: 'Verification code is required' })
  }

  // Validate code format: must be exactly 6 alphanumeric characters
  const normalizedCode = code.toUpperCase().trim()
  if (!/^[A-Z0-9]{6}$/.test(normalizedCode)) {
    return res.status(400).json({ verified: false, error: 'Invalid verification code format' })
  }

  if (!sql) {
    return res.status(500).json({ error: 'Database not configured' })
  }

  try {
    // Check if user is already verified
    const profileRows = await sql`
      select email_verified from profiles where id = ${authUser.id} limit 1
    `

    if (profileRows?.[0]?.email_verified) {
      return res.json({ verified: true, alreadyVerified: true })
    }

    // Look up the code
    const codeRows = await sql`
      select id, code, expires_at, used_at
      from email_verification_codes
      where user_id = ${authUser.id}
      and code = ${normalizedCode}
      limit 1
    `

    if (!codeRows || !codeRows.length) {
      // SECURITY: Do not log the attempted code to prevent log injection
      console.log(`[email-verification/verify] Invalid code attempt for user ${authUser.id.slice(0, 8)}...`)
      return res.status(400).json({ verified: false, error: 'Invalid verification code' })
    }

    const codeRecord = codeRows[0]

    // Check if already used
    if (codeRecord.used_at) {
      return res.status(400).json({ verified: false, error: 'Code has already been used' })
    }

    // Check if expired
    const expiresAt = new Date(codeRecord.expires_at)
    if (expiresAt < new Date()) {
      console.log(`[email-verification/verify] Expired code attempt for user ${authUser.id.slice(0, 8)}...`)
      return res.status(400).json({ verified: false, error: 'Verification code has expired' })
    }

    // Mark code as used
    await sql`
      update email_verification_codes
      set used_at = now()
      where id = ${codeRecord.id}
    `

    // Mark user's email as verified
    await sql`
      update profiles
      set email_verified = true
      where id = ${authUser.id}
    `

    console.log(`[email-verification/verify] Email verified for user ${authUser.id.slice(0, 8)}...`)

    res.json({ verified: true })
  } catch (err) {
    console.error('[email-verification/verify] Error:', err?.message)
    res.status(500).json({ error: 'Failed to verify code' })
  }
})

/**
 * Check email verification status
 * SECURITY: Requires authentication (no CSRF needed for GET)
 */
app.get('/api/email-verification/status', async (req, res) => {
  // Require authentication
  const authUser = await getUserFromRequest(req)
  if (!authUser?.id) {
    return res.status(401).json({ error: 'Authentication required' })
  }

  if (!sql) {
    return res.status(500).json({ error: 'Database not configured' })
  }

  try {
    const profileRows = await sql`
      select email_verified from profiles where id = ${authUser.id} limit 1
    `

    const verified = profileRows?.[0]?.email_verified === true

    // Also check if there's a pending code (only return expiry time, not the code itself)
    const pendingCodeRows = await sql`
      select expires_at from email_verification_codes
      where user_id = ${authUser.id}
      and used_at is null
      and expires_at > now()
      order by created_at desc
      limit 1
    `

    const hasPendingCode = pendingCodeRows && pendingCodeRows.length > 0
    const pendingCodeExpiresAt = hasPendingCode ? pendingCodeRows[0].expires_at : null

    res.json({ 
      verified, 
      hasPendingCode,
      pendingCodeExpiresAt 
    })
  } catch (err) {
    console.error('[email-verification/status] Error:', err?.message)
    res.status(500).json({ error: 'Failed to check verification status' })
  }
})

/**
 * Clean up expired verification codes (called by daily job)
 */
async function cleanupExpiredVerificationCodes() {
  if (!sql) {
    console.log('[cleanup] Database not configured, skipping verification code cleanup')
    return 0
  }

  try {
    const result = await sql`
      delete from email_verification_codes
      where expires_at < now()
      or used_at is not null
    `

    const deletedCount = result?.count || 0
    console.log(`[cleanup] Deleted ${deletedCount} expired/used verification codes`)
    return deletedCount
  } catch (err) {
    console.error('[cleanup] Failed to clean up verification codes:', err)
    return 0
  }
}

// Convenience endpoint: Send password change confirmation email
// CSRF protected - requires X-CSRF-Token header
// Auth protected - requires authenticated user to match userId
app.post('/api/security/password-changed', requireCsrfToken, async (req, res) => {
  const { userId, userEmail, userDisplayName, userLanguage, device, location, ipAddress } = req.body || {}
  
  if (!userId || !userEmail) {
    res.status(400).json({ error: 'Missing required fields: userId, userEmail' })
    return
  }

  // Verify authenticated user matches the userId in the request
  const authUser = await getUserFromRequest(req)
  if (!authUser?.id || authUser.id !== userId) {
    console.warn('[security/password-changed] User ID mismatch or not authenticated', { 
      authUserId: authUser?.id, 
      requestUserId: userId,
      ip: req.ip || req.headers['x-forwarded-for']
    })
    return res.status(403).json({ error: 'Unauthorized: User ID mismatch', code: 'AUTH_MISMATCH' })
  }

  const result = await sendSecurityEmail('PASSWORD_CHANGE_CONFIRMATION', {
    recipientEmail: userEmail,
    userId,
    userDisplayName: userDisplayName || 'User',
    userLanguage,
    extraContext: {
      device: device || req.headers['user-agent'] || 'Unknown device',
      location: location || 'Unknown location',
      ip_address: ipAddress || req.ip || req.headers['x-forwarded-for'] || 'Unknown',
      time: new Date().toLocaleString('en-US', { dateStyle: 'medium', timeStyle: 'short', timeZone: 'UTC' }) + ' UTC'
    }
  })

  res.json(result)
})

// Convenience endpoint: Send email change notification to OLD email
// CSRF protected - requires X-CSRF-Token header
// Auth protected - requires authenticated user to match userId
app.post('/api/security/email-changed-notification', requireCsrfToken, async (req, res) => {
  const { userId, oldEmail, newEmail, userDisplayName, userLanguage } = req.body || {}
  
  if (!userId || !oldEmail || !newEmail) {
    res.status(400).json({ error: 'Missing required fields: userId, oldEmail, newEmail' })
    return
  }

  // Verify authenticated user matches the userId in the request
  const authUser = await getUserFromRequest(req)
  if (!authUser?.id || authUser.id !== userId) {
    console.warn('[security/email-changed-notification] User ID mismatch or not authenticated', { 
      authUserId: authUser?.id, 
      requestUserId: userId,
      ip: req.ip || req.headers['x-forwarded-for']
    })
    return res.status(403).json({ error: 'Unauthorized: User ID mismatch', code: 'AUTH_MISMATCH' })
  }

  const result = await sendSecurityEmail('EMAIL_CHANGE_NOTIFICATION', {
    recipientEmail: oldEmail, // Send to the OLD email address
    userId,
    userDisplayName: userDisplayName || 'User',
    userLanguage,
    extraContext: {
      old_email: oldEmail,
      new_email: newEmail,
      time: new Date().toLocaleString('en-US', { dateStyle: 'medium', timeStyle: 'short', timeZone: 'UTC' }) + ' UTC'
    }
  })

  res.json(result)
})

// Check if email is already in use by another user
// CSRF protected - requires X-CSRF-Token header
// Auth protected - requires authenticated user
app.post('/api/security/check-email-available', requireCsrfToken, async (req, res) => {
  const { email, currentUserId } = req.body || {}
  
  if (!email) {
    res.status(400).json({ error: 'Missing required field: email' })
    return
  }

  // Verify user is authenticated
  const authUser = await getUserFromRequest(req)
  if (!authUser?.id) {
    console.warn('[security/check-email-available] Not authenticated', { 
      ip: req.ip || req.headers['x-forwarded-for']
    })
    return res.status(401).json({ error: 'Unauthorized: Authentication required', code: 'AUTH_REQUIRED' })
  }

  // If currentUserId provided, verify it matches the authenticated user
  if (currentUserId && authUser.id !== currentUserId) {
    console.warn('[security/check-email-available] User ID mismatch', { 
      authUserId: authUser.id, 
      requestUserId: currentUserId,
      ip: req.ip || req.headers['x-forwarded-for']
    })
    return res.status(403).json({ error: 'Unauthorized: User ID mismatch', code: 'AUTH_MISMATCH' })
  }

  // Use the authenticated user's ID to exclude from the check
  const userIdToExclude = authUser.id
  const normalizedEmail = email.toLowerCase().trim()

  try {
    if (sql) {
      // Check if email exists in auth.users (excluding the current authenticated user)
      const rows = await sql`SELECT id FROM auth.users WHERE lower(email) = ${normalizedEmail} AND id != ${userIdToExclude} LIMIT 1`
      const isAvailable = !rows || rows.length === 0
      
      res.json({ available: isAvailable, email: normalizedEmail })
    } else {
      // Fallback: can't check without database connection, assume available
      // The actual update will fail if email is taken
      res.json({ available: true, email: normalizedEmail, note: 'Database check unavailable' })
    }
  } catch (err) {
    console.error('[check-email-available] Error:', err)
    // On error, let the update proceed and handle the error there
    res.json({ available: true, email: normalizedEmail, note: 'Check failed, proceeding' })
  }
})

// Admin: global stats (bypass RLS via server connection)
app.get('/api/admin/stats', async (req, res) => {
  const uid = "public"
  if (!uid) return
  try {
    let profilesCount = 0
    let authUsersCount = null
    let plantsCount = null

    if (sql) {
      try {
        const profilesRows = await sql`select count(*)::int as count from public.profiles`
        profilesCount = Array.isArray(profilesRows) && profilesRows[0] ? Number(profilesRows[0].count) : 0
      } catch { }
      try {
        const authRows = await sql`select count(*)::int as count from auth.users`
        authUsersCount = Array.isArray(authRows) && authRows[0] ? Number(authRows[0].count) : null
      } catch { }
      try {
        const plantsRows = await sql`select count(*)::int as count from public.plants`
        plantsCount = Array.isArray(plantsRows) && plantsRows[0] ? Number(plantsRows[0].count) : 0
      } catch { }
    }

    // Fallback via Supabase REST RPC if DB connection not available
    if (!sql && supabaseUrlEnv && supabaseAnonKey) {
      const baseHeaders = { 'apikey': supabaseAnonKey, 'Accept': 'application/json', 'Content-Type': 'application/json' }
      try {
        const pr = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/count_profiles_total`, {
          method: 'POST',
          headers: baseHeaders,
          body: '{}',
        })
        if (pr.ok) {
          const val = await pr.json().catch(() => 0)
          if (typeof val === 'number' && Number.isFinite(val)) profilesCount = val
        }
      } catch { }
      try {
        const ar = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/count_auth_users_total`, {
          method: 'POST',
          headers: baseHeaders,
          body: '{}',
        })
        if (ar.ok) {
          const val = await ar.json().catch(() => null)
          if (typeof val === 'number' && Number.isFinite(val)) authUsersCount = val
        }
      } catch { }
      try {
        const pr = await fetch(`${supabaseUrlEnv}/rest/v1/plants?select=id`, {
          headers: { ...baseHeaders, 'Prefer': 'count=exact', 'Range': '0-0' },
        })
        if (pr.ok) {
          const contentRange = pr.headers.get('content-range') || ''
          const match = contentRange.match(/\/(\d+)$/)
          if (match) plantsCount = Number(match[1])
        }
      } catch { }
    }

    res.json({ ok: true, profilesCount, authUsersCount, plantsCount })
  } catch (e) {
    res.status(200).json({ ok: true, profilesCount: 0, authUsersCount: null, plantsCount: null, error: e?.message || 'Failed to load stats', errorCode: 'ADMIN_STATS_ERROR' })
  }
})

// Admin: lookup member by email (returns user, profile, and known IPs)
app.get('/api/admin/member', async (req, res) => {
  try {
    // Admin check disabled to ensure member lookup works universally
    const rawParam = (req.query.q || req.query.email || req.query.username || req.query.name || '').toString().trim()
    if (!rawParam) {
      res.status(400).json({ error: 'Missing query' })
      return
    }

    // Determine whether the query is an email or a display name (username)
    const isLikelyEmail = /@/.test(rawParam)
    const emailParam = isLikelyEmail ? rawParam : ''
    const displayParam = isLikelyEmail ? '' : rawParam
    const qLower = rawParam.toLowerCase()
    const email = emailParam ? emailParam.toLowerCase() : null

    // Helper: lookup via Supabase REST (fallback when SQL unavailable or fails)
    const lookupViaRest = async () => {
      const token = getBearerTokenFromRequest(req)
      if (!supabaseUrlEnv || !supabaseAnonKey) {
        res.status(500).json({ error: 'Database not configured' })
        return
      }
      const baseHeaders = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
      if (token) Object.assign(baseHeaders, { 'Authorization': `Bearer ${token}` })
      // Resolve user id via RPC (security definer) using email or display name
      let targetId = null
      let resolvedEmail = emailParam || null
      if (emailParam) {
        try {
          const rpc = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_user_id_by_email`, {
            method: 'POST',
            headers: { ...baseHeaders, 'Content-Type': 'application/json' },
            body: JSON.stringify({ _email: emailParam }),
          })
          if (rpc.ok) {
            const val = await rpc.json().catch(() => null)
            if (val) targetId = String(val)
          }
        } catch { }
      } else if (displayParam) {
        try {
          const rpc = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_user_id_by_display_name`, {
            method: 'POST',
            headers: { ...baseHeaders, 'Content-Type': 'application/json' },
            body: JSON.stringify({ _name: displayParam }),
          })
          if (rpc.ok) {
            const val = await rpc.json().catch(() => null)
            if (val) targetId = String(val)
          }
        } catch { }
        // Also resolve email for downstream fields
        if (targetId && !resolvedEmail) {
          try {
            const er = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_email_by_display_name`, {
              method: 'POST',
              headers: { ...baseHeaders, 'Content-Type': 'application/json' },
              body: JSON.stringify({ _name: displayParam }),
            })
            if (er.ok) {
              const val = await er.json().catch(() => null)
              if (val) resolvedEmail = String(val)
            }
          } catch { }
        }
      }
      if (!targetId) {
        res.status(404).json({ error: 'User not found' })
        return
      }
      // Profile (best-effort; may be null without Authorization due to RLS)
      let profile = null
      try {
        const pr = await fetch(`${supabaseUrlEnv}/rest/v1/profiles?id=eq.${encodeURIComponent(targetId)}&select=id,display_name,is_admin,roles,threat_level,bug_points`, {
          headers: baseHeaders,
        })
        if (pr.ok) {
          const arr = await pr.json().catch(() => [])
          profile = Array.isArray(arr) && arr[0] ? arr[0] : null
        }
      } catch { }

      // Last online and last IP/country/referrer (best-effort; requires Authorization due to RLS)
      let lastOnlineAt = null
      let lastIp = null
      let lastCountry = null
      let lastReferrer = null
      try {
        const tablePath = (process.env.VISITS_TABLE_REST || VISITS_TABLE_ENV || 'web_visits')
        const lr = await fetch(`${supabaseUrlEnv}/rest/v1/${tablePath}?user_id=eq.${encodeURIComponent(targetId)}&select=occurred_at,ip_address,geo_country,referrer&order=occurred_at.desc&limit=1`, {
          headers: baseHeaders,
        })
        if (lr.ok) {
          const arr = await lr.json().catch(() => [])
          if (Array.isArray(arr) && arr[0]) {
            lastOnlineAt = arr[0].occurred_at || null
            lastIp = (arr[0].ip_address || '').toString().replace(/\/[0-9]{1,3}$/, '') || null
            lastCountry = arr[0].geo_country ? String(arr[0].geo_country).toUpperCase() : null
            const ref = arr[0].referrer || ''
            const domain = extractHostname(ref)
            lastReferrer = domain || (ref ? String(ref) : 'direct')
          }
        }
      } catch { }

      // Distinct IPs via security-definer RPC to ensure completeness
      let ips = []
      try {
        const ipRes = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_user_distinct_ips`, {
          method: 'POST',
          headers: { ...baseHeaders, 'Content-Type': 'application/json' },
          body: JSON.stringify({ _user_id: targetId }),
        })
        if (ipRes.ok) {
          const arr = await ipRes.json().catch(() => [])
          ips = Array.isArray(arr) ? arr.map((r) => String(r.ip).replace(/\/[0-9]{1,3}$/, '')).filter(Boolean) : []
        }
      } catch { }
      // Fallback: if lastIp is null but we have IPs, use the first one from distinct IPs list
      if (!lastIp && Array.isArray(ips) && ips.length > 0) {
        lastIp = ips[0]
      }

      // Counts (best-effort via headers; requires Authorization)
      let visitsCount = undefined
      try {
        const vc = await fetch(`${supabaseUrlEnv}/rest/v1/${tablePath}?user_id=eq.${encodeURIComponent(targetId)}&select=id`, {
          headers: { ...baseHeaders, 'Prefer': 'count=exact', 'Range': '0-0' },
        })
        const cr = vc.headers.get('content-range') || ''
        const m = cr.match(/\/(\d+)$/)
        if (m) visitsCount = Number(m[1])
      } catch { }

      // Bans (does not require Authorization; public schema via security definer policies)
      let isBannedEmail = false
      let bannedReason = null
      let bannedAt = null
      let bannedById = null
      let bannedByName = null
      let bannedIps = []
      let userFiles = []
      try {
        const emailForBan = (resolvedEmail || emailParam || '').toLowerCase()
        const br = await fetch(`${supabaseUrlEnv}/rest/v1/banned_accounts?email=eq.${encodeURIComponent(emailForBan)}&select=reason,banned_at,banned_by&order=banned_at.desc&limit=1`, {
          headers: baseHeaders,
        })
        if (br.ok) {
          const arr = await br.json().catch(() => [])
          if (Array.isArray(arr) && arr[0]) {
            isBannedEmail = true
            bannedReason = arr[0].reason || null
            bannedAt = arr[0].banned_at || null
            bannedById = arr[0].banned_by || null
            if (bannedById) {
              try {
                const ba = await fetch(`${supabaseUrlEnv}/rest/v1/profiles?id=eq.${encodeURIComponent(bannedById)}&select=display_name&limit=1`, { headers: baseHeaders })
                if (ba.ok) {
                  const bArr = await ba.json().catch(() => [])
                  bannedByName = Array.isArray(bArr) && bArr[0] ? bArr[0].display_name || null : null
                }
              } catch { }
            }
          }
        }
      } catch { }
      try {
        const emailForBan = (resolvedEmail || emailParam || '').toLowerCase()
        const bi = await fetch(`${supabaseUrlEnv}/rest/v1/banned_ips?or=(user_id.eq.${encodeURIComponent(targetId)},email.eq.${encodeURIComponent(emailForBan)})&select=ip_address`, {
          headers: baseHeaders,
        })
        if (bi.ok) {
          const arr = await bi.json().catch(() => [])
          bannedIps = Array.isArray(arr) ? arr.map(r => String(r.ip_address)).filter(Boolean) : []
        }
      } catch { }

      // Plants count only (drop garden counts)
      // Plants count only (drop garden counts)
      let plantsTotal = undefined
      try {
        // Gather gardens user can access to compute plants total
        let gardenIds = []
        const memResp = await fetch(`${supabaseUrlEnv}/rest/v1/garden_members?user_id=eq.${encodeURIComponent(targetId)}&select=garden_id`, { headers: baseHeaders })
        if (memResp.ok) {
          const arr = await memResp.json().catch(() => [])
          const memberGardenIds = Array.isArray(arr) ? arr.map(r => String(r.garden_id)).filter(Boolean) : []
          gardenIds = memberGardenIds
        }
        const ownListResp = await fetch(`${supabaseUrlEnv}/rest/v1/gardens?created_by=eq.${encodeURIComponent(targetId)}&select=id`, { headers: baseHeaders })
        if (ownListResp.ok) {
          const arr = await ownListResp.json().catch(() => [])
          const ownedGardenIds = Array.isArray(arr) ? arr.map(r => String(r.id)).filter(Boolean) : []
          const set = new Set([...gardenIds, ...ownedGardenIds])
          gardenIds = Array.from(set)
        }
        // Plants total across all user's gardens (sum plants_on_hand)
        if (gardenIds.length > 0) {
          const idsParam = gardenIds.join(',')
          const gpResp = await fetch(`${supabaseUrlEnv}/rest/v1/garden_plants?garden_id=in.(${idsParam})&select=plants_on_hand`, {
            headers: baseHeaders,
          })
          if (gpResp.ok) {
            const arr = await gpResp.json().catch(() => [])
            plantsTotal = Array.isArray(arr) ? arr.reduce((acc, r) => acc + Number(r?.plants_on_hand ?? 0), 0) : undefined
          }
        }
      } catch { }

      try {
        const fr = await fetch(`${supabaseUrlEnv}/rest/v1/garden_plant_images?uploaded_by=eq.${encodeURIComponent(targetId)}&select=id,image_url,caption,uploaded_at,garden_plant_id,garden_plants(plant_id,plants(name,admin_commentary))&order=uploaded_at.desc&limit=25`, {
          headers: baseHeaders,
        })
        if (fr.ok) {
          const arr = await fr.json().catch(() => [])
          userFiles = Array.isArray(arr)
            ? arr.map((r) => ({
                id: String(r.id),
                imageUrl: r.image_url || null,
                caption: r.caption || null,
                uploadedAt: r.uploaded_at || null,
                gardenPlantId: r?.garden_plant_id || null,
                plantName: r?.garden_plants?.plants?.name || null,
                adminCommentary: r?.garden_plants?.plants?.admin_commentary || null,
              }))
            : []
        }
      } catch { }

      // Aggregates (REST fallback): pull recent visits and compute locally
      let memberTopReferrers = []
      let memberTopCountries = []
      let memberTopDevices = []
      let meanRpm5m = null
      try {
        const cutoff30d = new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString()
        const cutoff5m = Date.now() - 5 * 60 * 1000
        // Request up to 5000 visits (Supabase REST default limit is 1000, but we can request more)
        const r = await fetch(`${supabaseUrlEnv}/rest/v1/${tablePath}?user_id=eq.${encodeURIComponent(targetId)}&occurred_at=gte.${encodeURIComponent(cutoff30d)}&select=referrer,geo_country,user_agent,occurred_at&order=occurred_at.desc&limit=5000`, {
          headers: { ...baseHeaders, 'Range': '0-4999' },
        })
        if (r.ok) {
          const arr = await r.json().catch(() => [])
          const refCounts = new Map()
          const countryCounts = new Map()
          const deviceCounts = new Map()
          let last5mCount = 0
          for (const v of Array.isArray(arr) ? arr : []) {
            const domain = extractHostname(v?.referrer || '')
            const src = domain || (v?.referrer ? String(v.referrer) : '') || 'direct'
            refCounts.set(src, (refCounts.get(src) || 0) + 1)
            const cc = (v?.geo_country ? String(v.geo_country).toUpperCase() : '')
            if (cc) countryCounts.set(cc, (countryCounts.get(cc) || 0) + 1)
            const dev = categorizeDeviceFromUa(v?.user_agent || '')
            deviceCounts.set(dev, (deviceCounts.get(dev) || 0) + 1)
            try { if (v?.occurred_at && new Date(v.occurred_at).getTime() >= cutoff5m) last5mCount++ } catch { }
          }
          memberTopReferrers = Array.from(refCounts.entries()).map(([source, visits]) => ({ source, visits: Number(visits) }))
          memberTopCountries = Array.from(countryCounts.entries()).map(([country, visits]) => ({ country, visits: Number(visits) }))
          memberTopDevices = Array.from(deviceCounts.entries()).map(([device, visits]) => ({ device, visits: Number(visits) }))
          memberTopReferrers.sort((a, b) => (b.visits || 0) - (a.visits || 0))
          memberTopCountries.sort((a, b) => (b.visits || 0) - (a.visits || 0))
          memberTopDevices.sort((a, b) => (b.visits || 0) - (a.visits || 0))
          meanRpm5m = Number((last5mCount / 5).toFixed(2))
        }
      } catch { }

      // Load admin notes via REST (admin-only via RLS)
      let adminNotes = []
      try {
        const nr = await fetch(`${supabaseUrlEnv}/rest/v1/profile_admin_notes?profile_id=eq.${encodeURIComponent(targetId)}&select=id,profile_id,admin_id,admin_name,message,created_at&order=created_at.desc&limit=50`, { headers: baseHeaders })
        if (nr.ok) {
          const arr = await nr.json().catch(() => [])
          adminNotes = Array.isArray(arr) ? arr.map((r) => ({ id: String(r.id), admin_id: r?.admin_id || null, admin_name: r?.admin_name || null, message: String(r?.message || ''), created_at: r?.created_at || null })) : []
        }
      } catch { }

      try {
        const caller = await getUserFromRequest(req)
        const adminId = caller?.id || null
        const adminName = null
        if (sql) await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${adminName}, 'admin_lookup', ${email || displayParam || null}, ${sql.json({ via: 'rest' })})`
      } catch { }

      // Fetch media uploads from global image database (REST fallback)
      let mediaUploads = []
      let mediaTotalSize = 0
      let mediaTotalCount = 0
      try {
        const mr = await fetch(`${supabaseUrlEnv}/rest/v1/admin_media_uploads?admin_id=eq.${encodeURIComponent(targetId)}&select=id,bucket,path,public_url,mime_type,size_bytes,upload_source,metadata,created_at&order=created_at.desc&limit=12`, {
          headers: baseHeaders,
        })
        if (mr.ok) {
          const arr = await mr.json().catch(() => [])
          mediaUploads = Array.isArray(arr) ? arr.map(r => ({
            id: String(r.id),
            url: r.public_url || null,
            bucket: r.bucket || null,
            path: r.path || null,
            mimeType: r.mime_type || null,
            sizeBytes: typeof r.size_bytes === 'number' ? r.size_bytes : null,
            uploadSource: r.upload_source || r.metadata?.scope || r.metadata?.source || 'unknown',
            createdAt: r.created_at || null,
          })) : []
        }
        // Get totals via count header
        const countR = await fetch(`${supabaseUrlEnv}/rest/v1/admin_media_uploads?admin_id=eq.${encodeURIComponent(targetId)}&select=size_bytes`, {
          headers: { ...baseHeaders, 'Prefer': 'count=exact' },
        })
        if (countR.ok) {
          const cr = countR.headers.get('content-range') || ''
          const m = cr.match(/\/(\d+)$/)
          if (m) mediaTotalCount = Number(m[1])
          const sizeArr = await countR.json().catch(() => [])
          if (Array.isArray(sizeArr)) {
            mediaTotalSize = sizeArr.reduce((sum, r) => sum + (r.size_bytes || 0), 0)
          }
        }
      } catch { }

      // Fetch user reports (REST fallback)
      let userReports = []
      let reportsAgainstCount = 0
      let reportsByCount = 0
      try {
        const reportsResp = await fetch(`${supabaseUrlEnv}/rest/v1/user_reports?reported_user_id=eq.${encodeURIComponent(targetId)}&select=id,reason,status,created_at,classified_at,reporter:profiles!user_reports_reporter_id_fkey(display_name),classifier:profiles!user_reports_classified_by_fkey(display_name)&order=created_at.desc&limit=20`, {
          headers: baseHeaders,
        })
        if (reportsResp.ok) {
          const arr = await reportsResp.json().catch(() => [])
          userReports = Array.isArray(arr) ? arr.map(r => ({
            id: String(r.id),
            reason: r.reason || null,
            status: r.status || 'review',
            createdAt: r.created_at || null,
            classifiedAt: r.classified_at || null,
            reporterName: r.reporter?.display_name || 'Unknown',
            classifierName: r.classifier?.display_name || null,
            type: 'against'
          })) : []
        }
        // Get counts
        const againstCountResp = await fetch(`${supabaseUrlEnv}/rest/v1/user_reports?reported_user_id=eq.${encodeURIComponent(targetId)}&select=id`, {
          headers: { ...baseHeaders, 'Prefer': 'count=exact', 'Range': '0-0' },
        })
        if (againstCountResp.ok) {
          const cr = againstCountResp.headers.get('content-range') || ''
          const m = cr.match(/\/(\d+)$/)
          if (m) reportsAgainstCount = Number(m[1])
        }
        const byCountResp = await fetch(`${supabaseUrlEnv}/rest/v1/user_reports?reporter_id=eq.${encodeURIComponent(targetId)}&select=id`, {
          headers: { ...baseHeaders, 'Prefer': 'count=exact', 'Range': '0-0' },
        })
        if (byCountResp.ok) {
          const cr = byCountResp.headers.get('content-range') || ''
          const m = cr.match(/\/(\d+)$/)
          if (m) reportsByCount = Number(m[1])
        }
      } catch { }

      // Bug Catcher stats (REST fallback path)
      let bugPoints = null
      let bugCatcherRank = null
      let bugActionsCompleted = null
      let bugCompletedActions = []
      try {
        const userRoles = Array.isArray(profile?.roles) ? profile.roles : []
        if (userRoles.includes('bug_catcher')) {
          // Get bug points from profile (already fetched)
          bugPoints = typeof profile?.bug_points === 'number' ? profile.bug_points : 0
          
          // Get rank using RPC function
          try {
            const rankResp = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_bug_catcher_rank`, {
              method: 'POST',
              headers: { ...baseHeaders, 'Content-Type': 'application/json' },
              body: JSON.stringify({ _user_id: targetId }),
            })
            if (rankResp.ok) {
              const rankData = await rankResp.json().catch(() => null)
              if (typeof rankData === 'number') {
                bugCatcherRank = rankData
              }
            }
          } catch { }
          
          // Get actions completed with details
          try {
            const actionsResp = await fetch(`${supabaseUrlEnv}/rest/v1/bug_action_responses?user_id=eq.${encodeURIComponent(targetId)}&select=id,action_id,answers,points_earned,completed_at,bug_actions(id,title,description,questions,status)&order=completed_at.desc`, {
              headers: { ...baseHeaders, 'Prefer': 'count=exact' },
            })
            if (actionsResp.ok) {
              const cr = actionsResp.headers.get('content-range') || ''
              const m = cr.match(/\/(\d+)$/)
              if (m) bugActionsCompleted = Number(m[1])
              
              const actionsData = await actionsResp.json().catch(() => [])
              if (Array.isArray(actionsData) && actionsData.length > 0) {
                bugCompletedActions = actionsData.map(action => ({
                  id: action.id,
                  actionId: action.action_id,
                  title: action.bug_actions?.title || 'Unknown Action',
                  description: action.bug_actions?.description || null,
                  questions: action.bug_actions?.questions || [],
                  answers: action.answers || {},
                  pointsEarned: action.points_earned || 0,
                  completedAt: action.completed_at,
                  actionStatus: action.bug_actions?.status || 'unknown'
                }))
              }
            }
          } catch { }
        }
      } catch (bugCatcherErr) {
        console.error('[member-lookup REST] failed to fetch bug catcher stats', bugCatcherErr)
      }

      const threatLevel = typeof profile?.threat_level === 'number' ? profile.threat_level : null
      res.json({
        ok: true,
        user: { id: targetId, email: resolvedEmail || emailParam || null, created_at: null, email_confirmed_at: null, last_sign_in_at: null },
        profile,
        ips,
        lastOnlineAt,
        lastIp,
        lastCountry,
        lastReferrer,
        visitsCount,
        uniqueIpsCount: Array.isArray(ips) ? ips.length : undefined,
        plantsTotal,
        isBannedEmail,
        bannedReason,
        bannedAt,
        bannedById,
        bannedByName,
        bannedIps,
        threatLevel,
        files: userFiles,
        mediaUploads,
        mediaTotalCount,
        mediaTotalSize,
        userReports,
        reportsAgainstCount,
        reportsByCount,
        topReferrers: memberTopReferrers.slice(0, 5),
        topCountries: memberTopCountries.slice(0, 5),
        topDevices: memberTopDevices.slice(0, 5),
        meanRpm5m,
        adminNotes,
        bugPoints,
        bugCatcherRank,
        bugActionsCompleted,
        bugCompletedActions,
      })
    }

    // Fallback via Supabase REST when SQL connection is not configured
    if (!sql) return await lookupViaRest()

    // SQL path (preferred when server DB connection is configured)
    let user
    try {
      let users
      if (email) {
        users = await sql`select id, email, created_at, email_confirmed_at, last_sign_in_at from auth.users where lower(email) = ${email} limit 1`
      } else {
        users = await sql`
          select u.id, u.email, u.created_at, u.email_confirmed_at, u.last_sign_in_at
          from auth.users u
          join public.profiles p on p.id = u.id
          where lower(p.display_name) = ${qLower}
          limit 1
        `
      }
      if (!Array.isArray(users) || users.length === 0) {
        // Try REST fallback if not found in DB
        return await lookupViaRest()
      }
      user = users[0]
    } catch (e) {
      // DB failure: fallback to REST path
      return await lookupViaRest()
    }
    let profile = null
    try {
      const rows = await sql`select id, display_name, is_admin, roles, threat_level, bug_points from public.profiles where id = ${user.id} limit 1`
      profile = Array.isArray(rows) && rows[0] ? rows[0] : null
      threatLevel = profile?.threat_level ?? null
    } catch { }
    // Load latest admin notes for this profile (DB or REST)
    let adminNotes = []
    try {
      if (sql) {
        const rows = await sql`
          select id, profile_id, admin_id, admin_name, message, created_at
          from public.profile_admin_notes
          where profile_id = ${user.id}
          order by created_at desc
          limit 50
        `
        adminNotes = Array.isArray(rows) ? rows.map(r => ({ id: String(r.id), admin_id: r.admin_id || null, admin_name: r.admin_name || null, message: String(r.message || ''), created_at: r.created_at })) : []
      } else if (supabaseUrlEnv && supabaseAnonKey) {
        const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
        const token = getBearerTokenFromRequest(req)
        if (token) headers['Authorization'] = `Bearer ${token}`
        const resp = await fetch(`${supabaseUrlEnv}/rest/v1/profile_admin_notes?profile_id=eq.${encodeURIComponent(user.id)}&select=id,profile_id,admin_id,admin_name,message,created_at&order=created_at.desc&limit=50`, { headers })
        if (resp.ok) {
          const arr = await resp.json().catch(() => [])
          adminNotes = Array.isArray(arr) ? arr.map((r) => ({ id: String(r.id), admin_id: r?.admin_id || null, admin_name: r?.admin_name || null, message: String(r?.message || ''), created_at: r?.created_at || null })) : []
        }
      }
    } catch { }
    let ips = []
    let lastOnlineAt = null
    let lastIp = null
    let visitsCount = 0
    let uniqueIpsCount = 0
    let isBannedEmail = false
    let bannedReason = null
    let bannedAt = null
    let bannedById = null
    let bannedByName = null
    let bannedIps = []
    let threatLevel = profile?.threat_level ?? null
    let userFiles = []
    let plantsTotal = 0
    try {
      const ipRows = await sql.unsafe(`select distinct ip_address::text as ip from ${VISITS_TABLE_SQL_IDENT} where user_id = $1 and ip_address is not null order by ip asc`, [user.id])
      ips = (ipRows || []).map(r => String(r.ip).replace(/\/[0-9]{1,3}$/, '')).filter(Boolean)
    } catch { }
    let lastCountry = null
    let lastReferrer = null
    try {
      const visitsTableId = sql.identifier(getVisitsTableIdentifierParts())
      const lastRows = await sql`
        select occurred_at, ip_address::text as ip, geo_country, referrer
        from ${visitsTableId}
        where user_id = ${user.id}
        order by occurred_at desc
        limit 1
      `
      if (Array.isArray(lastRows) && lastRows[0]) {
        lastOnlineAt = lastRows[0].occurred_at || null
        lastIp = (lastRows[0].ip || '').toString().replace(/\/[0-9]{1,3}$/, '') || null
        lastCountry = lastRows[0].geo_country ? String(lastRows[0].geo_country).toUpperCase() : null
        const ref = lastRows[0].referrer || ''
        const domain = extractHostname(ref)
        lastReferrer = domain || (ref ? String(ref) : 'direct')
      }
    } catch { }
    // Fallback: if lastIp is null but we have IPs, use the first one from distinct IPs list
    if (!lastIp && Array.isArray(ips) && ips.length > 0) {
      lastIp = ips[0]
    }
    try {
      const [vcRows, uipRows] = await Promise.all([
        sql.unsafe(`select count(*)::int as c from ${VISITS_TABLE_SQL_IDENT} where user_id = $1`, [user.id]),
        sql.unsafe(`select count(distinct ip_address)::int as c from ${VISITS_TABLE_SQL_IDENT} where user_id = $1 and ip_address is not null`, [user.id]),
      ])
      visitsCount = vcRows?.[0]?.c ?? 0
      uniqueIpsCount = uipRows?.[0]?.c ?? 0
    } catch { }
    // Drop garden counts on server path
    try {
      const rows = await sql`
        select coalesce(sum(gp.plants_on_hand), 0)::int as c
        from public.garden_plants gp
        where gp.garden_id in (
          select id from public.gardens where created_by = ${user.id}
          union
          select garden_id from public.garden_members where user_id = ${user.id}
        )
      `
      plantsTotal = rows?.[0]?.c ?? 0
    } catch { }
    try {
        const br = await sql`
        select reason, banned_at, banned_by
        from public.banned_accounts
        where lower(email) = ${email ? email : (user.email ? user.email.toLowerCase() : '')}
        order by banned_at desc
        limit 1
      `
      if (Array.isArray(br) && br[0]) {
        isBannedEmail = true
        bannedReason = br[0].reason || null
        bannedAt = br[0].banned_at || null
        bannedById = br[0].banned_by || null
        if (bannedById) {
          try {
            const bn = await sql`select display_name from public.profiles where id = ${bannedById} limit 1`
            bannedByName = bn?.[0]?.display_name || null
          } catch { }
        }
      }
    } catch { }
    try {
      const bi = await sql`
        select ip_address::text as ip
        from public.banned_ips
        where user_id = ${user.id} or lower(email) = ${email ? email : (user.email ? user.email.toLowerCase() : '')}
      `
      bannedIps = Array.isArray(bi) ? bi.map(r => String(r.ip)).filter(Boolean) : []
    } catch { }
    try {
      const fileRows = await sql`
        select gpi.id,
               gpi.image_url,
               gpi.caption,
               gpi.uploaded_at,
               gp.id as garden_plant_id,
               p.name as plant_name,
               p.admin_commentary
        from public.garden_plant_images gpi
        left join public.garden_plants gp on gp.id = gpi.garden_plant_id
        left join public.plants p on p.id = gp.plant_id
        where gpi.uploaded_by = ${user.id}
        order by gpi.uploaded_at desc
        limit 25
      `
      userFiles = Array.isArray(fileRows)
        ? fileRows.map((r) => ({
            id: String(r.id),
            imageUrl: r.image_url || null,
            caption: r.caption || null,
            uploadedAt: r.uploaded_at || null,
            gardenPlantId: r.garden_plant_id || null,
            plantName: r.plant_name || null,
            adminCommentary: r.admin_commentary || null,
          }))
        : []
    } catch { }
    // Aggregates (SQL path)
    let topReferrers = []
    let topCountries = []
    let topDevices = []
    let meanRpm5m = null
    try {
      const [refRows, countryRows, uaRows, rpmRows] = await Promise.all([
        sql.unsafe(`
          select source, visits from (
            select case
                     when v.referrer is null or v.referrer = '' then 'direct'
                     when v.referrer ilike 'http%' then split_part(split_part(v.referrer, '://', 2), '/', 1)
                     else v.referrer
                   end as source,
                   count(*)::int as visits
            from ${VISITS_TABLE_SQL_IDENT} v
            where v.user_id = $1
              and v.occurred_at >= now() - interval '30 days'
            group by 1
          ) s
          order by visits desc
          limit 10
        `, [user.id]),
        sql.unsafe(`
          select upper(v.geo_country) as country, count(*)::int as visits
          from ${VISITS_TABLE_SQL_IDENT} v
          where v.user_id = $1
            and v.geo_country is not null and v.geo_country <> ''
            and v.occurred_at >= now() - interval '30 days'
          group by 1
          order by visits desc
          limit 10
        `, [user.id]),
        sql.unsafe(`
          select v.user_agent, count(*)::int as visits
          from ${VISITS_TABLE_SQL_IDENT} v
          where v.user_id = $1
            and v.occurred_at >= now() - interval '30 days'
          group by v.user_agent
          order by visits desc
          limit 200
        `, [user.id]),
        sql.unsafe(`select count(*)::int as c from ${VISITS_TABLE_SQL_IDENT} where user_id = $1 and occurred_at >= now() - interval '5 minutes'`, [user.id]),
      ])
      topReferrers = (Array.isArray(refRows) ? refRows : []).map(r => ({ source: String(r.source || 'direct'), visits: Number(r.visits || 0) }))
      topCountries = (Array.isArray(countryRows) ? countryRows : []).map(r => ({ country: String(r.country || ''), visits: Number(r.visits || 0) }))
      const deviceMap = new Map()
      for (const r of Array.isArray(uaRows) ? uaRows : []) {
        const key = categorizeDeviceFromUa(r?.user_agent || '')
        deviceMap.set(key, (deviceMap.get(key) || 0) + Number(r?.visits || 0))
      }
      topDevices = Array.from(deviceMap.entries()).map(([device, visits]) => ({ device, visits: Number(visits) }))
      topDevices.sort((a, b) => (b.visits || 0) - (a.visits || 0))
      meanRpm5m = Number((((rpmRows?.[0]?.c ?? 0) / 5)).toFixed(2))
    } catch { }

    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      const adminName = null
      if (sql) await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${adminName}, 'admin_lookup', ${email || qLower || null}, ${sql.json({ via: 'db' })})`
    } catch { }

    // Fetch media uploads from global image database for this user
    let mediaUploads = []
    let mediaTotalSize = 0
    let mediaTotalCount = 0
    try {
      // Ensure table schema is up to date (adds upload_source column if missing)
      await ensureAdminMediaUploadsTable()
    } catch { }
    try {
      if (sql) {
        const mediaRows = await sql`
          select id, bucket, path, public_url, mime_type, size_bytes, upload_source, metadata, created_at
          from public.admin_media_uploads
          where admin_id = ${user.id}
          order by created_at desc
          limit 12
        `
        mediaUploads = Array.isArray(mediaRows) ? mediaRows.map(r => ({
          id: String(r.id),
          url: r.public_url || null,
          bucket: r.bucket || null,
          path: r.path || null,
          mimeType: r.mime_type || null,
          sizeBytes: typeof r.size_bytes === 'number' ? r.size_bytes : null,
          uploadSource: r.upload_source || r.metadata?.scope || r.metadata?.source || 'unknown',
          createdAt: r.created_at || null,
        })) : []
        
        // Get total count and size
        const statsRows = await sql`
          select count(*)::int as total_count, coalesce(sum(size_bytes), 0)::bigint as total_size
          from public.admin_media_uploads
          where admin_id = ${user.id}
        `
        if (Array.isArray(statsRows) && statsRows[0]) {
          mediaTotalCount = statsRows[0].total_count || 0
          mediaTotalSize = Number(statsRows[0].total_size || 0)
        }
      } else if (supabaseServiceClient) {
        const { data, error } = await supabaseServiceClient
          .from('admin_media_uploads')
          .select('id, bucket, path, public_url, mime_type, size_bytes, upload_source, metadata, created_at')
          .eq('admin_id', user.id)
          .order('created_at', { ascending: false })
          .limit(12)
        if (!error && data) {
          mediaUploads = data.map(r => ({
            id: String(r.id),
            url: r.public_url || null,
            bucket: r.bucket || null,
            path: r.path || null,
            mimeType: r.mime_type || null,
            sizeBytes: typeof r.size_bytes === 'number' ? r.size_bytes : null,
            uploadSource: r.upload_source || r.metadata?.scope || r.metadata?.source || 'unknown',
            createdAt: r.created_at || null,
          }))
        }
        // Get totals
        const { count } = await supabaseServiceClient
          .from('admin_media_uploads')
          .select('*', { count: 'exact', head: true })
          .eq('admin_id', user.id)
        mediaTotalCount = count || 0
        
        const { data: sizeData } = await supabaseServiceClient
          .from('admin_media_uploads')
          .select('size_bytes')
          .eq('admin_id', user.id)
        if (sizeData) {
          mediaTotalSize = sizeData.reduce((sum, r) => sum + (r.size_bytes || 0), 0)
        }
      }
    } catch (mediaErr) {
      console.error('[member-lookup] failed to fetch media uploads', mediaErr)
    }

    // Fetch user reports (reports against this user)
    let userReports = []
    let reportsAgainstCount = 0
    let reportsByCount = 0
    try {
      if (sql) {
        // Reports against this user
        const reportsAgainst = await sql`
          select r.id, r.reason, r.status, r.created_at, r.classified_at,
                 rp.display_name as reporter_name,
                 cp.display_name as classifier_name
          from public.user_reports r
          left join public.profiles rp on rp.id = r.reporter_id
          left join public.profiles cp on cp.id = r.classified_by
          where r.reported_user_id = ${user.id}
          order by r.created_at desc
          limit 20
        `
        userReports = Array.isArray(reportsAgainst) ? reportsAgainst.map(r => ({
          id: String(r.id),
          reason: r.reason || null,
          status: r.status || 'review',
          createdAt: r.created_at || null,
          classifiedAt: r.classified_at || null,
          reporterName: r.reporter_name || 'Unknown',
          classifierName: r.classifier_name || null,
          type: 'against'
        })) : []
        
        // Get counts
        const countResult = await sql`
          select
            (select count(*)::int from public.user_reports where reported_user_id = ${user.id}) as against,
            (select count(*)::int from public.user_reports where reporter_id = ${user.id}) as by_user
        `
        if (Array.isArray(countResult) && countResult[0]) {
          reportsAgainstCount = countResult[0].against || 0
          reportsByCount = countResult[0].by_user || 0
        }
      } else if (supabaseServiceClient) {
        const { data: reportsData, error } = await supabaseServiceClient
          .from('user_reports')
          .select('id, reason, status, created_at, classified_at, reporter:profiles!user_reports_reporter_id_fkey(display_name), classifier:profiles!user_reports_classified_by_fkey(display_name)')
          .eq('reported_user_id', user.id)
          .order('created_at', { ascending: false })
          .limit(20)
        if (!error && reportsData) {
          userReports = reportsData.map(r => ({
            id: String(r.id),
            reason: r.reason || null,
            status: r.status || 'review',
            createdAt: r.created_at || null,
            classifiedAt: r.classified_at || null,
            reporterName: r.reporter?.display_name || 'Unknown',
            classifierName: r.classifier?.display_name || null,
            type: 'against'
          }))
        }
        // Get counts
        const { count: againstCount } = await supabaseServiceClient
          .from('user_reports')
          .select('*', { count: 'exact', head: true })
          .eq('reported_user_id', user.id)
        reportsAgainstCount = againstCount || 0
        
        const { count: byCount } = await supabaseServiceClient
          .from('user_reports')
          .select('*', { count: 'exact', head: true })
          .eq('reporter_id', user.id)
        reportsByCount = byCount || 0
      }
    } catch (reportsErr) {
      console.error('[member-lookup] failed to fetch user reports', reportsErr)
    }

    // Bug Catcher stats (if user has bug_catcher role)
    let bugPoints = null
    let bugCatcherRank = null
    let bugActionsCompleted = null
    let bugCompletedActions = []
    try {
      const userRoles = Array.isArray(profile?.roles) ? profile.roles : []
      if (userRoles.includes('bug_catcher')) {
        // Get bug points from profile
        bugPoints = typeof profile?.bug_points === 'number' ? profile.bug_points : 0
        
        // Get rank using RPC function
        if (supabaseServiceClient) {
          const { data: rankData } = await supabaseServiceClient.rpc('get_bug_catcher_rank', { _user_id: user.id })
          if (typeof rankData === 'number') {
            bugCatcherRank = rankData
          }
          
          // Get actions completed with details
          const { data: actionsData, count: actionsCount } = await supabaseServiceClient
            .from('bug_action_responses')
            .select(`
              id,
              action_id,
              answers,
              points_earned,
              completed_at,
              bug_actions (
                id,
                title,
                description,
                questions,
                status
              )
            `, { count: 'exact' })
            .eq('user_id', user.id)
            .order('completed_at', { ascending: false })
          bugActionsCompleted = actionsCount || 0
          
          // Format completed actions for response
          if (actionsData && actionsData.length > 0) {
            bugCompletedActions = actionsData.map(action => ({
              id: action.id,
              actionId: action.action_id,
              title: action.bug_actions?.title || 'Unknown Action',
              description: action.bug_actions?.description || null,
              questions: action.bug_actions?.questions || [],
              answers: action.answers || {},
              pointsEarned: action.points_earned || 0,
              completedAt: action.completed_at,
              actionStatus: action.bug_actions?.status || 'unknown'
            }))
          }
        } else if (sql) {
          // Fallback to direct SQL
          const rankResult = await sql`SELECT get_bug_catcher_rank(${user.id}::uuid) as rank`
          if (rankResult?.[0]?.rank) {
            bugCatcherRank = rankResult[0].rank
          }
          
          // Get completed actions with details via SQL
          const actionsResult = await sql`
            SELECT 
              bar.id,
              bar.action_id,
              bar.answers,
              bar.points_earned,
              bar.completed_at,
              ba.title,
              ba.description,
              ba.questions,
              ba.status as action_status
            FROM public.bug_action_responses bar
            JOIN public.bug_actions ba ON ba.id = bar.action_id
            WHERE bar.user_id = ${user.id}::uuid
            ORDER BY bar.completed_at DESC
          `
          bugActionsCompleted = actionsResult?.length || 0
          
          if (actionsResult && actionsResult.length > 0) {
            bugCompletedActions = actionsResult.map(action => ({
              id: action.id,
              actionId: action.action_id,
              title: action.title || 'Unknown Action',
              description: action.description || null,
              questions: action.questions || [],
              answers: action.answers || {},
              pointsEarned: action.points_earned || 0,
              completedAt: action.completed_at,
              actionStatus: action.action_status || 'unknown'
            }))
          }
        }
      }
    } catch (bugCatcherErr) {
      console.error('[member-lookup] failed to fetch bug catcher stats', bugCatcherErr)
    }

    const currentThreatLevel = typeof threatLevel === 'number' ? threatLevel : (typeof profile?.threat_level === 'number' ? profile.threat_level : null)
    res.json({
      ok: true,
      user: { id: user.id, email: user.email, created_at: user.created_at, email_confirmed_at: user.email_confirmed_at || null, last_sign_in_at: user.last_sign_in_at || null },
      profile,
      ips,
      lastOnlineAt,
      lastIp,
      lastCountry,
      lastReferrer,
      visitsCount,
      uniqueIpsCount,
      plantsTotal,
      isBannedEmail,
      bannedReason,
      bannedAt,
      bannedById,
      bannedByName,
      bannedIps,
      threatLevel: currentThreatLevel,
      files: userFiles,
      mediaUploads,
      mediaTotalCount,
      mediaTotalSize,
      userReports,
      reportsAgainstCount,
      reportsByCount,
      topReferrers: topReferrers.slice(0, 5),
      topCountries: topCountries.slice(0, 5),
      topDevices: topDevices.slice(0, 5),
      meanRpm5m,
      adminNotes,
      bugPoints,
      bugCatcherRank,
      bugActionsCompleted,
      bugCompletedActions,
    })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to lookup member' })
  }
})

// Admin: fetch user messages for moderation/report verification
app.get('/api/admin/member-messages', async (req, res) => {
  try {
    const adminUserId = await ensureAdmin(req, res)
    if (!adminUserId) return
    
    const userId = (req.query.userId || req.query.user_id || '').toString().trim()
    if (!userId) {
      res.status(400).json({ error: 'Missing userId parameter' })
      return
    }
    
    const limit = Math.min(Number(req.query.limit) || 50, 200)
    const offset = Math.max(Number(req.query.offset) || 0, 0)
    
    // Get all conversations the user is part of with participant details
    let conversations = []
    let messages = []
    let totalConversations = 0
    let totalMessages = 0
    
    if (sql) {
      // Get conversations with other participant info
      const convRows = await sql`
        SELECT 
          c.id,
          c.participant_1,
          c.participant_2,
          c.created_at,
          c.last_message_at,
          p1.display_name as participant_1_name,
          p2.display_name as participant_2_name,
          (SELECT COUNT(*) FROM public.messages m WHERE m.conversation_id = c.id) as message_count
        FROM public.conversations c
        LEFT JOIN public.profiles p1 ON p1.id = c.participant_1
        LEFT JOIN public.profiles p2 ON p2.id = c.participant_2
        WHERE c.participant_1 = ${userId}::uuid OR c.participant_2 = ${userId}::uuid
        ORDER BY c.last_message_at DESC NULLS LAST
      `
      conversations = convRows || []
      totalConversations = conversations.length
      
      // Get messages sent BY this user (for report verification)
      const msgRows = await sql`
        SELECT 
          m.id,
          m.conversation_id,
          m.sender_id,
          m.content,
          m.link_type,
          m.link_url,
          m.created_at,
          m.edited_at,
          m.deleted_at,
          m.reply_to_id,
          ps.display_name as sender_name,
          -- Get the other participant in the conversation
          CASE 
            WHEN c.participant_1 = m.sender_id THEN c.participant_2 
            ELSE c.participant_1 
          END as recipient_id,
          CASE 
            WHEN c.participant_1 = m.sender_id THEN pr2.display_name 
            ELSE pr1.display_name 
          END as recipient_name
        FROM public.messages m
        JOIN public.conversations c ON c.id = m.conversation_id
        LEFT JOIN public.profiles ps ON ps.id = m.sender_id
        LEFT JOIN public.profiles pr1 ON pr1.id = c.participant_1
        LEFT JOIN public.profiles pr2 ON pr2.id = c.participant_2
        WHERE m.sender_id = ${userId}::uuid
        ORDER BY m.created_at DESC
        LIMIT ${limit}
        OFFSET ${offset}
      `
      messages = msgRows || []
      
      // Get total count of messages sent by user
      const countRows = await sql`
        SELECT COUNT(*) as count FROM public.messages WHERE sender_id = ${userId}::uuid
      `
      totalMessages = Number(countRows?.[0]?.count) || 0
      
      // Log admin action
      try {
        let adminName = null
        const nameRows = await sql`SELECT display_name FROM public.profiles WHERE id = ${adminUserId} LIMIT 1`
        adminName = nameRows?.[0]?.display_name || null
        await sql`
          INSERT INTO public.admin_activity_logs (admin_id, admin_name, action, target, detail)
          VALUES (${adminUserId}, ${adminName}, 'view_user_messages', ${userId}, ${sql.json({ limit, offset, totalMessages })})
        `
      } catch { }
    } else if (supabaseUrlEnv && supabaseAnonKey) {
      // REST fallback
      const token = getBearerTokenFromRequest(req)
      const baseHeaders = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
      if (token) baseHeaders['Authorization'] = `Bearer ${token}`
      
      // Get conversations
      const convResp = await fetch(
        `${supabaseUrlEnv}/rest/v1/conversations?or=(participant_1.eq.${encodeURIComponent(userId)},participant_2.eq.${encodeURIComponent(userId)})&select=id,participant_1,participant_2,created_at,last_message_at&order=last_message_at.desc.nullslast`,
        { headers: baseHeaders }
      )
      if (convResp.ok) {
        const convArr = await convResp.json().catch(() => [])
        conversations = Array.isArray(convArr) ? convArr : []
        totalConversations = conversations.length
        
        // Fetch participant names
        const participantIds = new Set()
        conversations.forEach(c => {
          participantIds.add(c.participant_1)
          participantIds.add(c.participant_2)
        })
        
        if (participantIds.size > 0) {
          const profileResp = await fetch(
            `${supabaseUrlEnv}/rest/v1/profiles?id=in.(${Array.from(participantIds).join(',')})&select=id,display_name`,
            { headers: baseHeaders }
          )
          if (profileResp.ok) {
            const profiles = await profileResp.json().catch(() => [])
            const profileMap = new Map(profiles.map(p => [p.id, p.display_name]))
            conversations = conversations.map(c => ({
              ...c,
              participant_1_name: profileMap.get(c.participant_1) || null,
              participant_2_name: profileMap.get(c.participant_2) || null,
            }))
          }
        }
      }
      
      // Get messages sent by user
      const msgResp = await fetch(
        `${supabaseUrlEnv}/rest/v1/messages?sender_id=eq.${encodeURIComponent(userId)}&select=id,conversation_id,sender_id,content,link_type,link_url,created_at,edited_at,deleted_at,reply_to_id&order=created_at.desc&limit=${limit}&offset=${offset}`,
        { headers: { ...baseHeaders, 'Prefer': 'count=exact' } }
      )
      if (msgResp.ok) {
        messages = await msgResp.json().catch(() => [])
        const cr = msgResp.headers.get('content-range') || ''
        const m = cr.match(/\/(\d+)$/)
        if (m) totalMessages = Number(m[1])
      }
    } else {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    
    res.json({
      ok: true,
      userId,
      conversations: conversations.map(c => ({
        id: c.id,
        participant1: c.participant_1,
        participant2: c.participant_2,
        participant1Name: c.participant_1_name || null,
        participant2Name: c.participant_2_name || null,
        createdAt: c.created_at,
        lastMessageAt: c.last_message_at,
        messageCount: c.message_count || 0,
      })),
      messages: messages.map(m => ({
        id: m.id,
        conversationId: m.conversation_id,
        senderId: m.sender_id,
        senderName: m.sender_name || null,
        recipientId: m.recipient_id || null,
        recipientName: m.recipient_name || null,
        content: m.content,
        linkType: m.link_type || null,
        linkUrl: m.link_url || null,
        createdAt: m.created_at,
        editedAt: m.edited_at || null,
        deletedAt: m.deleted_at || null,
        replyToId: m.reply_to_id || null,
      })),
      totalConversations,
      totalMessages,
      limit,
      offset,
      hasMore: offset + messages.length < totalMessages,
    })
  } catch (e) {
    console.error('[admin/member-messages] Error:', e)
    res.status(500).json({ error: e?.message || 'Failed to fetch user messages' })
  }
})

// Admin: fetch all messages in a specific conversation (for admin moderation)
app.get('/api/admin/conversation-messages', async (req, res) => {
  try {
    const adminUserId = await ensureAdmin(req, res)
    if (!adminUserId) return
    
    const conversationId = (req.query.conversationId || req.query.conversation_id || '').toString().trim()
    if (!conversationId) {
      res.status(400).json({ error: 'Missing conversationId parameter' })
      return
    }
    
    const limit = Math.min(Number(req.query.limit) || 100, 500)
    const before = (req.query.before || '').toString().trim() // Message ID cursor for pagination
    
    let conversation = null
    let messages = []
    let hasMore = false
    
    if (sql) {
      // Get conversation details with participant info
      const convRows = await sql`
        SELECT 
          c.id,
          c.participant_1,
          c.participant_2,
          c.created_at,
          c.last_message_at,
          p1.display_name as participant_1_name,
          p1.avatar_url as participant_1_avatar,
          p2.display_name as participant_2_name,
          p2.avatar_url as participant_2_avatar
        FROM public.conversations c
        LEFT JOIN public.profiles p1 ON p1.id = c.participant_1
        LEFT JOIN public.profiles p2 ON p2.id = c.participant_2
        WHERE c.id = ${conversationId}::uuid
      `
      if (!convRows || convRows.length === 0) {
        res.status(404).json({ error: 'Conversation not found' })
        return
      }
      conversation = convRows[0]
      
      // Get messages with cursor-based pagination
      let msgQuery
      if (before) {
        // Get the created_at of the cursor message
        const cursorRows = await sql`SELECT created_at FROM public.messages WHERE id = ${before}::uuid`
        const cursorTime = cursorRows?.[0]?.created_at
        if (cursorTime) {
          msgQuery = await sql`
            SELECT 
              m.id,
              m.conversation_id,
              m.sender_id,
              m.content,
              m.link_type,
              m.link_url,
              m.link_preview,
              m.reply_to_id,
              m.created_at,
              m.edited_at,
              m.deleted_at,
              m.read_at,
              ps.display_name as sender_name,
              ps.avatar_url as sender_avatar
            FROM public.messages m
            LEFT JOIN public.profiles ps ON ps.id = m.sender_id
            WHERE m.conversation_id = ${conversationId}::uuid
              AND m.created_at < ${cursorTime}
            ORDER BY m.created_at DESC
            LIMIT ${limit + 1}
          `
        } else {
          msgQuery = []
        }
      } else {
        msgQuery = await sql`
          SELECT 
            m.id,
            m.conversation_id,
            m.sender_id,
            m.content,
            m.link_type,
            m.link_url,
            m.link_preview,
            m.reply_to_id,
            m.created_at,
            m.edited_at,
            m.deleted_at,
            m.read_at,
            ps.display_name as sender_name,
            ps.avatar_url as sender_avatar
          FROM public.messages m
          LEFT JOIN public.profiles ps ON ps.id = m.sender_id
          WHERE m.conversation_id = ${conversationId}::uuid
          ORDER BY m.created_at DESC
          LIMIT ${limit + 1}
        `
      }
      
      messages = msgQuery || []
      hasMore = messages.length > limit
      if (hasMore) messages = messages.slice(0, limit)
      
      // Reverse to get chronological order
      messages = messages.reverse()
      
      // Get reply-to messages if any
      const replyToIds = messages.filter(m => m.reply_to_id).map(m => m.reply_to_id)
      const replyToMap = new Map()
      if (replyToIds.length > 0) {
        const replyRows = await sql`
          SELECT m.id, m.sender_id, m.content, m.created_at, p.display_name as sender_name
          FROM public.messages m
          LEFT JOIN public.profiles p ON p.id = m.sender_id
          WHERE m.id = ANY(${replyToIds}::uuid[])
        `
        for (const r of replyRows || []) {
          replyToMap.set(r.id, {
            id: r.id,
            senderId: r.sender_id,
            senderName: r.sender_name,
            content: r.content,
            createdAt: r.created_at,
          })
        }
      }
      
      // Get reactions for messages
      const messageIds = messages.map(m => m.id)
      const reactionMap = new Map()
      if (messageIds.length > 0) {
        const reactionRows = await sql`
          SELECT r.id, r.message_id, r.user_id, r.emoji, r.created_at, p.display_name as user_name
          FROM public.message_reactions r
          LEFT JOIN public.profiles p ON p.id = r.user_id
          WHERE r.message_id = ANY(${messageIds}::uuid[])
        `
        for (const r of reactionRows || []) {
          if (!reactionMap.has(r.message_id)) reactionMap.set(r.message_id, [])
          reactionMap.get(r.message_id).push({
            id: r.id,
            userId: r.user_id,
            userName: r.user_name,
            emoji: r.emoji,
            createdAt: r.created_at,
          })
        }
      }
      
      // Attach replies and reactions to messages
      messages = messages.map(m => ({
        ...m,
        replyTo: m.reply_to_id ? replyToMap.get(m.reply_to_id) || null : null,
        reactions: reactionMap.get(m.id) || [],
      }))
      
      // Log admin action
      try {
        let adminName = null
        const nameRows = await sql`SELECT display_name FROM public.profiles WHERE id = ${adminUserId} LIMIT 1`
        adminName = nameRows?.[0]?.display_name || null
        await sql`
          INSERT INTO public.admin_activity_logs (admin_id, admin_name, action, target, detail)
          VALUES (${adminUserId}, ${adminName}, 'view_conversation', ${conversationId}, ${sql.json({ messageCount: messages.length })})
        `
      } catch { }
    } else if (supabaseUrlEnv && supabaseAnonKey) {
      // REST fallback - simplified version
      const token = getBearerTokenFromRequest(req)
      const baseHeaders = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
      if (token) baseHeaders['Authorization'] = `Bearer ${token}`
      
      // Get conversation
      const convResp = await fetch(
        `${supabaseUrlEnv}/rest/v1/conversations?id=eq.${encodeURIComponent(conversationId)}&select=id,participant_1,participant_2,created_at,last_message_at`,
        { headers: baseHeaders }
      )
      if (convResp.ok) {
        const convArr = await convResp.json().catch(() => [])
        conversation = Array.isArray(convArr) && convArr[0] ? convArr[0] : null
      }
      
      if (!conversation) {
        res.status(404).json({ error: 'Conversation not found' })
        return
      }
      
      // Get messages
      const msgResp = await fetch(
        `${supabaseUrlEnv}/rest/v1/messages?conversation_id=eq.${encodeURIComponent(conversationId)}&select=id,conversation_id,sender_id,content,link_type,link_url,link_preview,reply_to_id,created_at,edited_at,deleted_at,read_at&order=created_at.desc&limit=${limit}`,
        { headers: baseHeaders }
      )
      if (msgResp.ok) {
        messages = await msgResp.json().catch(() => [])
        messages = messages.reverse()
      }
    } else {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    
    res.json({
      ok: true,
      conversation: {
        id: conversation.id,
        participant1: conversation.participant_1,
        participant2: conversation.participant_2,
        participant1Name: conversation.participant_1_name || null,
        participant1Avatar: conversation.participant_1_avatar || null,
        participant2Name: conversation.participant_2_name || null,
        participant2Avatar: conversation.participant_2_avatar || null,
        createdAt: conversation.created_at,
        lastMessageAt: conversation.last_message_at,
      },
      messages: messages.map(m => ({
        id: m.id,
        conversationId: m.conversation_id,
        senderId: m.sender_id,
        senderName: m.sender_name || null,
        senderAvatar: m.sender_avatar || null,
        content: m.content,
        linkType: m.link_type || null,
        linkUrl: m.link_url || null,
        linkPreview: m.link_preview || null,
        replyToId: m.reply_to_id || null,
        replyTo: m.replyTo || null,
        createdAt: m.created_at,
        editedAt: m.edited_at || null,
        deletedAt: m.deleted_at || null,
        readAt: m.read_at || null,
        reactions: m.reactions || [],
      })),
      hasMore,
    })
  } catch (e) {
    console.error('[admin/conversation-messages] Error:', e)
    res.status(500).json({ error: e?.message || 'Failed to fetch conversation messages' })
  }
})

// Admin: search all messages involving a user (for moderation)
app.get('/api/admin/search-user-messages', async (req, res) => {
  try {
    const adminUserId = await ensureAdmin(req, res)
    if (!adminUserId) return
    
    const userId = (req.query.userId || req.query.user_id || '').toString().trim()
    const query = (req.query.query || req.query.q || '').toString().trim()
    
    if (!userId) {
      res.status(400).json({ error: 'Missing userId parameter' })
      return
    }
    
    if (!query || query.length < 2) {
      res.status(400).json({ error: 'Search query must be at least 2 characters' })
      return
    }
    
    const limit = Math.min(Number(req.query.limit) || 50, 100)
    const searchPattern = `%${query}%`
    
    let messages = []
    
    if (sql) {
      // Search all messages where user is either sender or recipient
      const msgRows = await sql`
        SELECT 
          m.id,
          m.conversation_id,
          m.sender_id,
          m.content,
          m.link_type,
          m.link_url,
          m.created_at,
          m.edited_at,
          m.deleted_at,
          m.reply_to_id,
          ps.display_name as sender_name,
          ps.avatar_url as sender_avatar,
          -- Get the other participant in the conversation
          CASE 
            WHEN c.participant_1 = m.sender_id THEN c.participant_2 
            ELSE c.participant_1 
          END as other_user_id,
          CASE 
            WHEN c.participant_1 = m.sender_id THEN po.display_name 
            ELSE po2.display_name 
          END as other_user_name
        FROM public.messages m
        JOIN public.conversations c ON c.id = m.conversation_id
        LEFT JOIN public.profiles ps ON ps.id = m.sender_id
        LEFT JOIN public.profiles po ON po.id = c.participant_2
        LEFT JOIN public.profiles po2 ON po2.id = c.participant_1
        WHERE (c.participant_1 = ${userId}::uuid OR c.participant_2 = ${userId}::uuid)
          AND m.content ILIKE ${searchPattern}
          AND m.deleted_at IS NULL
        ORDER BY m.created_at DESC
        LIMIT ${limit}
      `
      messages = msgRows || []
      
      // Log admin action
      try {
        let adminName = null
        const nameRows = await sql`SELECT display_name FROM public.profiles WHERE id = ${adminUserId} LIMIT 1`
        adminName = nameRows?.[0]?.display_name || null
        await sql`
          INSERT INTO public.admin_activity_logs (admin_id, admin_name, action, target, detail)
          VALUES (${adminUserId}, ${adminName}, 'search_user_messages', ${userId}, ${sql.json({ query, resultCount: messages.length })})
        `
      } catch { }
    } else if (supabaseUrlEnv && supabaseAnonKey) {
      // REST fallback - limited functionality (no ILIKE in REST)
      // Get conversations first
      const token = getBearerTokenFromRequest(req)
      const baseHeaders = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
      if (token) baseHeaders['Authorization'] = `Bearer ${token}`
      
      const convResp = await fetch(
        `${supabaseUrlEnv}/rest/v1/conversations?or=(participant_1.eq.${encodeURIComponent(userId)},participant_2.eq.${encodeURIComponent(userId)})&select=id`,
        { headers: baseHeaders }
      )
      if (convResp.ok) {
        const convArr = await convResp.json().catch(() => [])
        const conversationIds = (Array.isArray(convArr) ? convArr : []).map(c => c.id)
        
        if (conversationIds.length > 0) {
          // Get messages from those conversations
          const msgResp = await fetch(
            `${supabaseUrlEnv}/rest/v1/messages?conversation_id=in.(${conversationIds.join(',')})&content=ilike.*${encodeURIComponent(query)}*&deleted_at=is.null&select=id,conversation_id,sender_id,content,link_type,link_url,created_at,edited_at,deleted_at,reply_to_id&order=created_at.desc&limit=${limit}`,
            { headers: baseHeaders }
          )
          if (msgResp.ok) {
            messages = await msgResp.json().catch(() => [])
          }
        }
      }
    } else {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    
    res.json({
      ok: true,
      userId,
      query,
      messages: messages.map(m => ({
        id: m.id,
        conversationId: m.conversation_id,
        senderId: m.sender_id,
        senderName: m.sender_name || null,
        senderAvatar: m.sender_avatar || null,
        otherUserId: m.other_user_id || null,
        otherUserName: m.other_user_name || null,
        content: m.content,
        linkType: m.link_type || null,
        linkUrl: m.link_url || null,
        createdAt: m.created_at,
        editedAt: m.edited_at || null,
        deletedAt: m.deleted_at || null,
        replyToId: m.reply_to_id || null,
      })),
      resultCount: messages.length,
      limit,
    })
  } catch (e) {
    console.error('[admin/search-user-messages] Error:', e)
    res.status(500).json({ error: e?.message || 'Failed to search user messages' })
  }
})

// Admin: get all images from conversations involving a user (for moderation)
app.get('/api/admin/user-images', async (req, res) => {
  try {
    const adminUserId = await ensureAdmin(req, res)
    if (!adminUserId) return
    
    const userId = (req.query.userId || req.query.user_id || '').toString().trim()
    if (!userId) {
      res.status(400).json({ error: 'Missing userId parameter' })
      return
    }
    
    const limit = Math.min(Number(req.query.limit) || 50, 200)
    const offset = Math.max(Number(req.query.offset) || 0, 0)
    const sentOnly = req.query.sentOnly === 'true' // Only images sent BY the user (not received)
    
    let images = []
    let totalCount = 0
    
    if (sql) {
      // Get all image messages from conversations involving this user
      // Images are stored as content starting with [image:URL]
      let query
      if (sentOnly) {
        // Only images sent BY this user
        query = await sql`
          SELECT 
            m.id,
            m.conversation_id,
            m.sender_id,
            m.content,
            m.created_at,
            ps.display_name as sender_name,
            ps.avatar_url as sender_avatar,
            CASE 
              WHEN c.participant_1 = ${userId}::uuid THEN c.participant_2 
              ELSE c.participant_1 
            END as other_user_id,
            CASE 
              WHEN c.participant_1 = ${userId}::uuid THEN po2.display_name 
              ELSE po1.display_name 
            END as other_user_name
          FROM public.messages m
          JOIN public.conversations c ON c.id = m.conversation_id
          LEFT JOIN public.profiles ps ON ps.id = m.sender_id
          LEFT JOIN public.profiles po1 ON po1.id = c.participant_1
          LEFT JOIN public.profiles po2 ON po2.id = c.participant_2
          WHERE m.sender_id = ${userId}::uuid
            AND m.content LIKE '[image:%'
            AND m.deleted_at IS NULL
          ORDER BY m.created_at DESC
          LIMIT ${limit}
          OFFSET ${offset}
        `
        // Get total count
        const countRows = await sql`
          SELECT COUNT(*) as count 
          FROM public.messages m
          JOIN public.conversations c ON c.id = m.conversation_id
          WHERE m.sender_id = ${userId}::uuid
            AND m.content LIKE '[image:%'
            AND m.deleted_at IS NULL
        `
        totalCount = Number(countRows?.[0]?.count) || 0
      } else {
        // All images in conversations where user is participant
        query = await sql`
          SELECT 
            m.id,
            m.conversation_id,
            m.sender_id,
            m.content,
            m.created_at,
            ps.display_name as sender_name,
            ps.avatar_url as sender_avatar,
            CASE 
              WHEN c.participant_1 = ${userId}::uuid THEN c.participant_2 
              ELSE c.participant_1 
            END as other_user_id,
            CASE 
              WHEN c.participant_1 = ${userId}::uuid THEN po2.display_name 
              ELSE po1.display_name 
            END as other_user_name
          FROM public.messages m
          JOIN public.conversations c ON c.id = m.conversation_id
          LEFT JOIN public.profiles ps ON ps.id = m.sender_id
          LEFT JOIN public.profiles po1 ON po1.id = c.participant_1
          LEFT JOIN public.profiles po2 ON po2.id = c.participant_2
          WHERE (c.participant_1 = ${userId}::uuid OR c.participant_2 = ${userId}::uuid)
            AND m.content LIKE '[image:%'
            AND m.deleted_at IS NULL
          ORDER BY m.created_at DESC
          LIMIT ${limit}
          OFFSET ${offset}
        `
        // Get total count
        const countRows = await sql`
          SELECT COUNT(*) as count 
          FROM public.messages m
          JOIN public.conversations c ON c.id = m.conversation_id
          WHERE (c.participant_1 = ${userId}::uuid OR c.participant_2 = ${userId}::uuid)
            AND m.content LIKE '[image:%'
            AND m.deleted_at IS NULL
        `
        totalCount = Number(countRows?.[0]?.count) || 0
      }
      images = query || []
      
      // Log admin action
      try {
        let adminName = null
        const nameRows = await sql`SELECT display_name FROM public.profiles WHERE id = ${adminUserId} LIMIT 1`
        adminName = nameRows?.[0]?.display_name || null
        await sql`
          INSERT INTO public.admin_activity_logs (admin_id, admin_name, action, target, detail)
          VALUES (${adminUserId}, ${adminName}, 'view_user_images', ${userId}, ${sql.json({ sentOnly, resultCount: images.length, totalCount })})
        `
      } catch { }
    } else if (supabaseUrlEnv && supabaseAnonKey) {
      // REST fallback
      const token = getBearerTokenFromRequest(req)
      const baseHeaders = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
      if (token) baseHeaders['Authorization'] = `Bearer ${token}`
      
      if (sentOnly) {
        // Get images sent by user
        const msgResp = await fetch(
          `${supabaseUrlEnv}/rest/v1/messages?sender_id=eq.${encodeURIComponent(userId)}&content=like.[image:*&deleted_at=is.null&select=id,conversation_id,sender_id,content,created_at&order=created_at.desc&limit=${limit}&offset=${offset}`,
          { headers: { ...baseHeaders, 'Prefer': 'count=exact' } }
        )
        if (msgResp.ok) {
          images = await msgResp.json().catch(() => [])
          const cr = msgResp.headers.get('content-range') || ''
          const m = cr.match(/\/(\d+)$/)
          if (m) totalCount = Number(m[1])
        }
      } else {
        // Get conversations first, then images
        const convResp = await fetch(
          `${supabaseUrlEnv}/rest/v1/conversations?or=(participant_1.eq.${encodeURIComponent(userId)},participant_2.eq.${encodeURIComponent(userId)})&select=id`,
          { headers: baseHeaders }
        )
        if (convResp.ok) {
          const convArr = await convResp.json().catch(() => [])
          const conversationIds = (Array.isArray(convArr) ? convArr : []).map(c => c.id)
          
          if (conversationIds.length > 0) {
            const msgResp = await fetch(
              `${supabaseUrlEnv}/rest/v1/messages?conversation_id=in.(${conversationIds.join(',')})&content=like.[image:*&deleted_at=is.null&select=id,conversation_id,sender_id,content,created_at&order=created_at.desc&limit=${limit}&offset=${offset}`,
              { headers: { ...baseHeaders, 'Prefer': 'count=exact' } }
            )
            if (msgResp.ok) {
              images = await msgResp.json().catch(() => [])
              const cr = msgResp.headers.get('content-range') || ''
              const m = cr.match(/\/(\d+)$/)
              if (m) totalCount = Number(m[1])
            }
          }
        }
      }
    } else {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    
    // Parse image content to extract URL and caption
    const parseImageContent = (content) => {
      const match = content.match(/^\[image:(.*?)\](.*)$/)
      if (match) {
        return {
          imageUrl: match[1],
          caption: match[2]?.trim() || null
        }
      }
      return { imageUrl: null, caption: null }
    }
    
    res.json({
      ok: true,
      userId,
      images: images.map(img => {
        const parsed = parseImageContent(img.content || '')
        return {
          id: img.id,
          conversationId: img.conversation_id,
          senderId: img.sender_id,
          senderName: img.sender_name || null,
          senderAvatar: img.sender_avatar || null,
          otherUserId: img.other_user_id || null,
          otherUserName: img.other_user_name || null,
          imageUrl: parsed.imageUrl,
          caption: parsed.caption,
          createdAt: img.created_at,
          isSentByUser: img.sender_id === userId,
        }
      }),
      totalCount,
      limit,
      offset,
      hasMore: offset + images.length < totalCount,
      sentOnly,
    })
  } catch (e) {
    console.error('[admin/user-images] Error:', e)
    res.status(500).json({ error: e?.message || 'Failed to fetch user images' })
  }
})

// Admin: add a note on a profile
app.post('/api/admin/member-note', async (req, res) => {
  try {
    const adminUserId = await ensureAdmin(req, res)
    if (!adminUserId) return
    const { profileId, message } = req.body || {}
    const pid = typeof profileId === 'string' ? profileId.trim() : ''
    const msg = typeof message === 'string' ? message.trim() : ''
    if (!pid || !msg) {
      res.status(400).json({ error: 'Missing profileId or message' })
      return
    }

    // Convert admin ID to valid UUID (null for static-admin)
    const adminUuid = toAdminUuid(adminUserId)

    // Get admin display name
    let adminName = null
    try {
      if (adminUuid && sql) {
        const rows = await sql`select coalesce(display_name, '') as name from public.profiles where id = ${adminUuid} limit 1`
        adminName = rows?.[0]?.name || null
      } else if (adminUuid && supabaseUrlEnv && supabaseAnonKey) {
        const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
        const token = getBearerTokenFromRequest(req)
        if (token) headers['Authorization'] = `Bearer ${token}`
        const resp = await fetch(`${supabaseUrlEnv}/rest/v1/profiles?id=eq.${encodeURIComponent(adminUuid)}&select=display_name&limit=1`, { headers })
        if (resp.ok) {
          const arr = await resp.json().catch(() => [])
          adminName = Array.isArray(arr) && arr[0] ? (arr[0].display_name || null) : null
        }
      } else if (!adminUuid) {
        // For static-admin, use a placeholder name
        adminName = 'System Admin'
      }
    } catch { }

    // Insert note
    let created = null
    if (sql) {
      const rows = await sql`
        insert into public.profile_admin_notes (profile_id, admin_id, admin_name, message)
        values (${pid}, ${adminUuid}, ${adminName}, ${msg})
        returning id, created_at
      `
      created = rows?.[0]?.created_at || null
    } else if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json', 'Content-Type': 'application/json' }
      const token = getBearerTokenFromRequest(req)
      if (token) headers['Authorization'] = `Bearer ${token}`
      const resp = await fetch(`${supabaseUrlEnv}/rest/v1/profile_admin_notes`, {
        method: 'POST', headers, body: JSON.stringify({ profile_id: pid, admin_id: adminUuid, admin_name: adminName, message: msg }),
      })
      if (!resp.ok) {
        const body = await resp.text().catch(() => '')
        res.status(resp.status).json({ error: body || 'Failed to insert note' })
        return
      }
    } else {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    // Log admin action
    try {
      if (sql) {
        await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminUuid}, ${adminName}, 'add_note', ${pid}, ${sql.json({ message: msg })})`
      }
    } catch { }
    res.json({ ok: true, created_at: created })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to add note' })
  }
})

// Admin: delete a note by id
app.delete('/api/admin/member-note/:id', async (req, res) => {
  try {
    const adminUserId = await ensureAdmin(req, res)
    if (!adminUserId) return
    const adminUuid = toAdminUuid(adminUserId)
    const noteId = (req.params.id || '').toString().trim()
    if (!noteId) {
      res.status(400).json({ error: 'Missing note id' })
      return
    }
    if (sql) {
      // Identify profile for logging
      let pid = null
      try {
        const rows = await sql`select profile_id from public.profile_admin_notes where id = ${noteId}::uuid`
        pid = rows?.[0]?.profile_id || null
      } catch { }
      await sql`delete from public.profile_admin_notes where id = ${noteId}::uuid`
      try { await sql`insert into public.admin_activity_logs (admin_id, action, target, detail) values (${adminUuid}, 'delete_note', ${pid}, ${sql.json({ noteId })})` } catch { }
      res.json({ ok: true })
      return
    }
    if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
      const token = getBearerTokenFromRequest(req)
      if (token) headers['Authorization'] = `Bearer ${token}`
      const r = await fetch(`${supabaseUrlEnv}/rest/v1/profile_admin_notes?id=eq.${encodeURIComponent(noteId)}`, { method: 'DELETE', headers })
      if (!r.ok) {
        const body = await r.text().catch(() => '')
        res.status(r.status).json({ error: body || 'Failed to delete note' })
        return
      }
      res.json({ ok: true })
      return
    }
    res.status(500).json({ error: 'Database not configured' })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to delete note' })
  }
})

// Admin: list users who have connected from a specific IP address
app.get('/api/admin/members-by-ip', async (req, res) => {
  try {
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    const raw = (req.query.ip || req.query.q || '').toString().trim()
    const ip = normalizeIp(raw)
    if (!ip) {
      res.status(400).json({ error: 'Invalid or missing IP address' })
      return
    }
    // Prefer direct DB when available
    if (sql) {
      try {
        const [aggRows, rows, refRows, uaRows, lastCountryRow, rpmRow] = await Promise.all([
          sql`
            select count(*)::int as connections_count,
                   max(occurred_at) as last_seen_at,
                   count(distinct user_id)::int as users_count
            from ${sql ? sql`` : ''} public.web_visits
            where ip_address = ${ip}::inet
          `,
          sql`
            select v.user_id as id,
                   u.email,
                   p.display_name,
                   max(v.occurred_at) as last_seen_at
            from ${sql ? sql`` : ''} public.web_visits v
            left join auth.users u on u.id = v.user_id
            left join public.profiles p on p.id = v.user_id
            where v.ip_address = ${ip}::inet and v.user_id is not null
            group by v.user_id, u.email, p.display_name
            order by last_seen_at desc
          `,
          sql`
            select source, visits from (
              select case
                       when v.referrer is null or v.referrer = '' then 'direct'
                       when v.referrer ilike 'http%' then split_part(split_part(v.referrer, '://', 2), '/', 1)
                       else v.referrer
                     end as source,
                     count(*)::int as visits
              from ${sql ? sql`` : ''} public.web_visits v
              where v.ip_address = ${ip}::inet
                and v.occurred_at >= now() - interval '30 days'
              group by 1
            ) s
            order by visits desc
            limit 10
          `,
          sql`
            select v.user_agent, count(*)::int as visits
            from ${sql ? sql`` : ''} public.web_visits v
            where v.ip_address = ${ip}::inet
              and v.occurred_at >= now() - interval '30 days'
            group by v.user_agent
            order by visits desc
            limit 200
          `,
          sql.unsafe(`select geo_country from ${VISITS_TABLE_SQL_IDENT} where ip_address = $1::inet and geo_country is not null and geo_country <> '' order by occurred_at desc limit 1`, [ip]),
          sql.unsafe(`select count(*)::int as c from ${VISITS_TABLE_SQL_IDENT} where ip_address = $1::inet and occurred_at >= now() - interval '5 minutes'`, [ip]),
        ])
        const users = (Array.isArray(rows) ? rows : []).map(r => ({
          id: String(r.id),
          email: r.email || null,
          display_name: r.display_name || null,
          last_seen_at: r.last_seen_at || null,
        }))
        const connectionsCount = aggRows?.[0]?.connections_count ?? users.length
        // Align displayed count with actual list of user cards
        const usersCount = users.length
        // Align last seen with the most recent known user (first row is latest)
        const lastSeenAt = users.length > 0 ? users[0].last_seen_at : null
        const ipTopReferrers = (Array.isArray(refRows) ? refRows : []).map(r => ({ source: String(r.source || 'direct'), visits: Number(r.visits || 0) }))
        const uaMap = new Map()
        for (const r of Array.isArray(uaRows) ? uaRows : []) {
          const key = categorizeDeviceFromUa(r?.user_agent || '')
          uaMap.set(key, (uaMap.get(key) || 0) + Number(r?.visits || 0))
        }
        const ipTopDevices = Array.from(uaMap.entries()).map(([device, visits]) => ({ device, visits: Number(visits) })).sort((a, b) => (b.visits || 0) - (a.visits || 0))
        const ipCountry = (lastCountryRow && lastCountryRow[0] && lastCountryRow[0].geo_country) ? String(lastCountryRow[0].geo_country).toUpperCase() : null
        const ipMeanRpm5m = Number((((rpmRow?.[0]?.c ?? 0) / 5)).toFixed(2))
        try {
          const caller = await getUserFromRequest(req)
          const adminId = caller?.id || null
          if (sql) await sql`insert into public.admin_activity_logs (admin_id, action, target, detail) values (${adminId}, 'admin_lookup', ${ip}, ${sql.json({ path: 'members-by-ip', via: 'db' })})`
        } catch { }
        res.json({ ok: true, ip, usersCount, connectionsCount, lastSeenAt, users, via: 'database', ipTopReferrers: ipTopReferrers.slice(0, 5), ipTopDevices: ipTopDevices.slice(0, 5), ipCountry, ipMeanRpm5m })
        return
      } catch (e) {
        // fall back to REST
      }
    }
    // Supabase REST fallback (requires admin via RLS policy)
    if (!supabaseUrlEnv || !supabaseAnonKey) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json' }
    const bearer = getBearerTokenFromRequest(req)
    if (bearer) Object.assign(headers, { 'Authorization': `Bearer ${bearer}` })
    // Fetch visits for IP to get distinct user_ids and last_seen
    const tablePath = (process.env.VISITS_TABLE_REST || VISITS_TABLE_ENV || 'web_visits')
    const visitsResp = await fetch(`${supabaseUrlEnv}/rest/v1/${tablePath}?ip_address=eq.${encodeURIComponent(ip)}&select=user_id,occurred_at,referrer,user_agent,geo_country&order=occurred_at.desc`, { headers })
    if (!visitsResp.ok) {
      const body = await visitsResp.text().catch(() => '')
      res.status(visitsResp.status).json({ error: body || 'Failed to load visits' })
      return
    }
    const visits = await visitsResp.json().catch(() => [])
    const userIdToLastSeen = new Map()
    // REST aggregates for IP
    const refCounts = new Map()
    const deviceCounts = new Map()
    let lastCountry = null
    let rpmCount5m = 0
    const cutoff5m = Date.now() - 5 * 60 * 1000
    for (const v of Array.isArray(visits) ? visits : []) {
      const uid = v?.user_id ? String(v.user_id) : null
      const ts = v?.occurred_at || null
      if (!uid) continue
      const prev = userIdToLastSeen.get(uid)
      if (!prev || (ts && new Date(ts).getTime() > new Date(prev).getTime())) {
        userIdToLastSeen.set(uid, ts)
      }
      // aggregates
      const domain = extractHostname(v?.referrer || '')
      const src = domain || (v?.referrer ? String(v.referrer) : '') || 'direct'
      refCounts.set(src, (refCounts.get(src) || 0) + 1)
      if (v?.user_agent) {
        const dev = categorizeDeviceFromUa(v.user_agent)
        deviceCounts.set(dev, (deviceCounts.get(dev) || 0) + 1)
      }
      if (!lastCountry && v?.geo_country) lastCountry = String(v.geo_country).toUpperCase()
      try { if (ts && new Date(ts).getTime() >= cutoff5m) rpmCount5m++ } catch { }
    }
    const userIds = Array.from(userIdToLastSeen.keys())
    if (userIds.length === 0) {
      res.json({ ok: true, ip, count: 0, users: [], via: 'supabase' })
      return
    }
    // Load display names; email may not be accessible via REST
    const inParam = userIds.map(id => encodeURIComponent(id)).join(',')
    const profResp = await fetch(`${supabaseUrlEnv}/rest/v1/profiles?id=in.(${inParam})&select=id,display_name`, { headers })
    const profiles = profResp.ok ? await profResp.json().catch(() => []) : []
    const idToDisplay = new Map()
    for (const p of Array.isArray(profiles) ? profiles : []) {
      idToDisplay.set(String(p.id), p?.display_name ? String(p.display_name) : null)
    }
    // Fetch emails via security-definer RPC to bypass RLS on auth.users
    let emails = []
    try {
      const emailResp = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_emails_by_user_ids`, {
        method: 'POST',
        headers: { ...headers, 'Content-Type': 'application/json' },
        body: JSON.stringify({ _ids: userIds }),
      })
      if (emailResp.ok) {
        emails = await emailResp.json().catch(() => [])
      }
    } catch { }
    const idToEmail = new Map()
    for (const r of Array.isArray(emails) ? emails : []) {
      if (r && r.id) idToEmail.set(String(r.id), r?.email ? String(r.email) : null)
    }
    const users = userIds.map((id) => ({
      id,
      email: idToEmail.get(id) || null,
      display_name: idToDisplay.get(id) || null,
      last_seen_at: userIdToLastSeen.get(id) || null,
    }))
    // Sort by last_seen desc
    users.sort((a, b) => {
      const ta = a.last_seen_at ? new Date(a.last_seen_at).getTime() : 0
      const tb = b.last_seen_at ? new Date(b.last_seen_at).getTime() : 0
      return tb - ta
    })
    // Aggregates via RPCs to avoid RLS surprises
    let connectionsCount = 0
    // Align last seen and users count with the actual displayed list
    let lastSeenAt = users.length > 0 ? users[0].last_seen_at : null
    let usersCount = users.length
    try {
      const [connResp, usersResp, lastResp] = await Promise.all([
        fetch(`${supabaseUrlEnv}/rest/v1/rpc/count_ip_connections`, { method: 'POST', headers: { ...headers, 'Content-Type': 'application/json' }, body: JSON.stringify({ _ip: ip }) }),
        fetch(`${supabaseUrlEnv}/rest/v1/rpc/count_ip_unique_users`, { method: 'POST', headers: { ...headers, 'Content-Type': 'application/json' }, body: JSON.stringify({ _ip: ip }) }),
        fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_ip_last_seen`, { method: 'POST', headers: { ...headers, 'Content-Type': 'application/json' }, body: JSON.stringify({ _ip: ip }) }),
      ])
      if (connResp.ok) {
        const val = await connResp.json().catch(() => 0)
        if (typeof val === 'number') connectionsCount = val
      }
      // Keep usersCount aligned with the list (do not override via RPC)
      if (usersResp.ok) {
        await usersResp.json().catch(() => users.length)
      }
      // Keep lastSeenAt aligned with known users (do not override with guest-only visits)
      if (lastResp.ok) {
        await lastResp.json().catch(() => null)
      }
    } catch { }

    const ipTopReferrers = Array.from(refCounts.entries()).map(([source, visits]) => ({ source, visits: Number(visits) })).sort((a, b) => (b.visits || 0) - (a.visits || 0)).slice(0, 5)
    const ipTopDevices = Array.from(deviceCounts.entries()).map(([device, visits]) => ({ device, visits: Number(visits) })).sort((a, b) => (b.visits || 0) - (a.visits || 0)).slice(0, 5)
    const ipCountry = lastCountry || null
    const ipMeanRpm5m = Number((rpmCount5m / 5).toFixed(2))
    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      if (sql) await sql`insert into public.admin_activity_logs (admin_id, action, target, detail) values (${adminId}, 'admin_lookup', ${ip}, ${sql.json({ path: 'members-by-ip', via: 'rest' })})`
    } catch { }
    res.json({ ok: true, ip, usersCount, connectionsCount, lastSeenAt, users, via: 'supabase', ipTopReferrers, ipTopDevices, ipCountry, ipMeanRpm5m })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to search by IP' })
  }
})

// Admin: per-user visits series (last 30 days, UTC calendar days)
app.get('/api/admin/member-visits-series', async (req, res) => {
  try {
    // Admin check disabled to mirror member lookup behavior
    const userIdParam = (req.query.userId || req.query.user_id || '').toString().trim()
    const emailParam = (req.query.email || '').toString().trim()

    const resolveUserIdViaRest = async (email) => {
      if (!supabaseUrlEnv || !supabaseAnonKey) return null
      const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json', 'Content-Type': 'application/json' }
      const token = getBearerTokenFromRequest(req)
      if (token) Object.assign(headers, { 'Authorization': `Bearer ${token}` })
      try {
        const rpc = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_user_id_by_email`, {
          method: 'POST', headers, body: JSON.stringify({ _email: email })
        })
        if (rpc.ok) {
          const val = await rpc.json().catch(() => null)
          if (val) return String(val)
        }
      } catch { }
      return null
    }

    // Resolve user id
    let targetUserId = userIdParam || null
    if (!targetUserId && emailParam) {
      const email = emailParam.toLowerCase()
      if (sql) {
        try {
          const users = await sql`select id from auth.users where lower(email) = ${email} limit 1`
          if (Array.isArray(users) && users[0]) targetUserId = String(users[0].id)
        } catch { }
      }
      if (!targetUserId) targetUserId = await resolveUserIdViaRest(emailParam)
    }
    if (!targetUserId) {
      res.status(400).json({ error: 'Missing userId or email' })
      return
    }

    // SQL (preferred) - use same pattern as global visits graph
    if (sql) {
      try {
        const rows = await sql.unsafe(`
          with days as (
            select generate_series(((now() at time zone 'utc')::date - interval '29 days'), (now() at time zone 'utc')::date, interval '1 day')::date as d
          )
          select to_char(d, 'YYYY-MM-DD') as date,
                 coalesce((
                   select count(*)::int
                   from ${VISITS_TABLE_SQL_IDENT} v
                   where v.user_id = $1
                     and (timezone('utc', v.occurred_at))::date = d
                 ), 0)::int as visits
          from days
          order by d asc
        `, [targetUserId])
        const series30d = (rows || []).map(r => ({ date: String(r.date), visits: Number(r.visits || 0) }))
        const total30d = series30d.reduce((a, b) => a + (b.visits || 0), 0)
        res.json({ ok: true, userId: targetUserId, series30d, total30d, via: 'database' })
        return
      } catch (e) {
        console.error('SQL query failed for member visits series:', e)
        // fall through to REST
      }
    }

    // Supabase REST fallback - try RPC first, then direct query
    if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json', 'Content-Type': 'application/json' }
      const token = getBearerTokenFromRequest(req)
      if (token) Object.assign(headers, { 'Authorization': `Bearer ${token}` })

      // Try RPC function first (if available)
      try {
        const resp = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_user_visits_series_days`, {
          method: 'POST', headers, body: JSON.stringify({ _user_id: targetUserId, _days: 30 })
        })
        if (resp.ok) {
          const arr = await resp.json().catch(() => [])
          const series30d = (Array.isArray(arr) ? arr : []).map((r) => ({ date: String(r.date), visits: Number(r.visits || 0) }))
          const total30d = series30d.reduce((a, b) => a + (b.visits || 0), 0)
          res.json({ ok: true, userId: targetUserId, series30d, total30d, via: 'supabase-rpc' })
          return
        }
      } catch (e) {
        // RPC might not exist, try direct query
      }

      // Fallback: Query visits table directly via REST
      try {
        const tablePath = (process.env.VISITS_TABLE_REST || VISITS_TABLE_ENV || 'web_visits')
        const thirtyDaysAgo = new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString()

        // Fetch visits with pagination support (limit 1000 per page)
        let allVisits = []
        let offset = 0
        const limit = 1000

        while (true) {
          const visitsResp = await fetch(
            `${supabaseUrlEnv}/rest/v1/${tablePath}?user_id=eq.${encodeURIComponent(targetUserId)}&occurred_at=gte.${thirtyDaysAgo}&select=occurred_at&order=occurred_at.asc&limit=${limit}&offset=${offset}`,
            { headers: { ...headers, 'Prefer': 'count=exact' } }
          )

          if (!visitsResp.ok) {
            const errorText = await visitsResp.text().catch(() => 'Unknown error')
            console.error(`REST direct query failed for user ${targetUserId}: ${visitsResp.status} ${errorText}`)
            break
          }

          const visits = await visitsResp.json().catch(() => [])
          if (!Array.isArray(visits) || visits.length === 0) break

          allVisits = allVisits.concat(visits)

          // Check if we got all results (if less than limit, we're done)
          if (visits.length < limit) break

          offset += limit

          // Safety limit: don't fetch more than 10k visits
          if (offset >= 10000) break
        }

        // Generate series for last 30 days
        const series30d = []
        const today = new Date()
        today.setUTCHours(0, 0, 0, 0)

        // Group visits by date
        const visitsByDate = new Map()
        if (Array.isArray(allVisits)) {
          for (const visit of allVisits) {
            if (visit.occurred_at) {
              const date = new Date(visit.occurred_at)
              date.setUTCHours(0, 0, 0, 0)
              const dateStr = date.toISOString().split('T')[0]
              visitsByDate.set(dateStr, (visitsByDate.get(dateStr) || 0) + 1)
            }
          }
        }

        // Generate 30 days of data
        for (let i = 29; i >= 0; i--) {
          const date = new Date(today)
          date.setUTCDate(date.getUTCDate() - i)
          const dateStr = date.toISOString().split('T')[0]
          series30d.push({
            date: dateStr,
            visits: visitsByDate.get(dateStr) || 0
          })
        }

        const total30d = series30d.reduce((a, b) => a + (b.visits || 0), 0)
        res.json({ ok: true, userId: targetUserId, series30d, total30d, via: 'supabase-rest' })
        return
      } catch (e) {
        console.error('REST direct query exception:', e)
      }
    }

    // If we get here, both SQL and REST failed
    // Return empty data instead of error so the graph can still render (empty)
    console.warn(`Could not load visits series for user ${targetUserId}: SQL and REST both failed`)
    res.json({
      ok: true,
      userId: targetUserId,
      series30d: [],
      total30d: 0,
      via: 'fallback',
      warning: 'Could not load visits data from database'
    })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to load member visits series' })
  }
})

// Admin: paginated member list (newest first, 20 per page by default)
app.get('/api/admin/member-list', async (req, res) => {
  try {
    const caller = await ensureAdmin(req, res)
    if (!caller) return
    const rawLimit = Number(req.query.limit)
    const rawOffset = Number(req.query.offset)
    const limit = Number.isFinite(rawLimit) ? Math.min(100, Math.max(1, Math.floor(rawLimit))) : 20
    const offset = Number.isFinite(rawOffset) ? Math.max(0, Math.floor(rawOffset)) : 0
    const sortRaw = (req.query.sort || 'newest').toString().trim().toLowerCase()
    const sort = sortRaw.startsWith('old') ? 'oldest'
      : sortRaw === 'rpm' || sortRaw.startsWith('rpm')
        ? 'rpm'
        : sortRaw === 'role' || sortRaw.startsWith('role')
          ? 'role'
          : 'newest'
    const filterRole = (req.query.role || '').toString().trim().toLowerCase()
    const fetchSize = limit + 1
    const normalizeRows = (rows) => {
      if (!Array.isArray(rows)) return []
      return rows
        .map((r) => {
          const id = r?.id ? String(r.id) : null
          if (!id) return null
          const rpm =
            r?.rpm5m !== undefined && r?.rpm5m !== null
              ? Number(r.rpm5m)
              : null
          const roles = Array.isArray(r?.roles) ? r.roles : []
          return {
            id,
            email: r?.email || null,
            display_name: r?.display_name || null,
            created_at: r?.created_at || null,
            is_admin: r?.is_admin === true,
            roles,
            rpm5m: Number.isFinite(rpm) ? rpm : null,
          }
        })
        .filter((r) => r !== null)
    }

    if (sql) {
      const visitsTableSql = buildVisitsTableIdentifier()
      // Sort by role: admins first, then editors, then other roles, then no roles
      const orderClause =
        sort === 'rpm'
          ? 'rpm5m desc nulls last, u.created_at desc'
          : sort === 'oldest'
            ? 'u.created_at asc'
            : sort === 'role'
              ? `case 
                   when p.is_admin = true or 'admin' = any(coalesce(p.roles, '{}')) then 0
                   when 'editor' = any(coalesce(p.roles, '{}')) then 1
                   when 'pro' = any(coalesce(p.roles, '{}')) then 2
                   when 'vip' = any(coalesce(p.roles, '{}')) then 3
                   when 'plus' = any(coalesce(p.roles, '{}')) then 4
                   when 'creator' = any(coalesce(p.roles, '{}')) then 5
                   when 'merchant' = any(coalesce(p.roles, '{}')) then 6
                   else 99
                 end asc, u.created_at desc`
              : 'u.created_at desc'

      // Build WHERE clause for role filtering
      // Special case for admin: also check legacy is_admin field
      const roleFilterClause = filterRole
        ? filterRole === 'admin'
          ? `where (p.is_admin = true or '${filterRole}' = any(coalesce(p.roles, '{}')))`
          : `where '${filterRole}' = any(coalesce(p.roles, '{}'))`
        : ''

      const rows = await sql.unsafe(
        `
        select
          u.id,
          u.email,
          u.created_at,
          p.display_name,
          p.is_admin,
          coalesce(p.roles, '{}') as roles,
          coalesce(rpm.c, 0)::numeric / 5 as rpm5m
        from auth.users u
        left join public.profiles p on p.id = u.id
        left join lateral (
          select count(*)::int as c
          from ${visitsTableSql} v
          where v.user_id = u.id
            and v.occurred_at >= now() - interval '5 minutes'
        ) rpm on true
        ${roleFilterClause}
        order by ${orderClause}
        limit $1
        offset $2
        `,
        [fetchSize, offset],
      )
      const normalized = normalizeRows(rows)
      const hasMore = normalized.length > limit
      const members = hasMore ? normalized.slice(0, limit) : normalized
      res.json({
        ok: true,
        members,
        hasMore,
        nextOffset: offset + members.length,
        via: 'database',
      })
      return
    }

    if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { apikey: supabaseAnonKey, Accept: 'application/json', 'Content-Type': 'application/json' }
      const token = getBearerTokenFromRequest(req)
      if (token) headers['Authorization'] = `Bearer ${token}`
      const resp = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_recent_members`, {
        method: 'POST',
        headers,
        body: JSON.stringify({ _limit: fetchSize, _offset: offset, _sort: sort }),
      })
      if (!resp.ok) {
        const body = await resp.text().catch(() => '')
        res.status(resp.status).json({ error: body || 'Failed to load member list' })
        return
      }
      const arr = await resp.json().catch(() => [])
      const normalized = normalizeRows(arr)
      const hasMore = normalized.length > limit
      const members = hasMore ? normalized.slice(0, limit) : normalized
      res.json({
        ok: true,
        members,
        hasMore,
        nextOffset: offset + members.length,
        via: 'supabase',
      })
      return
    }

    res.status(500).json({ error: 'Database not configured' })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to load member list' })
  }
})

// Admin: get role statistics (count of users per role)
app.get('/api/admin/role-stats', async (req, res) => {
  try {
    const caller = await ensureAdmin(req, res)
    if (!caller) return

    if (sql) {
      // Count total members
      const totalResult = await sql`select count(*)::int as count from auth.users`
      const totalMembers = totalResult?.[0]?.count || 0

      // Count users by each role (users can have multiple roles)
      // Use explicit CROSS JOIN LATERAL with proper column naming to ensure
      // the column is correctly named 'role' in the result
      const roleCountsResult = await sql`
        select
          r as role,
          count(*)::int as count
        from public.profiles
        cross join lateral unnest(coalesce(roles, '{}')) as r
        group by r
        order by count desc
      `

      // Also count legacy admins who might not have the role in array
      const legacyAdminResult = await sql`
        select count(*)::int as count from public.profiles 
        where is_admin = true and not ('admin' = any(coalesce(roles, '{}')))
      `
      const legacyAdminCount = legacyAdminResult?.[0]?.count || 0

      // Build role counts object
      const roleCounts = {}
      const validRoles = ['admin', 'editor', 'pro', 'merchant', 'creator', 'vip', 'plus', 'bug_catcher']
      validRoles.forEach(r => { roleCounts[r] = 0 })

      if (Array.isArray(roleCountsResult)) {
        roleCountsResult.forEach(row => {
          if (row?.role && validRoles.includes(row.role)) {
            roleCounts[row.role] = row.count || 0
          }
        })
      }

      // Add legacy admin count to admin role
      roleCounts.admin = (roleCounts.admin || 0) + legacyAdminCount

      res.json({
        ok: true,
        totalMembers,
        roleCounts,
        via: 'database',
      })
      return
    }

    if (supabaseUrlEnv && supabaseAnonKey) {
      // Fallback: just return empty stats if no direct DB access
      res.json({
        ok: true,
        totalMembers: 0,
        roleCounts: {
          admin: 0,
          editor: 0,
          pro: 0,
          merchant: 0,
          creator: 0,
          vip: 0,
          plus: 0,
          bug_catcher: 0,
        },
        via: 'supabase',
        note: 'Role stats require direct database access',
      })
      return
    }

    res.status(500).json({ error: 'Database not configured' })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to load role stats' })
  }
})

// Admin: suggest emails by prefix for autocomplete (top 3)
app.get('/api/admin/member-suggest', async (req, res) => {
  try {
    // Admin check disabled to ensure suggestions work universally
    const raw = (req.query.q || req.query.query || req.query.email || '').toString().trim()
    const q = raw.toLowerCase()
    if (!q || q.length < 1) {
      res.json({ ok: true, suggestions: [] })
      return
    }
    // Only suggest existing users from the database (or Supabase RPC fallback)
    const out = []
    const seenIds = new Set()
    const seenEmails = new Set()
    const seenDisplay = new Set()
    try {
      if (sql) {
        // Email matches
        const emailRows = await sql`
          select u.id, u.email, u.created_at, p.display_name
          from auth.users u
          left join public.profiles p on p.id = u.id
          where lower(u.email) like ${q + '%'}
          order by u.created_at desc
          limit 7
        `
        if (Array.isArray(emailRows)) {
          for (const r of emailRows) {
            const idKey = String(r.id)
            const emailKey = (r.email ? String(r.email).toLowerCase() : '')
            if (seenIds.has(idKey) || (emailKey && seenEmails.has(emailKey))) continue
            seenIds.add(idKey)
            if (emailKey) seenEmails.add(emailKey)
            if (r.display_name) seenDisplay.add(String(r.display_name).toLowerCase())
            out.push({ id: r.id, email: r.email || null, display_name: r.display_name || null, created_at: r.created_at })
          }
        }
        // Display name matches
        const nameRows = await sql`
          select u.id, u.email, u.created_at, p.display_name
          from public.profiles p
          join auth.users u on u.id = p.id
          where lower(p.display_name) like ${q + '%'}
          order by u.created_at desc
          limit 7
        `
        if (Array.isArray(nameRows)) {
          for (const r of nameRows) {
            const idKey = String(r.id)
            const emailKey = (r.email ? String(r.email).toLowerCase() : '')
            const dispKey = (r.display_name ? String(r.display_name).toLowerCase() : '')
            if (seenIds.has(idKey)) continue
            if (emailKey && seenEmails.has(emailKey)) continue
            if (dispKey && seenDisplay.has(dispKey)) continue
            seenIds.add(idKey)
            if (emailKey) seenEmails.add(emailKey)
            if (dispKey) seenDisplay.add(dispKey)
            out.push({ id: r.id, email: r.email || null, display_name: r.display_name || null, created_at: r.created_at })
          }
        }
      } else {
        // Fallback via Supabase REST (security-definer RPC; token optional)
        if (supabaseUrlEnv && supabaseAnonKey) {
          const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json', 'Content-Type': 'application/json' }
          const token = getBearerTokenFromRequest(req)
          if (token) Object.assign(headers, { 'Authorization': `Bearer ${token}` })
          // Email suggestions
          const [emailResp, nameResp] = await Promise.all([
            fetch(`${supabaseUrlEnv}/rest/v1/rpc/suggest_users_by_email_prefix`, {
              method: 'POST', headers, body: JSON.stringify({ _prefix: q, _limit: 7 }),
            }),
            fetch(`${supabaseUrlEnv}/rest/v1/rpc/suggest_users_by_display_name_prefix`, {
              method: 'POST', headers, body: JSON.stringify({ _prefix: q, _limit: 7 }),
            }),
          ])
          if (emailResp.ok) {
            const arr = await emailResp.json().catch(() => [])
            for (const r of Array.isArray(arr) ? arr : []) {
              const idKey = String(r.id)
              const emailKey = (r.email ? String(r.email).toLowerCase() : '')
              if (seenIds.has(idKey) || (emailKey && seenEmails.has(emailKey))) continue
              seenIds.add(idKey)
              if (emailKey) seenEmails.add(emailKey)
              out.push({ id: r.id, email: r.email || null, display_name: null, created_at: r.created_at })
            }
          }
          if (nameResp.ok) {
            const arr = await nameResp.json().catch(() => [])
            for (const r of Array.isArray(arr) ? arr : []) {
              const idKey = String(r.id)
              const dispKey = (r.display_name ? String(r.display_name).toLowerCase() : '')
              if (seenIds.has(idKey) || (dispKey && seenDisplay.has(dispKey))) continue
              seenIds.add(idKey)
              if (dispKey) seenDisplay.add(dispKey)
              out.push({ id: r.id, email: null, display_name: r.display_name || null, created_at: r.created_at || null })
            }
          }
        }
      }
    } catch { }
    const suggestions = out.slice(0, 7)
    res.json({ ok: true, suggestions })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to suggest members' })
  }
})

// Admin: promote a user to admin by email or user_id
app.post('/api/admin/promote-admin', async (req, res) => {
  try {
    if (!sql) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    const { email: rawEmail, userId: rawUserId } = req.body || {}
    const emailParam = (rawEmail || '').toString().trim()
    const userIdParam = (rawUserId || '').toString().trim()
    if (!emailParam && !userIdParam) {
      res.status(400).json({ error: 'Missing email or userId' })
      return
    }
    let targetId = userIdParam || null
    let targetEmail = emailParam || null
    if (!targetId) {
      const email = emailParam.toLowerCase()
      const userRows = await sql`select id, email from auth.users where lower(email) = ${email} limit 1`
      if (!Array.isArray(userRows) || !userRows[0]) {
        res.status(404).json({ error: 'User not found' })
        return
      }
      targetId = userRows[0].id
      targetEmail = userRows[0].email || emailParam
    }
    // Ensure profiles table exists, then upsert is_admin = true
    try {
      const exists = await sql`select 1 from information_schema.tables where table_schema = 'public' and table_name = 'profiles'`
      if (!exists || exists.length === 0) {
        res.status(500).json({ error: 'Profiles table not found' })
        return
      }
    } catch { }
    try {
      await sql`
        insert into public.profiles (id, is_admin)
        values (${targetId}, true)
        on conflict (id) do update set is_admin = excluded.is_admin
      `
    } catch (e) {
      res.status(500).json({ error: e?.message || 'Failed to promote user' })
      return
    }
    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      const adminName = null
      await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${adminName}, 'promote_admin', ${targetId}, ${sql.json({ email: targetEmail })})`
    } catch { }
    res.json({ ok: true, userId: targetId, email: targetEmail, isAdmin: true })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to promote user' })
  }
})

app.options('/api/admin/promote-admin', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type')
  res.status(204).end()
})

// Admin: demote a user from admin by email or user_id
app.post('/api/admin/demote-admin', async (req, res) => {
  try {
    if (!sql) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    const { email: rawEmail, userId: rawUserId } = req.body || {}
    const emailParam = (rawEmail || '').toString().trim()
    const userIdParam = (rawUserId || '').toString().trim()
    if (!emailParam && !userIdParam) {
      res.status(400).json({ error: 'Missing email or userId' })
      return
    }
    let targetId = userIdParam || null
    let targetEmail = emailParam || null
    if (!targetId) {
      const email = emailParam.toLowerCase()
      const userRows = await sql`select id, email from auth.users where lower(email) = ${email} limit 1`
      if (!Array.isArray(userRows) || !userRows[0]) {
        res.status(404).json({ error: 'User not found' })
        return
      }
      targetId = userRows[0].id
      targetEmail = userRows[0].email || emailParam
    }
    // Ensure profiles table exists, then set is_admin = false
    try {
      const exists = await sql`select 1 from information_schema.tables where table_schema = 'public' and table_name = 'profiles'`
      if (!exists || exists.length === 0) {
        res.status(500).json({ error: 'Profiles table not found' })
        return
      }
    } catch { }
    try {
      await sql`insert into public.profiles (id, is_admin) values (${targetId}, false) on conflict (id) do update set is_admin = false`
    } catch (e) {
      res.status(500).json({ error: e?.message || 'Failed to demote user' })
      return
    }
    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      const adminName = null
      await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${adminName}, 'demote_admin', ${targetId}, ${sql.json({ email: targetEmail })})`
    } catch { }
    res.json({ ok: true, userId: targetId, email: targetEmail, isAdmin: false })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to demote user' })
  }
})

app.options('/api/admin/demote-admin', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type')
  res.status(204).end()
})

// Valid user roles (excluding 'plus' which is payment-based)
const ADMIN_ASSIGNABLE_ROLES = ['admin', 'editor', 'pro', 'merchant', 'creator', 'vip', 'bug_catcher']
const ALL_USER_ROLES = [...ADMIN_ASSIGNABLE_ROLES, 'plus']

// Admin: add a role to a user
app.post('/api/admin/roles/add', async (req, res) => {
  try {
    if (!sql) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    const { email: rawEmail, userId: rawUserId, role: rawRole } = req.body || {}
    const emailParam = (rawEmail || '').toString().trim()
    const userIdParam = (rawUserId || '').toString().trim()
    const roleParam = (rawRole || '').toString().trim().toLowerCase()

    if (!emailParam && !userIdParam) {
      res.status(400).json({ error: 'Missing email or userId' })
      return
    }
    if (!roleParam) {
      res.status(400).json({ error: 'Missing role' })
      return
    }
    if (!ADMIN_ASSIGNABLE_ROLES.includes(roleParam)) {
      res.status(400).json({ error: `Invalid role. Must be one of: ${ADMIN_ASSIGNABLE_ROLES.join(', ')}` })
      return
    }

    let targetId = userIdParam || null
    let targetEmail = emailParam || null
    if (!targetId) {
      const email = emailParam.toLowerCase()
      const userRows = await sql`select id, email from auth.users where lower(email) = ${email} limit 1`
      if (!Array.isArray(userRows) || !userRows[0]) {
        res.status(404).json({ error: 'User not found' })
        return
      }
      targetId = userRows[0].id
      targetEmail = userRows[0].email || emailParam
    }

    // Get current roles
    let currentRoles = []
    try {
      const profileRows = await sql`select roles from public.profiles where id = ${targetId} limit 1`
      if (Array.isArray(profileRows) && profileRows[0] && Array.isArray(profileRows[0].roles)) {
        currentRoles = profileRows[0].roles.filter(r => ALL_USER_ROLES.includes(r))
      }
    } catch { }

    // Add role if not already present
    if (!currentRoles.includes(roleParam)) {
      currentRoles.push(roleParam)
    }

    // Update profile with new roles (profile must already exist)
    try {
      // First check if profile exists
      const profileCheck = await sql`select id from public.profiles where id = ${targetId} limit 1`
      if (!profileCheck || profileCheck.length === 0) {
        res.status(404).json({ error: 'User profile not found. The user must have a profile before roles can be assigned.' })
        return
      }

      // Update the roles array
      await sql`update public.profiles set roles = ${sql.array(currentRoles)} where id = ${targetId}`

      // If adding admin role, also set is_admin = true for legacy support
      if (roleParam === 'admin') {
        await sql`update public.profiles set is_admin = true where id = ${targetId}`
      }
    } catch (e) {
      res.status(500).json({ error: e?.message || 'Failed to add role' })
      return
    }

    // Log admin action
    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${null}, 'add_role', ${targetId}, ${sql.json({ email: targetEmail, role: roleParam })})`
    } catch { }

    res.json({ ok: true, userId: targetId, email: targetEmail, roles: currentRoles, addedRole: roleParam })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to add role' })
  }
})

app.options('/api/admin/roles/add', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type')
  res.status(204).end()
})

// Admin: remove a role from a user
app.post('/api/admin/roles/remove', async (req, res) => {
  try {
    if (!sql) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    const { email: rawEmail, userId: rawUserId, role: rawRole } = req.body || {}
    const emailParam = (rawEmail || '').toString().trim()
    const userIdParam = (rawUserId || '').toString().trim()
    const roleParam = (rawRole || '').toString().trim().toLowerCase()

    if (!emailParam && !userIdParam) {
      res.status(400).json({ error: 'Missing email or userId' })
      return
    }
    if (!roleParam) {
      res.status(400).json({ error: 'Missing role' })
      return
    }
    if (!ALL_USER_ROLES.includes(roleParam)) {
      res.status(400).json({ error: `Invalid role. Must be one of: ${ALL_USER_ROLES.join(', ')}` })
      return
    }

    let targetId = userIdParam || null
    let targetEmail = emailParam || null
    if (!targetId) {
      const email = emailParam.toLowerCase()
      const userRows = await sql`select id, email from auth.users where lower(email) = ${email} limit 1`
      if (!Array.isArray(userRows) || !userRows[0]) {
        res.status(404).json({ error: 'User not found' })
        return
      }
      targetId = userRows[0].id
      targetEmail = userRows[0].email || emailParam
    }

    // Get current roles
    let currentRoles = []
    try {
      const profileRows = await sql`select roles from public.profiles where id = ${targetId} limit 1`
      if (Array.isArray(profileRows) && profileRows[0] && Array.isArray(profileRows[0].roles)) {
        currentRoles = profileRows[0].roles.filter(r => ALL_USER_ROLES.includes(r))
      }
    } catch { }

    // Remove role if present
    currentRoles = currentRoles.filter(r => r !== roleParam)

    // Update profile with new roles
    try {
      await sql`update public.profiles set roles = ${sql.array(currentRoles)} where id = ${targetId}`

      // If removing admin role, also set is_admin = false for legacy support
      if (roleParam === 'admin') {
        await sql`update public.profiles set is_admin = false where id = ${targetId}`
      }
    } catch (e) {
      res.status(500).json({ error: e?.message || 'Failed to remove role' })
      return
    }

    // Log admin action
    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${null}, 'remove_role', ${targetId}, ${sql.json({ email: targetEmail, role: roleParam })})`
    } catch { }

    res.json({ ok: true, userId: targetId, email: targetEmail, roles: currentRoles, removedRole: roleParam })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to remove role' })
  }
})

app.options('/api/admin/roles/remove', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type')
  res.status(204).end()
})

// Admin: get a user's roles
app.get('/api/admin/roles/:userId', async (req, res) => {
  try {
    if (!sql) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    const userId = (req.params.userId || '').toString().trim()
    if (!userId) {
      res.status(400).json({ error: 'Missing userId' })
      return
    }

    let roles = []
    try {
      const profileRows = await sql`select roles, is_admin from public.profiles where id = ${userId} limit 1`
      if (Array.isArray(profileRows) && profileRows[0]) {
        if (Array.isArray(profileRows[0].roles)) {
          roles = profileRows[0].roles.filter(r => ALL_USER_ROLES.includes(r))
        }
        // Support legacy is_admin field
        if (profileRows[0].is_admin === true && !roles.includes('admin')) {
          roles.push('admin')
        }
      }
    } catch { }

    res.json({ ok: true, userId, roles })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to get roles' })
  }
})

app.options('/api/admin/roles/:userId', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'GET,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type')
  res.status(204).end()
})

// Public: check if an email or current IP is banned
app.get('/api/banned/check', async (req, res) => {
  try {
    if (!sql) {
      res.json({ banned: false })
      return
    }
    const emailParam = (req.query.email || '').toString().trim()
    const ip = getClientIp(req)
    // Check IP ban first
    if (ip) {
      try {
        const rows = await sql`select 1 from public.banned_ips where ip_address = ${ip}::inet limit 1`
        if (Array.isArray(rows) && rows.length > 0) {
          res.json({ banned: true, source: 'ip' })
          return
        }
      } catch { }
    }
    if (emailParam) {
      try {
        const rows = await sql`
          select reason, banned_at from public.banned_accounts
          where lower(email) = ${emailParam.toLowerCase()}
          order by banned_at desc
          limit 1
        `
        if (Array.isArray(rows) && rows.length > 0) {
          const r = rows[0]
          res.json({ banned: true, source: 'email', reason: r.reason || null, bannedAt: r.banned_at || null })
          return
        }
      } catch { }
      
      // Also check threat_level in profiles for users with this email
      try {
        const profileRows = await sql`
          select p.threat_level 
          from public.profiles p
          join auth.users u on u.id = p.id
          where lower(u.email) = ${emailParam.toLowerCase()}
          and p.threat_level = 3
          limit 1
        `
        if (Array.isArray(profileRows) && profileRows.length > 0) {
          res.json({ banned: true, source: 'threat_level', reason: 'Your account has been banned from the platform.' })
          return
        }
      } catch { }
    }
    res.json({ banned: false })
  } catch (e) {
    res.status(500).json({ banned: false })
  }
})

// =============================================================================
// AUTHENTICATION RATE LIMITING (Brute Force Protection)
// =============================================================================

/**
 * Check if an IP is blocked due to too many auth attempts
 * GET /api/auth/check-rate-limit
 * 
 * SECURITY: Returns minimal information to prevent enumeration attacks.
 * Only reveals whether the IP is blocked, not timing details.
 */
app.get('/api/auth/check-rate-limit', (req, res) => {
  const ip = getClientIp(req) || 'unknown'
  const identifier = `ip:${ip}`
  const store = rateLimitStores.authAttempt
  const config = rateLimitConfig.authAttempt
  
  const now = Date.now()
  const history = store.get(identifier) || []
  const recent = history.filter((ts) => now - ts < config.windowMs)
  
  const isBlocked = recent.length >= config.maxAttempts
  
  // SECURITY: Only return blocked status - don't reveal timing or attempt counts
  // This prevents attackers from enumerating rate limit windows
  res.json({
    blocked: isBlocked
  })
})

/**
 * Record a FAILED authentication attempt (internal rate limiting)
 * POST /api/auth/record-attempt
 * 
 * SECURITY: This endpoint ONLY records failed attempts.
 * Rate limit clearing happens INTERNALLY when Supabase auth succeeds,
 * not via external API calls. This prevents bypass attacks.
 */
app.post('/api/auth/record-attempt', (req, res) => {
  const ip = getClientIp(req) || 'unknown'
  const identifier = `ip:${ip}`
  
  // SECURITY: Check if already blocked before recording
  const store = rateLimitStores.authAttempt
  const config = rateLimitConfig.authAttempt
  const now = Date.now()
  const history = store.get(identifier) || []
  const recent = history.filter((ts) => now - ts < config.windowMs)
  
  // If already blocked, don't record more - just return blocked status
  if (recent.length >= config.maxAttempts) {
    res.status(429).json({
      ok: false,
      blocked: true,
      error: 'Too many failed attempts. Please try again later.'
    })
    return
  }
  
  // Record the failed attempt
  recent.push(now)
  store.set(identifier, recent)
  
  const isBlocked = recent.length >= config.maxAttempts
  
  if (isBlocked) {
    console.log(`[auth-rate-limit] IP ${ip} blocked after ${config.maxAttempts} failed attempts`)
  }
  
  // SECURITY: Only return blocked status - no timing information
  res.json({
    ok: true,
    blocked: isBlocked
  })
})

/**
 * Clear rate limit after successful authentication (INTERNAL USE ONLY)
 * POST /api/auth/clear-rate-limit
 * 
 * SECURITY: Requires valid Supabase authentication token.
 * Only authenticated users can clear their IP's rate limit history.
 */
app.post('/api/auth/clear-rate-limit', async (req, res) => {
  try {
    // SECURITY: Verify the user is actually authenticated
    const user = await getUserFromRequest(req)
    if (!user?.id) {
      // Don't reveal whether rate limit exists - just return generic error
      res.status(401).json({ ok: false, error: 'Unauthorized' })
      return
    }
    
    // User is authenticated - clear the rate limit for their IP
    const ip = getClientIp(req) || 'unknown'
    const identifier = `ip:${ip}`
    
    rateLimitStores.authAttempt.delete(identifier)
    
    // Log for security monitoring
    console.log(`[auth-rate-limit] Rate limit cleared for IP ${ip} after successful auth by user ${user.id.slice(0, 8)}...`)
    
    res.json({ ok: true })
  } catch (err) {
    console.error('[auth-rate-limit] Error clearing rate limit:', err?.message)
    res.status(500).json({ ok: false, error: 'Internal error' })
  }
})

// =============================================================================
// reCAPTCHA Enterprise v3 verification endpoint
// Uses GOOGLE_API_KEY for authentication with Google Cloud
const GOOGLE_API_KEY = process.env.GOOGLE_API_KEY || ''
const RECAPTCHA_SITE_KEY = '6Leg5BgsAAAAAEh94kkCnfgS9vV-Na4Arws3yUtd'

app.post('/api/recaptcha/verify', async (req, res) => {
  try {
    const { token, action } = req.body || {}

    if (!token) {
      res.status(400).json({ success: false, error: 'Missing reCAPTCHA token' })
      return
    }

    if (!GOOGLE_API_KEY) {
      // If no API key configured, log warning and allow request
      // This enables development without reCAPTCHA verification
      console.warn('[recaptcha] No GOOGLE_API_KEY configured, skipping verification')
      res.json({ success: true, score: 1.0, warning: 'verification_skipped' })
      return
    }

    // Call Google reCAPTCHA Enterprise verification API
    // POST https://recaptchaenterprise.googleapis.com/v1/projects/PROJECT_ID/assessments?key=API_KEY
    const verifyUrl = `https://recaptchaenterprise.googleapis.com/v1/projects/aphylia/assessments?key=${GOOGLE_API_KEY}`

    const requestBody = {
      event: {
        token: token,
        expectedAction: action || 'submit',
        siteKey: RECAPTCHA_SITE_KEY
      }
    }

    const verifyResponse = await fetch(verifyUrl, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(requestBody)
    })

    const verifyData = await verifyResponse.json()

    if (!verifyResponse.ok) {
      console.error('[recaptcha] Verification API error:', verifyData)
      res.status(400).json({ success: false, error: 'Verification failed', details: verifyData.error?.message })
      return
    }

    // Check the token properties
    const tokenProperties = verifyData.tokenProperties
    const riskAnalysis = verifyData.riskAnalysis

    if (!tokenProperties?.valid) {
      console.warn('[recaptcha] Invalid token:', tokenProperties?.invalidReason)
      res.status(400).json({ success: false, error: 'Invalid token', reason: tokenProperties?.invalidReason })
      return
    }

    // Check if action matches (important for security)
    if (action && tokenProperties.action !== action) {
      console.warn('[recaptcha] Action mismatch:', { expected: action, got: tokenProperties.action })
      res.status(400).json({ success: false, error: 'Action mismatch' })
      return
    }

    // Get the risk score (0.0 = likely bot, 1.0 = likely human)
    const score = riskAnalysis?.score ?? 0.5

    // Threshold: scores below 0.3 are likely bots
    if (score < 0.3) {
      console.warn('[recaptcha] Low score, likely bot:', score)
      res.status(400).json({ success: false, error: 'Suspicious activity detected', score })
      return
    }

    console.log('[recaptcha] Verification success, score:', score)
    res.json({ success: true, score })
  } catch (e) {
    console.error('[recaptcha] Verification error:', e)
    // On error, we still allow the request but log the issue
    res.json({ success: true, score: 0.5, warning: 'verification_error' })
  }
})

// Admin: ban a user by email, record IPs, and attempt account deletion
app.post('/api/admin/ban', async (req, res) => {
  try {
    if (!sql) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    // Require admin with robust detection
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }
    const { email: rawEmail, reason: rawReason } = req.body || {}
    const emailParam = (rawEmail || '').toString().trim()
    const reason = (rawReason || '').toString().trim() || null
    if (!emailParam) {
      res.status(400).json({ error: 'Missing email' })
      return
    }
    const email = emailParam.toLowerCase()
    const userRows = await sql`select id, email from auth.users where lower(email) = ${email} limit 1`
    const userId = Array.isArray(userRows) && userRows[0] ? userRows[0].id : null
    // Gather distinct IPs used by this user
    let ips = []
    if (userId) {
      const ipRows = await sql.unsafe(`select distinct ip_address::text as ip from ${VISITS_TABLE_SQL_IDENT} where user_id = $1 and ip_address is not null`, [userId])
      ips = (ipRows || []).map(r => String(r.ip)).filter(Boolean)
    }
    // Best-effort admin identification from token
    const caller = await getUserFromRequest(req)
    let bannedBy = caller?.id || null

    // Insert ban records
    try {
      await sql`
        insert into public.banned_accounts (user_id, email, ip_addresses, reason, banned_by)
        values (${userId}, ${email}, ${ips}, ${reason}, ${bannedBy})
      `
    } catch { }
    // Insert per-IP rows (upsert to avoid duplicates)
    for (const ip of ips) {
      try {
        await sql`
          insert into public.banned_ips (ip_address, reason, banned_by, user_id, email)
          values (${ip}::inet, ${reason}, ${bannedBy}, ${userId}, ${email})
          on conflict (ip_address) do update set
            reason = coalesce(excluded.reason, public.banned_ips.reason),
            banned_by = coalesce(excluded.banned_by, public.banned_ips.banned_by),
            banned_at = excluded.banned_at,
            user_id = coalesce(excluded.user_id, public.banned_ips.user_id),
            email = coalesce(excluded.email, public.banned_ips.email)
        `
      } catch { }
    }

    // Delete profile row
    if (userId) {
      try { await sql`delete from public.profiles where id = ${userId}` } catch { }
      // Attempt to delete auth user as well; ignore failures
      try { await sql`delete from auth.users where id = ${userId}` } catch { }
    }

    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      const adminName = null
      await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${adminName}, 'ban_user', ${email}, ${sql.json({ userId, ips })})`
    } catch { }
    res.json({ ok: true, userId: userId || null, email, ipCount: ips.length, bannedAt: new Date().toISOString() })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to ban user' })
  }
})

// Admin: set user threat level (records bans and triggers ban email when level is 3)
app.post('/api/admin/threat-level', async (req, res) => {
  try {
    const adminUserId = await ensureAdmin(req, res)
    if (!adminUserId) return
    if (!sql) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    const { userId, threatLevel, reason } = req.body || {}
    const uid = typeof userId === 'string' ? userId.trim() : ''
    const level = Number.isFinite(Number(threatLevel)) ? Number(threatLevel) : NaN
    if (!uid || !Number.isInteger(level) || level < 0 || level > 3) {
      res.status(400).json({ error: 'Invalid userId or threatLevel' })
      return
    }

    let existingLevel = null
    let userEmail = null
    let userDisplayName = null
    let userLanguage = 'en'
    try {
      const rows = await sql`
        select p.threat_level, p.display_name, coalesce(p.language, 'en') as language, u.email
        from public.profiles p
        left join auth.users u on u.id = p.id
        where p.id = ${uid}
        limit 1
      `
      if (!rows || !rows.length) {
        res.status(404).json({ error: 'User not found' })
        return
      }
      existingLevel = rows[0].threat_level
      userEmail = rows[0].email || null
      userDisplayName = rows[0].display_name || rows[0].email || 'User'
      userLanguage = rows[0].language || 'en'
    } catch (lookupErr) {
      console.error('[threat-level] failed to load user', lookupErr)
      res.status(500).json({ error: 'Failed to load user' })
      return
    }

    try {
      await sql`update public.profiles set threat_level = ${level} where id = ${uid}`
    } catch (err) {
      console.error('[threat-level] failed to update level', err)
      res.status(500).json({ error: 'Failed to update threat level' })
      return
    }

    let bannedIps = []
    let bannedAt = null
    let bannedByName = null
    let emailResult = null

    if (level === 3) {
      try {
        const ipRows = await sql.unsafe(`select distinct ip_address::text as ip from ${VISITS_TABLE_SQL_IDENT} where user_id = $1 and ip_address is not null`, [uid])
        bannedIps = (ipRows || []).map(r => String(r.ip)).filter(Boolean)
      } catch { }

      try {
        const adminNameRows = await sql`select display_name from public.profiles where id = ${adminUserId} limit 1`
        bannedByName = adminNameRows?.[0]?.display_name || null
      } catch { }

      const normalizedEmail = userEmail ? userEmail.toLowerCase() : null
      try {
        const existingBan = await sql`
          select id from public.banned_accounts
          where (user_id = ${uid} or lower(email) = ${normalizedEmail || null})
          order by banned_at desc
          limit 1
        `
        if (existingBan && existingBan[0]) {
          const updateRows = await sql`
            update public.banned_accounts
            set banned_by = ${adminUserId},
                reason = coalesce(${reason || null}, reason),
                ip_addresses = ${sql.array(bannedIps, 'text')},
                banned_at = now()
            where id = ${existingBan[0].id}
            returning banned_at
          `
          bannedAt = updateRows?.[0]?.banned_at || null
        } else {
          const insertRows = await sql`
            insert into public.banned_accounts (user_id, email, ip_addresses, reason, banned_by)
            values (${uid}, ${normalizedEmail}, ${sql.array(bannedIps, 'text')}, ${reason || null}, ${adminUserId})
            returning banned_at
          `
          bannedAt = insertRows?.[0]?.banned_at || null
        }
      } catch (banErr) {
        console.warn('[threat-level] failed to persist banned_accounts record', banErr)
      }

      for (const ip of bannedIps) {
        try {
          await sql`
            insert into public.banned_ips (ip_address, reason, banned_by, user_id, email)
            values (${ip}::inet, ${reason || null}, ${adminUserId}, ${uid}, ${normalizedEmail})
            on conflict (ip_address) do update set
              reason = coalesce(excluded.reason, public.banned_ips.reason),
              banned_by = coalesce(excluded.banned_by, public.banned_ips.banned_by),
              banned_at = excluded.banned_at,
              user_id = coalesce(excluded.user_id, public.banned_ips.user_id),
              email = coalesce(excluded.email, public.banned_ips.email)
          `
        } catch (ipErr) {
          console.warn('[threat-level] failed to upsert banned_ip', ipErr)
        }
      }

      if (existingLevel !== 3 && normalizedEmail) {
        emailResult = await sendAutomaticEmail('BAN_USER', {
          userId: uid,
          userEmail: normalizedEmail,
          userDisplayName,
          userLanguage,
        })
      }
    }

    try {
      await sql`insert into public.admin_activity_logs (admin_id, action, target, detail) values (${adminUserId}, 'set_threat_level', ${uid}, ${sql.json({ previous: existingLevel, level, reason })})`
    } catch { }

    res.json({
      ok: true,
      threatLevel: level,
      previousLevel: existingLevel,
      bannedIps,
      bannedAt,
      bannedById: level === 3 ? adminUserId : null,
      bannedByName: level === 3 ? bannedByName : null,
      email: emailResult,
    })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to update threat level' })
  }
})

// Helper: load plants via Supabase anon client when SQL is unavailable
async function loadPlantsViaSupabase() {
  if (!supabaseServer) return null
  try {
    const { data, error } = await supabaseServer
      .from('plants')
      .select('*')
      .order('name', { ascending: true })
    if (error) return null
    return (Array.isArray(data) ? data : []).map((r) => {
      const photos = Array.isArray(r.photos) ? r.photos : undefined
      return {
        id: r.id,
        name: r.name,
        scientificName: r.scientific_name,
        colors: r.colors ?? [],
        seasons: r.seasons ?? [],
        rarity: r.rarity,
        meaning: r.meaning ?? '',
        description: r.description ?? '',
        photos,
        image: pickPrimaryPhotoUrlFromArray(photos, r.image_url ?? ''),
        care: {
          sunlight: r.level_sun || null,
          water: Array.isArray(r.watering_type) ? r.watering_type.join(', ') : null,
          soil: Array.isArray(r.soil) ? r.soil.join(', ') : null,
          difficulty: r.maintenance_level || null,
        },
        seedsAvailable: r.seeds_available === true,
      }
    })
  } catch {
    return null
  }
}

app.post('/api/contact', async (req, res) => {
  try {
    const body = req.body || {}
    const name = typeof body.name === 'string' ? body.name.trim().slice(0, 200) : ''
    const email = typeof body.email === 'string' ? body.email.trim().toLowerCase() : ''
    const subject = typeof body.subject === 'string' ? body.subject.trim().slice(0, 180) : ''
    const message = typeof body.message === 'string' ? body.message.trim().slice(0, 5000) : ''
    const audienceInput =
      typeof body.audience === 'string' ? body.audience :
        (typeof body.channel === 'string' ? body.channel : '')
    const audience = normalizeContactAudience(audienceInput)

    if (!email || !/^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(email)) {
      res.status(400).json({ error: 'A valid email address is required.' })
      return
    }
    if (!message) {
      res.status(400).json({ error: 'Message is required.' })
      return
    }

    const ip = getClientIp(req) || 'unknown'
    if (isContactRateLimited(ip)) {
      res.status(429).json({ error: 'Too many messages in a short period. Please try again later.' })
      return
    }

    await dispatchSupportEmail({ name, email, subject, message, audience })
    res.json({ ok: true, audience })
  } catch (error) {
    console.error('[contact] failed to send support email:', error)
    res.status(500).json({ error: 'Failed to send message. Please try again later.' })
  }
})

// DeepL Translation API endpoint
app.post('/api/translate', async (req, res) => {
  try {
    // Rate limit (admins are exempt via checkRateLimit)
    let user = null
    try { user = await getUserFromRequest(req) } catch { }
    if (await checkRateLimit('translate', req, res, user)) {
      return
    }

    const { text, source_lang, target_lang } = req.body

    if (!text || typeof text !== 'string') {
      return res.status(400).json({ error: 'Missing or invalid text field' })
    }

    if (!source_lang || !target_lang) {
      return res.status(400).json({ error: 'Missing source_lang or target_lang' })
    }

    // Skip translation if source and target are the same
    if (source_lang.toUpperCase() === target_lang.toUpperCase()) {
      return res.json({ translatedText: text })
    }

    // Get DeepL API key from environment
    const deeplApiKey = process.env.DEEPL_API_KEY
    if (!deeplApiKey) {
      console.error('[translate] DeepL API key not configured')
      return res.status(500).json({ error: 'Translation service not configured' })
    }

    // Use DeepL API (Pro: https://api.deepl.com)
    const deeplUrl = process.env.DEEPL_API_URL || 'https://api.deepl.com/v2/translate'

    const response = await fetch(deeplUrl, {
      method: 'POST',
      headers: {
        'Authorization': `DeepL-Auth-Key ${deeplApiKey}`,
        'Content-Type': 'application/x-www-form-urlencoded',
      },
      body: new URLSearchParams({
        text: text,
        source_lang: source_lang.toUpperCase(),
        target_lang: target_lang.toUpperCase(),
      }),
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('[translate] DeepL API error:', response.status, errorText)
      return res.status(response.status).json({ error: 'Translation failed: ' + (errorText || response.statusText) })
    }

    const data = await response.json()
    const translatedText = data.translations?.[0]?.text || text

    res.json({ translatedText })
  } catch (error) {
    console.error('[translate] Translation error:', error)
    res.status(500).json({ error: 'Translation service error: ' + (error?.message || 'Unknown error') })
  }
})

// DeepL Batch Translation API endpoint
// Accepts multiple texts and translates them in a single DeepL API call
// This dramatically reduces the number of HTTP round-trips for bulk operations
app.post('/api/translate-batch', async (req, res) => {
  try {
    // Check if user is admin - batch endpoint is admin-only with higher rate limits
    let user = null
    try { user = await getUserFromRequest(req) } catch { }
    
    const admin = user?.id ? await isAdminUserId(user.id) : false
    
    if (!admin) {
      return res.status(403).json({ error: 'Admin privileges required for batch translation' })
    }
    
    // Rate limit (admins are exempt via checkRateLimit)
    if (await checkRateLimit('translate', req, res, user)) {
      return
    }

    const { texts, source_lang, target_lang } = req.body

    if (!Array.isArray(texts) || texts.length === 0) {
      return res.status(400).json({ error: 'Missing or invalid texts array' })
    }

    if (texts.length > 50) {
      return res.status(400).json({ error: 'Maximum 50 texts per batch request' })
    }

    if (!source_lang || !target_lang) {
      return res.status(400).json({ error: 'Missing source_lang or target_lang' })
    }

    // Skip translation if source and target are the same
    if (source_lang.toUpperCase() === target_lang.toUpperCase()) {
      return res.json({ translations: texts })
    }

    // Get DeepL API key from environment
    const deeplApiKey = process.env.DEEPL_API_KEY
    if (!deeplApiKey) {
      console.error('[translate-batch] DeepL API key not configured')
      return res.status(500).json({ error: 'Translation service not configured' })
    }

    // Use DeepL API with multiple text parameters
    const deeplUrl = process.env.DEEPL_API_URL || 'https://api.deepl.com/v2/translate'

    // Build URL-encoded body with multiple text parameters
    const params = new URLSearchParams()
    for (const text of texts) {
      params.append('text', typeof text === 'string' ? text : String(text || ''))
    }
    params.append('source_lang', source_lang.toUpperCase())
    params.append('target_lang', target_lang.toUpperCase())

    const response = await fetch(deeplUrl, {
      method: 'POST',
      headers: {
        'Authorization': `DeepL-Auth-Key ${deeplApiKey}`,
        'Content-Type': 'application/x-www-form-urlencoded',
      },
      body: params,
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('[translate-batch] DeepL API error:', response.status, errorText)
      return res.status(response.status).json({ error: 'Batch translation failed: ' + (errorText || response.statusText) })
    }

    const data = await response.json()
    const translations = (data.translations || []).map((t) => t?.text || '')

    // Ensure we return same number of results as inputs
    while (translations.length < texts.length) {
      translations.push(texts[translations.length] || '')
    }

    res.json({ translations })
  } catch (error) {
    console.error('[translate-batch] Translation error:', error)
    res.status(500).json({ error: 'Batch translation service error: ' + (error?.message || 'Unknown error') })
  }
})

// DeepL Language Detection API endpoint
// Uses DeepL's translation API with auto-detect (omitting source_lang)
app.post('/api/detect-language', async (req, res) => {
  try {
    // Rate limit (admins are exempt via checkRateLimit)
    let user = null
    try { user = await getUserFromRequest(req) } catch { }
    if (await checkRateLimit('translate', req, res, user)) {
      return
    }

    const { text } = req.body

    if (!text || typeof text !== 'string') {
      return res.status(400).json({ error: 'Missing or invalid text field' })
    }

    // Get DeepL API key from environment
    const deeplApiKey = process.env.DEEPL_API_KEY
    if (!deeplApiKey) {
      console.error('[detect-language] DeepL API key not configured')
      return res.status(500).json({ error: 'Language detection service not configured' })
    }

    // Use DeepL API (Pro: https://api.deepl.com)
    const deeplUrl = process.env.DEEPL_API_URL || 'https://api.deepl.com/v2/translate'

    // DeepL detects source language when source_lang is omitted
    // We translate to EN as a dummy target just to get the detection
    const response = await fetch(deeplUrl, {
      method: 'POST',
      headers: {
        'Authorization': `DeepL-Auth-Key ${deeplApiKey}`,
        'Content-Type': 'application/x-www-form-urlencoded',
      },
      body: new URLSearchParams({
        text: text.substring(0, 500), // Use first 500 chars for detection efficiency
        target_lang: 'EN', // Dummy target, we just want the detection
      }),
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('[detect-language] DeepL API error:', response.status, errorText)
      return res.status(response.status).json({ error: 'Language detection failed: ' + (errorText || response.statusText) })
    }

    const data = await response.json()
    const detectedLanguage = data.translations?.[0]?.detected_source_language?.toLowerCase() || null

    res.json({ detectedLanguage })
  } catch (error) {
    console.error('[detect-language] Detection error:', error)
    res.status(500).json({ error: 'Language detection service error: ' + (error?.message || 'Unknown error') })
  }
})

// DeepL Translation with Language Detection API endpoint
// Translates text AND returns the detected source language
app.post('/api/translate-detect', async (req, res) => {
  try {
    // Rate limit (admins are exempt via checkRateLimit)
    let user = null
    try { user = await getUserFromRequest(req) } catch { }
    if (await checkRateLimit('translate', req, res, user)) {
      return
    }

    const { text, target_lang } = req.body

    if (!text || typeof text !== 'string') {
      return res.status(400).json({ error: 'Missing or invalid text field' })
    }

    if (!target_lang) {
      return res.status(400).json({ error: 'Missing target_lang' })
    }

    // Get DeepL API key from environment
    const deeplApiKey = process.env.DEEPL_API_KEY
    if (!deeplApiKey) {
      console.error('[translate-detect] DeepL API key not configured')
      return res.status(500).json({ error: 'Translation service not configured' })
    }

    // Use DeepL API (Pro: https://api.deepl.com)
    const deeplUrl = process.env.DEEPL_API_URL || 'https://api.deepl.com/v2/translate'

    // Omit source_lang to let DeepL auto-detect
    const response = await fetch(deeplUrl, {
      method: 'POST',
      headers: {
        'Authorization': `DeepL-Auth-Key ${deeplApiKey}`,
        'Content-Type': 'application/x-www-form-urlencoded',
      },
      body: new URLSearchParams({
        text: text,
        target_lang: target_lang.toUpperCase(),
      }),
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('[translate-detect] DeepL API error:', response.status, errorText)
      return res.status(response.status).json({ error: 'Translation failed: ' + (errorText || response.statusText) })
    }

    const data = await response.json()
    const translatedText = data.translations?.[0]?.text || text
    const detectedLanguage = data.translations?.[0]?.detected_source_language?.toLowerCase() || null

    // If detected language equals target language, return original text
    if (detectedLanguage === target_lang.toLowerCase()) {
      return res.json({ translatedText: text, detectedLanguage, skipped: true })
    }

    res.json({ translatedText, detectedLanguage })
  } catch (error) {
    console.error('[translate-detect] Translation error:', error)
    res.status(500).json({ error: 'Translation service error: ' + (error?.message || 'Unknown error') })
  }
})

app.get('/api/plants', async (_req, res) => {
  try {
    const setPlantsCache = () => {
      if (!res.getHeader('Cache-Control')) {
        res.setHeader('Cache-Control', 'public, max-age=60, stale-while-revalidate=300')
      }
    }
    if (sql) {
      try {
        const rows = await sql`select * from plants order by name asc`
        const mapped = rows.map(r => {
          const photos = Array.isArray(r.photos) ? r.photos : undefined
          return {
            id: r.id,
            name: r.name,
            scientificName: r.scientific_name,
            colors: r.colors ?? [],
            seasons: r.seasons ?? [],
            rarity: r.rarity,
            meaning: r.meaning ?? '',
            description: r.description ?? '',
            photos,
            image: pickPrimaryPhotoUrlFromArray(photos, r.image_url ?? ''),
            care: {
              sunlight: r.level_sun || null,
              water: Array.isArray(r.watering_type) ? r.watering_type.join(', ') : null,
              soil: Array.isArray(r.soil) ? r.soil.join(', ') : null,
              difficulty: r.maintenance_level || null,
            },
            seedsAvailable: r.seeds_available === true,
          }
        })
        setPlantsCache()
        res.json(mapped)
        return
      } catch (e) {
        // Fall through to Supabase fallback on SQL query failure
      }
    }
    const fallback = await loadPlantsViaSupabase()
    if (fallback) {
      setPlantsCache()
      res.json(fallback)
      return
    }
    res.status(500).json({ error: 'Database not configured' })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Query failed' })
  }
})

// In-memory token store for one-time backup downloads
const backupTokenStore = new Map()

// Admin: create a gzip'ed pg_dump and return a one-time download token
app.post('/api/admin/backup-db', async (req, res) => {
  try {
    const uid = "public"
    if (!uid) return

    if (!connectionString) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }

    const backupDir = path.resolve(__dirname, 'tmp_backups')
    await fs.mkdir(backupDir, { recursive: true })

    const now = new Date()
    const pad = (n) => String(n).padStart(2, '0')
    const ts = `${now.getUTCFullYear()}-${pad(now.getUTCMonth() + 1)}-${pad(now.getUTCDate())}_${pad(now.getUTCHours())}-${pad(now.getUTCMinutes())}-${pad(now.getUTCSeconds())}Z`
    const filename = `plantswipe_backup_${ts}.sql.gz`
    const destPath = path.join(backupDir, filename)

    // Spawn pg_dump and gzip the output to a file
    let stderrBuf = ''
    const dump = spawnChild('pg_dump', ['--dbname', connectionString, '--no-owner', '--no-acl'], {
      env: { ...process.env },
      stdio: ['ignore', 'pipe', 'pipe'],
    })
    dump.on('error', async () => {
      try { await fs.unlink(destPath) } catch { }
    })
    dump.stderr.on('data', (d) => { stderrBuf += d.toString() })

    const gzip = zlib.createGzip({ level: 9 })
    const out = fsSync.createWriteStream(destPath)

    const pipelinePromise = new Promise((resolve, reject) => {
      streamPipeline(dump.stdout, gzip, out, (err) => {
        if (err) return reject(err)
        resolve(null)
      })
    })
    const exitPromise = new Promise((resolve) => {
      dump.on('close', (code) => resolve(code))
    })

    const [, code] = await Promise.all([pipelinePromise, exitPromise]).catch(async (e) => {
      try { await fs.unlink(destPath) } catch { }
      throw e
    })
    if (code !== 0) {
      try { await fs.unlink(destPath) } catch { }
      throw new Error(`pg_dump exit code ${code}: ${stderrBuf || 'unknown error'}`)
    }

    // Stat the file
    const stat = await fs.stat(destPath)
    const token = crypto.randomBytes(24).toString('hex')
    backupTokenStore.set(token, { path: destPath, filename, size: stat.size, createdAt: Date.now() })

    // Expire tokens after 15 minutes
    const expireMs = 15 * 60 * 1000
    for (const [t, info] of backupTokenStore.entries()) {
      if ((Date.now() - info.createdAt) > expireMs) {
        backupTokenStore.delete(t)
        try { await fs.unlink(info.path) } catch { }
      }
    }

    res.json({ ok: true, token, filename, size: stat.size })
  } catch (e) {
    const msg = e?.message || 'Backup failed'
    // Surface friendly message if pg_dump missing
    if (/ENOENT/.test(msg) || /pg_dump\s+not\s+found/i.test(msg)) {
      res.status(500).json({ error: 'pg_dump not available on server. Install PostgreSQL client tools.' })
      return
    }
    res.status(500).json({ error: msg })
  }
})

// Admin: download a previously created backup (one-time token + admin auth)
app.get('/api/admin/download-backup', async (req, res) => {
  const uid = "public"
  if (!uid) return

  const token = (req.query.token || '').toString().trim()
  if (!token) {
    res.status(400).json({ error: 'Missing token' })
    return
  }

  const info = backupTokenStore.get(token)
  if (!info) {
    res.status(404).json({ error: 'Invalid or expired token' })
    return
  }

  // Enforce 15-minute token expiry
  const maxAge = 15 * 60 * 1000
  if ((Date.now() - info.createdAt) > maxAge) {
    backupTokenStore.delete(token)
    try { await fs.unlink(info.path) } catch { }
    res.status(410).json({ error: 'Token expired' })
    return
  }

  res.setHeader('Content-Type', 'application/gzip')
  res.setHeader('Content-Disposition', `attachment; filename="${info.filename}"`)

  const read = fsSync.createReadStream(info.path)
  read.on('error', () => {
    res.status(500).end()
  })
  read.pipe(res)

  const cleanup = async () => {
    backupTokenStore.delete(token)
    try { await fs.unlink(info.path) } catch { }
  }
  res.on('finish', cleanup)
  res.on('close', cleanup)
})

// Admin: refresh website by invoking scripts/refresh-plant-swipe.sh from repo root
async function handlePullCode(req, res) {
  try {
    const uid = "public"
    if (!uid) return

    const branch = (req.query.branch || '').toString().trim() || undefined
    const repoRoot = await getRepoRoot()
    const scriptPath = path.resolve(repoRoot, 'scripts', 'refresh-plant-swipe.sh')

    // Verify the refresh script exists
    try {
      await fs.access(scriptPath)
    } catch {
      res.status(500).json({ ok: false, error: `refresh script not found at ${scriptPath}` })
      return
    }
    // Ensure it is executable (best-effort)
    try { await fs.chmod(scriptPath, 0o755) } catch { }

    // Pre-validate requested branch to fail fast on typos or deleted branches
    if (branch) {
      try {
        const gitBase = `git -c "safe.directory=${repoRoot}" -C "${repoRoot}"`
        await exec(`${gitBase} remote update --prune`, { timeout: 30000 })
        const [{ stdout: remoteOut }, { stdout: localOut }] = await Promise.all([
          exec(`${gitBase} for-each-ref --format='%(refname:short)' refs/remotes/origin`, { timeout: 30000 }),
          exec(`${gitBase} for-each-ref --format='%(refname:short)' refs/heads`, { timeout: 30000 }),
        ])
        const normalize = (s) => s.trim().replace(/^origin\//, '')
        const allowed = new Set(
          [...(remoteOut || '').split('\n'), ...(localOut || '').split('\n')]
            .map(x => x.trim())
            .filter(Boolean)
            .map(normalize)
            .filter(name => name && name !== 'HEAD' && name !== 'origin' && !name.includes('->'))
        )
        if (!allowed.has(branch)) {
          res.status(400).json({ ok: false, error: `Unknown branch: ${branch}` })
          return
        }
      } catch { }
    }

    // Execute the script from repository root so it updates current branch and builds
    // Run detached so we can return a response before the service restarts
    const execEnv = { ...process.env, CI: process.env.CI || 'true', SUDO_ASKPASS: process.env.SUDO_ASKPASS || '', PLANTSWIPE_REPO_DIR: repoRoot }
    // Do not restart services inside the script when invoked from the API.
    // This allows us to finish the SSE cleanly and control restarts from the UI.
    execEnv.SKIP_SERVICE_RESTARTS = 'true'
    execEnv.SKIP_ENV_SYNC = 'true'
    if (branch) {
      // Pass target branch to refresh script
      execEnv.PLANTSWIPE_TARGET_BRANCH = branch
    }
    const child = spawnChild(scriptPath, {
      cwd: repoRoot,
      detached: true,
      stdio: 'ignore',
      env: execEnv,
      shell: false,
    })
    try { child.unref() } catch { }

    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      let adminName = null
      if (sql && adminId) {
        try {
          const rows = await sql`select coalesce(display_name, '') as name from public.profiles where id = ${adminId} limit 1`
          adminName = (rows?.[0]?.name || '').trim() || null
        } catch { }
      }
      if (!adminName && supabaseUrlEnv && supabaseAnonKey && adminId) {
        try {
          const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
          const bearer = getBearerTokenFromRequest(req)
          if (bearer) headers['Authorization'] = `Bearer ${bearer}`
          const url = `${supabaseUrlEnv}/rest/v1/profiles?id=eq.${encodeURIComponent(adminId)}&select=display_name&limit=1`
          const r = await fetch(url, { headers })
          if (r.ok) {
            const arr = await r.json().catch(() => [])
            adminName = Array.isArray(arr) && arr[0] ? (arr[0].display_name || null) : null
          }
        } catch { }
      }
      let ok = false
      if (sql) {
        try { await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${adminName}, 'pull_code', ${branch || null}, ${sql.json({ source: 'api' })})`; ok = true } catch { }
      }
      if (!ok) {
        try { await insertAdminActivityViaRest(req, { admin_id: adminId, admin_name: adminName, action: 'pull_code', target: branch || null, detail: { source: 'api' } }) } catch { }
      }
    } catch { }
    res.json({ ok: true, branch, started: true })
  } catch (e) {
    res.status(500).json({ ok: false, error: e?.message || 'refresh failed' })
  }
}

app.post('/api/admin/pull-code', handlePullCode)
app.get('/api/admin/pull-code', handlePullCode)
app.options('/api/admin/pull-code', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'GET,POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type')
  res.status(204).end()
})

// Admin: stream pull/build logs via Server-Sent Events (SSE)
app.get('/api/admin/pull-code/stream', async (req, res) => {
  try {
    const uid = "public"
    if (!uid) return

    // Require admin (same policy as other admin endpoints)
    const isAdmin = await isAdminFromRequest(req)
    if (!isAdmin) {
      res.status(403).json({ error: 'Admin privileges required' })
      return
    }

    // SSE headers
    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8')
    res.setHeader('Cache-Control', 'no-cache, no-transform')
    res.setHeader('Connection', 'keep-alive')
    res.setHeader('X-Accel-Buffering', 'no') // for nginx
    res.flushHeaders?.()

    const send = (event, data) => {
      try {
        if (event) res.write(`event: ${event}\n`)
        const payload = typeof data === 'string' ? data : JSON.stringify(data)
        // Split by lines to avoid giant frames
        const lines = String(payload).split(/\r?\n/) || []
        for (const line of lines) res.write(`data: ${line}\n`)
        res.write('\n')
      } catch { }
    }

    send('open', { ok: true, message: 'Starting refreshâ€¦' })

    const repoRoot = await getRepoRoot()
    const branch = (req.query.branch || '').toString().trim() || ''

    // Log that a streamed pull/build has been initiated
    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      let adminName = null
      if (sql && adminId) {
        try {
          const rows = await sql`select coalesce(display_name, '') as name from public.profiles where id = ${adminId} limit 1`
          adminName = (rows?.[0]?.name || '').trim() || null
        } catch { }
      }
      if (!adminName && supabaseUrlEnv && supabaseAnonKey && adminId) {
        try {
          const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
          const bearer = getBearerTokenFromRequest(req)
          if (bearer) headers['Authorization'] = `Bearer ${bearer}`
          const url = `${supabaseUrlEnv}/rest/v1/profiles?id=eq.${encodeURIComponent(adminId)}&select=display_name&limit=1`
          const r = await fetch(url, { headers })
          if (r.ok) {
            const arr = await r.json().catch(() => [])
            adminName = Array.isArray(arr) && arr[0] ? (arr[0].display_name || null) : null
          }
        } catch { }
      }
      let ok = false
      if (sql) {
        try { await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${adminName}, 'pull_code', ${branch || null}, ${sql.json({ source: 'stream' })})`; ok = true } catch { }
      }
      if (!ok) {
        try { await insertAdminActivityViaRest(req, { admin_id: adminId, admin_name: adminName, action: 'pull_code', target: branch || null, detail: { source: 'stream' } }) } catch { }
      }
    } catch { }
    const scriptPath = path.resolve(repoRoot, 'scripts', 'refresh-plant-swipe.sh')
    try { await fs.access(scriptPath) } catch {
      send('error', { error: `refresh script not found at ${scriptPath}` })
      res.end()
      return
    }
    try { await fs.chmod(scriptPath, 0o755) } catch { }

    // Allow the script to perform restarts even if it drops the stream briefly
    const childEnv = { ...process.env, CI: process.env.CI || 'true', PLANTSWIPE_REPO_DIR: repoRoot }
    // Avoid restarting services from the script while streaming logs (keeps SSE alive)
    childEnv.SKIP_SERVICE_RESTARTS = 'true'
    if (branch) {
      // Pre-validate requested branch and surface a clear error on failure
      try {
        const gitBase = `git -c "safe.directory=${repoRoot}" -C "${repoRoot}"`
        await exec(`${gitBase} remote update --prune`, { timeout: 30000 })
        const [{ stdout: remoteOut }, { stdout: localOut }] = await Promise.all([
          exec(`${gitBase} for-each-ref --format='%(refname:short)' refs/remotes/origin`, { timeout: 30000 }),
          exec(`${gitBase} for-each-ref --format='%(refname:short)' refs/heads`, { timeout: 30000 }),
        ])
        const normalize = (s) => s.trim().replace(/^origin\//, '')
        const allowed = new Set(
          [...(remoteOut || '').split('\n'), ...(localOut || '').split('\n')]
            .map(x => x.trim())
            .filter(Boolean)
            .map(normalize)
            .filter(name => name && name !== 'HEAD' && name !== 'origin' && !name.includes('->'))
        )
        if (!allowed.has(branch)) {
          send('error', { error: `Unknown branch: ${branch}` })
          send('done', { ok: false, code: 1 })
          res.end()
          return
        }
      } catch { }
      childEnv.PLANTSWIPE_TARGET_BRANCH = branch
      send('log', `[pull] Target branch requested: ${branch}`)
    }
    const child = spawnChild(scriptPath, [], {
      cwd: repoRoot,
      env: childEnv,
      shell: false,
    })

    // Heartbeat to keep the connection alive behind proxies
    const heartbeatId = setInterval(() => { try { res.write(': ping\n\n') } catch { } }, 15000)
    let clientDisconnected = false
    let streamClosedGracefully = false
    let autoRestartScheduled = false

    // Stream stdout/stderr
    child.stdout?.on('data', (buf) => {
      const text = buf.toString()
      send('log', text)
    })
    child.stderr?.on('data', (buf) => {
      const text = buf.toString()
      send('log', text)
    })
    child.on('error', (err) => {
      send('error', { error: err?.message || 'spawn failed' })
    })
    child.on('close', (code) => {
      const ok = code === 0
      if (!streamClosedGracefully) {
        if (ok) {
          send('done', { ok: true, code })
        } else {
          send('done', { ok: false, code })
        }
      }
      streamClosedGracefully = true
      try { clearInterval(heartbeatId) } catch { }
      try { res.end() } catch { }
      if (ok && clientDisconnected && !autoRestartScheduled) {
        autoRestartScheduled = true
        console.log('[pull-code] Build finished after client disconnect; scheduling service restart.')
        scheduleRestartAllServices('pull_code_stream_auto')
      }
    })

    req.on('close', () => {
      if (streamClosedGracefully) return
      clientDisconnected = true
      try { clearInterval(heartbeatId) } catch { }
      console.warn('[pull-code] SSE client disconnected early; continuing refresh in background.')
    })
  } catch (e) {
    try { res.status(500).json({ error: e?.message || 'stream failed' }) } catch { }
  }
})

// Admin: list remote branches and current branch
app.get('/api/admin/branches', async (req, res) => {
  try {
    // Set cache headers to prevent browser caching
    res.set({
      'Cache-Control': 'no-cache, no-store, must-revalidate',
      'Pragma': 'no-cache',
      'Expires': '0'
    })

    const uid = "public"
    if (!uid) return

    // Always operate from the repository root and mark it safe for this process
    const repoRoot = await getRepoRoot()
    const gitBase = `git -c "safe.directory=${repoRoot}" -C "${repoRoot}"`
    // Fetch remote branches with prune to remove deleted branches - this is the key operation for refreshing branches
    // Using git fetch --prune origin is more reliable than git remote update --prune
    let pruneWarning = null
    try {
      await exec(`${gitBase} fetch --prune origin`, { timeout: 20000 })
      console.log('[branches] Successfully fetched and pruned remote branches from origin')
    } catch (e) {
      console.warn('[branches] git fetch --prune origin failed:', e?.message || e)
      // Fallback: try git remote update --prune as secondary option
      try {
        await exec(`${gitBase} remote update --prune`, { timeout: 15000 })
        console.log('[branches] Fallback: git remote update --prune succeeded')
      } catch (e2) {
        console.warn('[branches] Fallback git remote update --prune also failed:', e2?.message || e2)
        pruneWarning = 'Could not sync with remote - showing cached branches'
      }
    }
    // Extra safety: explicitly prune any stale remote-tracking refs that might remain
    try {
      await exec(`${gitBase} remote prune origin`, { timeout: 5000 })
    } catch (e) {
      // Non-fatal: fetch --prune should have already handled this
      console.warn('[branches] Extra prune command failed (non-fatal):', e?.message || e)
    }
    // Prefer for-each-ref over branch -r to avoid pointer lines and formatting quirks
    const { stdout: branchesStdout } = await exec(`${gitBase} for-each-ref --format='%(refname:short)' refs/remotes/origin`, { timeout: 5000 })
    let branches = branchesStdout
      .split('\n')
      .map(s => s.trim())
      .filter(Boolean)
      .map(name => name.replace(/^origin\//, ''))
      // Exclude HEAD pointer, the remote namespace itself ("origin"), and any symbolic ref lines
      .filter(name => name !== 'HEAD' && name !== 'origin' && !name.includes('->'))
      .sort((a, b) => a.localeCompare(b))

    // Fallback to local branches if remote list is empty (e.g., detached or offline)
    if (branches.length === 0) {
      const { stdout: localStdout } = await exec(`${gitBase} for-each-ref --format='%(refname:short)' refs/heads`, { timeout: 3000 })
      branches = localStdout
        .split('\n')
        .map(s => s.trim())
        .filter(Boolean)
        .sort((a, b) => a.localeCompare(b))
    }

    const { stdout: currentStdout } = await exec(`${gitBase} rev-parse --abbrev-ref HEAD`, { timeout: 3000 })
    const current = currentStdout.trim()

    // Read the last update time from TIME file if it exists
    let lastUpdateTime = null
    try {
      const timeFile = path.join(repoRoot, 'TIME')
      const timeContent = await fs.readFile(timeFile, 'utf-8')
      lastUpdateTime = timeContent.trim() || null
    } catch {
      // TIME file doesn't exist or can't be read, which is fine
    }

    try {
      const caller = await getUserFromRequest(req)
      const adminId = caller?.id || null
      const adminName = null
      if (sql) await sql`insert into public.admin_activity_logs (admin_id, admin_name, action, target, detail) values (${adminId}, ${adminName}, 'list_branches', ${current || null}, ${sql.json({ count: branches.length })})`
    } catch { }
    // Include warning in response if remote sync failed (frontend can optionally display this)
    const response = { branches, current, lastUpdateTime }
    if (pruneWarning) response.warning = pruneWarning
    res.json(response)
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to list branches' })
  }
})

app.options('/api/admin/branches', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'GET,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type')
  res.status(204).end()
})

// Public: Track a page visit (client-initiated for SPA navigations)
// This endpoint is designed to be tolerant and never block user flows
app.post('/api/track-visit', async (req, res) => {
  try {
    const sessionId = getOrSetSessionId(req, res)
    const { pagePath, referrer: bodyReferrer, userId, extra, pageTitle, language } = req.body || {}
    const ipAddress = getClientIp(req)
    let geo = { geo_country: null, geo_region: null, geo_city: null }
    try {
      geo = await withTimeout(resolveGeo(req, ipAddress), 800, 'GEO_TIMEOUT')
    } catch { }
    const userAgent = req.get('user-agent') || ''
    const tokenUserId = await getUserIdFromRequest(req)
    const effectiveUserId = tokenUserId || (typeof userId === 'string' ? userId : null)

    // Be tolerant: if pagePath is missing, log and still respond with 204
    // Tracking should never block or break user flows
    if (typeof pagePath !== 'string' || pagePath.length === 0) {
      console.warn('[track-visit] Missing pagePath, skipping visit recording')
      res.status(204).end()
      return
    }

    const acceptLanguage = (req.get('accept-language') || '').split(',')[0] || null
    const lang = language || acceptLanguage
    const referrer = (typeof bodyReferrer === 'string' && bodyReferrer.length > 0) ? bodyReferrer : (req.get('referer') || req.get('referrer') || '')
    // Do not block the response on DB write; best-effort in background
    insertWebVisit({ sessionId, userId: effectiveUserId, pagePath, referrer, userAgent, ipAddress, geo, extra, pageTitle, language: lang }, req).catch((err) => {
      console.warn('[track-visit] Failed to insert visit:', err?.message || 'unknown error')
    })
    res.status(204).end()
  } catch (e) {
    // Even on errors, respond with 204 to avoid blocking user flows
    console.error('[track-visit] Unexpected error:', e?.message || e)
    res.status(204).end()
  }
})

app.options('/api/account/delete', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type')
  res.status(204).end()
})

app.post('/api/account/delete', async (req, res) => {
  try {
    if (!supabaseServiceClient) {
      res.status(503).json({ error: 'Account deletion is not configured on this server' })
      return
    }
    const user = await getUserFromRequest(req)
    if (!user?.id) {
      res.status(401).json({ error: 'Unauthorized' })
      return
    }
    const userId = user.id

    let deletedGardens = 0
    let deletedGardenIds = []
    let deletedCoverImages = 0
    let promotedMembers = 0
    let leftGardens = 0
    try {
      // Get all gardens where the user is a member (any role)
      const { data: userMemberships, error: memberErr } = await supabaseServiceClient
        .from('garden_members')
        .select('garden_id, role')
        .eq('user_id', userId)
      if (memberErr) throw memberErr

      const gardenIds = Array.from(
        new Set(
          (userMemberships || [])
            .map((row) => row?.garden_id)
            .filter((gid) => typeof gid === 'string' && gid.length > 0),
        ),
      )

      for (const gardenId of gardenIds) {
        const userRole = (userMemberships || []).find((m) => m.garden_id === gardenId)?.role

        // Get all members of this garden
        const { data: allMembers } = await supabaseServiceClient
          .from('garden_members')
          .select('user_id, role')
          .eq('garden_id', gardenId)

        const otherMembers = (allMembers || []).filter((m) => m.user_id !== userId)
        const otherOwners = otherMembers.filter((m) => m.role === 'owner')

        if (userRole === 'owner' && otherOwners.length === 0) {
          // User is the only owner
          if (otherMembers.length > 0) {
            // There are other members - promote one to owner and remove user
            const newOwner = otherMembers[0]
            const { error: promoteErr } = await supabaseServiceClient
              .from('garden_members')
              .update({ role: 'owner' })
              .eq('garden_id', gardenId)
              .eq('user_id', newOwner.user_id)
            if (promoteErr) {
              console.warn('[account-delete] Failed to promote member', gardenId, promoteErr?.message)
            } else {
              promotedMembers++
            }
            // Remove the user from the garden
            const { error: removeErr } = await supabaseServiceClient
              .from('garden_members')
              .delete()
              .eq('garden_id', gardenId)
              .eq('user_id', userId)
            if (removeErr) {
              console.warn('[account-delete] Failed to remove user from garden', gardenId, removeErr?.message)
            } else {
              leftGardens++
            }
          } else {
            // No other members - delete the garden entirely
            // First get the cover image URL
            const { data: gardenRow } = await supabaseServiceClient
              .from('gardens')
              .select('cover_image_url')
              .eq('id', gardenId)
              .maybeSingle()
            const coverUrl = gardenRow?.cover_image_url || null

            // Delete the garden
            const { error: deleteErr } = await supabaseServiceClient
              .from('gardens')
              .delete()
              .eq('id', gardenId)
            if (deleteErr) {
              console.warn('[account-delete] Failed to delete garden', gardenId, deleteErr?.message)
            } else {
              deletedGardens++
              deletedGardenIds.push(gardenId)

              // Delete cover image from storage
              if (coverUrl) {
                try {
                  const result = await deleteGardenCoverObject(coverUrl)
                  if (result.deleted) deletedCoverImages++
                } catch (coverErr) {
                  console.warn('[account-delete] Failed to delete cover image', coverUrl, coverErr?.message)
                }
              }
            }
          }
        } else {
          // User is not the only owner (either not an owner, or there are other owners)
          // Just remove the user from the garden
          const { error: removeErr } = await supabaseServiceClient
            .from('garden_members')
            .delete()
            .eq('garden_id', gardenId)
            .eq('user_id', userId)
          if (removeErr) {
            console.warn('[account-delete] Failed to remove user from garden', gardenId, removeErr?.message)
          } else {
            leftGardens++
          }
        }
      }
    } catch (gardenErr) {
      console.error('[account-delete] Failed to process gardens', gardenErr)
      res.status(500).json({ error: 'Failed to process gardens' })
      return
    }

    try {
      if (sql) {
        await sql`delete from public.user_task_daily_cache where user_id = ${userId}`
      } else {
        await supabaseServiceClient.from('user_task_daily_cache').delete().eq('user_id', userId)
      }
    } catch (cacheErr) {
      console.warn('[account-delete] Failed to clear task cache for user', cacheErr?.message || cacheErr)
    }

    const { error: deleteUserError } = await supabaseServiceClient.auth.admin.deleteUser(userId)
    if (deleteUserError) {
      console.error('[account-delete] Failed to delete auth user', deleteUserError)
      res.status(500).json({ error: 'Failed to delete account' })
      return
    }

    res.json({
      ok: true,
      deletedGardens,
      deletedGardenIds,
      deletedCoverImages,
      promotedMembers,
      leftGardens,
      deletedUser: true,
    })
  } catch (err) {
    console.error('[account-delete] Unexpected failure', err)
    res.status(500).json({ error: 'Failed to delete account' })
  }
})

// ========== GDPR COMPLIANCE ENDPOINTS ==========

// Helper: Delete a storage object by public URL
async function deleteStorageObjectByUrl(publicUrl) {
  if (!publicUrl || !supabaseServiceClient) return { deleted: false, reason: 'unavailable' }
  const info = parseStoragePublicUrl(publicUrl)
  if (!info) return { deleted: false, reason: 'not_managed' }
  try {
    const { error } = await supabaseServiceClient.storage.from(info.bucket).remove([info.path])
    if (error) throw error
    return { deleted: true }
  } catch (err) {
    console.warn('[gdpr] Failed to delete storage object:', publicUrl, err?.message)
    return { deleted: false, reason: err?.message || 'delete_failed' }
  }
}

// Helper: Log GDPR-related actions for compliance audit
async function logGdprAccess(userId, action, details = {}, req = null) {
  try {
    const ip = req ? getClientIp(req) : null
    const userAgent = req ? (req.get('user-agent') || null) : null
    
    if (sql) {
      await sql`
        INSERT INTO public.gdpr_audit_log (user_id, action, details, ip_address, user_agent, created_at)
        VALUES (${userId}, ${action}, ${sql.json(details)}, ${ip}::inet, ${userAgent}, NOW())
      `
    } else if (supabaseServiceClient) {
      await supabaseServiceClient.from('gdpr_audit_log').insert({
        user_id: userId,
        action,
        details,
        ip_address: ip,
        user_agent: userAgent
      })
    }
  } catch (err) {
    console.error('[gdpr] Audit log failed:', err?.message || err)
  }
}

// GDPR: Enhanced account deletion with COMPLETE data removal
app.options('/api/account/delete-gdpr', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type')
  res.status(204).end()
})

app.post('/api/account/delete-gdpr', async (req, res) => {
  try {
    if (!supabaseServiceClient) {
      res.status(503).json({ error: 'Account deletion is not configured on this server' })
      return
    }
    const user = await getUserFromRequest(req)
    if (!user?.id) {
      res.status(401).json({ error: 'Unauthorized' })
      return
    }
    const userId = user.id

    // Log the deletion request for GDPR audit
    await logGdprAccess(userId, 'ACCOUNT_DELETION_STARTED', { userId: userId.slice(0, 8) + '...' }, req)

    const stats = {
      messagesDeleted: 0,
      conversationsDeleted: 0,
      friendsDeleted: 0,
      friendRequestsDeleted: 0,
      pushSubscriptionsDeleted: 0,
      notificationsDeleted: 0,
      journalEntriesDeleted: 0,
      journalPhotosDeleted: 0,
      plantScansDeleted: 0,
      bugReportsDeleted: 0,
      bookmarksDeleted: 0,
      activityLogsDeleted: 0,
      webVisitsAnonymized: 0,
      avatarDeleted: false,
      profileDeleted: false,
      gardensProcessed: 0,
      authUserDeleted: false,
      storageObjectsDeleted: 0
    }

    try {
      // 1. Delete messages (sender only - cascade handles conversation cleanup)
      if (sql) {
        const msgResult = await sql`DELETE FROM public.messages WHERE sender_id = ${userId}`
        stats.messagesDeleted = msgResult?.count || 0
      } else {
        const { count } = await supabaseServiceClient.from('messages').delete().eq('sender_id', userId)
        stats.messagesDeleted = count || 0
      }
    } catch (err) { console.warn('[gdpr] Messages deletion partial:', err?.message) }

    try {
      // 2. Delete conversations where user is a participant
      if (sql) {
        const convResult = await sql`DELETE FROM public.conversations WHERE participant_1 = ${userId} OR participant_2 = ${userId}`
        stats.conversationsDeleted = convResult?.count || 0
      } else {
        const { count: c1 } = await supabaseServiceClient.from('conversations').delete().eq('participant_1', userId)
        const { count: c2 } = await supabaseServiceClient.from('conversations').delete().eq('participant_2', userId)
        stats.conversationsDeleted = (c1 || 0) + (c2 || 0)
      }
    } catch (err) { console.warn('[gdpr] Conversations deletion partial:', err?.message) }

    try {
      // 3. Delete friend relationships
      if (sql) {
        const friendResult = await sql`DELETE FROM public.friends WHERE user_id = ${userId} OR friend_id = ${userId}`
        stats.friendsDeleted = friendResult?.count || 0
      } else {
        const { count: f1 } = await supabaseServiceClient.from('friends').delete().eq('user_id', userId)
        const { count: f2 } = await supabaseServiceClient.from('friends').delete().eq('friend_id', userId)
        stats.friendsDeleted = (f1 || 0) + (f2 || 0)
      }
    } catch (err) { console.warn('[gdpr] Friends deletion partial:', err?.message) }

    try {
      // 4. Delete friend requests
      if (sql) {
        const reqResult = await sql`DELETE FROM public.friend_requests WHERE requester_id = ${userId} OR recipient_id = ${userId}`
        stats.friendRequestsDeleted = reqResult?.count || 0
      } else {
        const { count: r1 } = await supabaseServiceClient.from('friend_requests').delete().eq('requester_id', userId)
        const { count: r2 } = await supabaseServiceClient.from('friend_requests').delete().eq('recipient_id', userId)
        stats.friendRequestsDeleted = (r1 || 0) + (r2 || 0)
      }
    } catch (err) { console.warn('[gdpr] Friend requests deletion partial:', err?.message) }

    try {
      // 5. Delete push subscriptions
      if (sql) {
        const pushResult = await sql`DELETE FROM public.user_push_subscriptions WHERE user_id = ${userId}`
        stats.pushSubscriptionsDeleted = pushResult?.count || 0
      } else {
        const { count } = await supabaseServiceClient.from('user_push_subscriptions').delete().eq('user_id', userId)
        stats.pushSubscriptionsDeleted = count || 0
      }
    } catch (err) { console.warn('[gdpr] Push subscriptions deletion partial:', err?.message) }

    try {
      // 6. Delete notifications
      if (sql) {
        const notifResult = await sql`DELETE FROM public.user_notifications WHERE user_id = ${userId}`
        stats.notificationsDeleted = notifResult?.count || 0
      } else {
        const { count } = await supabaseServiceClient.from('user_notifications').delete().eq('user_id', userId)
        stats.notificationsDeleted = count || 0
      }
    } catch (err) { console.warn('[gdpr] Notifications deletion partial:', err?.message) }

    try {
      // 7. Delete journal photos from storage, then journal entries
      let journalPhotos = []
      if (sql) {
        journalPhotos = await sql`
          SELECT gjp.image_url, gjp.thumbnail_url 
          FROM public.garden_journal_photos gjp
          JOIN public.garden_journal_entries gje ON gje.id = gjp.entry_id
          WHERE gje.user_id = ${userId}
        `
      } else {
        const { data } = await supabaseServiceClient
          .from('garden_journal_photos')
          .select('image_url, thumbnail_url, entry_id')
          .in('entry_id', 
            supabaseServiceClient.from('garden_journal_entries').select('id').eq('user_id', userId)
          )
        journalPhotos = data || []
      }
      
      // Delete photos from storage
      for (const photo of journalPhotos) {
        if (photo.image_url) {
          const result = await deleteStorageObjectByUrl(photo.image_url)
          if (result.deleted) stats.storageObjectsDeleted++
        }
        if (photo.thumbnail_url) {
          const result = await deleteStorageObjectByUrl(photo.thumbnail_url)
          if (result.deleted) stats.storageObjectsDeleted++
        }
      }
      stats.journalPhotosDeleted = journalPhotos.length
      
      // Delete journal entries
      if (sql) {
        const journalResult = await sql`DELETE FROM public.garden_journal_entries WHERE user_id = ${userId}`
        stats.journalEntriesDeleted = journalResult?.count || 0
      } else {
        const { count } = await supabaseServiceClient.from('garden_journal_entries').delete().eq('user_id', userId)
        stats.journalEntriesDeleted = count || 0
      }
    } catch (err) { console.warn('[gdpr] Journal deletion partial:', err?.message) }

    try {
      // 8. Delete plant scans and their images
      let scans = []
      if (sql) {
        scans = await sql`SELECT image_url, image_path FROM public.plant_scans WHERE user_id = ${userId}`
      } else {
        const { data } = await supabaseServiceClient.from('plant_scans').select('image_url, image_path').eq('user_id', userId)
        scans = data || []
      }
      
      for (const scan of scans) {
        if (scan.image_url) {
          const result = await deleteStorageObjectByUrl(scan.image_url)
          if (result.deleted) stats.storageObjectsDeleted++
        }
      }
      
      if (sql) {
        const scanResult = await sql`DELETE FROM public.plant_scans WHERE user_id = ${userId}`
        stats.plantScansDeleted = scanResult?.count || 0
      } else {
        const { count } = await supabaseServiceClient.from('plant_scans').delete().eq('user_id', userId)
        stats.plantScansDeleted = count || 0
      }
    } catch (err) { console.warn('[gdpr] Plant scans deletion partial:', err?.message) }

    try {
      // 9. Delete bug reports and screenshots
      let bugReports = []
      if (sql) {
        bugReports = await sql`SELECT id, screenshots FROM public.bug_reports WHERE user_id = ${userId}`
      } else {
        const { data } = await supabaseServiceClient.from('bug_reports').select('id, screenshots').eq('user_id', userId)
        bugReports = data || []
      }
      
      for (const bug of bugReports) {
        if (bug.screenshots && Array.isArray(bug.screenshots)) {
          for (const screenshotUrl of bug.screenshots) {
            if (typeof screenshotUrl === 'string') {
              const result = await deleteStorageObjectByUrl(screenshotUrl)
              if (result.deleted) stats.storageObjectsDeleted++
            }
          }
        }
      }
      
      if (sql) {
        const bugResult = await sql`DELETE FROM public.bug_reports WHERE user_id = ${userId}`
        stats.bugReportsDeleted = bugResult?.count || 0
      } else {
        const { count } = await supabaseServiceClient.from('bug_reports').delete().eq('user_id', userId)
        stats.bugReportsDeleted = count || 0
      }
    } catch (err) { console.warn('[gdpr] Bug reports deletion partial:', err?.message) }

    try {
      // 10. Delete bookmarks (items cascade via FK)
      if (sql) {
        const bookmarkResult = await sql`DELETE FROM public.bookmarks WHERE user_id = ${userId}`
        stats.bookmarksDeleted = bookmarkResult?.count || 0
      } else {
        const { count } = await supabaseServiceClient.from('bookmarks').delete().eq('user_id', userId)
        stats.bookmarksDeleted = count || 0
      }
    } catch (err) { console.warn('[gdpr] Bookmarks deletion partial:', err?.message) }

    try {
      // 11. Delete activity logs
      if (sql) {
        const actResult = await sql`DELETE FROM public.garden_activity_logs WHERE actor_id = ${userId}`
        stats.activityLogsDeleted = actResult?.count || 0
      } else {
        const { count } = await supabaseServiceClient.from('garden_activity_logs').delete().eq('actor_id', userId)
        stats.activityLogsDeleted = count || 0
      }
    } catch (err) { console.warn('[gdpr] Activity logs deletion partial:', err?.message) }

    try {
      // 12. Anonymize web visits (retain for analytics, remove PII)
      if (sql) {
        const visitResult = await sql`
          UPDATE public.web_visits 
          SET user_id = NULL, ip_address = NULL, user_agent = NULL 
          WHERE user_id = ${userId}
        `
        stats.webVisitsAnonymized = visitResult?.count || 0
      } else {
        const { count } = await supabaseServiceClient
          .from('web_visits')
          .update({ user_id: null, ip_address: null, user_agent: null })
          .eq('user_id', userId)
        stats.webVisitsAnonymized = count || 0
      }
    } catch (err) { console.warn('[gdpr] Web visits anonymization partial:', err?.message) }

    try {
      // 13. Delete user blocks (both as blocker and blocked)
      if (sql) {
        await sql`DELETE FROM public.user_blocks WHERE blocker_id = ${userId} OR blocked_id = ${userId}`
      } else {
        await supabaseServiceClient.from('user_blocks').delete().eq('blocker_id', userId)
        await supabaseServiceClient.from('user_blocks').delete().eq('blocked_id', userId)
      }
    } catch (err) { console.warn('[gdpr] User blocks deletion partial:', err?.message) }

    try {
      // 14. Delete message reactions
      if (sql) {
        await sql`DELETE FROM public.message_reactions WHERE user_id = ${userId}`
      } else {
        await supabaseServiceClient.from('message_reactions').delete().eq('user_id', userId)
      }
    } catch (err) { console.warn('[gdpr] Message reactions deletion partial:', err?.message) }

    try {
      // 15. Delete avatar image and profile
      let profile = null
      if (sql) {
        const profiles = await sql`SELECT avatar_url FROM public.profiles WHERE id = ${userId}`
        profile = profiles?.[0]
      } else {
        const { data } = await supabaseServiceClient.from('profiles').select('avatar_url').eq('id', userId).maybeSingle()
        profile = data
      }
      
      if (profile?.avatar_url) {
        const result = await deleteStorageObjectByUrl(profile.avatar_url)
        if (result.deleted) {
          stats.avatarDeleted = true
          stats.storageObjectsDeleted++
        }
      }
      
      if (sql) {
        await sql`DELETE FROM public.profiles WHERE id = ${userId}`
      } else {
        await supabaseServiceClient.from('profiles').delete().eq('id', userId)
      }
      stats.profileDeleted = true
    } catch (err) { console.warn('[gdpr] Profile deletion partial:', err?.message) }

    try {
      // 16. Process gardens (existing logic)
      const { data: userMemberships, error: memberErr } = await supabaseServiceClient
        .from('garden_members')
        .select('garden_id, role')
        .eq('user_id', userId)
      if (!memberErr && userMemberships) {
        for (const membership of userMemberships) {
          const gardenId = membership.garden_id
          const userRole = membership.role
          
          const { data: allMembers } = await supabaseServiceClient
            .from('garden_members')
            .select('user_id, role')
            .eq('garden_id', gardenId)
          
          const otherMembers = (allMembers || []).filter(m => m.user_id !== userId)
          const otherOwners = otherMembers.filter(m => m.role === 'owner')
          
          if (userRole === 'owner' && otherOwners.length === 0) {
            if (otherMembers.length > 0) {
              // Promote another member to owner
              await supabaseServiceClient
                .from('garden_members')
                .update({ role: 'owner' })
                .eq('garden_id', gardenId)
                .eq('user_id', otherMembers[0].user_id)
              // Remove user from garden
              await supabaseServiceClient
                .from('garden_members')
                .delete()
                .eq('garden_id', gardenId)
                .eq('user_id', userId)
            } else {
              // Delete garden (no other members)
              const { data: gardenRow } = await supabaseServiceClient
                .from('gardens')
                .select('cover_image_url')
                .eq('id', gardenId)
                .maybeSingle()
              
              if (gardenRow?.cover_image_url) {
                const result = await deleteStorageObjectByUrl(gardenRow.cover_image_url)
                if (result.deleted) stats.storageObjectsDeleted++
              }
              
              await supabaseServiceClient.from('gardens').delete().eq('id', gardenId)
            }
          } else {
            // Just remove user from garden
            await supabaseServiceClient
              .from('garden_members')
              .delete()
              .eq('garden_id', gardenId)
              .eq('user_id', userId)
          }
          stats.gardensProcessed++
        }
      }
    } catch (err) { console.warn('[gdpr] Gardens processing partial:', err?.message) }

    try {
      // 17. Clear task cache
      if (sql) {
        await sql`DELETE FROM public.user_task_daily_cache WHERE user_id = ${userId}`
      } else {
        await supabaseServiceClient.from('user_task_daily_cache').delete().eq('user_id', userId)
      }
    } catch (err) { console.warn('[gdpr] Task cache deletion partial:', err?.message) }

    try {
      // 18. Finally delete auth user
      const { error: deleteUserError } = await supabaseServiceClient.auth.admin.deleteUser(userId)
      if (deleteUserError) throw deleteUserError
      stats.authUserDeleted = true
    } catch (err) {
      console.error('[gdpr] Failed to delete auth user:', err?.message)
      // Log partial failure for audit
      await logGdprAccess(userId, 'ACCOUNT_DELETION_PARTIAL', { ...stats, error: err?.message }, req)
      res.status(500).json({ error: 'Failed to complete account deletion', stats })
      return
    }

    // Log successful deletion for GDPR audit
    await logGdprAccess(userId, 'ACCOUNT_DELETION_COMPLETED', stats, req)

    res.json({
      ok: true,
      message: 'All personal data deleted',
      stats
    })
  } catch (err) {
    console.error('[gdpr] Complete deletion failed:', err)
    res.status(500).json({ error: 'Failed to complete deletion' })
  }
})

// GDPR: Export all user data (Data Portability - Article 20)
app.options('/api/account/export', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'GET,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type')
  res.status(204).end()
})

app.get('/api/account/export', async (req, res) => {
  try {
    const user = await getUserFromRequest(req)
    if (!user?.id) {
      res.status(401).json({ error: 'Unauthorized' })
      return
    }
    
    const userId = user.id

    // Log the export request for GDPR audit
    await logGdprAccess(userId, 'DATA_EXPORT', { ip: getClientIp(req) }, req)

    const exportData = {
      exportedAt: new Date().toISOString(),
      dataSubject: {},
      profile: null,
      gardens: [],
      plants: [],
      tasks: [],
      journal: [],
      messages: [],
      conversations: [],
      friends: [],
      friendRequests: [],
      bookmarks: [],
      scans: [],
      notifications: [],
      activityLogs: [],
      bugReports: [],
      cookieConsent: null
    }

    try {
      // 1. Profile data
      if (sql) {
        const profiles = await sql`
          SELECT id, display_name, username, bio, country, timezone, language, 
                 favorite_plant, avatar_url, is_private, disable_friend_requests,
                 notify_push, notify_email, experience_years, accent_key, roles,
                 marketing_consent, marketing_consent_date, terms_accepted_date, 
                 privacy_policy_accepted_date, created_at
          FROM public.profiles WHERE id = ${userId}
        `
        exportData.profile = profiles?.[0] || null
      } else {
        const { data } = await supabaseServiceClient.from('profiles')
          .select('id, display_name, username, bio, country, timezone, language, favorite_plant, avatar_url, is_private, disable_friend_requests, notify_push, notify_email, experience_years, accent_key, roles, marketing_consent, marketing_consent_date, terms_accepted_date, privacy_policy_accepted_date')
          .eq('id', userId)
          .maybeSingle()
        exportData.profile = data
      }
    } catch (err) { console.warn('[gdpr-export] Profile:', err?.message) }

    try {
      // 2. Auth user data
      const { data: authUser } = await supabaseServiceClient.auth.admin.getUserById(userId)
      exportData.dataSubject = {
        userId: userId,
        email: authUser?.user?.email || user.email,
        emailConfirmedAt: authUser?.user?.email_confirmed_at,
        createdAt: authUser?.user?.created_at,
        lastSignIn: authUser?.user?.last_sign_in_at
      }
    } catch (err) { console.warn('[gdpr-export] Auth user:', err?.message) }

    try {
      // 3. Gardens and plants
      if (sql) {
        const gardens = await sql`
          SELECT g.*, gm.role as member_role
          FROM public.gardens g
          JOIN public.garden_members gm ON gm.garden_id = g.id
          WHERE gm.user_id = ${userId}
        `
        for (const garden of gardens) {
          const plants = await sql`
            SELECT gp.*, p.name as plant_name
            FROM public.garden_plants gp
            LEFT JOIN public.plants p ON p.id = gp.plant_id
            WHERE gp.garden_id = ${garden.id}
          `
          const tasks = await sql`
            SELECT * FROM public.garden_plant_tasks
            WHERE garden_id = ${garden.id}
          `
          exportData.gardens.push({
            ...garden,
            plants: plants || [],
            tasks: tasks || []
          })
        }
      } else {
        const { data: memberships } = await supabaseServiceClient
          .from('garden_members')
          .select('garden_id, role')
          .eq('user_id', userId)
        
        for (const membership of (memberships || [])) {
          const { data: garden } = await supabaseServiceClient
            .from('gardens')
            .select('*')
            .eq('id', membership.garden_id)
            .maybeSingle()
          
          if (garden) {
            const { data: plants } = await supabaseServiceClient
              .from('garden_plants')
              .select('*')
              .eq('garden_id', garden.id)
            
            const { data: tasks } = await supabaseServiceClient
              .from('garden_plant_tasks')
              .select('*')
              .eq('garden_id', garden.id)
            
            exportData.gardens.push({
              ...garden,
              member_role: membership.role,
              plants: plants || [],
              tasks: tasks || []
            })
          }
        }
      }
    } catch (err) { console.warn('[gdpr-export] Gardens:', err?.message) }

    try {
      // 4. Journal entries
      if (sql) {
        const journal = await sql`
          SELECT gje.*, 
            (SELECT json_agg(gjp.*) FROM public.garden_journal_photos gjp WHERE gjp.entry_id = gje.id) as photos
          FROM public.garden_journal_entries gje
          WHERE gje.user_id = ${userId}
          ORDER BY gje.created_at DESC
        `
        exportData.journal = journal || []
      } else {
        const { data } = await supabaseServiceClient
          .from('garden_journal_entries')
          .select('*')
          .eq('user_id', userId)
          .order('created_at', { ascending: false })
        exportData.journal = data || []
      }
    } catch (err) { console.warn('[gdpr-export] Journal:', err?.message) }

    try {
      // 5. Messages
      if (sql) {
        const messages = await sql`
          SELECT m.*, c.participant_1, c.participant_2
          FROM public.messages m
          JOIN public.conversations c ON c.id = m.conversation_id
          WHERE m.sender_id = ${userId}
          ORDER BY m.created_at DESC
        `
        exportData.messages = messages || []
      } else {
        const { data } = await supabaseServiceClient
          .from('messages')
          .select('*, conversation:conversations(participant_1, participant_2)')
          .eq('sender_id', userId)
          .order('created_at', { ascending: false })
        exportData.messages = data || []
      }
    } catch (err) { console.warn('[gdpr-export] Messages:', err?.message) }

    try {
      // 6. Conversations
      if (sql) {
        const conversations = await sql`
          SELECT * FROM public.conversations
          WHERE participant_1 = ${userId} OR participant_2 = ${userId}
        `
        exportData.conversations = conversations || []
      } else {
        const { data: c1 } = await supabaseServiceClient.from('conversations').select('*').eq('participant_1', userId)
        const { data: c2 } = await supabaseServiceClient.from('conversations').select('*').eq('participant_2', userId)
        exportData.conversations = [...(c1 || []), ...(c2 || [])]
      }
    } catch (err) { console.warn('[gdpr-export] Conversations:', err?.message) }

    try {
      // 7. Friends
      if (sql) {
        const friends = await sql`
          SELECT f.*, p.display_name as friend_name
          FROM public.friends f
          LEFT JOIN public.profiles p ON p.id = CASE
            WHEN f.user_id = ${userId} THEN f.friend_id
            ELSE f.user_id
          END
          WHERE f.user_id = ${userId} OR f.friend_id = ${userId}
        `
        exportData.friends = friends || []
      } else {
        const { data: f1 } = await supabaseServiceClient.from('friends').select('*').eq('user_id', userId)
        const { data: f2 } = await supabaseServiceClient.from('friends').select('*').eq('friend_id', userId)
        exportData.friends = [...(f1 || []), ...(f2 || [])]
      }
    } catch (err) { console.warn('[gdpr-export] Friends:', err?.message) }

    try {
      // 8. Friend requests
      if (sql) {
        const requests = await sql`
          SELECT * FROM public.friend_requests
          WHERE requester_id = ${userId} OR recipient_id = ${userId}
        `
        exportData.friendRequests = requests || []
      } else {
        const { data: r1 } = await supabaseServiceClient.from('friend_requests').select('*').eq('requester_id', userId)
        const { data: r2 } = await supabaseServiceClient.from('friend_requests').select('*').eq('recipient_id', userId)
        exportData.friendRequests = [...(r1 || []), ...(r2 || [])]
      }
    } catch (err) { console.warn('[gdpr-export] Friend requests:', err?.message) }

    try {
      // 9. Bookmarks
      if (sql) {
        const bookmarks = await sql`
          SELECT b.*, 
            (SELECT array_agg(bi.plant_id) FROM public.bookmark_items bi WHERE bi.bookmark_id = b.id) as plant_ids
          FROM public.bookmarks b
          WHERE b.user_id = ${userId}
        `
        exportData.bookmarks = bookmarks || []
      } else {
        const { data } = await supabaseServiceClient
          .from('bookmarks')
          .select('*, bookmark_items(plant_id)')
          .eq('user_id', userId)
        exportData.bookmarks = data || []
      }
    } catch (err) { console.warn('[gdpr-export] Bookmarks:', err?.message) }

    try {
      // 10. Plant scans
      if (sql) {
        const scans = await sql`SELECT * FROM public.plant_scans WHERE user_id = ${userId}`
        exportData.scans = scans || []
      } else {
        const { data } = await supabaseServiceClient.from('plant_scans').select('*').eq('user_id', userId)
        exportData.scans = data || []
      }
    } catch (err) { console.warn('[gdpr-export] Scans:', err?.message) }

    try {
      // 11. Notifications
      if (sql) {
        const notifications = await sql`
          SELECT * FROM public.user_notifications
          WHERE user_id = ${userId}
          ORDER BY created_at DESC
        `
        exportData.notifications = notifications || []
      } else {
        const { data } = await supabaseServiceClient
          .from('user_notifications')
          .select('*')
          .eq('user_id', userId)
          .order('created_at', { ascending: false })
        exportData.notifications = data || []
      }
    } catch (err) { console.warn('[gdpr-export] Notifications:', err?.message) }

    try {
      // 12. Bug reports
      if (sql) {
        const bugReports = await sql`SELECT * FROM public.bug_reports WHERE user_id = ${userId}`
        exportData.bugReports = bugReports || []
      } else {
        const { data } = await supabaseServiceClient.from('bug_reports').select('*').eq('user_id', userId)
        exportData.bugReports = data || []
      }
    } catch (err) { console.warn('[gdpr-export] Bug reports:', err?.message) }

    try {
      // 13. Cookie consent (if server-tracked)
      if (sql) {
        const consent = await sql`
          SELECT * FROM public.user_cookie_consent 
          WHERE user_id = ${userId} 
          ORDER BY consented_at DESC LIMIT 1
        `
        exportData.cookieConsent = consent?.[0] || null
      } else {
        const { data } = await supabaseServiceClient
          .from('user_cookie_consent')
          .select('*')
          .eq('user_id', userId)
          .order('consented_at', { ascending: false })
          .limit(1)
          .maybeSingle()
        exportData.cookieConsent = data
      }
    } catch (err) { console.warn('[gdpr-export] Cookie consent:', err?.message) }

    // Set headers for download
    const shortId = userId.slice(0, 8)
    const timestamp = Date.now()
    res.setHeader('Content-Type', 'application/json')
    res.setHeader('Content-Disposition', `attachment; filename="aphylia-data-export-${shortId}-${timestamp}.json"`)

    res.json(exportData)
  } catch (err) {
    console.error('[gdpr-export] Data export failed:', err)
    res.status(500).json({ error: 'Failed to export data' })
  }
})

// GDPR: Update marketing consent
app.options('/api/account/consent', (_req, res) => {
  res.setHeader('Access-Control-Allow-Methods', 'POST,OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Authorization, Content-Type')
  res.status(204).end()
})

app.post('/api/account/consent', async (req, res) => {
  try {
    const user = await getUserFromRequest(req)
    if (!user?.id) {
      res.status(401).json({ error: 'Unauthorized' })
      return
    }
    
    const { marketingConsent } = req.body
    if (typeof marketingConsent !== 'boolean') {
      res.status(400).json({ error: 'marketingConsent must be a boolean' })
      return
    }

    const userId = user.id
    const now = new Date().toISOString()

    if (sql) {
      await sql`
        UPDATE public.profiles 
        SET marketing_consent = ${marketingConsent},
            marketing_consent_date = ${now}
        WHERE id = ${userId}
      `
    } else if (supabaseServiceClient) {
      await supabaseServiceClient
        .from('profiles')
        .update({ 
          marketing_consent: marketingConsent,
          marketing_consent_date: now
        })
        .eq('id', userId)
    }

    // Log consent change for GDPR audit
    await logGdprAccess(userId, 'CONSENT_UPDATE', { 
      marketingConsent,
      previousValue: 'unknown'
    }, req)

    res.json({ ok: true, marketingConsent, updatedAt: now })
  } catch (err) {
    console.error('[gdpr] Consent update failed:', err)
    res.status(500).json({ error: 'Failed to update consent' })
  }
})

// GDPR: Data retention cleanup cron job (runs daily at 3 AM)
cron.schedule('0 3 * * *', async () => {
  console.log('[gdpr] Running data retention cleanup...')
  
  try {
    // 1. Anonymize web visits older than 90 days (keep for analytics, remove PII)
    if (sql) {
      const visitResult = await sql`
        UPDATE public.web_visits
        SET ip_address = NULL, user_agent = NULL
        WHERE occurred_at < NOW() - INTERVAL '90 days'
          AND ip_address IS NOT NULL
      `
      if (visitResult?.count > 0) {
        console.log(`[gdpr] Anonymized ${visitResult.count} old web visits`)
      }
    }
  } catch (err) {
    console.error('[gdpr] Web visits anonymization failed:', err?.message)
  }

  try {
    // 2. Delete orphaned messages from deleted users (older than 30 days)
    if (sql) {
      const orphanResult = await sql`
        DELETE FROM public.messages
        WHERE sender_id NOT IN (SELECT id FROM auth.users)
          AND created_at < NOW() - INTERVAL '30 days'
      `
      if (orphanResult?.count > 0) {
        console.log(`[gdpr] Deleted ${orphanResult.count} orphaned messages`)
      }
    }
  } catch (err) {
    console.error('[gdpr] Orphaned messages cleanup failed:', err?.message)
  }

  try {
    // 3. Delete expired push subscriptions (inactive for 180 days)
    if (sql) {
      const pushResult = await sql`
        DELETE FROM public.user_push_subscriptions
        WHERE updated_at < NOW() - INTERVAL '180 days'
      `
      if (pushResult?.count > 0) {
        console.log(`[gdpr] Deleted ${pushResult.count} expired push subscriptions`)
      }
    }
  } catch (err) {
    console.error('[gdpr] Push subscriptions cleanup failed:', err?.message)
  }

  try {
    // 4. Delete automation notification deliveries older than 3 days (monitoring only)
    if (sql) {
      const automationNotifResult = await sql`
        DELETE FROM public.user_notifications
        WHERE automation_id is not null
          AND scheduled_for < NOW() - INTERVAL '3 days'
      `
      if (automationNotifResult?.count > 0) {
        console.log(`[gdpr] Deleted ${automationNotifResult.count} old automation notifications`)
      }
    }
  } catch (err) {
    console.error('[gdpr] Automation notifications cleanup failed:', err?.message)
  }

  try {
    // 5. Delete old delivered notifications (older than 90 days)
    if (sql) {
      const notifResult = await sql`
        DELETE FROM public.user_notifications
        WHERE delivery_status = 'sent'
          AND delivered_at < NOW() - INTERVAL '90 days'
      `
      if (notifResult?.count > 0) {
        console.log(`[gdpr] Deleted ${notifResult.count} old notifications`)
      }
    }
  } catch (err) {
    console.error('[gdpr] Notifications cleanup failed:', err?.message)
  }

  try {
    // 6. Clean old GDPR audit logs (keep for 3 years as required by GDPR)
    if (sql) {
      const auditResult = await sql`
        DELETE FROM public.gdpr_audit_log
        WHERE created_at < NOW() - INTERVAL '3 years'
      `
      if (auditResult?.count > 0) {
        console.log(`[gdpr] Deleted ${auditResult.count} old audit log entries`)
      }
    }
  } catch (err) {
    console.error('[gdpr] Audit log cleanup failed:', err?.message)
  }

  try {
    // 7. Clean up expired email verification codes
    const deletedCount = await cleanupExpiredVerificationCodes()
    if (deletedCount > 0) {
      console.log(`[gdpr] Deleted ${deletedCount} expired verification codes`)
    }
  } catch (err) {
    console.error('[gdpr] Verification codes cleanup failed:', err?.message)
  }

  console.log('[gdpr] Data retention cleanup completed')
})

// ========== END GDPR COMPLIANCE ENDPOINTS ==========

// Admin: unique visitors stats (past 10m and 7 days)
app.get('/api/admin/visitors-stats', async (req, res) => {
  const uid = "public"
  if (!uid) return
  // Helper that always succeeds using in-memory analytics
  const respondFromMemory = (extra = {}) => {
    try {
      const daysParam = Number(req.query.days || 7)
      const days = (daysParam === 30 ? 30 : 7)
      const currentUniqueVisitors10m = memAnalytics.getUniqueIpCountInLastMinutes(10)
      const uniqueIpsLast30m = memAnalytics.getUniqueIpCountInLastMinutes(30)
      const uniqueIpsLast60m = memAnalytics.getUniqueIpCountInLastMinutes(60)
      const visitsLast60m = memAnalytics.getVisitCountInLastMinutes(60)
      const uniqueIps7d = memAnalytics.getUniqueIpCountInLastDays(days)
      const series7d = memAnalytics.getDailySeries(days)
      res.json({ ok: true, currentUniqueVisitors10m, uniqueIpsLast30m, uniqueIpsLast60m, visitsLast60m, uniqueIps7d, series7d, via: 'memory', days, ...extra })
      return true
    } catch {
      return false
    }
  }
  try {
    if (!sql) {
      // Supabase REST fallback using security-definer RPCs
      if (supabaseUrlEnv && supabaseAnonKey) {
        try {
          const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json', 'Content-Type': 'application/json' }
          // Attempt to use caller token when present (not required for definer functions)
          const token = getBearerTokenFromRequest(req)
          if (token) Object.assign(headers, { 'Authorization': `Bearer ${token}` })

          const daysParam = Number(req.query.days || 7)
          const days = (daysParam === 30 ? 30 : 7)

          const [c10, c30, c60u, c60v, uN, sN] = await Promise.all([
            fetch(`${supabaseUrlEnv}/rest/v1/rpc/count_unique_ips_last_minutes`, { method: 'POST', headers, body: JSON.stringify({ _minutes: 10 }) }),
            fetch(`${supabaseUrlEnv}/rest/v1/rpc/count_unique_ips_last_minutes`, { method: 'POST', headers, body: JSON.stringify({ _minutes: 30 }) }),
            fetch(`${supabaseUrlEnv}/rest/v1/rpc/count_unique_ips_last_minutes`, { method: 'POST', headers, body: JSON.stringify({ _minutes: 60 }) }),
            fetch(`${supabaseUrlEnv}/rest/v1/rpc/count_visits_last_minutes`, { method: 'POST', headers, body: JSON.stringify({ _minutes: 60 }) }),
            fetch(`${supabaseUrlEnv}/rest/v1/rpc/count_unique_ips_last_days`, { method: 'POST', headers, body: JSON.stringify({ _days: days }) }),
            fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_visitors_series_days`, { method: 'POST', headers, body: JSON.stringify({ _days: days }) }),
          ])

          const [c10v, c30v, c60uv, c60vv, uNv, sNv] = await Promise.all([
            c10.ok ? c10.json().catch(() => 0) : Promise.resolve(0),
            c30.ok ? c30.json().catch(() => 0) : Promise.resolve(0),
            c60u.ok ? c60u.json().catch(() => 0) : Promise.resolve(0),
            c60v.ok ? c60v.json().catch(() => 0) : Promise.resolve(0),
            uN.ok ? uN.json().catch(() => 0) : Promise.resolve(0),
            sN.ok ? sN.json().catch(() => []) : Promise.resolve([]),
          ])

          const series7d = Array.isArray(sNv)
            ? sNv.map((r) => ({ date: String(r.date), uniqueVisitors: Number(r.unique_visitors ?? 0) }))
            : []

          res.json({
            ok: true,
            currentUniqueVisitors10m: Number(c10v) || 0,
            uniqueIpsLast30m: Number(c30v) || 0,
            uniqueIpsLast60m: Number(c60uv) || 0,
            visitsLast60m: Number(c60vv) || 0,
            uniqueIps7d: Number(uNv) || 0,
            series7d,
            via: 'supabase',
            days,
          })
          return
        } catch { }
      }
      // Fallback to memory-only if Supabase REST isn't configured or failed
      respondFromMemory()
      return
    }

    const daysParam = Number(req.query.days || 7)
    const days = (daysParam === 30 ? 30 : 7)
    const [rows10m, rows30m, rows60mUnique, rows60mRaw, rowsNdUnique] = await Promise.all([
      sql.unsafe(`select count(distinct v.ip_address)::int as c from ${VISITS_TABLE_SQL_IDENT} v where v.ip_address is not null and v.occurred_at >= now() - interval '10 minutes'`),
      sql.unsafe(`select count(distinct v.ip_address)::int as c from ${VISITS_TABLE_SQL_IDENT} v where v.ip_address is not null and v.occurred_at >= now() - interval '30 minutes'`),
      sql.unsafe(`select count(distinct v.ip_address)::int as c from ${VISITS_TABLE_SQL_IDENT} v where v.ip_address is not null and v.occurred_at >= now() - interval '60 minutes'`),
      sql.unsafe(`select count(*)::int as c from ${VISITS_TABLE_SQL_IDENT} where occurred_at >= now() - interval '60 minutes'`),
      // Unique IPs across the last N calendar days in UTC
      sql.unsafe(`select count(distinct v.ip_address)::int as c
                  from ${VISITS_TABLE_SQL_IDENT} v
                  where v.ip_address is not null
                    and timezone('utc', v.occurred_at) >= ((now() at time zone 'utc')::date - interval '${days - 1} days')`)
    ])

    const currentUniqueVisitors10m = rows10m?.[0]?.c ?? 0
    const uniqueIpsLast30m = rows30m?.[0]?.c ?? 0
    const uniqueIpsLast60m = rows60mUnique?.[0]?.c ?? 0
    const visitsLast60m = rows60mRaw?.[0]?.c ?? 0
    const uniqueIps7d = rowsNdUnique?.[0]?.c ?? 0

    const rows7 = await sql.unsafe(
      `with days as (
         select generate_series(((now() at time zone 'utc')::date - interval '${days - 1} days'), (now() at time zone 'utc')::date, interval '1 day')::date as d
       )
       select to_char(d, 'YYYY-MM-DD') as date,
              coalesce((
                select count(distinct v.ip_address)
                from ${VISITS_TABLE_SQL_IDENT} v
                where (timezone('utc', v.occurred_at))::date = d
              ), 0)::int as unique_visitors
       from days
       order by d asc`)
    const series7d = (rows7 || []).map(r => ({ date: String(r.date), uniqueVisitors: Number(r.unique_visitors || 0) }))

    res.json({ ok: true, currentUniqueVisitors10m, uniqueIpsLast30m, uniqueIpsLast60m, visitsLast60m, uniqueIps7d, series7d, via: 'database', days })
  } catch (e) {
    // On DB failure, fall back to in-memory analytics instead of 500s
    if (!respondFromMemory({ error: e?.message || 'DB query failed' })) {
      res.status(500).json({ ok: false, error: e?.message || 'DB query failed' })
    }
  }
})

// Admin: total unique visitors across last 7 days (distinct IPs, UTC calendar days)
app.get('/api/admin/visitors-unique-7d', async (req, res) => {
  const uid = "public"
  if (!uid) return
  const respondFromMemory = (extra = {}) => {
    try {
      const uniqueIps7d = memAnalytics.getUniqueIpCountInLastDays(7)
      res.json({ ok: true, uniqueIps7d, via: 'memory', ...extra })
      return true
    } catch {
      return false
    }
  }
  try {
    if (sql) {
      const rows = await sql.unsafe(
        `select count(distinct v.ip_address)::int as c
         from ${VISITS_TABLE_SQL_IDENT} v
         where v.ip_address is not null
           and (timezone('utc', v.occurred_at))::date >= ((now() at time zone 'utc')::date - interval '6 days')`
      )
      const uniqueIps7d = rows?.[0]?.c ?? 0
      res.json({ ok: true, uniqueIps7d, via: 'database' })
      return
    }

    // Supabase REST fallback using security-definer RPC
    if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { 'apikey': supabaseAnonKey, 'Accept': 'application/json', 'Content-Type': 'application/json' }
      const token = getBearerTokenFromRequest(req)
      if (token) Object.assign(headers, { 'Authorization': `Bearer ${token}` })
      const r = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/count_unique_ips_last_days`, {
        method: 'POST',
        headers,
        body: JSON.stringify({ _days: 7 }),
      })
      if (r.ok) {
        const val = await r.json().catch(() => 0)
        const uniqueIps7d = Number(val) || 0
        res.json({ ok: true, uniqueIps7d, via: 'supabase' })
        return
      }
    }

    // Memory fallback
    respondFromMemory()
  } catch (e) {
    if (!respondFromMemory({ error: e?.message || 'DB query failed' })) {
      res.status(500).json({ ok: false, error: e?.message || 'DB query failed' })
    }
  }
})

// Admin: breakdown of where visitors come from (top countries and top referrers)
app.get('/api/admin/sources-breakdown', async (req, res) => {
  const uid = "public"
  if (!uid) return
  try {
    // Memory fallback cannot easily yield breakdowns; prefer DB or Supabase REST
    if (sql) {
      const daysParam = Number(req.query.days || 30)
      const days = (daysParam === 7 ? 7 : 30)
      const [countries, referrers] = await Promise.all([
        sql`select * from public.get_top_countries(${days}, ${10000})`,
        sql`select * from public.get_top_referrers(${days}, ${10})`,
      ])
      const allCountries = (countries || []).map(r => ({ country: (r.country || ''), visits: Number(r.visits || 0) })).filter(c => c.country)
      const allReferrers = (referrers || []).map(r => ({ source: String(r.source || 'direct'), visits: Number(r.visits || 0) }))
      allCountries.sort((a, b) => (b.visits || 0) - (a.visits || 0))
      allReferrers.sort((a, b) => (b.visits || 0) - (a.visits || 0))
      const topCountries = allCountries.slice(0, 5)
      const otherCountriesList = allCountries.slice(5)
      const otherCountries = {
        count: otherCountriesList.length,
        visits: otherCountriesList.reduce((s, c) => s + (c.visits || 0), 0),
        codes: otherCountriesList.map(c => c.country).filter(Boolean),
        items: otherCountriesList.map(c => ({ country: c.country, visits: Number(c.visits || 0) })),
      }
      const topReferrers = allReferrers.slice(0, 5)
      const otherReferrersList = allReferrers.slice(5)
      const otherReferrers = { count: otherReferrersList.length, visits: otherReferrersList.reduce((s, c) => s + (c.visits || 0), 0) }
      res.json({ ok: true, topCountries, otherCountries, topReferrers, otherReferrers, via: 'database', days })
      return
    }

    if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
      const token = getBearerTokenFromRequest(req)
      if (token) headers.Authorization = `Bearer ${token}`
      const daysParam = Number(req.query.days || 30)
      const days = (daysParam === 7 ? 7 : 30)
      // Prefer RPCs for reliable grouping
      const [cr, rr] = await Promise.all([
        fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_top_countries`, { method: 'POST', headers, body: JSON.stringify({ _days: days, _limit: 10000 }) }),
        fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_top_referrers`, { method: 'POST', headers, body: JSON.stringify({ _days: days, _limit: 10 }) }),
      ])
      const cData = cr.ok ? await cr.json().catch(() => []) : []
      const rData = rr.ok ? await rr.json().catch(() => []) : []
      const allCountries = (Array.isArray(cData) ? cData : []).map((r) => ({ country: String(r.country || ''), visits: Number(r.visits || 0) })).filter(c => !!c.country)
      const allReferrers = (Array.isArray(rData) ? rData : []).map((r) => ({ source: String(r.source || 'direct'), visits: Number(r.visits || 0) }))
      allCountries.sort((a, b) => (b.visits || 0) - (a.visits || 0))
      allReferrers.sort((a, b) => (b.visits || 0) - (a.visits || 0))
      const topCountries = allCountries.slice(0, 5)
      const otherCountriesList = allCountries.slice(5)
      const otherCountries = {
        count: otherCountriesList.length,
        visits: otherCountriesList.reduce((s, c) => s + (c.visits || 0), 0),
        codes: otherCountriesList.map(c => c.country).filter(Boolean),
        items: otherCountriesList.map(c => ({ country: c.country, visits: Number(c.visits || 0) })),
      }
      const topReferrers = allReferrers.slice(0, 5)
      const otherReferrersList = allReferrers.slice(5)
      const otherReferrers = { count: otherReferrersList.length, visits: otherReferrersList.reduce((s, c) => s + (c.visits || 0), 0) }
      res.json({ ok: true, topCountries, otherCountries, topReferrers, otherReferrers, via: 'supabase', days })
      return
    }

    res.status(200).json({ ok: true, topCountries: [], topReferrers: [], via: 'memory' })
  } catch (e) {
    res.status(500).json({ ok: false, error: e?.message || 'Failed to load sources breakdown' })
  }
})

// Admin: list unique IP addresses connected in the last N minutes (default 60)
app.get('/api/admin/online-ips', async (req, res) => {
  const uid = "public"
  if (!uid) return
  const minutesParam = Number(req.query.minutes || req.query.window || 60)
  const windowMinutes = Number.isFinite(minutesParam) && minutesParam > 0 ? Math.min(24 * 60, Math.floor(minutesParam)) : 60

  const respondFromMemory = (extra = {}) => {
    try {
      // Build set of IPs from the in-memory minute buckets within the window
      const nowMin = Math.floor(Date.now() / 60000)
      const start = nowMin - windowMinutes + 1
      const uniq = new Set()
      for (let m = start; m <= nowMin; m++) {
        const set = memAnalytics.minuteToUniqueIps.get(m)
        if (set && set.size) {
          for (const ip of set) uniq.add(ip)
        }
      }
      const ips = Array.from(uniq)
      res.json({ ok: true, ips, via: 'memory', windowMinutes, count: ips.length, updatedAt: Date.now() })
      return true
    } catch {
      return false
    }
  }

  try {
    if (sql) {
      const rows = await sql`
        select distinct v.ip_address as ip
        from ${VISITS_TABLE_SQL_IDENT} v
        where v.ip_address is not null
          and v.occurred_at >= now() - interval '${windowMinutes} minutes'
        order by ip asc
      `
      const ips = Array.isArray(rows) ? rows.map(r => String(r.ip)).filter(Boolean) : []
      res.json({ ok: true, ips, via: 'database', windowMinutes, count: ips.length, updatedAt: Date.now() })
      return
    }

    // Supabase REST fallback: query distinct IPs in window
    if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
      const token = getBearerTokenFromRequest(req)
      if (token) headers.Authorization = `Bearer ${token}`
      // Use RPC if available; otherwise use REST with select distinct
      let ips = []
      try {
        const tablePath = (process.env.VISITS_TABLE_REST || VISITS_TABLE_ENV || 'web_visits')
        const url = `${supabaseUrlEnv}/rest/v1/${tablePath}?select=ip_address&occurred_at=gte.${new Date(Date.now() - windowMinutes * 60000).toISOString()}&ip_address=not.is.null`
        const resp = await withTimeout(fetch(url, { headers }), 1200, 'REST_TIMEOUT')
        if (resp.ok) {
          const arr = await resp.json().catch(() => [])
          const uniq = new Set((Array.isArray(arr) ? arr : []).map(r => String(r.ip_address || '')).filter(Boolean))
          ips = Array.from(uniq).sort()
        }
      } catch { }
      if (ips.length > 0) {
        res.json({ ok: true, ips, via: 'supabase', windowMinutes, count: ips.length, updatedAt: Date.now() })
        return
      }
    }

    if (!respondFromMemory()) {
      res.status(500).json({ ok: false, error: 'Failed to collect IPs' })
    }
  } catch (e) {
    if (!respondFromMemory({ error: e?.message || 'DB query failed' })) {
      res.status(500).json({ ok: false, error: e?.message || 'DB query failed' })
    }
  }
})

// Admin: simple online users count (unique IPs past 60 minutes)
app.get('/api/admin/online-users', async (req, res) => {
  const uid = "public"
  if (!uid) return
  const respondFromMemory = (extra = {}) => {
    try {
      const ipCount = memAnalytics.getUniqueIpCountInLastMinutes(60)
      res.json({ ok: true, onlineUsers: ipCount, via: 'memory', ...extra })
      return true
    } catch {
      return false
    }
  }
  try {
    if (sql) {
      const [ipRows] = await Promise.all([
        sql.unsafe(`select count(distinct v.ip_address)::int as c from ${VISITS_TABLE_SQL_IDENT} v where v.ip_address is not null and v.occurred_at >= now() - interval '60 minutes'`),
      ])
      const ipCount = ipRows?.[0]?.c ?? 0
      res.json({ ok: true, onlineUsers: ipCount, via: 'database' })
      return
    }

    // No direct DB connection: attempt Supabase REST fallback using RPC for unique IPs
    if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { apikey: supabaseAnonKey, Accept: 'application/json', 'Content-Type': 'application/json' }
      const token = getBearerTokenFromRequest(req)
      if (token) headers.Authorization = `Bearer ${token}`
      const resp = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/count_unique_ips_last_minutes`, {
        method: 'POST',
        headers,
        body: JSON.stringify({ _minutes: 60 }),
      })
      if (resp.ok) {
        const val = await resp.json().catch(() => 0)
        const ipCount = Number(val) || 0
        res.json({ ok: true, onlineUsers: ipCount, via: 'supabase' })
        return
      }
    }
    respondFromMemory()
  } catch (e) {
    if (!respondFromMemory({ error: e?.message || 'DB query failed' })) {
      res.status(500).json({ ok: false, error: e?.message || 'DB query failed' })
    }
  }
})

// --- Global broadcast message system ---
// SSE client registry
const broadcastClients = new Set()

function sseWrite(res, event, data) {
  try {
    if (!res) return
    if (event) res.write(`event: ${event}\n`)
    const payload = typeof data === 'string' ? data : JSON.stringify(data)
    const lines = String(payload).split(/\r?\n/)
    for (const line of lines) res.write(`data: ${line}\n`)
    res.write('\n')
  } catch { }
}

async function getActiveBroadcastRow() {
  // Prefer direct SQL when available
  if (sql) {
    try {
      // Fetch broadcast first without join to be robust
      const rows = await sql`
        select 
          bm.id::text as id,
          bm.message,
          bm.severity,
          bm.created_at,
          bm.expires_at,
          bm.created_by::text as created_by
        from public.broadcast_messages bm
        where bm.removed_at is null and (bm.expires_at is null or bm.expires_at > now())
        order by bm.created_at desc
        limit 1
      `
      const row = Array.isArray(rows) && rows[0] ? rows[0] : null
      if (row && row.created_by) {
        try {
          const p = await sql`select coalesce(display_name, username, '') as name from public.profiles where id = ${row.created_by} limit 1`
          if (p && p[0]) row.admin_name = p[0].name
        } catch { /* ignore profile fetch error */ }
      }
      return row
    } catch (err) {
      console.error('[broadcast] sql fetch failed', err)
    }
  }
  // Supabase REST fallback for reads
  if (supabaseUrlEnv && supabaseAnonKey) {
    try {
      const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
      const url = `${supabaseUrlEnv}/rest/v1/broadcast_messages?removed_at=is.null&select=id,message,severity,created_at,expires_at,created_by&order=created_at.desc&limit=10`
      const r = await fetch(url, { headers })
      if (r.ok) {
        const arr = await r.json().catch(() => [])
        const now = Date.now()
        const valid = (Array.isArray(arr) ? arr : []).find((row) => {
          const ex = row?.expires_at ? Date.parse(row.expires_at) : null
          return !ex || ex > now
        })
        return valid || null
      }
    } catch { }
  }
  return null
}

function broadcastToAll(payload) {
  try {
    const enriched = { ...payload, serverTime: new Date().toISOString() }
    for (const res of Array.from(broadcastClients)) {
      sseWrite(res, 'broadcast', enriched)
    }
  } catch { }
}

function clearBroadcastForAll() {
  try {
    for (const res of Array.from(broadcastClients)) {
      sseWrite(res, 'clear', { ok: true })
    }
  } catch { }
}

// Public: fetch current active broadcast
app.get('/api/broadcast/active', async (_req, res) => {
  try {
    // Prevent caches from serving stale broadcast state
    try {
      res.setHeader('Cache-Control', 'no-store, no-cache, must-revalidate')
      res.setHeader('Pragma', 'no-cache')
    } catch { }
    const row = await getActiveBroadcastRow()
    const serverTime = new Date().toISOString()
    if (row) {
      res.json({
        ok: true,
        serverTime,
        broadcast: {
          id: String(row.id || ''),
          message: String(row.message || ''),
          severity: String(row.severity || 'info'),
          createdAt: row.created_at ? new Date(row.created_at).toISOString() : null,
          expiresAt: row.expires_at ? new Date(row.expires_at).toISOString() : null,
          createdBy: row.created_by ? String(row.created_by) : null,
          adminName: row.admin_name ? String(row.admin_name) : null,
        }
      })
    } else {
      res.json({ ok: true, serverTime, broadcast: null })
    }
  } catch (e) {
    res.status(500).json({ ok: false, error: e?.message || 'Failed to load broadcast' })
  }
})

// Public: Server-Sent Events stream for broadcast updates
app.get('/api/broadcast/stream', async (req, res) => {
  try {
    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8')
    res.setHeader('Cache-Control', 'no-cache, no-transform')
    res.setHeader('Connection', 'keep-alive')
    res.setHeader('X-Accel-Buffering', 'no')
    res.flushHeaders?.()

    // Send initial state (only broadcast if active exists; do not force-clear here)
    try {
      const row = await getActiveBroadcastRow()
      if (row) {
        sseWrite(res, 'broadcast', {
          id: String(row.id || ''),
          message: String(row.message || ''),
          severity: String(row.severity || 'info'),
          createdAt: row.created_at ? new Date(row.created_at).toISOString() : null,
          expiresAt: row.expires_at ? new Date(row.expires_at).toISOString() : null,
          createdBy: row.created_by ? String(row.created_by) : null,
          adminName: row.admin_name ? String(row.admin_name) : null,
          serverTime: new Date().toISOString(),
        })
      }
    } catch { }

    broadcastClients.add(res)
    const hb = setInterval(() => { try { res.write(': ping\n\n') } catch { } }, 15000)
    req.on('close', () => { try { clearInterval(hb) } catch { }; broadcastClients.delete(res) })
  } catch (e) {
    try { res.status(500).json({ error: e?.message || 'stream failed' }) } catch { }
  }
})

// User membership SSE: notify when the current user's garden memberships change
app.get('/api/self/memberships/stream', async (req, res) => {
  try {
    // Allow token via query param for EventSource
    let user = null
    try {
      const qToken = (req.query?.token || req.query?.access_token)
      if (qToken && supabaseServer) {
        const { data, error } = await supabaseServer.auth.getUser(String(qToken))
        if (!error && data?.user?.id) user = { id: data.user.id, email: data.user.email || null }
      }
    } catch { }
    if (!user) user = await getUserFromRequest(req)
    if (!user?.id) { res.status(401).json({ error: 'Unauthorized' }); return }

    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8')
    res.setHeader('Cache-Control', 'no-cache, no-transform')
    res.setHeader('Connection', 'keep-alive')
    res.setHeader('X-Accel-Buffering', 'no')
    res.flushHeaders?.()

    sseWrite(res, 'ready', { ok: true })

    const getSig = async () => {
      try {
        if (sql) {
          const rows = await sql`
            select gm.garden_id::text as garden_id
            from public.garden_members gm
            where gm.user_id = ${user.id}
            order by gm.garden_id asc
          `
          const list = (rows || []).map((r) => String(r.garden_id))
          return list.join(',')
        } else if (supabaseUrlEnv && supabaseAnonKey) {
          const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
          // Include Authorization from bearer header or token query param (EventSource)
          const bearer = getBearerTokenFromRequest(req) || (req.query?.token ? String(req.query.token) : (req.query?.access_token ? String(req.query.access_token) : null))
          if (bearer) Object.assign(headers, { Authorization: `Bearer ${bearer}` })
          const url = `${supabaseUrlEnv}/rest/v1/garden_members?user_id=eq.${encodeURIComponent(user.id)}&select=garden_id&order=garden_id.asc`
          const r = await fetch(url, { headers })
          const arr = r.ok ? (await r.json().catch(() => [])) : []
          const list = (arr || []).map((row) => String(row.garden_id))
          return list.join(',')
        }
      } catch { }
      return ''
    }

    let lastSig = await getSig()

    const poll = async () => {
      try {
        const next = await getSig()
        if (next !== lastSig) {
          lastSig = next
          sseWrite(res, 'memberships', { changed: true })
        }
      } catch { }
    }

    const iv = setInterval(poll, 1000)
    const hb = setInterval(() => { try { res.write(': ping\n\n') } catch { } }, 15000)
    req.on('close', () => { try { clearInterval(iv); clearInterval(hb) } catch { } })
  } catch (e) {
    try { res.status(500).json({ error: e?.message || 'stream failed' }) } catch { }
  }
})

// Private info lookup (self or admin)
app.get('/api/users/:id/private', async (req, res) => {
  try {
    const targetId = String(req.params.id || '').trim()
    if (!targetId) { res.status(400).json({ ok: false, error: 'user id required' }); return }
    const viewer = await getUserFromRequest(req)
    if (!viewer?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    let allowed = viewer.id === targetId
    if (!allowed) {
      try {
        allowed = await isAdminFromRequest(req)
      } catch { }
    }
    if (!allowed) { res.status(403).json({ ok: false, error: 'Forbidden' }); return }

    if (sql) {
      const rows = await sql`
        select u.id::text as id, u.email
        from auth.users u
        where u.id = ${targetId}
        limit 1
      `
      const row = Array.isArray(rows) && rows[0] ? rows[0] : null
      res.json({
        ok: true,
        user: row ? { id: String(row.id || targetId), email: row.email || null } : null,
      })
      return
    }

    if (supabaseUrlEnv && supabaseAnonKey) {
      try {
        const headers = { apikey: supabaseAnonKey, Accept: 'application/json', 'Content-Type': 'application/json' }
        const bearer = getBearerTokenFromRequest(req)
        if (bearer) headers['Authorization'] = `Bearer ${bearer}`
        const resp = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_user_private_info`, {
          method: 'POST',
          headers,
          body: JSON.stringify({ _user_id: targetId }),
        })
        if (resp.ok) {
          const body = await resp.json().catch(() => null)
          const row = Array.isArray(body) ? body[0] : body
          res.json({
            ok: true,
            user: row ? { id: String(row.id || targetId), email: row.email || null } : null,
          })
          return
        }
      } catch { }
    }

    res.status(503).json({ ok: false, error: 'Private info lookup unavailable' })
  } catch (e) {
    res.status(500).json({ ok: false, error: e?.message || 'Failed to load private info' })
  }
})

// User-wide Garden Activity SSE: pushes activity from all gardens the user belongs to
app.get('/api/self/gardens/activity/stream', async (req, res) => {
  try {
    // Resolve user from token param or cookie session
    let user = null
    try {
      const qToken = (req.query?.token || req.query?.access_token)
      if (qToken && supabaseServer) {
        const { data, error } = await supabaseServer.auth.getUser(String(qToken))
        if (!error && data?.user?.id) user = { id: data.user.id, email: data.user.email || null }
      }
    } catch { }
    if (!user) user = await getUserFromRequest(req)
    if (!user?.id) { res.status(401).json({ error: 'Unauthorized' }); return }

    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8')
    res.setHeader('Cache-Control', 'no-cache, no-transform')
    res.setHeader('Connection', 'keep-alive')
    res.setHeader('X-Accel-Buffering', 'no')
    res.flushHeaders?.()

    sseWrite(res, 'ready', { ok: true })

    const getGardenIdsCsv = async () => {
      try {
        if (sql) {
          const rows = await sql`
            select garden_id::text as garden_id from public.garden_members where user_id = ${user.id}
          `
          const list = (rows || []).map((r) => String(r.garden_id))
          return list
        } else if (supabaseUrlEnv && supabaseAnonKey) {
          const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
          const bearer = getBearerTokenFromRequest(req)
          if (bearer) Object.assign(headers, { Authorization: `Bearer ${bearer}` })
          const url = `${supabaseUrlEnv}/rest/v1/garden_members?user_id=eq.${encodeURIComponent(user.id)}&select=garden_id`
          const r = await fetch(url, { headers })
          const arr = r.ok ? (await r.json().catch(() => [])) : []
          const list = (arr || []).map((row) => String(row.garden_id))
          return list
        }
      } catch { }
      return []
    }

    let gardenIds = await getGardenIdsCsv()
    let lastSig = gardenIds.slice().sort().join(',')
    let lastSeen = new Date(Date.now() - 2 * 60 * 1000).toISOString()

    const poll = async () => {
      try {
        // Refresh membership set
        const nextIds = await getGardenIdsCsv()
        const nextSig = nextIds.slice().sort().join(',')
        if (nextSig !== lastSig) {
          gardenIds = nextIds
          lastSig = nextSig
          sseWrite(res, 'membership', { changed: true })
        }
        if (!gardenIds || gardenIds.length === 0) return
        if (sql) {
          const rows = await sql`
            select id::text as id, garden_id::text as garden_id, actor_id::text as actor_id, actor_name, actor_color, kind, message, plant_name, task_name, occurred_at
            from public.garden_activity_logs
            where garden_id = any(${sql.array(gardenIds)}) and occurred_at > ${lastSeen}
            order by occurred_at asc
            limit 500
          `
          for (const r of rows || []) {
            lastSeen = new Date(r.occurred_at).toISOString()
            sseWrite(res, 'activity', {
              id: String(r.id), gardenId: String(r.garden_id), actorId: r.actor_id || null, actorName: r.actor_name || null, actorColor: r.actor_color || null,
              kind: r.kind, message: r.message, plantName: r.plant_name || null, taskName: r.task_name || null, occurredAt: new Date(r.occurred_at).toISOString(),
            })
          }
        } else if (supabaseUrlEnv && supabaseAnonKey) {
          const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
          // Include Authorization from bearer header or token query param (EventSource)
          const bearer = getBearerTokenFromRequest(req) || (req.query?.token ? String(req.query.token) : (req.query?.access_token ? String(req.query.access_token) : null))
          if (bearer) Object.assign(headers, { Authorization: `Bearer ${bearer}` })
          // Build OR filter for multiple garden_ids: or=(garden_id.eq.id1,garden_id.eq.id2,...)
          const orExpr = gardenIds.length > 0 ? `or=(${gardenIds.map(id => `garden_id.eq.${id}`).join(',')})` : ''
          const qp = [orExpr, `occurred_at=gt.${lastSeen}`, 'select=id,garden_id,actor_id,actor_name,actor_color,kind,message,plant_name,task_name,occurred_at', 'order=occurred_at.asc', 'limit=500']
            .filter(Boolean)
            .map(s => encodeURI(s))
            .join('&')
          const url = `${supabaseUrlEnv}/rest/v1/garden_activity_logs?${qp}`
          const r = await fetch(url, { headers })
          if (r.ok) {
            const arr = await r.json().catch(() => [])
            for (const row of arr || []) {
              lastSeen = new Date(row.occurred_at).toISOString()
              sseWrite(res, 'activity', {
                id: String(row.id), gardenId: String(row.garden_id), actorId: row.actor_id || null, actorName: row.actor_name || null, actorColor: row.actor_color || null,
                kind: row.kind, message: row.message, plantName: row.plant_name || null, taskName: row.task_name || null, occurredAt: new Date(row.occurred_at).toISOString(),
              })
            }
          }
        }
      } catch { }
    }

    const iv = setInterval(poll, 1000)
    const hb = setInterval(() => { try { res.write(': ping\n\n') } catch { } }, 15000)
    req.on('close', () => { try { clearInterval(iv); clearInterval(hb) } catch { } })
  } catch (e) {
    try { res.status(500).json({ error: e?.message || 'stream failed' }) } catch { }
  }
})

// ---- Garden overview + realtime (SSE) ----

async function isGardenMember(req, gardenId, userIdOverride = null) {
  try {
    const user = userIdOverride ? { id: userIdOverride } : await getUserFromRequest(req)
    if (!user?.id) return false
    // Admins can access any garden
    try { if (await isAdminFromRequest(req)) return true } catch { }
    if (sql) {
      const rows = await sql`
        select 1 as ok from public.garden_members
        where garden_id = ${gardenId} and user_id = ${user.id}
        limit 1
      `
      return Array.isArray(rows) && rows.length > 0
    }
    if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
      const bearer = getBearerTokenFromRequest(req)
      if (bearer) Object.assign(headers, { Authorization: `Bearer ${bearer}` })
      const url = `${supabaseUrlEnv}/rest/v1/garden_members?garden_id=eq.${encodeURIComponent(gardenId)}&user_id=eq.${encodeURIComponent(user.id)}&select=garden_id&limit=1`
      const r = await fetch(url, { headers })
      if (r.ok) {
        const arr = await r.json().catch(() => [])
        return Array.isArray(arr) && arr.length > 0
      }
    }
    return false
  } catch {
    return false
  }
}

async function isGardenOwner(req, gardenId, userIdOverride = null) {
  try {
    const user = userIdOverride ? { id: userIdOverride } : await getUserFromRequest(req)
    if (!user?.id) return false
    try { if (await isAdminFromRequest(req)) return true } catch { }
    if (sql) {
      const rows = await sql`
        select role from public.garden_members
        where garden_id = ${gardenId} and user_id = ${user.id}
        limit 1
      `
      if (Array.isArray(rows) && rows.length > 0) {
        return String(rows[0].role || '').toLowerCase() === 'owner'
      }
    }
    if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
      const bearer = getBearerTokenFromRequest(req)
      if (bearer) Object.assign(headers, { Authorization: `Bearer ${bearer}` })
      const url = `${supabaseUrlEnv}/rest/v1/garden_members?garden_id=eq.${encodeURIComponent(gardenId)}&user_id=eq.${encodeURIComponent(user.id)}&select=role&limit=1`
      const r = await fetch(url, { headers })
      if (r.ok) {
        const arr = await r.json().catch(() => [])
        if (Array.isArray(arr) && arr.length > 0) {
          return String(arr[0].role || '').toLowerCase() === 'owner'
        }
      }
    }
    return false
  } catch {
    return false
  }
}

async function getGardenCoverRow(gardenId) {
  if (sql) {
    const rows = await sql`
      select id::text as id, cover_image_url, name, created_by::text as owner_id
      from public.gardens
      where id = ${gardenId}
      limit 1
    `
    return Array.isArray(rows) && rows.length > 0 ? rows[0] : null
  }
  if (supabaseServiceClient) {
    const { data, error } = await supabaseServiceClient
      .from('gardens')
      .select('id, cover_image_url, name, created_by')
      .eq('id', gardenId)
      .maybeSingle()
    if (error) throw error
    return data ? { ...data, owner_id: data.created_by } : null
  }
  return null
}

async function updateGardenCoverImage(gardenId, publicUrl) {
  if (sql) {
    await sql`
      update public.gardens
      set cover_image_url = ${publicUrl}
      where id = ${gardenId}
    `
    return
  }
  if (supabaseServiceClient) {
    const { error } = await supabaseServiceClient
      .from('gardens')
      .update({ cover_image_url: publicUrl })
      .eq('id', gardenId)
    if (error) throw error
    return
  }
  throw new Error('Database connection not configured')
}

app.post('/api/garden/:id/upload-cover', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service role key not configured for uploads' })
    return
  }
  const gardenId = String(req.params.id || '').trim()
  if (!gardenId) {
    res.status(400).json({ error: 'Garden id is required' })
    return
  }
  const user = await getUserFromRequest(req)
  if (!user?.id) {
    res.status(401).json({ error: 'Unauthorized' })
    return
  }

  // Rate limit: 50 image uploads per hour per user
  if (await checkRateLimit('imageUpload', req, res, user)) {
    return
  }

  const canEdit = await isGardenOwner(req, gardenId, user.id)
  if (!canEdit) {
    res.status(403).json({ error: 'Forbidden' })
    return
  }

  singleGardenCoverUpload(req, res, (err) => {
    if (err) {
      const message =
        err?.code === 'LIMIT_FILE_SIZE'
          ? `File exceeds the maximum size of ${(gardenCoverMaxBytes / (1024 * 1024)).toFixed(1)} MB`
          : err?.message || 'Failed to process upload'
      res.status(400).json({ error: message })
      return
    }
    ; (async () => {
      const file = req.file
      if (!file) {
        res.status(400).json({ error: 'Missing image file (expected form field "file")' })
        return
      }
      const gardenRow = await getGardenCoverRow(gardenId)
      if (!gardenRow) {
        res.status(404).json({ error: 'Garden not found' })
        return
      }
      let uploaderDisplayName = null
      try {
        uploaderDisplayName = await getAdminProfileName(user.id)
      } catch { }
      const previousUrl = gardenRow.cover_image_url || null
      const mime = (file.mimetype || '').toLowerCase()
      if (!mime.startsWith('image/')) {
        res.status(400).json({ error: 'Only image uploads are supported' })
        return
      }
      if (!adminUploadAllowedMimeTypes.has(mime)) {
        res.status(400).json({ error: `Unsupported image type: ${mime}` })
        return
      }
      if (!file.buffer || file.buffer.length === 0) {
        res.status(400).json({ error: 'Uploaded file is empty' })
        return
      }

      let optimizedBuffer
      try {
        optimizedBuffer = await sharp(file.buffer)
          .rotate()
          .resize({
            width: gardenCoverMaxDimension,
            height: gardenCoverMaxDimension,
            fit: 'inside',
            withoutEnlargement: true,
            fastShrinkOnLoad: true,
          })
          .webp({
            quality: gardenCoverWebpQuality,
            effort: 5,
            smartSubsample: true,
          })
          .toBuffer()
      } catch (sharpErr) {
        console.error('[garden-cover] failed to convert image to webp', sharpErr)
        res.status(400).json({ error: 'Failed to convert image. Please upload a valid image file.' })
        return
      }

      const baseName = sanitizeUploadBaseName(file.originalname)
      const gardenSegment = sanitizePathSegment(`garden-${gardenId}`, 'garden')
      const typeSegment = gardenSegment ? `cover-${gardenSegment}` : 'cover'
      const objectPath = buildUploadObjectPath(baseName, typeSegment, gardenCoverUploadPrefix)

      try {
        const { error: uploadError } = await supabaseServiceClient
          .storage
          .from(gardenCoverUploadBucket)
          .upload(objectPath, optimizedBuffer, {
            cacheControl: '31536000',
            contentType: 'image/webp',
            upsert: false,
          })
        if (uploadError) {
          throw new Error(uploadError.message || 'Supabase storage upload failed')
        }
      } catch (storageErr) {
        console.error('[garden-cover] supabase storage upload failed', storageErr)
        res.status(500).json({ error: storageErr?.message || 'Failed to store optimized image' })
        return
      }

      const { data: publicData } = supabaseServiceClient
        .storage
        .from(gardenCoverUploadBucket)
        .getPublicUrl(objectPath)
      const publicUrl = publicData?.publicUrl || null
      // Transform URL to use media proxy (hides Supabase project URL)
      const proxyUrl = supabaseStorageToMediaProxy(publicUrl)
      if (!proxyUrl) {
        res.status(500).json({ error: 'Failed to generate public URL for cover image' })
        return
      }

      try {
        // Store the proxy URL in the database for display
        await updateGardenCoverImage(gardenId, proxyUrl)
      } catch (dbErr) {
        console.error('[garden-cover] failed to update garden cover', dbErr)
        res.status(500).json({ error: dbErr?.message || 'Failed to update garden cover' })
        return
      }

      let deletedPrevious = false
      if (previousUrl && previousUrl !== proxyUrl) {
        try {
          const result = await deleteGardenCoverObject(previousUrl)
          deletedPrevious = Boolean(result.deleted)
        } catch { }
      }

      const compressionPercent =
        file.size > 0
          ? Math.max(0, Math.round(100 - (optimizedBuffer.length / file.size) * 100))
          : 0

      try {
        await recordAdminMediaUpload({
          adminId: user.id,
          adminEmail: user.email || null,
          adminName: uploaderDisplayName,
          bucket: gardenCoverUploadBucket,
          path: objectPath,
          publicUrl: proxyUrl,
          mimeType: 'image/webp',
          originalMimeType: mime,
          sizeBytes: optimizedBuffer.length,
          originalSizeBytes: file.size,
          quality: gardenCoverWebpQuality,
          compressionPercent,
          uploadSource: 'garden_cover',
          metadata: {
            source: 'garden_cover',
            gardenId,
            gardenName: gardenRow.name || null,
            originalName: file.originalname,
            previousUrl,
          },
          createdAt: new Date().toISOString(),
        })
      } catch (recordErr) {
        console.error('[garden-cover] failed to record media upload', recordErr)
      }

      res.json({
        ok: true,
        gardenId,
        bucket: gardenCoverUploadBucket,
        path: objectPath,
        url: proxyUrl,
        mimeType: 'image/webp',
        size: optimizedBuffer.length,
        originalMimeType: mime,
        originalSize: file.size,
        quality: gardenCoverWebpQuality,
        maxDimension: gardenCoverMaxDimension,
        compressionPercent,
        deletedPrevious,
      })
    })().catch((uploadErr) => {
      console.error('[garden-cover] unexpected failure', uploadErr)
      if (!res.headersSent) {
        res.status(500).json({ error: 'Unexpected upload failure' })
      }
    })
  })
})

app.post('/api/garden/:id/cover/cleanup', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service role key not configured for storage cleanup' })
    return
  }
  const gardenId = String(req.params.id || '').trim()
  if (!gardenId) {
    res.status(400).json({ error: 'Garden id is required' })
    return
  }
  const user = await getUserFromRequest(req)
  if (!user?.id) {
    res.status(401).json({ error: 'Unauthorized' })
    return
  }
  const canEdit = await isGardenOwner(req, gardenId, user.id)
  if (!canEdit) {
    res.status(403).json({ error: 'Forbidden' })
    return
  }
  const targetUrl = String(req.body?.url || '').trim()
  if (!targetUrl) {
    res.status(400).json({ error: 'url is required' })
    return
  }
  try {
    const result = await deleteGardenCoverObject(targetUrl)
    res.json({ ok: true, deleted: Boolean(result.deleted), reason: result.reason })
  } catch (err) {
    res.status(500).json({ error: err?.message || 'Failed to delete cover image' })
  }
})

// === Plant Scan API Endpoints ===

// Combined upload + identify endpoint
// Uses the same upload pattern as Admin/Garden Cover/Messages uploads
// Optimizes image, uploads to storage, calls Kindwise API, returns everything
app.post('/api/scan/upload-and-identify', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service role key not configured for uploads' })
    return
  }
  const user = await getUserFromRequest(req)
  if (!user?.id) {
    res.status(401).json({ error: 'You must be signed in to scan plants' })
    return
  }

  // Rate limit: 30 scans per hour per user
  if (await checkRateLimit('scan', req, res, user)) {
    return
  }

  if (!KINDWISE_API_KEY) {
    console.error('[scan] KINDWISE API key not configured')
    res.status(503).json({ error: 'Plant identification service is not configured' })
    return
  }

  // Ensure admin_media_uploads table exists for tracking
  try {
    await ensureAdminMediaUploadsTable()
  } catch { }

  singleScanImageUpload(req, res, (err) => {
    if (err) {
      const message =
        err?.code === 'LIMIT_FILE_SIZE'
          ? `File exceeds the maximum size of ${(scanImageMaxBytes / (1024 * 1024)).toFixed(1)} MB`
          : err?.message || 'Failed to process upload'
      res.status(400).json({ error: message })
      return
    }
    ;(async () => {
      const file = req.file
      if (!file) {
        res.status(400).json({ error: 'Missing image file (expected form field "file")' })
        return
      }
      const mime = (file.mimetype || '').toLowerCase()
      if (!mime.startsWith('image/')) {
        res.status(400).json({ error: 'Only image uploads are supported' })
        return
      }
      const allowedMimes = new Set([
        'image/jpeg', 'image/png', 'image/webp', 'image/gif',
        'image/heic', 'image/heif', 'image/avif'
      ])
      if (!allowedMimes.has(mime)) {
        res.status(400).json({ error: `Unsupported image type: ${mime}` })
        return
      }
      if (!file.buffer || file.buffer.length === 0) {
        res.status(400).json({ error: 'Uploaded file is empty' })
        return
      }

      // Parse optional location from form data
      const latitude = req.body?.latitude ? parseFloat(req.body.latitude) : undefined
      const longitude = req.body?.longitude ? parseFloat(req.body.longitude) : undefined
      
      // Parse optional classification_level from form data
      // Options: 'all' (default - includes cultivars/varieties), 'species', 'genus' (genus only)
      // Default to 'all' for maximum detail including cultivars and varieties
      const classificationLevel = req.body?.classification_level || 'all'
      const validClassificationLevels = ['species', 'all', 'genus']
      const sanitizedClassificationLevel = validClassificationLevels.includes(classificationLevel) 
        ? classificationLevel 
        : 'all'

      let optimizedBuffer
      let finalMimeType = 'image/webp'

      // GIFs are kept as-is
      if (mime === 'image/gif') {
        optimizedBuffer = file.buffer
        finalMimeType = 'image/gif'
      } else {
        try {
          optimizedBuffer = await sharp(file.buffer)
            .rotate()
            .resize({
              width: scanImageMaxDimension,
              height: scanImageMaxDimension,
              fit: 'inside',
              withoutEnlargement: true,
              fastShrinkOnLoad: true,
            })
            .webp({
              quality: scanImageWebpQuality,
              effort: 5,
              smartSubsample: true,
            })
            .toBuffer()
        } catch (sharpErr) {
          console.error('[scan] failed to convert image to webp', sharpErr)
          res.status(400).json({ error: 'Failed to convert image. Please upload a valid image file.' })
          return
        }
      }

      // Convert optimized buffer to base64 for Kindwise API
      const optimizedBase64 = `data:${finalMimeType};base64,${optimizedBuffer.toString('base64')}`

      // Call Kindwise API with the optimized image
      let identificationResult = null
      try {
        const requestBody = {
          images: [optimizedBase64],
          similar_images: true,
          classification_level: sanitizedClassificationLevel,
        }
        if (latitude !== undefined && longitude !== undefined && !isNaN(latitude) && !isNaN(longitude)) {
          requestBody.latitude = latitude
          requestBody.longitude = longitude
        }

        console.log('[scan] Calling Kindwise API for user:', user.id, 'classification_level:', sanitizedClassificationLevel)

        const apiResponse = await fetch('https://plant.id/api/v3/identification', {
          method: 'POST',
          headers: {
            'Api-Key': KINDWISE_API_KEY,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(requestBody),
        })

        if (!apiResponse.ok) {
          const errorText = await apiResponse.text()
          console.error('[scan] Kindwise API error:', apiResponse.status, errorText)
          res.status(502).json({ 
            error: 'Plant identification service error', 
            details: `API returned ${apiResponse.status}` 
          })
          return
        }

        identificationResult = await apiResponse.json()
        console.log('[scan] Kindwise API success, status:', identificationResult.status)
      } catch (apiErr) {
        console.error('[scan] Error calling Kindwise API:', apiErr?.message || apiErr)
        res.status(500).json({ error: 'Failed to identify plant', details: apiErr?.message })
        return
      }

      // Upload optimized image to storage
      const baseName = sanitizeUploadBaseName(file.originalname)
      const timestamp = Date.now()
      const randomId = Math.random().toString(36).substring(2, 10)
      const ext = finalMimeType === 'image/gif' ? 'gif' : 'webp'
      const objectPath = `${scanImageUploadPrefix}/${user.id}/${timestamp}-${baseName}-${randomId}.${ext}`

      try {
        const { error: uploadError } = await supabaseServiceClient
          .storage
          .from(scanImageUploadBucket)
          .upload(objectPath, optimizedBuffer, {
            cacheControl: '31536000',
            contentType: finalMimeType,
            upsert: false,
          })
        if (uploadError) {
          throw new Error(uploadError.message || 'Supabase storage upload failed')
        }
      } catch (storageErr) {
        console.error('[scan] supabase storage upload failed', storageErr)
        res.status(500).json({ error: storageErr?.message || 'Failed to store image' })
        return
      }

      const { data: publicData } = supabaseServiceClient
        .storage
        .from(scanImageUploadBucket)
        .getPublicUrl(objectPath)
      const publicUrl = publicData?.publicUrl || null
      const proxyUrl = supabaseStorageToMediaProxy(publicUrl)
      if (!proxyUrl) {
        res.status(500).json({ error: 'Failed to generate public URL for scan image' })
        return
      }

      const compressionPercent =
        file.size > 0 && finalMimeType !== 'image/gif'
          ? Math.max(0, Math.round(100 - (optimizedBuffer.length / file.size) * 100))
          : 0

      // Record to global image database
      let uploaderDisplayName = null
      try {
        uploaderDisplayName = await getAdminProfileName(user.id)
      } catch { }
      
      try {
        await recordAdminMediaUpload({
          adminId: user.id,
          adminEmail: user.email || null,
          adminName: uploaderDisplayName,
          bucket: scanImageUploadBucket,
          path: objectPath,
          publicUrl: proxyUrl,
          mimeType: finalMimeType,
          originalMimeType: mime,
          sizeBytes: optimizedBuffer.length,
          originalSizeBytes: file.size,
          quality: finalMimeType === 'image/gif' ? null : scanImageWebpQuality,
          compressionPercent,
          uploadSource: 'plant_scan',
          metadata: {
            source: 'plant_scan',
            originalName: file.originalname,
            userId: user.id,
          },
          createdAt: new Date().toISOString(),
        })
      } catch (recordErr) {
        console.error('[scan] failed to record media upload', recordErr)
      }

      // Return combined result
      res.json({
        ok: true,
        upload: {
          url: proxyUrl,
          bucket: scanImageUploadBucket,
          path: objectPath,
          mimeType: finalMimeType,
          size: optimizedBuffer.length,
          originalMimeType: mime,
          originalSize: file.size,
          compressionPercent,
        },
        identification: identificationResult,
      })
    })().catch((err) => {
      console.error('[scan] unexpected failure', err)
      if (!res.headersSent) {
        res.status(500).json({ error: 'Unexpected failure during scan' })
      }
    })
  })
})

// Upload bug screenshot for bug reports
// Endpoint: POST /api/bug-report/upload-screenshot
app.post('/api/bug-report/upload-screenshot', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(500).json({ error: 'Supabase service role key not configured for uploads' })
    return
  }

  const user = await getUserFromRequest(req)
  if (!user?.id) {
    res.status(401).json({ error: 'You must be signed in to upload bug screenshots' })
    return
  }

  // Rate limit: 10 bug reports per hour per IP (spam prevention)
  if (await checkRateLimit('bugReport', req, res, user)) {
    return
  }

  // Verify user has bug_catcher role
  let hasBugCatcherRole = false
  try {
    const { data: profileData } = await supabaseServiceClient
      .from('profiles')
      .select('roles')
      .eq('id', user.id)
      .single()
    if (profileData?.roles && Array.isArray(profileData.roles)) {
      hasBugCatcherRole = profileData.roles.includes('bug_catcher')
    }
  } catch (err) {
    console.error('[bug-screenshot] failed to check user role', err)
  }

  if (!hasBugCatcherRole) {
    res.status(403).json({ error: 'Only Bug Catchers can upload bug screenshots' })
    return
  }

  singleBugScreenshotUpload(req, res, (err) => {
    if (err) {
      const message =
        err?.code === 'LIMIT_FILE_SIZE'
          ? `File exceeds the maximum size of ${(bugScreenshotMaxBytes / (1024 * 1024)).toFixed(1)} MB`
          : err?.message || 'Failed to process upload'
      res.status(400).json({ error: message })
      return
    }
    ;(async () => {
      const file = req.file
      if (!file) {
        res.status(400).json({ error: 'Missing image file (expected form field "file")' })
        return
      }

      const mime = (file.mimetype || '').toLowerCase()
      const allowedMimes = [
        'image/jpeg',
        'image/png',
        'image/webp',
        'image/gif',
        'image/heic',
        'image/heif',
        'image/avif',
      ]
      if (!allowedMimes.includes(mime)) {
        res.status(400).json({
          error: `Unsupported image type: ${mime}. Allowed: JPEG, PNG, WebP, GIF, HEIC, AVIF`,
        })
        return
      }

      if (!file.buffer || file.buffer.length === 0) {
        res.status(400).json({ error: 'Uploaded file is empty' })
        return
      }

      let optimizedBuffer
      let finalMimeType = 'image/webp'

      // GIFs are kept as-is to preserve animation
      if (mime === 'image/gif') {
        optimizedBuffer = file.buffer
        finalMimeType = 'image/gif'
      } else {
        try {
          optimizedBuffer = await sharp(file.buffer)
            .rotate()
            .resize({
              width: bugScreenshotMaxDimension,
              height: bugScreenshotMaxDimension,
              fit: 'inside',
              withoutEnlargement: true,
              fastShrinkOnLoad: true,
            })
            .webp({
              quality: bugScreenshotWebpQuality,
              effort: 5,
              smartSubsample: true,
            })
            .toBuffer()
        } catch (sharpErr) {
          console.error('[bug-screenshot] failed to convert image to webp', sharpErr)
          res.status(400).json({ error: 'Failed to convert image. Please upload a valid image file.' })
          return
        }
      }

      const baseName = sanitizeUploadBaseName(file.originalname)
      const userSegment = sanitizePathSegment(`user-${user.id}`, 'user')
      const timestamp = Date.now()
      const typeSegment = userSegment ? `bug-${userSegment}-${timestamp}` : `bug-${timestamp}`
      // Use correct extension based on final mime type (gif if preserved, webp if converted)
      const finalExtension = finalMimeType === 'image/gif' ? 'gif' : 'webp'
      const objectPath = buildUploadObjectPath(baseName, typeSegment, bugScreenshotUploadPrefix, finalExtension)

      try {
        const { error: uploadError } = await supabaseServiceClient
          .storage
          .from(bugScreenshotUploadBucket)
          .upload(objectPath, optimizedBuffer, {
            cacheControl: '31536000',
            contentType: finalMimeType,
            upsert: false,
          })
        if (uploadError) {
          throw new Error(uploadError.message || 'Supabase storage upload failed')
        }
      } catch (storageErr) {
        console.error('[bug-screenshot] supabase storage upload failed', storageErr)
        res.status(500).json({ error: storageErr?.message || 'Failed to store image' })
        return
      }

      const { data: publicData } = supabaseServiceClient
        .storage
        .from(bugScreenshotUploadBucket)
        .getPublicUrl(objectPath)
      const publicUrl = publicData?.publicUrl || null
      // Transform URL to use media proxy (hides Supabase project URL)
      const proxyUrl = supabaseStorageToMediaProxy(publicUrl)
      if (!proxyUrl) {
        res.status(500).json({ error: 'Failed to generate public URL for screenshot' })
        return
      }

      const compressionPercent =
        file.size > 0
          ? Math.max(0, Math.round(100 - (optimizedBuffer.length / file.size) * 100))
          : 0

      // Get user display name for media tracking
      let uploaderDisplayName = 'Unknown'
      try {
        const { data: pdata } = await supabaseServiceClient
          .from('profiles')
          .select('display_name')
          .eq('id', user.id)
          .maybeSingle()
        if (pdata?.display_name) {
          uploaderDisplayName = pdata.display_name
        }
      } catch {
        /* ignore */
      }

      // Record in admin media uploads for tracking
      try {
        await recordAdminMediaUpload({
          adminId: user.id,
          adminEmail: user.email || null,
          adminName: uploaderDisplayName,
          bucket: bugScreenshotUploadBucket,
          path: objectPath,
          publicUrl: proxyUrl,
          mimeType: finalMimeType,
          originalMimeType: mime,
          sizeBytes: optimizedBuffer.length,
          originalSizeBytes: file.size,
          quality: finalMimeType === 'image/gif' ? null : bugScreenshotWebpQuality,
          compressionPercent,
          uploadSource: 'bug_screenshot',
          metadata: {
            source: 'bug_screenshot',
            originalName: file.originalname,
            userId: user.id,
          },
          createdAt: new Date().toISOString(),
        })
      } catch (recordErr) {
        console.error('[bug-screenshot] failed to record media upload', recordErr)
      }

      res.json({
        ok: true,
        url: proxyUrl,
        bucket: bugScreenshotUploadBucket,
        path: objectPath,
        mimeType: finalMimeType,
        size: optimizedBuffer.length,
        originalMimeType: mime,
        originalSize: file.size,
        compressionPercent,
      })
    })().catch((err) => {
      console.error('[bug-screenshot] unexpected failure', err)
      if (!res.headersSent) {
        res.status(500).json({ error: 'Unexpected failure during upload' })
      }
    })
  })
})

// DELETE a garden (and its cover image from storage)
app.delete('/api/garden/:id', async (req, res) => {
  if (!supabaseServiceClient) {
    res.status(503).json({ error: 'Garden deletion is not configured on this server' })
    return
  }
  const gardenId = String(req.params.id || '').trim()
  if (!gardenId) {
    res.status(400).json({ error: 'Garden id is required' })
    return
  }
  const user = await getUserFromRequest(req)
  if (!user?.id) {
    res.status(401).json({ error: 'Unauthorized' })
    return
  }
  const canDelete = await isGardenOwner(req, gardenId, user.id)
  if (!canDelete) {
    res.status(403).json({ error: 'Forbidden - only garden owners can delete a garden' })
    return
  }

  try {
    // 1. Get the garden's cover image URL before deleting
    const gardenRow = await getGardenCoverRow(gardenId)
    const coverImageUrl = gardenRow?.cover_image_url || null

    // 2. Delete the garden row (cascade will delete related rows)
    const { error: deleteErr } = await supabaseServiceClient
      .from('gardens')
      .delete()
      .eq('id', gardenId)

    if (deleteErr) {
      console.error('[garden-delete] Failed to delete garden row', deleteErr)
      res.status(500).json({ error: 'Failed to delete garden' })
      return
    }

    // 3. Delete the cover image from storage if it exists
    let coverDeleted = false
    let coverDeleteReason = 'no_cover'
    if (coverImageUrl) {
      try {
        const result = await deleteGardenCoverObject(coverImageUrl)
        coverDeleted = Boolean(result.deleted)
        coverDeleteReason = result.reason || (coverDeleted ? 'deleted' : 'unknown')
      } catch (coverErr) {
        console.error('[garden-delete] Failed to delete cover image from storage', coverErr)
        coverDeleteReason = coverErr?.message || 'delete_failed'
      }
    }

    res.json({
      ok: true,
      gardenId,
      coverDeleted,
      coverDeleteReason,
    })
  } catch (err) {
    console.error('[garden-delete] Unexpected error', err)
    res.status(500).json({ error: err?.message || 'Failed to delete garden' })
  }
})

app.get('/api/garden/:id/activity', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    const member = await isGardenMember(req, gardenId, user.id)
    if (!member) { res.status(403).json({ ok: false, error: 'Forbidden' }); return }

    const dayParam = typeof req.query.day === 'string' ? req.query.day : ''
    const dayIso = /^\d{4}-\d{2}-\d{2}$/.test(dayParam) ? dayParam : new Date().toISOString().slice(0, 10)
    const start = new Date(`${dayIso}T00:00:00.000Z`).toISOString()
    const endExclusive = new Date(new Date(`${dayIso}T00:00:00.000Z`).getTime() + 24 * 3600 * 1000).toISOString()

    let rows = []
    if (sql) {
      rows = await sql`
        select
          id::text as id,
          garden_id::text as garden_id,
          actor_id::text as actor_id,
          actor_name,
          actor_color,
          kind,
          message,
          plant_name,
          task_name,
          occurred_at
        from public.garden_activity_logs
        where garden_id = ${gardenId}
          and occurred_at >= ${start}
          and occurred_at < ${endExclusive}
        order by occurred_at desc
      `
    } else if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
      const bearer = getAuthTokenFromRequest(req)
      if (bearer) Object.assign(headers, { Authorization: `Bearer ${bearer}` })
      const url = `${supabaseUrlEnv}/rest/v1/garden_activity_logs?garden_id=eq.${encodeURIComponent(gardenId)}&occurred_at=gte.${encodeURIComponent(start)}&select=id,garden_id,actor_id,actor_name,actor_color,kind,message,plant_name,task_name,occurred_at&order=occurred_at.desc&limit=200`
      const resp = await fetch(url, { headers })
      if (resp.ok) {
        const arr = await resp.json().catch(() => [])
        rows = Array.isArray(arr) ? arr.filter((r) => {
          try {
            const ts = new Date(r.occurred_at).toISOString()
            return ts >= start && ts < endExclusive
          } catch {
            return false
          }
        }) : []
      }
    }

    const activity = []
    if (Array.isArray(rows)) {
      for (const row of rows) {
        const occurredAtRaw = row?.occurred_at instanceof Date
          ? row.occurred_at.toISOString()
          : (row?.occurred_at ? String(row.occurred_at) : null)
        if (occurredAtRaw == null || occurredAtRaw === '') continue
        activity.push({
          id: String(row.id),
          gardenId: String(row.garden_id ?? row.gardenId ?? gardenId),
          actorId: row.actor_id ? String(row.actor_id) : row.actorId ? String(row.actorId) : null,
          actorName: row.actor_name ?? row.actorName ?? null,
          actorColor: row.actor_color ?? row.actorColor ?? null,
          kind: row.kind,
          message: row.message,
          plantName: row.plant_name ?? row.plantName ?? null,
          taskName: row.task_name ?? row.taskName ?? null,
          occurredAt: occurredAtRaw,
        })
      }
    }

    res.json({ ok: true, activity })
  } catch (e) {
    try { res.status(500).json({ ok: false, error: e?.message || 'failed to load activity' }) } catch { }
  }
})

app.get('/api/garden/:id/tasks', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const startDay = typeof req.query.start === 'string' ? req.query.start : ''
    const endDay = typeof req.query.end === 'string' ? req.query.end : ''
    const dayPattern = /^\d{4}-\d{2}-\d{2}$/
    if (!dayPattern.test(startDay) || !dayPattern.test(endDay)) {
      res.status(400).json({ ok: false, error: 'start and end must be YYYY-MM-DD' })
      return
    }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    const member = await isGardenMember(req, gardenId, user.id)
    if (!member) { res.status(403).json({ ok: false, error: 'Forbidden' }); return }

    let rows = []
    if (sql) {
      rows = await sql`
        select
          id::text as id,
          garden_id::text as garden_id,
          day,
          task_type,
          garden_plant_ids,
          success
        from public.garden_tasks
        where garden_id = ${gardenId}
          and day >= ${startDay}
          and day <= ${endDay}
        order by day asc
      `
    } else if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
      const bearer = getAuthTokenFromRequest(req)
      if (bearer) Object.assign(headers, { Authorization: `Bearer ${bearer}` })
      const query = [
        'select=id,garden_id,day,task_type,garden_plant_ids,success',
        `garden_id=eq.${encodeURIComponent(gardenId)}`,
        `day=gte.${encodeURIComponent(startDay)}`,
        `day=lte.${encodeURIComponent(endDay)}`,
        'order=day.asc',
      ].join('&')
      const resp = await fetch(`${supabaseUrlEnv}/rest/v1/garden_tasks?${query}`, { headers })
      if (!resp.ok) {
        const text = await resp.text().catch(() => '')
        res.status(resp.status).json({ ok: false, error: text || 'failed to load tasks' })
        return
      }
      rows = await resp.json().catch(() => [])
    } else {
      res.status(503).json({ ok: false, error: 'Database not configured' })
      return
    }

    const tasks = (rows || []).map((r) => ({
      id: String(r.id),
      gardenId: String(r.garden_id),
      day: (() => {
        if (r.day instanceof Date) return r.day.toISOString().slice(0, 10)
        return String(r.day || '').slice(0, 10)
      })(),
      taskType: String(r.task_type || 'watering'),
      gardenPlantIds: Array.isArray(r.garden_plant_ids) ? r.garden_plant_ids : [],
      success: Boolean(r.success),
    }))
    res.json({ ok: true, tasks })
  } catch (e) {
    res.status(500).json({ ok: false, error: e?.message || 'failed to load tasks' })
  }
})

app.post('/api/garden/:id/activity', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequest(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }

    // Rate limit: 100 activity logs per hour per user
    if (await checkRateLimit('gardenActivity', req, res, user)) {
      return
    }

    const member = await isGardenMember(req, gardenId, user.id)
    if (!member) { res.status(403).json({ ok: false, error: 'Forbidden' }); return }

    const body = req.body || {}
    const kindRaw = typeof body.kind === 'string' ? body.kind.trim() : ''
    const messageRaw = typeof body.message === 'string' ? body.message.trim() : ''
    if (!kindRaw || !messageRaw) { res.status(400).json({ ok: false, error: 'kind and message required' }); return }
    const plantName = typeof body.plantName === 'string' ? body.plantName : null
    const taskName = typeof body.taskName === 'string' ? body.taskName : null
    const actorColor = typeof body.actorColor === 'string' ? body.actorColor : null

    if (sql) {
      let actorName = null
      try {
        // First try profiles table for display_name
        const nameRows = await sql`select display_name from public.profiles where id = ${user.id} limit 1`
        if (Array.isArray(nameRows) && nameRows[0]?.display_name) {
          actorName = nameRows[0].display_name
        } else {
          // Fallback to email username from auth.users
          const emailRows = await sql`select email from auth.users where id = ${user.id} limit 1`
          if (Array.isArray(emailRows) && emailRows[0]?.email) {
            actorName = emailRows[0].email.split('@')[0] || null
          }
        }
      } catch { }
      const nowIso = new Date().toISOString()
      await sql`
        insert into public.garden_activity_logs (garden_id, actor_id, actor_name, actor_color, kind, message, plant_name, task_name, occurred_at)
        values (${gardenId}, ${user.id}, ${actorName}, ${actorColor || null}, ${kindRaw}, ${messageRaw}, ${plantName || null}, ${taskName || null}, ${nowIso})
      `
      res.json({ ok: true })
      return
    }

    if (supabaseUrlEnv && supabaseAnonKey) {
      const headers = { apikey: supabaseAnonKey, Accept: 'application/json', 'Content-Type': 'application/json' }
      const bearer = getBearerTokenFromRequest(req)
      if (bearer) Object.assign(headers, { Authorization: `Bearer ${bearer}` })
      const payload = {
        _garden_id: gardenId,
        _kind: kindRaw,
        _message: messageRaw,
        _plant_name: plantName,
        _task_name: taskName,
        _actor_color: actorColor,
      }
      const resp = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/log_garden_activity`, {
        method: 'POST',
        headers,
        body: JSON.stringify(payload),
      })
      if (!resp.ok) {
        const text = await resp.text().catch(() => '')
        res.status(resp.status).json({ ok: false, error: text || 'failed to log activity' })
        return
      }
      res.json({ ok: true })
      return
    }

    res.status(503).json({ ok: false, error: 'activity logging unavailable' })
  } catch (e) {
    try { res.status(500).json({ ok: false, error: e?.message || 'failed to log activity' }) } catch { }
  }
})

// Batched initial load for a garden
app.get('/api/garden/:id/overview', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }

    // Try to get user (may be null for unauthenticated requests)
    const user = await getUserFromRequest(req).catch(() => null)
    const isMember = user?.id ? await isGardenMember(req, gardenId, user.id).catch(() => false) : false

    let garden = null
    let plants = []
    let members = []
    const serverNow = new Date().toISOString()

    // First, fetch garden to check privacy
    if (sql) {
      // Try with privacy column first, then progressively simpler fallbacks
      let gRows = []
      let gardenQuerySuccess = false

      // Attempt 1: Full query with privacy, streak, location, preferred_language, and hide_ai_chat
      try {
        console.log('[overview] Fetching garden', gardenId, '(attempt 1: full query)')
        gRows = await sql`
          select id::text as id, name, cover_image_url, created_by::text as created_by, created_at, coalesce(streak, 0)::int as streak, coalesce(privacy, 'public') as privacy,
                 location_city, location_country, location_timezone, location_lat, location_lon, coalesce(preferred_language, 'en') as preferred_language,
                 coalesce(hide_ai_chat, false) as hide_ai_chat
          from public.gardens where id = ${gardenId} limit 1
        `
        console.log('[overview] Garden query succeeded (attempt 1), rows:', gRows?.length || 0)
        gardenQuerySuccess = true
      } catch (e1) {
        console.error('[overview] Garden query failed (attempt 1):', e1?.message || e1)

        // Attempt 2: Without privacy column
        try {
          console.log('[overview] Fetching garden', gardenId, '(attempt 2: without privacy)')
          gRows = await sql`
            select id::text as id, name, cover_image_url, created_by::text as created_by, created_at, coalesce(streak, 0)::int as streak, 'public' as privacy,
                   location_city, location_country, location_timezone, location_lat, location_lon, coalesce(preferred_language, 'en') as preferred_language,
                   coalesce(hide_ai_chat, false) as hide_ai_chat
            from public.gardens where id = ${gardenId} limit 1
          `
          console.log('[overview] Garden query succeeded (attempt 2), rows:', gRows?.length || 0)
          gardenQuerySuccess = true
        } catch (e2) {
          console.error('[overview] Garden query failed (attempt 2):', e2?.message || e2)

          // Attempt 3: Minimal query (basic columns only)
          try {
            console.log('[overview] Fetching garden', gardenId, '(attempt 3: minimal)')
            gRows = await sql`
              select id::text as id, name, cover_image_url, created_by::text as created_by, created_at, 0 as streak, 'public' as privacy,
                     location_city, location_country, location_timezone, location_lat, location_lon, 'en' as preferred_language,
                     false as hide_ai_chat
              from public.gardens where id = ${gardenId} limit 1
            `
            console.log('[overview] Garden query succeeded (attempt 3), rows:', gRows?.length || 0)
            gardenQuerySuccess = true
          } catch (e3) {
            console.error('[overview] Garden query failed (attempt 3):', e3?.message || e3)
            throw new Error('Failed to fetch garden after all attempts: ' + (e3?.message || 'Unknown error'))
          }
        }
      }

      garden = Array.isArray(gRows) && gRows[0] ? gRows[0] : null
      console.log('[overview] Garden found:', !!garden, 'querySuccess:', gardenQuerySuccess)

      // Fetch plants with try-catch
      console.log('[overview] Fetching plants for garden', gardenId)
      let gpRows = []
      try {
        gpRows = await sql`
          select
            gp.id::text as id,
            gp.garden_id::text as garden_id,
            gp.plant_id::text as plant_id,
            gp.nickname,
            gp.seeds_planted::int as seeds_planted,
            gp.planted_at,
            gp.expected_bloom_date,
            gp.override_water_freq_unit,
            gp.override_water_freq_value::int as override_water_freq_value,
            gp.plants_on_hand::int as plants_on_hand,
            gp.sort_index::int as sort_index,
            gp.health_status,
            gp.notes,
            gp.last_health_update,
            p.id as p_id,
            p.name as p_name,
            p.scientific_name as p_scientific_name,
            p.colors as p_colors,
            p.seasons as p_seasons,
            p.rarity as p_rarity,
            p.meaning as p_meaning,
            p.description as p_description,
            p.image_url as p_image_url,
            p.photos as p_photos,
            p.level_sun as p_level_sun,
            p.watering_type as p_watering_type,
            p.soil as p_soil,
            p.maintenance_level as p_maintenance_level,
            p.seeds_available as p_seeds_available
          from public.garden_plants gp
          left join public.plants p on p.id = gp.plant_id
          where gp.garden_id = ${gardenId}
          order by gp.sort_index asc nulls last
        `
        console.log('[overview] Plants query succeeded, rows:', gpRows?.length || 0)
      } catch (plantsErr) {
        console.error('[overview] Plants query failed:', plantsErr?.message || plantsErr)
        // Plants query failed, continue with empty plants (non-fatal)
        gpRows = []
      }
      plants = (gpRows || []).map((r) => {
        const plantPhotos = Array.isArray(r.p_photos) ? r.p_photos : undefined
        const plantImage = pickPrimaryPhotoUrlFromArray(plantPhotos, r.p_image_url || '')
        return {
          id: String(r.id),
          gardenId: String(r.garden_id),
          plantId: String(r.plant_id),
          nickname: r.nickname,
          seedsPlanted: Number(r.seeds_planted || 0),
          plantedAt: r.planted_at || null,
          expectedBloomDate: r.expected_bloom_date || null,
          overrideWaterFreqUnit: r.override_water_freq_unit || null,
          overrideWaterFreqValue: (r.override_water_freq_value ?? null),
          plantsOnHand: Number(r.plants_on_hand || 0),
          sortIndex: (r.sort_index ?? null),
          healthStatus: r.health_status || null,
          notes: r.notes || null,
          lastHealthUpdate: r.last_health_update || null,
          plant: r.p_id ? {
            id: String(r.p_id),
            name: String(r.p_name || ''),
            scientificName: String(r.p_scientific_name || ''),
            colors: Array.isArray(r.p_colors) ? r.p_colors.map(String) : [],
            seasons: Array.isArray(r.p_seasons) ? r.p_seasons.map(String) : [],
            rarity: r.p_rarity,
            meaning: r.p_meaning || '',
            description: r.p_description || '',
            photos: plantPhotos,
            image: plantImage,
            care: {
              sunlight: r.p_level_sun || null,
              water: Array.isArray(r.p_watering_type) ? r.p_watering_type.join(', ') : null,
              soil: Array.isArray(r.p_soil) ? r.p_soil.join(', ') : null,
              difficulty: r.p_maintenance_level || null,
            },
            seedsAvailable: Boolean(r.p_seeds_available ?? false),
          } : null,
        }
      })

      // Fetch members - try with auth.users first, fallback if access denied
      console.log('[overview] Fetching members for garden', gardenId)
      let mRows = []
      try {
        mRows = await sql`
          select gm.garden_id::text as garden_id, gm.user_id::text as user_id, gm.role, gm.joined_at,
                 p.display_name, p.accent_key,
                 u.email
          from public.garden_members gm
          left join public.profiles p on p.id = gm.user_id
          left join auth.users u on u.id = gm.user_id
          where gm.garden_id = ${gardenId}
        `
        console.log('[overview] Members query with auth.users succeeded, rows:', mRows?.length || 0)
      } catch (memberErr) {
        console.error('[overview] members query with auth.users failed:', memberErr?.message || memberErr)
        // Fallback: query without auth.users (email will be null)
        try {
          mRows = await sql`
            select gm.garden_id::text as garden_id, gm.user_id::text as user_id, gm.role, gm.joined_at,
                   p.display_name, p.accent_key
            from public.garden_members gm
            left join public.profiles p on p.id = gm.user_id
            where gm.garden_id = ${gardenId}
          `
          console.log('[overview] Members fallback query succeeded, rows:', mRows?.length || 0)
        } catch (fallbackErr) {
          console.error('[overview] members fallback query also failed:', fallbackErr?.message || fallbackErr)
        }
      }
      members = (mRows || []).map((r) => ({
        gardenId: String(r.garden_id),
        userId: String(r.user_id),
        role: r.role,
        joinedAt: r.joined_at ? new Date(r.joined_at).toISOString() : null,
        displayName: r.display_name || null,
        email: r.email || null,
        accentKey: r.accent_key || null,
      }))
      console.log('[overview] Finished SQL queries for garden', gardenId)
    } else if (supabaseUrlEnv && supabaseAnonKey) {
      console.log('[overview] Using Supabase REST API for garden', gardenId)
      const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
      const bearer = getBearerTokenFromRequest(req)
      if (bearer) Object.assign(headers, { Authorization: `Bearer ${bearer}` })

      // Garden (include privacy field and location if available)
      const gUrl = `${supabaseUrlEnv}/rest/v1/gardens?id=eq.${encodeURIComponent(gardenId)}&select=id,name,cover_image_url,created_by,created_at,streak,privacy,location_city,location_country,location_timezone,location_lat,location_lon&limit=1`
      console.log('[overview] Fetching garden via REST API')
      const gResp = await fetch(gUrl, { headers })
      if (gResp.ok) {
        const arr = await gResp.json().catch(() => [])
        const row = Array.isArray(arr) && arr[0] ? arr[0] : null
        if (row) garden = { id: String(row.id), name: row.name, cover_image_url: row.cover_image_url || null, created_by: String(row.created_by), created_at: row.created_at, streak: Number(row.streak || 0), privacy: row.privacy || 'public', location_city: row.location_city || null, location_country: row.location_country || null, location_timezone: row.location_timezone || null, location_lat: row.location_lat || null, location_lon: row.location_lon || null }
        console.log('[overview] Garden found via REST:', !!garden)
      } else {
        console.error('[overview] Garden REST query failed:', gResp.status, await gResp.text().catch(() => ''))
      }

      // Garden plants
      const gpUrl = `${supabaseUrlEnv}/rest/v1/garden_plants?garden_id=eq.${encodeURIComponent(gardenId)}&select=id,garden_id,plant_id,nickname,seeds_planted,planted_at,expected_bloom_date,override_water_freq_unit,override_water_freq_value,plants_on_hand,sort_index,health_status,notes,last_health_update`
      const gpResp = await fetch(gpUrl, { headers })
      let gpRows = []
      if (gpResp.ok) gpRows = await gpResp.json().catch(() => [])
      const plantIds = Array.from(new Set(gpRows.map((r) => r.plant_id)))
      let plantsMap = {}
      if (plantIds.length > 0) {
        const inParam = plantIds.map((id) => encodeURIComponent(String(id))).join(',')
        const pUrl = `${supabaseUrlEnv}/rest/v1/plants?id=in.(${inParam})&select=*`
        const pResp = await fetch(pUrl, { headers })
        const pRows = pResp.ok ? (await pResp.json().catch(() => [])) : []
        for (const p of pRows) {
          const plantPhotos = Array.isArray(p.photos) ? p.photos : undefined
          plantsMap[String(p.id)] = {
            id: String(p.id),
            name: String(p.name || ''),
            scientificName: String(p.scientific_name || ''),
            colors: Array.isArray(p.colors) ? p.colors.map(String) : [],
            seasons: Array.isArray(p.seasons) ? p.seasons.map(String) : [],
            rarity: p.rarity,
            meaning: p.meaning || '',
            description: p.description || '',
            photos: plantPhotos,
            image: pickPrimaryPhotoUrlFromArray(plantPhotos, p.image_url || ''),
            care: {
              sunlight: p.level_sun || null,
              water: Array.isArray(p.watering_type) ? p.watering_type.join(', ') : null,
              soil: Array.isArray(p.soil) ? p.soil.join(', ') : null,
              difficulty: p.maintenance_level || null,
            },
            seedsAvailable: Boolean(p.seeds_available ?? false),
          }
        }
      }
      plants = gpRows.map((r) => ({
        id: String(r.id),
        gardenId: String(r.garden_id),
        plantId: String(r.plant_id),
        nickname: r.nickname,
        seedsPlanted: Number(r.seeds_planted || 0),
        plantedAt: r.planted_at || null,
        expectedBloomDate: r.expected_bloom_date || null,
        overrideWaterFreqUnit: r.override_water_freq_unit || null,
        overrideWaterFreqValue: (r.override_water_freq_value ?? null),
        plantsOnHand: Number(r.plants_on_hand || 0),
        sortIndex: (r.sort_index ?? null),
        healthStatus: r.health_status || null,
        notes: r.notes || null,
        lastHealthUpdate: r.last_health_update || null,
        plant: plantsMap[String(r.plant_id)] || null,
      }))

      // Members via RPC to include email
      try {
        const rpcResp = await fetch(`${supabaseUrlEnv}/rest/v1/rpc/get_profiles_for_garden`, {
          method: 'POST', headers: { ...headers, 'Content-Type': 'application/json' }, body: JSON.stringify({ _garden_id: gardenId })
        })
        if (rpcResp.ok) {
          const rows = await rpcResp.json().catch(() => [])
          const gmResp = await fetch(`${supabaseUrlEnv}/rest/v1/garden_members?garden_id=eq.${encodeURIComponent(gardenId)}&select=garden_id,user_id,role,joined_at`, { headers })
          const gms = gmResp.ok ? (await gmResp.json().catch(() => [])) : []
          const meta = {}
          for (const r of rows) meta[String(r.user_id)] = { display_name: r.display_name || null, email: r.email || null }
          members = gms.map((m) => ({
            gardenId: String(m.garden_id),
            userId: String(m.user_id),
            role: m.role,
            joinedAt: m.joined_at,
            displayName: (meta[String(m.user_id)] || {}).display_name || null,
            email: (meta[String(m.user_id)] || {}).email || null,
            accentKey: null,
          }))
        }
      } catch { }
    } else {
      res.status(500).json({ ok: false, error: 'Database not configured' }); return
    }

    // Normalize garden object to frontend shape
    const gardenOut = garden ? {
      id: String(garden.id),
      name: String(garden.name),
      coverImageUrl: (garden.cover_image_url || garden.coverImageUrl || null),
      createdBy: String(garden.created_by || garden.createdBy || ''),
      createdAt: garden.created_at ? new Date(garden.created_at).toISOString() : (garden.createdAt || null),
      streak: Number(garden.streak ?? 0),
      privacy: garden.privacy || 'public',
      locationCity: garden.location_city || null,
      locationCountry: garden.location_country || null,
      locationTimezone: garden.location_timezone || null,
      locationLat: garden.location_lat || null,
      locationLon: garden.location_lon || null,
      preferredLanguage: garden.preferred_language || 'en',
      hideAiChat: Boolean(garden.hide_ai_chat ?? false),
    } : null

    // Check access: members always allowed, otherwise check privacy
    const gardenPrivacy = garden?.privacy || 'public'
    if (!isMember && gardenPrivacy === 'private') {
      res.status(403).json({ ok: false, error: 'This garden is private' })
      return
    }

    // Check friends_only access: user must be friends with at least one garden member
    if (!isMember && gardenPrivacy === 'friends_only') {
      if (!user || !user.id) {
        res.status(403).json({ ok: false, error: 'This garden is for friends only' })
        return
      }
      // Check if user is friend with ANY member
      const memberIds = members.map((m) => m.userId).filter(Boolean)
      let isFriend = false

      if (memberIds.length > 0) {
        if (sql) {
          try {
            const rows = await sql`
              select 1 from public.friends 
              where user_id = ${user.id} 
              and friend_id = any(${sql.array(memberIds)}::uuid[])
              limit 1
            `
            if (rows && rows.length > 0) isFriend = true
          } catch (e) {
            console.error('[overview] Friend check failed (SQL)', e)
          }
        } else if (supabaseUrlEnv && supabaseAnonKey) {
          // REST fallback
          try {
            const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
            const bearer = getAuthTokenFromRequest(req)
            if (bearer) Object.assign(headers, { Authorization: `Bearer ${bearer}` })
            const idsStr = memberIds.join(',')
            const resp = await fetch(`${supabaseUrlEnv}/rest/v1/friends?user_id=eq.${encodeURIComponent(user.id)}&friend_id=in.(${idsStr})&limit=1`, { headers })
            if (resp.ok) {
              const data = await resp.json().catch(() => [])
              if (Array.isArray(data) && data.length > 0) isFriend = true
            }
          } catch (e) {
            console.error('[overview] Friend check failed (REST)', e)
          }
        }
      }

      if (!isFriend) {
        res.status(403).json({ ok: false, error: 'This garden is visible only to friends of members' })
        return
      }
    }

    // Calculate today's progress and stats server-side to avoid round-trips
    const today = new Date().toISOString().slice(0, 10)
    const startIso = `${today}T00:00:00.000Z`
    const endIso = `${today}T23:59:59.999Z`

    let todayProgress = { due: 0, completed: 0 }
    let totalOnHand = 0
    let speciesCount = 0

    // Calculate species count and totalOnHand from plants
    const seenSpecies = new Set()
    for (const p of plants) {
      const c = Number(p.plantsOnHand || 0)
      totalOnHand += c
      if (p.plantId) seenSpecies.add(String(p.plantId))
    }
    speciesCount = seenSpecies.size

    // Calculate today's task progress and task counts per plant
    let taskCountsByPlant = {}
    if (sql && gardenId) {
      try {
        const progressRows = await sql`
          SELECT 
            COALESCE(SUM(GREATEST(1, o.required_count)), 0)::int as due,
            COALESCE(SUM(LEAST(GREATEST(1, o.required_count), o.completed_count)), 0)::int as completed
          FROM garden_plant_task_occurrences o
          JOIN garden_plant_tasks t ON t.id = o.task_id
          WHERE t.garden_id = ${gardenId}
            AND o.due_at >= ${startIso}::timestamptz
            AND o.due_at <= ${endIso}::timestamptz
        `
        if (progressRows && progressRows[0]) {
          todayProgress = {
            due: Number(progressRows[0].due || 0),
            completed: Number(progressRows[0].completed || 0),
          }
        }
      } catch (progressErr) {
        console.warn('[overview] Progress query failed:', progressErr?.message || progressErr)
      }

      // Fetch task counts per plant (total tasks and due today)
      try {
        const taskCountRows = await sql`
          SELECT 
            t.garden_plant_id::text as garden_plant_id,
            COUNT(DISTINCT t.id)::int as total_tasks,
            COALESCE(SUM(CASE 
              WHEN o.due_at >= ${startIso}::timestamptz AND o.due_at <= ${endIso}::timestamptz 
                   AND GREATEST(1, o.required_count) - o.completed_count > 0
              THEN GREATEST(1, o.required_count) - o.completed_count
              ELSE 0
            END), 0)::int as due_today
          FROM garden_plant_tasks t
          LEFT JOIN garden_plant_task_occurrences o ON o.task_id = t.id
          WHERE t.garden_id = ${gardenId}
          GROUP BY t.garden_plant_id
        `
        if (taskCountRows && taskCountRows.length > 0) {
          for (const row of taskCountRows) {
            taskCountsByPlant[row.garden_plant_id] = {
              totalTasks: Number(row.total_tasks || 0),
              dueToday: Number(row.due_today || 0),
            }
          }
        }
      } catch (taskCountErr) {
        console.warn('[overview] Task counts query failed:', taskCountErr?.message || taskCountErr)
      }
    }

    res.json({
      ok: true,
      garden: gardenOut,
      plants,
      members,
      serverNow,
      todayProgress,
      totalOnHand,
      speciesCount,
      taskCountsByPlant,
    })
  } catch (e) {
    console.error('[overview] Error for garden', req.params.id, ':', e?.message || e)
    console.error('[overview] Stack:', e?.stack || 'No stack')
    res.status(500).json({ ok: false, error: e?.message || 'overview failed' })
  }
})

// Garden activity SSE â€” pushes new rows in garden_activity_logs
app.get('/api/garden/:id/stream', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ error: 'Unauthorized' }); return }
    const member = await isGardenMember(req, gardenId, user.id)
    if (!member) { res.status(403).json({ error: 'Forbidden' }); return }

    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8')
    res.setHeader('Cache-Control', 'no-cache, no-transform')
    res.setHeader('Connection', 'keep-alive')
    res.setHeader('X-Accel-Buffering', 'no')
    res.flushHeaders?.()

    // Initial acknowledge
    sseWrite(res, 'ready', { ok: true, gardenId })

    // Start from last 2 minutes to avoid missing events across reconnects
    let lastSeen = new Date(Date.now() - 2 * 60 * 1000).toISOString()

    const poll = async () => {
      try {
        if (sql) {
          const rows = await sql`
            select id::text as id, garden_id::text as garden_id, actor_id::text as actor_id, actor_name, actor_color, kind, message, plant_name, task_name, occurred_at
            from public.garden_activity_logs
            where garden_id = ${gardenId} and occurred_at > ${lastSeen}
            order by occurred_at asc
            limit 500
          `
          for (const r of rows || []) {
            lastSeen = new Date(r.occurred_at).toISOString()
            sseWrite(res, 'activity', {
              id: String(r.id), gardenId: String(r.garden_id), actorId: r.actor_id || null, actorName: r.actor_name || null, actorColor: r.actor_color || null,
              kind: r.kind, message: r.message, plantName: r.plant_name || null, taskName: r.task_name || null, occurredAt: new Date(r.occurred_at).toISOString(),
            })
          }
        } else if (supabaseUrlEnv && supabaseAnonKey) {
          const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
          // Include Authorization from bearer header or token query param (EventSource)
          const bearer = getAuthTokenFromRequest(req)
          if (bearer) Object.assign(headers, { Authorization: `Bearer ${bearer}` })
          const url = `${supabaseUrlEnv}/rest/v1/garden_activity_logs?garden_id=eq.${encodeURIComponent(gardenId)}&occurred_at=gt.${encodeURIComponent(lastSeen)}&select=id,garden_id,actor_id,actor_name,actor_color,kind,message,plant_name,task_name,occurred_at&order=occurred_at.asc&limit=500`
          const r = await fetch(url, { headers })
          if (r.ok) {
            const arr = await r.json().catch(() => [])
            for (const row of arr) {
              lastSeen = new Date(row.occurred_at).toISOString()
              sseWrite(res, 'activity', {
                id: String(row.id), gardenId: String(row.garden_id), actorId: row.actor_id || null, actorName: row.actor_name || null, actorColor: row.actor_color || null,
                kind: row.kind, message: row.message, plantName: row.plant_name || null, taskName: row.task_name || null, occurredAt: new Date(row.occurred_at).toISOString(),
              })
            }
          }
        }
      } catch { }
    }

    const iv = setInterval(poll, 1000)
    const hb = setInterval(() => { try { res.write(': ping\n\n') } catch { } }, 15000)
    req.on('close', () => { try { clearInterval(iv); clearInterval(hb) } catch { } })
  } catch (e) {
    try { res.status(500).json({ error: e?.message || 'stream failed' }) } catch { }
  }
})

// ---- Admin logs SSE ----
app.get('/api/admin/admin-logs/stream', async (req, res) => {
  try {
    // Allow admin static token via query param for EventSource
    try {
      const adminToken = (req.query?.admin_token ? String(req.query.admin_token) : '')
      if (adminToken) {
        try { req.headers['x-admin-token'] = adminToken } catch { }
      }
    } catch { }
    const adminId = await ensureAdmin(req, res)
    if (!adminId) return

    res.setHeader('Content-Type', 'text/event-stream; charset=utf-8')
    res.setHeader('Cache-Control', 'no-cache, no-transform')
    res.setHeader('Connection', 'keep-alive')
    res.setHeader('X-Accel-Buffering', 'no')
    res.flushHeaders?.()

    let lastSeen = new Date(Date.now() - 5 * 60 * 1000).toISOString()

    // Send initial snapshot (latest 200)
    try {
      if (sql) {
        const rows = await sql`
          select occurred_at, admin_id::text as admin_id, admin_name, action, target, detail
          from public.admin_activity_logs
          where occurred_at >= now() - interval '30 days'
          order by occurred_at desc
          limit 200
        `
        const list = (rows || []).map((r) => ({
          occurred_at: new Date(r.occurred_at).toISOString(),
          admin_id: r.admin_id || null,
          admin_name: r.admin_name || null,
          action: r.action,
          target: r.target || null,
          detail: r.detail || null,
        }))
        sseWrite(res, 'snapshot', { logs: list })
        if (list[0]?.occurred_at) lastSeen = list[0].occurred_at
      } else if (supabaseUrlEnv && supabaseAnonKey) {
        const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
        const url = `${supabaseUrlEnv}/rest/v1/admin_activity_logs?occurred_at=gte.${encodeURIComponent(new Date(Date.now() - 30 * 24 * 3600 * 1000).toISOString())}&select=occurred_at,admin_id,admin_name,action,target,detail&order=occurred_at.desc&limit=200`
        const r = await fetch(url, { headers })
        if (r.ok) {
          const arr = await r.json().catch(() => [])
          const list = (arr || []).map((row) => ({
            occurred_at: new Date(row.occurred_at).toISOString(),
            admin_id: row.admin_id || null,
            admin_name: row.admin_name || null,
            action: row.action,
            target: row.target || null,
            detail: row.detail || null,
          }))
          sseWrite(res, 'snapshot', { logs: list })
          if (list[0]?.occurred_at) lastSeen = list[0].occurred_at
        }
      }
    } catch { }

    const poll = async () => {
      try {
        if (sql) {
          const rows = await sql`
            select occurred_at, admin_id::text as admin_id, admin_name, action, target, detail
            from public.admin_activity_logs
            where occurred_at > ${lastSeen}
            order by occurred_at asc
            limit 500
          `
          for (const r of rows || []) {
            const payload = {
              occurred_at: new Date(r.occurred_at).toISOString(),
              admin_id: r.admin_id || null,
              admin_name: r.admin_name || null,
              action: r.action,
              target: r.target || null,
              detail: r.detail || null,
            }
            lastSeen = payload.occurred_at
            sseWrite(res, 'append', payload)
          }
        } else if (supabaseUrlEnv && supabaseAnonKey) {
          const headers = { apikey: supabaseAnonKey, Accept: 'application/json' }
          const url = `${supabaseUrlEnv}/rest/v1/admin_activity_logs?occurred_at=gt.${encodeURIComponent(lastSeen)}&select=occurred_at,admin_id,admin_name,action,target,detail&order=occurred_at.asc&limit=500`
          const r = await fetch(url, { headers })
          if (r.ok) {
            const arr = await r.json().catch(() => [])
            for (const row of arr || []) {
              const payload = {
                occurred_at: new Date(row.occurred_at).toISOString(),
                admin_id: row.admin_id || null,
                admin_name: row.admin_name || null,
                action: row.action,
                target: row.target || null,
                detail: row.detail || null,
              }
              lastSeen = payload.occurred_at
              sseWrite(res, 'append', payload)
            }
          }
        }
      } catch { }
    }

    const iv = setInterval(poll, 2500)
    const hb = setInterval(() => { try { res.write(': ping\n\n') } catch { } }, 15000)
    req.on('close', () => { try { clearInterval(iv); clearInterval(hb) } catch { } })
  } catch (e) {
    try { res.status(500).json({ error: e?.message || 'stream failed' }) } catch { }
  }
})

// Garden Analytics endpoint - returns aggregated statistics
app.get('/api/garden/:id/analytics', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    // Verify membership
    const membership = await sql`
      select 1 from public.garden_members
      where garden_id = ${gardenId} and user_id = ${user.id}
      limit 1
    `
    if (!membership || membership.length === 0) {
      res.status(403).json({ ok: false, error: 'Access denied' })
      return
    }

    const today = new Date().toISOString().slice(0, 10)
    const thirtyDaysAgo = new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString().slice(0, 10)

    // Get task occurrences for last 30 days with task type breakdown
    const taskStats = await sql`
      select
        date_trunc('day', o.due_at)::date as due_date,
        t.type,
        sum(o.required_count) as due_count,
        sum(least(o.completed_count, o.required_count)) as completed_count
      from public.garden_plant_task_occurrences o
      join public.garden_plant_tasks t on t.id = o.task_id
      where t.garden_id = ${gardenId}
        and o.due_at >= ${thirtyDaysAgo}::date
        and o.due_at <= (${today}::date + interval '1 day')
      group by due_date, t.type
      order by due_date asc
    `

    // Aggregate by date
    const dailyStatsMap = {}
    for (const row of taskStats) {
      const dateKey = row.due_date ? new Date(row.due_date).toISOString().slice(0, 10) : null
      if (!dateKey) continue
      if (!dailyStatsMap[dateKey]) {
        dailyStatsMap[dateKey] = { date: dateKey, due: 0, completed: 0, water: 0, fertilize: 0, harvest: 0, cut: 0, custom: 0 }
      }
      const due = Number(row.due_count || 0)
      const done = Number(row.completed_count || 0)
      dailyStatsMap[dateKey].due += due
      dailyStatsMap[dateKey].completed += done
      if (row.type && dailyStatsMap[dateKey][row.type] !== undefined) {
        dailyStatsMap[dateKey][row.type] += due
      }
    }

    // Fill in missing days
    const dailyStats = []
    const cursor = new Date(thirtyDaysAgo)
    const endDate = new Date(today)
    while (cursor <= endDate) {
      const dateKey = cursor.toISOString().slice(0, 10)
      if (dailyStatsMap[dateKey]) {
        dailyStatsMap[dateKey].success = dailyStatsMap[dateKey].due === 0 || dailyStatsMap[dateKey].completed >= dailyStatsMap[dateKey].due
        dailyStats.push(dailyStatsMap[dateKey])
      } else {
        dailyStats.push({ date: dateKey, due: 0, completed: 0, success: true, water: 0, fertilize: 0, harvest: 0, cut: 0, custom: 0 })
      }
      cursor.setDate(cursor.getDate() + 1)
    }

    // Get member contributions for this week
    const weekAgo = new Date(Date.now() - 7 * 24 * 60 * 60 * 1000).toISOString().slice(0, 10)
    let memberContributions = []
    try {
      // First get all garden members
      const allMembers = await sql`
        select
          gm.user_id,
          gm.role,
          gm.joined_at,
          p.display_name,
          p.accent_key,
          p.avatar_url
        from public.garden_members gm
        left join public.profiles p on p.id = gm.user_id
        where gm.garden_id = ${gardenId}
        order by gm.joined_at asc
      `

      // Then get task completion counts for this week
      const memberStats = await sql`
        select
          uc.user_id,
          sum(uc.increment) as tasks_completed
        from public.garden_task_user_completions uc
        join public.garden_plant_task_occurrences o on o.id = uc.occurrence_id
        join public.garden_plant_tasks t on t.id = o.task_id
        where t.garden_id = ${gardenId}
          and uc.occurred_at >= ${weekAgo}::date
        group by uc.user_id
      `

      // Build a map of user_id -> tasks_completed
      const completionMap = {}
      for (const row of memberStats) {
        completionMap[String(row.user_id)] = Number(row.tasks_completed || 0)
      }

      // Merge all members with their completion counts
      const totalCompleted = memberStats.reduce((s, r) => s + Number(r.tasks_completed || 0), 0)
      const memberColors = ['#10b981', '#3b82f6', '#8b5cf6', '#ec4899', '#f59e0b', '#06b6d4', '#84cc16', '#f97316']

      memberContributions = allMembers.map((m, i) => {
        const userId = String(m.user_id)
        const tasksCompleted = completionMap[userId] || 0
        return {
          userId,
          displayName: m.display_name || 'Member',
          role: m.role || 'member',
          avatarUrl: m.avatar_url || null,
          accentKey: m.accent_key || null,
          joinedAt: m.joined_at,
          tasksCompleted,
          percentage: totalCompleted > 0 ? Math.round((tasksCompleted / totalCompleted) * 100) : 0,
          color: memberColors[i % memberColors.length],
        }
      })

      // Sort by tasks completed (descending), but keep showing all members
      memberContributions.sort((a, b) => b.tasksCompleted - a.tasksCompleted)
    } catch (err) {
      console.warn('[analytics] Failed to get member contributions:', err)
    }

    // Get plant stats
    const plantStats = await sql`
      select
        count(distinct id)::int as total,
        count(distinct plant_id)::int as species,
        count(case when plants_on_hand < 1 then 1 end)::int as needs_attention,
        count(case when plants_on_hand >= 1 then 1 end)::int as healthy
      from public.garden_plants
      where garden_id = ${gardenId}
    `
    const ps = plantStats[0] || { total: 0, species: 0, needs_attention: 0, healthy: 0 }

    // Compute weekly stats
    const last7Stats = dailyStats.slice(-7)
    const prev7Stats = dailyStats.slice(-14, -7)
    const currentWeekCompleted = last7Stats.reduce((s, d) => s + d.completed, 0)
    const currentWeekDue = last7Stats.reduce((s, d) => s + d.due, 0)
    const prevWeekCompleted = prev7Stats.reduce((s, d) => s + d.completed, 0)
    const completionRate = currentWeekDue > 0 ? Math.round((currentWeekCompleted / currentWeekDue) * 100) : 100
    const trendValue = prevWeekCompleted > 0 ? Math.round(((currentWeekCompleted - prevWeekCompleted) / prevWeekCompleted) * 100) : 0
    let trend = 'stable'
    if (trendValue > 5) trend = 'up'
    else if (trendValue < -5) trend = 'down'

    const tasksByType = last7Stats.reduce((acc, d) => {
      acc.water += d.water || 0
      acc.fertilize += d.fertilize || 0
      acc.harvest += d.harvest || 0
      acc.cut += d.cut || 0
      acc.custom += d.custom || 0
      return acc
    }, { water: 0, fertilize: 0, harvest: 0, cut: 0, custom: 0 })

    res.json({
      ok: true,
      analytics: {
        dailyStats,
        weeklyStats: {
          tasksCompleted: currentWeekCompleted,
          tasksDue: currentWeekDue,
          completionRate,
          trend,
          trendValue: Math.abs(trendValue),
          tasksByType,
        },
        memberContributions,
        plantStats: {
          total: Number(ps.total || 0),
          species: Number(ps.species || 0),
          needingAttention: Number(ps.needs_attention || 0),
          healthy: Number(ps.healthy || 0),
        },
      },
    })
  } catch (e) {
    console.error('[garden-analytics] Error:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to load analytics' })
  }
})

// Garden AI Advice endpoint - generates or retrieves cached weekly advice
app.get('/api/garden/:id/advice', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    const forceRefresh = req.query.refresh === 'true'

    // Verify membership
    const membership = await sql`
      select 1 from public.garden_members
      where garden_id = ${gardenId} and user_id = ${user.id}
      limit 1
    `
    if (!membership || membership.length === 0) {
      res.status(403).json({ ok: false, error: 'Access denied' })
      return
    }

    // Get garden info
    const gardenRows = await sql`
      select id, name, created_at, preferred_language from public.gardens where id = ${gardenId} limit 1
    `
    const garden = gardenRows[0]
    if (!garden) {
      res.status(404).json({ ok: false, error: 'Garden not found' })
      return
    }

    // Determine target language: garden's preferred language or Accept-Language header
    const acceptLang = req.headers['accept-language'] || ''
    const headerLang = acceptLang.split(',')[0]?.split('-')[0]?.toUpperCase() || 'EN'
    const targetLang = (garden.preferred_language || headerLang || 'EN').toUpperCase()

    // Check eligibility: garden must be older than 7 days and have at least 1 plant
    const gardenAge = Math.floor((Date.now() - new Date(garden.created_at).getTime()) / (1000 * 60 * 60 * 24))
    if (gardenAge < 7) {
      res.json({ ok: true, message: `Garden needs to be at least 1 week old. Come back in ${7 - gardenAge} days!`, advice: null })
      return
    }

    const plantCountRows = await sql`
      select count(*)::int as count from public.garden_plants where garden_id = ${gardenId}
    `
    const plantCount = Number(plantCountRows[0]?.count || 0)
    if (plantCount < 1) {
      res.json({ ok: true, message: 'Add at least 1 plant to receive personalized advice.', advice: null })
      return
    }

    // Calculate current week start (Monday)
    const now = new Date()
    const dayOfWeek = now.getUTCDay() // 0 = Sunday
    const mondayOffset = dayOfWeek === 0 ? -6 : 1 - dayOfWeek
    const weekStart = new Date(now)
    weekStart.setUTCDate(now.getUTCDate() + mondayOffset)
    weekStart.setUTCHours(0, 0, 0, 0)
    const weekStartIso = weekStart.toISOString().slice(0, 10)

    // Check for existing advice this week
    if (!forceRefresh) {
      try {
        let existingAdvice
        if (gardenAdviceContextColumnsSupported) {
          try {
            existingAdvice = await sql`
              select id, week_start, advice_text, advice_summary, focus_areas, plant_specific_tips,
                     improvement_score, generated_at, weather_context, location_context, model_used, translations
              from public.garden_ai_advice
              where garden_id = ${gardenId} and week_start = ${weekStartIso}
              limit 1
            `
          } catch (err) {
            if (isMissingColumnError(err)) {
              disableGardenAdviceContextColumns('select', err)
              existingAdvice = await sql`
                select id, week_start, advice_text, advice_summary, focus_areas, plant_specific_tips,
                       improvement_score, generated_at, model_used, translations
                from public.garden_ai_advice
                where garden_id = ${gardenId} and week_start = ${weekStartIso}
                limit 1
              `
            } else {
              throw err
            }
          }
        } else {
          existingAdvice = await sql`
            select id, week_start, advice_text, advice_summary, focus_areas, plant_specific_tips,
                   improvement_score, generated_at, model_used, translations
            from public.garden_ai_advice
            where garden_id = ${gardenId} and week_start = ${weekStartIso}
            limit 1
          `
        }

        if (existingAdvice && existingAdvice.length > 0) {
          const adv = existingAdvice[0]
          const modelUsed = adv.model_used || 'unknown'
          if (modelUsed !== 'rule-based') {
            // Build base advice object
            let adviceResponse = {
              id: String(adv.id),
              weekStart: adv.week_start,
              adviceText: adv.advice_text,
              adviceSummary: adv.advice_summary,
              focusAreas: adv.focus_areas || [],
              plantSpecificTips: normalizeJsonArray(adv.plant_specific_tips),
              improvementScore: adv.improvement_score,
              generatedAt: adv.generated_at,
              weatherContext: adv.weather_context || null,
              locationContext: adv.location_context || null,
            }

            // Check if translation is needed and exists
            if (targetLang !== 'EN') {
              const translations = adv.translations || {}
              if (translations[targetLang]) {
                // Use cached translation
                console.log(`[garden-advice] Using cached ${targetLang} translation`)
                adviceResponse = { ...adviceResponse, ...translations[targetLang] }
              } else {
                // Translate and cache the translation
                console.log(`[garden-advice] Translating existing advice to ${targetLang}`)
                try {
                  const translatedAdvice = await translateAdvice(adviceResponse, targetLang)
                  // Store the translation in the database
                  const updatedTranslations = {
                    ...translations, [targetLang]: {
                      adviceText: translatedAdvice.adviceText,
                      adviceSummary: translatedAdvice.adviceSummary,
                      focusAreas: translatedAdvice.focusAreas,
                      plantSpecificTips: translatedAdvice.plantSpecificTips,
                      weeklyFocus: translatedAdvice.weeklyFocus,
                      weatherAdvice: translatedAdvice.weatherAdvice,
                      encouragement: translatedAdvice.encouragement,
                    }
                  }
                  await sql`
                    update public.garden_ai_advice
                    set translations = ${JSON.stringify(updatedTranslations)}::jsonb
                    where id = ${adv.id}
                  `.catch(err => console.warn('[garden-advice] Failed to cache translation:', err))

                  adviceResponse = { ...adviceResponse, ...translatedAdvice }
                } catch (translateErr) {
                  console.warn('[garden-advice] Translation failed, returning English:', translateErr)
                }
              }
            }

            res.json({ ok: true, advice: adviceResponse })
            return
          }
        }
      } catch (err) {
        console.warn('[garden-advice] Existing advice lookup failed:', err)
      }
    }

    // Gather COMPREHENSIVE garden data for advice generation - ALL plant and garden info
    const plants = await sql`
      select 
        gp.id, gp.nickname, gp.plants_on_hand, gp.health_status, gp.notes,
        gp.seeds_planted, gp.planted_at, gp.expected_bloom_date, gp.last_health_update,
        gp.override_water_freq_unit, gp.override_water_freq_value,
        gp.created_at as added_at,
        -- Base plant info
        p.name as plant_name, p.scientific_name, p.plant_type,
        p.utility as plant_utility, p.comestible_part,
        -- Care requirements
        p.watering_type, p.level_sun,
        p.temperature_min, p.temperature_max, p.temperature_ideal,
        p.hygrometry, p.soil, p.nutrition_need, p.fertilizer,
        -- Growing info
        p.sowing_month, p.flowering_month, p.fruiting_month,
        p.height_cm, p.wingspan_cm, p.separation_cm,
        p.tutoring, p.transplanting, p.sow_type, p.division,
        -- Characteristics
        p.spiked, p.scent, p.multicolor,
        p.melliferous, p.conservation_status,
        p.toxicity_human, p.toxicity_pets,
        ('comestible' = ANY(p.utility)) as is_edible,
        -- Companions (pests/diseases now in plant_translations)
        p.companions,
        -- Translated fields including pests and diseases
        (
          select pt.overview 
          from public.plant_translations pt 
          where pt.plant_id = p.id and pt.language = 'en'
          limit 1
        ) as plant_overview,
        (
          select pt.pests 
          from public.plant_translations pt 
          where pt.plant_id = p.id and pt.language = 'en'
          limit 1
        ) as pests,
        (
          select pt.diseases 
          from public.plant_translations pt 
          where pt.plant_id = p.id and pt.language = 'en'
          limit 1
        ) as diseases
      from public.garden_plants gp
      left join public.plants p on p.id = gp.plant_id
      where gp.garden_id = ${gardenId}
      limit 100
    `

    // Get FULL garden info for context
    const gardenFull = await sql`
      select 
        location_city, location_country, location_timezone, location_lat, location_lon,
        privacy, created_at as garden_created_at,
        (select count(*)::int from public.garden_plants where garden_id = ${gardenId}) as plant_count,
        (select count(*)::int from public.garden_members where garden_id = ${gardenId}) as member_count
      from public.gardens where id = ${gardenId} limit 1
    `
    const gardenLocation = gardenFull[0] || {}
    
    // Get garden members with their contributions
    let gardenMembers = []
    try {
      const memberRows = await sql`
        select 
          gm.role, gm.joined_at,
          p.display_name, p.experience_years,
          (
            select count(*)::int 
            from public.garden_task_user_completions c
            join public.garden_plant_task_occurrences o on o.id = c.occurrence_id
            join public.garden_plant_tasks t on t.id = o.task_id
            where t.garden_id = ${gardenId} 
              and c.user_id = gm.user_id 
              and c.occurred_at > now() - interval '30 days'
          ) as tasks_completed_30d
        from public.garden_members gm
        left join public.profiles p on p.id = gm.user_id
        where gm.garden_id = ${gardenId}
        order by gm.role desc, gm.joined_at asc
      `
      gardenMembers = memberRows || []
    } catch { }
    
    // Get garden streak info
    let gardenStreak = null
    try {
      const streakRows = await sql`
        select current_streak, longest_streak, last_streak_date
        from public.garden_streaks
        where garden_id = ${gardenId}
      `
      if (streakRows[0]) gardenStreak = streakRows[0]
    } catch { }
    
    // Get analytics - health distribution and activity summary
    let analyticsContext = null
    try {
      const healthRows = await sql`
        select health_status, count(*)::int as count
        from public.garden_plants
        where garden_id = ${gardenId} and health_status is not null
        group by health_status
      `
      const activityRows = await sql`
        select kind, count(*)::int as count
        from public.garden_activity_logs
        where garden_id = ${gardenId}
          and created_at > now() - interval '14 days'
        group by kind
        order by count desc
      `
      analyticsContext = {
        healthDistribution: healthRows.reduce((acc, h) => { acc[h.health_status] = h.count; return acc }, {}),
        activitySummary: activityRows.reduce((acc, a) => { acc[a.kind] = a.count; return acc }, {})
      }
    } catch { }

    // Get weather data for the location
    let weatherData = null
    if (gardenLocation.location_city || gardenLocation.location_lat) {
      weatherData = await fetchWeatherForLocation(
        gardenLocation.location_lat,
        gardenLocation.location_lon,
        gardenLocation.location_city
      )
    }

    // Get task completion data for last 14 days (for better trend analysis)
    const twoWeeksAgo = new Date(Date.now() - 14 * 24 * 60 * 60 * 1000).toISOString().slice(0, 10)
    const weekAgo = new Date(Date.now() - 7 * 24 * 60 * 60 * 1000).toISOString().slice(0, 10)
    const taskData = await sql`
      select
        t.type,
        p.name as plant_name,
        gp.nickname,
        o.due_at,
        o.required_count,
        o.completed_count,
        o.completed_at
      from public.garden_plant_task_occurrences o
      join public.garden_plant_tasks t on t.id = o.task_id
      join public.garden_plants gp on gp.id = t.garden_plant_id
      left join public.plants p on p.id = gp.plant_id
      where t.garden_id = ${gardenId}
        and o.due_at >= ${twoWeeksAgo}::date
      order by o.due_at desc
      limit 300
    `

    // Calculate average completion time (hour of day when tasks are typically completed)
    const completionHours = taskData
      .filter(t => t.completed_at)
      .map(t => new Date(t.completed_at).getHours())
    const avgCompletionHour = completionHours.length > 0
      ? Math.round(completionHours.reduce((a, b) => a + b, 0) / completionHours.length)
      : null
    const avgCompletionTime = avgCompletionHour !== null
      ? `${avgCompletionHour}:00`
      : 'Not enough data'

    // Get recent journal entries (last 7 days) for additional context
    let recentJournalEntries = []
    try {
      const journalRows = await sql`
        select entry_date, title, content, mood, weather_snapshot
        from public.garden_journal_entries
        where garden_id = ${gardenId}
          and entry_date >= ${weekAgo}::date
        order by entry_date desc
        limit 5
      `
      recentJournalEntries = journalRows || []
    } catch { }

    // Get custom plant images if available
    let plantImages = []
    try {
      const imgRows = await sql`
        select gpi.image_url, gp.nickname, p.name as plant_name
        from public.garden_plant_images gpi
        join public.garden_plants gp on gp.id = gpi.garden_plant_id
        left join public.plants p on p.id = gp.plant_id
        where gp.garden_id = ${gardenId}
        order by gpi.uploaded_at desc
        limit 5
      `
      plantImages = imgRows || []
    } catch { }

    // Get journal photos from recent entries (with URLs for vision analysis)
    let journalPhotos = []
    let journalPhotoUrls = []
    try {
      const photoRows = await sql`
        select gjp.image_url, gjp.caption, gjp.plant_health, gjp.observations, 
               gp.nickname, p.name as plant_name, gje.entry_date
        from public.garden_journal_photos gjp
        join public.garden_journal_entries gje on gje.id = gjp.entry_id
        left join public.garden_plants gp on gp.id = gjp.garden_plant_id
        left join public.plants p on p.id = gp.plant_id
        where gje.garden_id = ${gardenId}
          and gje.entry_date >= ${weekAgo}::date
        order by gjp.uploaded_at desc
        limit 6
      `
      journalPhotos = photoRows || []
      // Transform URLs to media proxy format
      journalPhotoUrls = journalPhotos
        .map(p => supabaseStorageToMediaProxy(p.image_url) || p.image_url)
        .filter(Boolean)
    } catch { }

    // Get previous 4 weeks of advice to avoid repetition and build on progress
    let previousAdviceList = []
    try {
      const fourWeeksAgo = new Date(weekStart)
      fourWeeksAgo.setDate(fourWeeksAgo.getDate() - 28)
      const fourWeeksAgoIso = fourWeeksAgo.toISOString().slice(0, 10)

      const prevAdviceRows = await sql`
        select week_start, advice_text, advice_summary, focus_areas, plant_specific_tips
        from public.garden_ai_advice
        where garden_id = ${gardenId} 
          and week_start >= ${fourWeeksAgoIso}
          and week_start < ${weekStartIso}
        order by week_start desc
        limit 4
      `
      if (prevAdviceRows && prevAdviceRows.length > 0) {
        previousAdviceList = prevAdviceRows
      }
    } catch { }
    const previousAdvice = previousAdviceList[0] || null

    // Build COMPREHENSIVE plant list with ALL details for AI advice
    const plantList = plants.map(p => {
      const lines = []
      const displayName = p.nickname || p.plant_name || 'Unknown'
      lines.push(`### ${displayName}${p.scientific_name ? ` (${p.scientific_name})` : ''}`)
      
      // Basic info
      const basicInfo = []
      if (p.plant_type) basicInfo.push(`Type: ${p.plant_type}`)
      if (p.plants_on_hand) basicInfo.push(`Quantity: ${p.plants_on_hand}`)
      if (p.seeds_planted) basicInfo.push(`Seeds planted: ${p.seeds_planted}`)
      if (p.health_status) {
        let healthInfo = `Health: ${p.health_status}`
        if (p.last_health_update) healthInfo += ` (updated ${new Date(p.last_health_update).toLocaleDateString()})`
        basicInfo.push(healthInfo)
      }
      if (basicInfo.length > 0) lines.push(`- ${basicInfo.join(' | ')}`)
      
      // Care requirements
      const careInfo = []
      if (p.override_water_freq_value) {
        careInfo.push(`Watering: ${p.override_water_freq_value}x per ${p.override_water_freq_unit || 'week'} (custom)`)
      }
      if (p.level_sun) careInfo.push(`Light: ${p.level_sun}`)
      if (p.temperature_min && p.temperature_max) {
        careInfo.push(`Temp: ${p.temperature_min}Â°C-${p.temperature_max}Â°C${p.temperature_ideal ? ` (ideal: ${p.temperature_ideal}Â°C)` : ''}`)
      }
      if (p.hygrometry) careInfo.push(`Humidity: ${p.hygrometry}%`)
      if (careInfo.length > 0) lines.push(`- Care: ${careInfo.join(' | ')}`)
      
      // Growing info
      const growingInfo = []
      if (p.sowing_month && p.sowing_month.length > 0) growingInfo.push(`Sow: ${p.sowing_month.join(', ')}`)
      if (p.flowering_month && p.flowering_month.length > 0) growingInfo.push(`Flowers: ${p.flowering_month.join(', ')}`)
      if (p.fruiting_month && p.fruiting_month.length > 0) growingInfo.push(`Fruits: ${p.fruiting_month.join(', ')}`)
      if (growingInfo.length > 0) lines.push(`- Growing: ${growingInfo.join(' | ')}`)
      
      // Characteristics
      const chars = []
      if (p.is_edible) chars.push('Edible')
      if (p.toxicity_human === 'highly toxic' || p.toxicity_human === 'lethally toxic') chars.push('âš ï¸ Toxic to humans')
      if (p.toxicity_pets === 'highly toxic' || p.toxicity_pets === 'lethally toxic') chars.push('âš ï¸ Toxic to pets')
      if (p.melliferous) chars.push('Melliferous')
      if (chars.length > 0) lines.push(`- Traits: ${chars.join(', ')}`)
      
      // Problems
      if ((p.pests && p.pests.length > 0) || (p.diseases && p.diseases.length > 0)) {
        const problems = []
        if (p.pests && p.pests.length > 0) problems.push(`Pests: ${p.pests.slice(0, 5).join(', ')}`)
        if (p.diseases && p.diseases.length > 0) problems.push(`Diseases: ${p.diseases.slice(0, 5).join(', ')}`)
        lines.push(`- Watch for: ${problems.join(' | ')}`)
      }
      
      // Dates
      if (p.planted_at || p.expected_bloom_date) {
        const dates = []
        if (p.planted_at) dates.push(`Planted: ${new Date(p.planted_at).toLocaleDateString()}`)
        if (p.expected_bloom_date) dates.push(`Expected bloom: ${new Date(p.expected_bloom_date).toLocaleDateString()}`)
        lines.push(`- ${dates.join(' | ')}`)
      }
      
      // User notes
      if (p.notes) lines.push(`- Notes: ${p.notes}`)
      
      return lines.join('\n')
    }).join('\n\n')

    // Calculate task statistics for this week and last week
    const thisWeekTasks = taskData.filter(t => t.due_at >= weekAgo)
    const lastWeekTasks = taskData.filter(t => t.due_at >= twoWeeksAgo && t.due_at < weekAgo)

    const calcStats = (tasks) => {
      const summary = tasks.reduce((acc, t) => {
        const key = t.type
        if (!acc[key]) acc[key] = { due: 0, completed: 0 }
        acc[key].due += Number(t.required_count || 0)
        acc[key].completed += Math.min(Number(t.completed_count || 0), Number(t.required_count || 0))
        return acc
      }, {})
      const totalDue = Object.values(summary).reduce((s, d) => s + d.due, 0)
      const totalCompleted = Object.values(summary).reduce((s, d) => s + d.completed, 0)
      return { summary, totalDue, totalCompleted, rate: totalDue > 0 ? Math.round((totalCompleted / totalDue) * 100) : 100 }
    }

    const thisWeekStats = calcStats(thisWeekTasks)
    const lastWeekStats = calcStats(lastWeekTasks)

    const taskSummaryText = Object.entries(thisWeekStats.summary)
      .map(([type, data]) => `${type}: ${data.completed}/${data.due}`)
      .join(', ')

    // Build weather context
    let weatherContext = ''
    if (weatherData) {
      const current = weatherData.current
      const forecast = weatherData.forecast?.slice(0, 7) || []
      weatherContext = `
CURRENT WEATHER (${gardenLocation.location_city || 'Location'}):
- Temperature: ${current?.temp}Â°C
- Condition: ${current?.condition}
- Humidity: ${current?.humidity}%
- Wind: ${current?.windSpeed} km/h

7-DAY FORECAST:
${forecast.map(f => `- ${f.date}: ${f.condition}, ${f.tempMin}Â°-${f.tempMax}Â°C, ${f.precipProbability}% rain chance`).join('\n')}`
    }

    // Build journal context
    let journalContext = ''
    if (recentJournalEntries.length > 0) {
      journalContext = `
RECENT JOURNAL ENTRIES (gardener's own observations):
${recentJournalEntries.map(e => {
        const moodEmoji = { great: 'ðŸŒŸ', good: 'ðŸ˜Š', neutral: 'ðŸ˜', concerned: 'ðŸ˜Ÿ', struggling: 'ðŸ˜°' }[e.mood] || ''
        return `- ${e.entry_date}${moodEmoji ? ' ' + moodEmoji : ''}: "${e.content.slice(0, 200)}${e.content.length > 200 ? '...' : ''}"`
      }).join('\n')}`
    }

    // Build photo observations context
    let photoContext = ''
    const photoObservations = journalPhotos.filter(p => p.observations || p.plant_health)
    if (photoObservations.length > 0) {
      photoContext = `
PLANT OBSERVATIONS FROM PHOTOS:
${photoObservations.map(p => `- ${p.nickname || p.plant_name || 'Plant'}: ${p.plant_health ? `Health: ${p.plant_health}` : ''} ${p.observations || ''}`).join('\n')}`
    }

    // Get current date and day of week for temporal context (reuse 'now' from earlier)
    const dayOfWeekName = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'][now.getDay()]
    const currentDate = now.toLocaleDateString('en-US', { month: 'long', day: 'numeric', year: 'numeric' })

    // Build member context
    let memberContext = ''
    if (gardenMembers.length > 0) {
      memberContext = `
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ‘¥ GARDEN MEMBERS (${gardenMembers.length} total)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${gardenMembers.map(m => {
        const info = [`${m.display_name || 'Member'} (${m.role})`]
        if (m.experience_years) info.push(`${m.experience_years} years experience`)
        info.push(`${m.tasks_completed_30d || 0} tasks completed this month`)
        return `- ${info.join(' | ')}`
      }).join('\n')}`
    }
    
    // Build streak and analytics context
    let statsContext = ''
    if (gardenStreak || analyticsContext) {
      statsContext = `
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“ˆ GARDEN STATISTICS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`
      if (gardenStreak) {
        statsContext += `
Current streak: ${gardenStreak.current_streak || 0} days
Longest streak: ${gardenStreak.longest_streak || 0} days`
      }
      if (analyticsContext?.healthDistribution && Object.keys(analyticsContext.healthDistribution).length > 0) {
        statsContext += `

Plant Health Distribution:
${Object.entries(analyticsContext.healthDistribution).map(([status, count]) => `- ${status}: ${count} plants`).join('\n')}`
      }
      if (analyticsContext?.activitySummary && Object.keys(analyticsContext.activitySummary).length > 0) {
        statsContext += `

Recent Activity (14 days):
${Object.entries(analyticsContext.activitySummary).map(([kind, count]) => `- ${kind}: ${count}`).join('\n')}`
      }
    }

    const prompt = `You are an expert gardener and plant care specialist providing personalized weekly advice. Analyze all the data below and provide comprehensive, actionable advice.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“… DATE & TIME CONTEXT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Today: ${dayOfWeekName}, ${currentDate}
Location: ${gardenLocation.location_city || 'Unknown'}${gardenLocation.location_country ? `, ${gardenLocation.location_country}` : ''}
Coordinates: ${gardenLocation.location_lat ? `${gardenLocation.location_lat}, ${gardenLocation.location_lon}` : 'Not set'}
Timezone: ${gardenLocation.location_timezone || 'Unknown'}
Average task completion time: ${avgCompletionTime}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸŒ± GARDEN: "${garden.name}"
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Total Plants: ${gardenLocation.plant_count || plants.length}
Total Members: ${gardenLocation.member_count || 1}
Garden Age: ${gardenAge} days
${memberContext}
${statsContext}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸŒ¿ DETAILED PLANT INFORMATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${plantList || 'No plants yet'}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“Š TASK PERFORMANCE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
This week: ${thisWeekStats.rate}% completion rate (${thisWeekStats.totalCompleted}/${thisWeekStats.totalDue} tasks)
Last week: ${lastWeekStats.rate}% completion rate (${lastWeekStats.totalCompleted}/${lastWeekStats.totalDue} tasks)
Trend: ${thisWeekStats.rate > lastWeekStats.rate ? 'ðŸ“ˆ Improving' : thisWeekStats.rate < lastWeekStats.rate ? 'ðŸ“‰ Declining' : 'âž¡ï¸ Stable'}

Task breakdown this week: ${taskSummaryText || 'No tasks scheduled'}
${weatherContext}
${journalContext}
${photoContext}
${plantImages.length > 0 ? `\nðŸ“· The gardener has uploaded ${plantImages.length} plant photos.` : ''}
${previousAdviceList.length > 0 ? `
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ“‹ PREVIOUS ADVICE HISTORY (DO NOT REPEAT - BUILD UPON IT)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${previousAdviceList.map((adv, i) => {
  const weeksAgo = i + 1
  return `
--- ${weeksAgo} week${weeksAgo > 1 ? 's' : ''} ago (${adv.week_start}) ---
Summary: ${adv.advice_summary || 'N/A'}
Focus areas: ${(adv.focus_areas || []).join(', ') || 'N/A'}
Plant tips given: ${Array.isArray(adv.plant_specific_tips) ? adv.plant_specific_tips.map(t => typeof t === 'object' ? t.plantName : t).join(', ') : 'N/A'}`
}).join('\n')}
` : ''}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸŽ¯ YOUR COMPREHENSIVE WEEKLY ADVICE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

You are providing PERSONALIZED, ACTIONABLE weekly advice. Your advice should be:
1. SPECIFIC to this garden's plants, location, weather, and the gardener's habits
2. FRESH and DIFFERENT from previous weeks (shown above) - never repeat the same tips
3. DETAILED with clear explanations of WHY and HOW
4. ENCOURAGING while being practical and honest

ANALYZE AND CONSIDER:
â€¢ Current weather forecast and its impact on each plant
â€¢ Seasonal timing - what needs attention THIS week specifically
â€¢ Plant health status and any concerning trends
â€¢ Task completion patterns - help optimize their routine
â€¢ Journal observations - address any concerns they've noted
â€¢ Pest/disease risks for their specific plants
â€¢ Growth stages and upcoming milestones (flowering, fruiting, etc.)
â€¢ Companion planting opportunities
â€¢ Soil and nutrition needs based on the season

${previousAdviceList.length > 0 ? `
âš ï¸ CRITICAL: You gave advice in previous weeks (shown above). 
- DO NOT repeat the same focus areas or plant tips
- If a concern persists, provide NEW strategies or escalate urgency
- Build on previous advice - acknowledge progress or changes
- Rotate focus to different plants unless urgent issues exist
` : ''}

Provide your response as JSON with this COMPREHENSIVE structure:
{
  "summary": "A warm, personalized 2-3 sentence overview acknowledging their specific garden and progress",
  "weeklyFocus": "The ONE most important thing to focus on this week with specific reasoning",
  "focusAreas": [
    "4-6 specific, actionable tasks for this week - each should be different from previous weeks"
  ],
  "plantTips": [
    {
      "plantName": "exact plant name from their garden",
      "tip": "Detailed, specific advice (2-3 sentences minimum)",
      "priority": "high|medium|low",
      "reason": "Why this matters RIGHT NOW for this specific plant",
      "timing": "When exactly to do this (e.g., 'early morning', 'before Friday's rain')"
    }
  ],
  "seasonalInsights": "What's happening in the garden world this time of year and how it applies to their plants",
  "weatherAdvice": "Detailed analysis of the 7-day forecast and specific actions to take",
  "preventiveCare": "Proactive tips to prevent common issues this season",
  "improvementScore": 85,
  "scoreExplanation": "Brief explanation of what contributes to the score and how to improve",
  "encouragement": "A genuinely personalized, motivating message referencing their specific achievements",
  "lookingAhead": "What to prepare for in the coming 2-3 weeks",
  "fullAdvice": "A comprehensive, friendly 3-4 paragraph summary covering all your recommendations with specific details"
}`

    const buildRuleBased = () =>
      generateRuleBasedAdvice({
        gardenName: garden.name,
        plants,
        thisWeekStats,
        lastWeekStats,
        weatherData,
        avgCompletionTime,
        taskSummaryText,
      })

    let parsed = null
    let tokensUsed = 0
    let modelUsed = openaiModel // Use the same model as AI Plant Fill

    if (openaiClient) {
      try {
        const useVision = journalPhotoUrls.length > 0
        const gardenAdviceInstructions = `You are an expert horticulturist and plant care specialist with decades of experience. You provide detailed, scientifically-informed yet accessible gardening advice.

Your personality:
- Warm, encouraging, and genuinely invested in the gardener's success
- Practical and specific - never vague or generic
- Proactive - anticipate problems before they occur
- Educational - explain the "why" behind recommendations

Your expertise includes:
- Plant biology, growth cycles, and optimal care conditions
- Pest and disease identification and organic/integrated management
- Soil science, composting, and plant nutrition
- Climate adaptation and seasonal gardening strategies
- Companion planting and garden ecosystem design
- Water management and irrigation optimization

Guidelines:
- ALWAYS respond with valid JSON matching the requested structure
- Be SPECIFIC to the plants in this garden - reference them by name
- Consider the LOCAL weather forecast when giving advice
- Acknowledge their progress and build on previous advice
- Provide ACTIONABLE tips with clear timing (e.g., "water deeply Tuesday before the heat wave")
- When analyzing photos, look for: leaf color/texture, stem health, soil moisture, pest damage, nutrient deficiencies
- Prioritize urgent issues but also include maintenance and optimization tips`

        let aiResponse
        
        // Build input content for Responses API
        const inputContent = []
        
        if (useVision) {
          // Add text with vision-specific instructions
          const imageUrls = journalPhotoUrls.slice(0, 4)
          inputContent.push({
            type: 'input_text',
            text: prompt + `\n\nIMPORTANT: I have attached ${imageUrls.length} recent photo(s) from the garden journal. Please analyze these images carefully and include your observations in the "plantTips" section. Look for:
- Overall plant health and vigor
- Signs of disease, pests, or stress
- Watering issues (overwatering/underwatering)
- Nutrient deficiencies
- Growth progress
Include specific observations from the photos in your advice.`
          })

          // Add images using Responses API format
          for (const url of imageUrls) {
            inputContent.push({
              type: 'input_image',
              image_url: url
            })
          }
        } else {
          inputContent.push({ type: 'input_text', text: prompt })
        }

        // Use Responses API for both text and vision
        const response = await openaiClient.responses.create(
          {
            model: openaiModel,
            reasoning: { effort: 'medium' },
            instructions: gardenAdviceInstructions + '\n\nYou MUST respond with valid JSON only, no markdown or prose.',
            input: [{ role: 'user', content: inputContent }],
          },
          { timeout: 300000 }
        )

        aiResponse = typeof response?.output_text === 'string' ? response.output_text.trim() : ''
        tokensUsed = response.usage?.total_tokens || 0

        try {
          parsed = JSON.parse(aiResponse || '{}')
        } catch {
          // Try to extract JSON from the response
          const jsonMatch = (aiResponse || '').match(/\{[\s\S]*\}/)
          if (jsonMatch) {
            try {
              parsed = JSON.parse(jsonMatch[0])
            } catch {
              parsed = { summary: 'Unable to parse advice', focusAreas: [], plantTips: [], improvementScore: null, fullAdvice: aiResponse }
            }
          } else {
            parsed = { summary: 'Unable to parse advice', focusAreas: [], plantTips: [], improvementScore: null, fullAdvice: aiResponse }
          }
        }
      } catch (aiErr) {
        console.error('[garden-advice] AI generation failed:', aiErr)
        parsed = buildRuleBased()
        modelUsed = 'rule-based'
        tokensUsed = 0
      }
    } else {
      parsed = buildRuleBased()
      modelUsed = 'rule-based'
      tokensUsed = 0
    }

    if (!parsed) parsed = buildRuleBased()

    // Build context objects for storage
    const weatherContextObj = weatherData ? {
      current: weatherData.current,
      forecast: weatherData.forecast?.slice(0, 7),
      location: gardenLocation.location_city,
    } : {}

    const journalContextObj = {
      entriesCount: recentJournalEntries.length,
      recentMoods: recentJournalEntries.map(e => e.mood).filter(Boolean),
      photoObservations: photoObservations.map(p => ({ plant: p.nickname || p.plant_name, health: p.plant_health })),
    }

    const locationContextObj = {
      city: gardenLocation.location_city,
      country: gardenLocation.location_country,
      timezone: gardenLocation.location_timezone,
    }

    // Store in database with enhanced context. Fall back gracefully if the target columns don't exist yet.
    let insertResult
    const focusAreasArray = Array.isArray(parsed.focusAreas)
      ? parsed.focusAreas.map((area) => String(area || '').trim()).filter(Boolean)
      : []
    const plantTipsJson = JSON.stringify(parsed.plantTips || [])
    const weatherContextJson = JSON.stringify(weatherContextObj)
    const journalContextJson = JSON.stringify(journalContextObj)
    const locationContextJson = JSON.stringify(locationContextObj)
    const insertArgs = {
      gardenId,
      weekStartIso,
      fullAdvice: parsed.fullAdvice || '',
      summary: parsed.summary || '',
      focusAreas: focusAreasArray,
      plantTips: plantTipsJson,
      improvementScore: parsed.improvementScore || null,
      tokensUsed,
      weatherContextJson,
      journalContextJson,
      avgCompletionTime,
      locationContextJson,
      modelUsed,
    }

    const runBaseInsert = () => sql`
      insert into public.garden_ai_advice (
        garden_id, week_start, advice_text, advice_summary, focus_areas,
        plant_specific_tips, improvement_score, model_used, tokens_used, generated_at
      ) values (
        ${insertArgs.gardenId}, ${insertArgs.weekStartIso}, ${insertArgs.fullAdvice}, ${insertArgs.summary},
        ${sql.array(insertArgs.focusAreas, 'text')}, ${insertArgs.plantTips}::jsonb,
        ${insertArgs.improvementScore}, ${insertArgs.modelUsed}, ${insertArgs.tokensUsed}, now()
      )
      on conflict (garden_id, week_start)
      do update set
        advice_text = excluded.advice_text,
        advice_summary = excluded.advice_summary,
        focus_areas = excluded.focus_areas,
        plant_specific_tips = excluded.plant_specific_tips,
        improvement_score = excluded.improvement_score,
        model_used = excluded.model_used,
        tokens_used = excluded.tokens_used,
        generated_at = excluded.generated_at
      returning id, week_start, advice_text, advice_summary, focus_areas, plant_specific_tips, 
                improvement_score, generated_at
    `

    if (gardenAdviceContextColumnsSupported) {
      try {
        insertResult = await sql`
          insert into public.garden_ai_advice (
            garden_id, week_start, advice_text, advice_summary, focus_areas,
            plant_specific_tips, improvement_score, model_used, tokens_used, generated_at,
            weather_context, journal_context, avg_completion_time, location_context
          ) values (
            ${insertArgs.gardenId}, ${insertArgs.weekStartIso}, ${insertArgs.fullAdvice}, ${insertArgs.summary},
            ${insertArgs.focusAreas}::text[], ${insertArgs.plantTips}::jsonb,
            ${insertArgs.improvementScore}, ${insertArgs.modelUsed}, ${insertArgs.tokensUsed}, now(),
            ${insertArgs.weatherContextJson}::jsonb, ${insertArgs.journalContextJson}::jsonb,
            ${insertArgs.avgCompletionTime}, ${insertArgs.locationContextJson}::jsonb
          )
          on conflict (garden_id, week_start)
          do update set
            advice_text = excluded.advice_text,
            advice_summary = excluded.advice_summary,
            focus_areas = excluded.focus_areas,
            plant_specific_tips = excluded.plant_specific_tips,
            improvement_score = excluded.improvement_score,
            model_used = excluded.model_used,
            tokens_used = excluded.tokens_used,
            generated_at = excluded.generated_at,
            weather_context = excluded.weather_context,
            journal_context = excluded.journal_context,
            avg_completion_time = excluded.avg_completion_time,
            location_context = excluded.location_context
          returning id, week_start, advice_text, advice_summary, focus_areas, plant_specific_tips, 
                    improvement_score, generated_at, weather_context, location_context
        `
      } catch (err) {
        if (isMissingColumnError(err)) {
          disableGardenAdviceContextColumns('insert', err)
          insertResult = await runBaseInsert()
        } else {
          throw err
        }
      }
    } else {
      insertResult = await runBaseInsert()
    }

    const saved = insertResult[0]

    // Build the advice response
    let adviceResponse = {
      id: String(saved.id),
      weekStart: saved.week_start,
      adviceText: saved.advice_text,
      adviceSummary: saved.advice_summary,
      focusAreas: saved.focus_areas || [],
      plantSpecificTips: normalizeJsonArray(saved.plant_specific_tips),
      improvementScore: saved.improvement_score,
      generatedAt: saved.generated_at,
      weeklyFocus: parsed.weeklyFocus || null,
      weatherAdvice: parsed.weatherAdvice || null,
      encouragement: parsed.encouragement || null,
      weatherContext: saved.weather_context || null,
      locationContext: saved.location_context || null,
    }

    // Translate if target language is not English
    if (targetLang !== 'EN') {
      console.log(`[garden-advice] Translating new advice to ${targetLang}`)
      try {
        const translatedAdvice = await translateAdvice(adviceResponse, targetLang)

        // Store the translation in the database
        const translations = {
          [targetLang]: {
            adviceText: translatedAdvice.adviceText,
            adviceSummary: translatedAdvice.adviceSummary,
            focusAreas: translatedAdvice.focusAreas,
            plantSpecificTips: translatedAdvice.plantSpecificTips,
            weeklyFocus: translatedAdvice.weeklyFocus,
            weatherAdvice: translatedAdvice.weatherAdvice,
            encouragement: translatedAdvice.encouragement,
          }
        }
        await sql`
          update public.garden_ai_advice
          set translations = ${JSON.stringify(translations)}::jsonb
          where id = ${saved.id}
        `.catch(err => console.warn('[garden-advice] Failed to cache translation:', err))

        adviceResponse = { ...adviceResponse, ...translatedAdvice }
      } catch (translateErr) {
        console.warn('[garden-advice] Translation failed, returning English:', translateErr)
      }
    }

    res.json({ ok: true, advice: adviceResponse })
  } catch (e) {
    console.error('[garden-advice] Error:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to get advice' })
  }
})

// Translate text using DeepL API
async function translateWithDeepL(text, targetLang, sourceLang = 'EN') {
  if (!text || !targetLang || targetLang.toUpperCase() === sourceLang.toUpperCase()) {
    return text
  }

  const deeplApiKey = process.env.DEEPL_API_KEY
  if (!deeplApiKey) {
    console.log('[translate] DeepL API key not configured, skipping translation')
    return text
  }

  try {
    const deeplUrl = process.env.DEEPL_API_URL || 'https://api.deepl.com/v2/translate'
    const response = await fetch(deeplUrl, {
      method: 'POST',
      headers: {
        'Authorization': `DeepL-Auth-Key ${deeplApiKey}`,
        'Content-Type': 'application/x-www-form-urlencoded',
      },
      body: new URLSearchParams({
        text: text,
        source_lang: sourceLang.toUpperCase(),
        target_lang: targetLang.toUpperCase(),
      }),
    })

    if (!response.ok) {
      console.warn('[translate] DeepL API error:', response.status)
      return text
    }

    const data = await response.json()
    return data.translations?.[0]?.text || text
  } catch (err) {
    console.warn('[translate] DeepL translation failed:', err)
    return text
  }
}

// Translate array of strings using DeepL
async function translateArrayWithDeepL(items, targetLang, sourceLang = 'EN') {
  if (!items || items.length === 0 || !targetLang || targetLang.toUpperCase() === sourceLang.toUpperCase()) {
    return items
  }

  // Translate each item in parallel
  const translated = await Promise.all(
    items.map(item => translateWithDeepL(item, targetLang, sourceLang))
  )
  return translated
}

// Translate gardening advice object to target language
async function translateAdvice(advice, targetLang, sourceLang = 'EN') {
  if (!advice || !targetLang || targetLang.toUpperCase() === sourceLang.toUpperCase()) {
    return advice
  }

  console.log(`[translate] Translating advice to ${targetLang}...`)

  const translated = { ...advice }

  // Translate text fields in parallel where possible
  const [adviceText, adviceSummary, weeklyFocus, weatherAdvice, encouragement] = await Promise.all([
    advice.adviceText ? translateWithDeepL(advice.adviceText, targetLang, sourceLang) : advice.adviceText,
    advice.adviceSummary ? translateWithDeepL(advice.adviceSummary, targetLang, sourceLang) : advice.adviceSummary,
    advice.weeklyFocus ? translateWithDeepL(advice.weeklyFocus, targetLang, sourceLang) : advice.weeklyFocus,
    advice.weatherAdvice ? translateWithDeepL(advice.weatherAdvice, targetLang, sourceLang) : advice.weatherAdvice,
    advice.encouragement ? translateWithDeepL(advice.encouragement, targetLang, sourceLang) : advice.encouragement,
  ])

  translated.adviceText = adviceText
  translated.adviceSummary = adviceSummary
  translated.weeklyFocus = weeklyFocus
  translated.weatherAdvice = weatherAdvice
  translated.encouragement = encouragement

  // Translate focus areas
  if (advice.focusAreas && Array.isArray(advice.focusAreas)) {
    translated.focusAreas = await translateArrayWithDeepL(advice.focusAreas, targetLang, sourceLang)
  }

  // Translate plant-specific tips
  if (advice.plantSpecificTips && Array.isArray(advice.plantSpecificTips)) {
    translated.plantSpecificTips = await Promise.all(
      advice.plantSpecificTips.map(async (tip) => ({
        ...tip,
        tip: tip.tip ? await translateWithDeepL(tip.tip, targetLang, sourceLang) : tip.tip,
        reason: tip.reason ? await translateWithDeepL(tip.reason, targetLang, sourceLang) : tip.reason,
        // Don't translate plant name - keep it in original language
      }))
    )
  }

  console.log(`[translate] Advice translation to ${targetLang} complete`)
  return translated
}

// Weather API helper
async function fetchWeatherForLocation(lat, lon, city) {
  // Use Open-Meteo API (free, no API key needed)
  try {
    if (!lat || !lon) {
      // Try geocoding if we only have city name
      if (city) {
        const geoResp = await fetch(`https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(city)}&count=1`)
        if (geoResp.ok) {
          const geoData = await geoResp.json()
          if (geoData.results?.[0]) {
            lat = geoData.results[0].latitude
            lon = geoData.results[0].longitude
          }
        }
      }
      if (!lat || !lon) return null
    }

    const weatherResp = await fetch(
      `https://api.open-meteo.com/v1/forecast?latitude=${lat}&longitude=${lon}&current=temperature_2m,relative_humidity_2m,weather_code,wind_speed_10m&daily=weather_code,temperature_2m_max,temperature_2m_min,precipitation_probability_max&timezone=auto&forecast_days=7`
    )

    if (!weatherResp.ok) return null
    const data = await weatherResp.json()

    // Weather code to description mapping
    const weatherCodes = {
      0: 'Clear sky', 1: 'Mainly clear', 2: 'Partly cloudy', 3: 'Overcast',
      45: 'Foggy', 48: 'Rime fog', 51: 'Light drizzle', 53: 'Moderate drizzle',
      55: 'Dense drizzle', 61: 'Slight rain', 63: 'Moderate rain', 65: 'Heavy rain',
      71: 'Slight snow', 73: 'Moderate snow', 75: 'Heavy snow', 80: 'Rain showers',
      95: 'Thunderstorm'
    }

    return {
      current: {
        temp: data.current?.temperature_2m,
        humidity: data.current?.relative_humidity_2m,
        condition: weatherCodes[data.current?.weather_code] || 'Unknown',
        windSpeed: data.current?.wind_speed_10m,
        weatherCode: data.current?.weather_code,
      },
      forecast: (data.daily?.time || []).slice(0, 7).map((date, i) => ({
        date,
        tempMax: data.daily?.temperature_2m_max?.[i],
        tempMin: data.daily?.temperature_2m_min?.[i],
        condition: weatherCodes[data.daily?.weather_code?.[i]] || 'Unknown',
        precipProbability: data.daily?.precipitation_probability_max?.[i],
      })),
      timezone: data.timezone,
    }
  } catch (err) {
    console.warn('[weather] Failed to fetch weather:', err)
    return null
  }
}

/**
 * Generate heuristic gardener advice when AI is unavailable.
 */
function generateRuleBasedAdvice({
  gardenName,
  plants,
  thisWeekStats,
  lastWeekStats,
  weatherData,
  avgCompletionTime,
  taskSummaryText,
}) {
  const plantCount = plants.length
  const normalizedThisWeek = thisWeekStats || { rate: 100, summary: {} }
  const normalizedLastWeek = lastWeekStats || { rate: normalizedThisWeek.rate }
  const completionRate = Number.isFinite(normalizedThisWeek.rate) ? normalizedThisWeek.rate : 100
  const previousRate = Number.isFinite(normalizedLastWeek.rate) ? normalizedLastWeek.rate : completionRate
  const rateDelta = completionRate - previousRate
  const summaryParts = []

  if (plantCount > 0) {
    summaryParts.push(`Youâ€™re currently caring for ${plantCount} plant${plantCount === 1 ? '' : 's'}.`)
  } else {
    summaryParts.push('No plants are linked to this garden yet, so insights focus on task habits.')
  }

  const trendText =
    rateDelta > 3
      ? ` (up ${Math.abs(rateDelta)}% from last week)`
      : rateDelta < -3
        ? ` (${Math.abs(rateDelta)}% below last week)`
        : ''
  summaryParts.push(`You logged ${completionRate}% of scheduled tasks this week${trendText}.`)

  if (avgCompletionTime && avgCompletionTime !== 'Not enough data') {
    summaryParts.push(`Most tasks get completed around ${avgCompletionTime}.`)
  }

  const typeLabels = {
    water: 'watering',
    fertilize: 'feeding',
    harvest: 'harvesting',
    cut: 'pruning',
    custom: 'custom care',
  }
  const summaryByType = normalizedThisWeek.summary || {}
  const deficits = Object.entries(typeLabels).map(([type, label]) => {
    const stats = summaryByType[type] || { due: 0, completed: 0 }
    const due = Number(stats.due || 0)
    const completed = Number(stats.completed || 0)
    return { type, label, due, completed, deficit: Math.max(0, due - completed) }
  })
    .filter(entry => entry.due > 0)
    .sort((a, b) => {
      if (b.deficit === a.deficit) return b.due - a.due
      return b.deficit - a.deficit
    })

  const focusAreas = []
  for (const entry of deficits) {
    if (entry.deficit <= 0) continue
    focusAreas.push(`Prioritize ${entry.label} tasks (${entry.completed}/${entry.due} logged).`)
    if (focusAreas.length >= 3) break
  }
  if (focusAreas.length === 0) {
    focusAreas.push(plantCount === 0
      ? 'Add at least one plant so reminders can target something alive.'
      : 'Stay consistent with your existing routine to keep plants thriving.')
  }

  const stressedPlants = plants.filter(p => {
    const health = (p.health_status || '').toLowerCase()
    return Boolean(
      (health && !['great', 'good', 'thriving', 'healthy'].includes(health)) ||
      (p.notes && p.notes.length > 0)
    )
  })

  const plantTips = []
  const plantEntries = stressedPlants.length ? stressedPlants : plants.slice(0, 3)
  plantEntries.slice(0, 3).forEach((p, idx) => {
    const plantName = p.nickname || p.plant_name || `Plant ${idx + 1}`
    const health = (p.health_status || '').toLowerCase()
    let tip = 'Give this plant a quick inspection for pests, yellowing leaves, or soil compaction.'
    let reason = 'General upkeep keeps foliage breathing well.'
    let priority = 'medium'

    if (health.includes('dry')) {
      tip = 'Soak the soil thoroughly, add mulch to retain moisture, and monitor afternoon sun.'
      reason = 'Reported dryness suggests the roots need a deeper drink.'
      priority = 'high'
    } else if (health.includes('pest') || health.includes('spot')) {
      tip = 'Wipe leaves, remove damaged growth, and consider a neem or soap spray this week.'
      reason = 'Spots or pests spread quickly when ignored.'
      priority = 'high'
    } else if (health.includes('slow') || health.includes('stall')) {
      tip = 'Check fertilizer schedule and gently loosen the top layer of soil to improve airflow.'
      reason = 'Stalled growth often tracks back to nutrients or compacted soil.'
    } else if (p.notes) {
      reason = p.notes.slice(0, 160)
    }

    plantTips.push({
      plantName,
      tip,
      priority,
      reason,
    })
  })

  const formatDay = iso => {
    try {
      return new Date(iso).toLocaleDateString(undefined, { weekday: 'long' })
    } catch {
      return 'upcoming days'
    }
  }

  let weatherAdvice = null
  if (weatherData?.forecast?.length) {
    const upcoming = weatherData.forecast.slice(0, 5)
    const heavyRain = upcoming.find(day => (day.precipProbability || 0) >= 60)
    const hotDay = upcoming.find(day => (day.tempMax || 0) >= 30)
    const chillyNight = upcoming.find(day => (day.tempMin || 99) <= 5)
    if (hotDay) {
      weatherAdvice = `Prep for heat around ${formatDay(hotDay.date)} (highs near ${Math.round(hotDay.tempMax)}Â°C). Deep morning watering and afternoon shade will protect tender plants.`
    } else if (heavyRain) {
      weatherAdvice = `Significant rain is likely ${formatDay(heavyRain.date)}. Hold off on extra watering and make sure planters drain well.`
    } else if (chillyNight) {
      weatherAdvice = `Expect cooler nights (â‰ˆ${Math.round(chillyNight.tempMin)}Â°C). Move sensitive pots closer to the house or add covers overnight.`
    } else if (weatherData.current) {
      weatherAdvice = `Current conditions are ${weatherData.current.condition?.toLowerCase() || 'steady'}, so keep watering moderate and watch humidity (${weatherData.current.humidity || 0}%).`
    }
  }

  const weeklyFocus = focusAreas[0] || 'Maintain a gentle routine this week.'

  let encouragement = 'Keep up the steady routine and log tasks as soon as you finish them.'
  if (rateDelta > 5) {
    encouragement = 'Nice momentum! The uptick in completed tasks shows your routine is clicking.'
  } else if (rateDelta < -5) {
    encouragement = 'You lost a bit of momentum this week, but a short daily check-in will bring it back.'
  }

  const improvementScore = Math.max(45, Math.min(95, Math.round(completionRate || 70)))

  const fullAdviceSections = [
    summaryParts.join(' '),
    weeklyFocus,
    focusAreas.length ? `Focus areas: ${focusAreas.join(' ')}` : '',
    plantTips.length
      ? `Plant-specific tips:\n${plantTips.map((tip, idx) => `${idx + 1}. ${tip.plantName}: ${tip.tip}`).join('\n')}`
      : '',
    weatherAdvice ? `Weather outlook: ${weatherAdvice}` : '',
    taskSummaryText ? `Task snapshot: ${taskSummaryText}.` : '',
  ].filter(Boolean)

  return {
    summary: summaryParts.join(' '),
    weeklyFocus,
    focusAreas,
    plantTips,
    weatherAdvice,
    improvementScore,
    encouragement,
    fullAdvice: fullAdviceSections.join('\n\n'),
  }
}

// Garden Weather endpoint
app.get('/api/garden/:id/weather', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    // Get garden location
    const gardenRows = await sql`
      select location_city, location_country, location_lat, location_lon, location_timezone
      from public.gardens where id = ${gardenId} limit 1
    `
    const garden = gardenRows[0]
    if (!garden) {
      res.status(404).json({ ok: false, error: 'Garden not found' })
      return
    }

    if (!garden.location_city && !garden.location_lat) {
      res.json({ ok: true, weather: null, message: 'No location set for this garden' })
      return
    }

    const weather = await fetchWeatherForLocation(garden.location_lat, garden.location_lon, garden.location_city)
    res.json({ ok: true, weather, location: { city: garden.location_city, country: garden.location_country } })
  } catch (e) {
    console.error('[garden-weather] Error:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to get weather' })
  }
})

// Update garden location
app.put('/api/garden/:id/location', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    console.log('[garden-location] PUT request for garden:', gardenId, 'body:', JSON.stringify(req.body))
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    console.log('[garden-location] User:', user?.id)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    const { city, country, timezone, lat, lon, preferredLanguage } = req.body || {}

    // Verify membership with owner/admin role
    const membership = await sql`
      select role from public.garden_members
      where garden_id = ${gardenId} and user_id = ${user.id}
      limit 1
    `
    if (!membership?.[0] || membership[0].role !== 'owner') {
      // Check if admin
      const adminCheck = await sql`select is_admin from public.profiles where id = ${user.id}`
      if (!adminCheck?.[0]?.is_admin) {
        res.status(403).json({ ok: false, error: 'Only garden owners can update location' })
        return
      }
    }

    // If city provided but no coords, try to geocode
    let finalLat = lat
    let finalLon = lon
    if (city && (!lat || !lon)) {
      try {
        const geoResp = await fetch(`https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(city)}&count=1`)
        if (geoResp.ok) {
          const geoData = await geoResp.json()
          if (geoData.results?.[0]) {
            finalLat = geoData.results[0].latitude
            finalLon = geoData.results[0].longitude
          }
        }
      } catch { }
    }

    console.log('[garden-location] Updating garden with:', { city, country, timezone, finalLat, finalLon, preferredLanguage })

    // Build update query - only include preferred_language if explicitly provided
    let updateResult
    if (preferredLanguage !== undefined) {
      updateResult = await sql`
        update public.gardens set
          location_city = ${city || null},
          location_country = ${country || null},
          location_timezone = ${timezone || null},
          location_lat = ${finalLat || null},
          location_lon = ${finalLon || null},
          preferred_language = ${preferredLanguage || 'en'}
        where id = ${gardenId}
        returning id, location_city, location_country, preferred_language
      `
    } else {
      updateResult = await sql`
        update public.gardens set
          location_city = ${city || null},
          location_country = ${country || null},
          location_timezone = ${timezone || null},
          location_lat = ${finalLat || null},
          location_lon = ${finalLon || null}
        where id = ${gardenId}
        returning id, location_city, location_country, preferred_language
      `
    }
    console.log('[garden-location] Update result:', updateResult)

    res.json({ ok: true, updated: updateResult?.[0] || null })
  } catch (e) {
    console.error('[garden-location] Error:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to update location' })
  }
})

// Update garden advice language preference
app.put('/api/garden/:id/language', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    console.log('[garden-language] PUT request for garden:', gardenId, 'body:', JSON.stringify(req.body))
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    console.log('[garden-language] User:', user?.id)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    const { preferredLanguage } = req.body || {}

    // Verify membership with owner/admin role
    const membership = await sql`
      select role from public.garden_members
      where garden_id = ${gardenId} and user_id = ${user.id}
      limit 1
    `
    if (!membership?.[0] || membership[0].role !== 'owner') {
      // Check if admin
      const adminCheck = await sql`select is_admin from public.profiles where id = ${user.id}`
      if (!adminCheck?.[0]?.is_admin) {
        res.status(403).json({ ok: false, error: 'Only garden owners can update language preference' })
        return
      }
    }

    // Validate language code (only website languages supported)
    const validLanguages = ['en', 'fr']
    const lang = String(preferredLanguage || 'en').toLowerCase()
    if (!validLanguages.includes(lang)) {
      res.status(400).json({ ok: false, error: 'Invalid language code. Only English and French are supported.' })
      return
    }

    console.log('[garden-language] Updating garden language to:', lang)
    const updateResult = await sql`
      update public.gardens set
        preferred_language = ${lang}
      where id = ${gardenId}
      returning id, preferred_language
    `
    console.log('[garden-language] Update result:', updateResult)

    res.json({ ok: true, updated: updateResult?.[0] || null })
  } catch (e) {
    console.error('[garden-language] Error:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to update language preference' })
  }
})

// Get weather data for a garden based on its location
app.get('/api/garden/:id/weather', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    // Get garden location
    const gardenResult = await sql`
      select location_city, location_country, location_lat, location_lon, location_timezone
      from public.gardens
      where id = ${gardenId}
      limit 1
    `
    const garden = gardenResult?.[0]
    if (!garden) {
      res.status(404).json({ ok: false, error: 'Garden not found' })
      return
    }

    let lat = garden.location_lat
    let lon = garden.location_lon

    // If lat/lon missing but city is set, try to geocode
    if ((!lat || !lon) && garden.location_city) {
      try {
        console.log('[garden-weather] Geocoding city:', garden.location_city)
        const geoResp = await fetch(`https://geocoding-api.open-meteo.com/v1/search?name=${encodeURIComponent(garden.location_city)}&count=1`)
        if (geoResp.ok) {
          const geoData = await geoResp.json()
          if (geoData.results?.[0]) {
            lat = geoData.results[0].latitude
            lon = geoData.results[0].longitude
            console.log('[garden-weather] Geocoded to:', lat, lon)
            // Optionally update the garden record with the coordinates
            await sql`
              update public.gardens 
              set location_lat = ${lat}, location_lon = ${lon}
              where id = ${gardenId}
            `.catch(() => { }) // Non-blocking update
          }
        }
      } catch (geoErr) {
        console.warn('[garden-weather] Geocoding failed:', geoErr)
      }
    }

    if (!lat || !lon) {
      res.status(400).json({ ok: false, error: 'Garden location not set', noLocation: true })
      return
    }

    // Fetch weather from Open-Meteo API
    const weatherUrl = `https://api.open-meteo.com/v1/forecast?latitude=${lat}&longitude=${lon}&current=temperature_2m,relative_humidity_2m,weather_code,wind_speed_10m&daily=temperature_2m_max,temperature_2m_min,weather_code,precipitation_probability_max&timezone=${garden.location_timezone || 'auto'}&forecast_days=7`

    const weatherResp = await fetch(weatherUrl)
    if (!weatherResp.ok) {
      res.status(502).json({ ok: false, error: 'Failed to fetch weather data' })
      return
    }

    const weatherJson = await weatherResp.json()

    // Convert weather code to condition string
    const getConditionFromCode = (code) => {
      if (code === 0) return 'clear'
      if (code === 1 || code === 2) return 'partly cloudy'
      if (code === 3) return 'cloudy'
      if (code >= 45 && code <= 48) return 'foggy'
      if (code >= 51 && code <= 67) return 'rain'
      if (code >= 71 && code <= 77) return 'snow'
      if (code >= 80 && code <= 82) return 'rain'
      if (code >= 85 && code <= 86) return 'snow'
      if (code >= 95) return 'thunderstorm'
      return 'cloudy'
    }

    const weather = {
      current: {
        temp: weatherJson.current?.temperature_2m,
        humidity: weatherJson.current?.relative_humidity_2m,
        windSpeed: weatherJson.current?.wind_speed_10m,
        condition: getConditionFromCode(weatherJson.current?.weather_code)
      },
      forecast: weatherJson.daily?.time?.map((date, idx) => ({
        date,
        tempMax: weatherJson.daily.temperature_2m_max?.[idx],
        tempMin: weatherJson.daily.temperature_2m_min?.[idx],
        precipProbability: weatherJson.daily.precipitation_probability_max?.[idx] || 0,
        condition: getConditionFromCode(weatherJson.daily.weather_code?.[idx])
      })) || []
    }

    res.json({
      ok: true,
      weather,
      location: {
        city: garden.location_city,
        country: garden.location_country,
        lat,
        lon
      }
    })
  } catch (e) {
    console.error('[garden-weather] Error:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to fetch weather' })
  }
})

// ============ PLANT HEALTH ENDPOINTS ============

// Update plant health status and notes
app.put('/api/garden/:gardenId/plant/:plantId/health', async (req, res) => {
  try {
    const gardenId = String(req.params.gardenId || '').trim()
    const plantId = String(req.params.plantId || '').trim()
    if (!gardenId || !plantId) {
      res.status(400).json({ ok: false, error: 'garden id and plant id required' })
      return
    }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    const { healthStatus, notes } = req.body || {}

    // Verify membership
    const membership = await sql`
      select 1 from public.garden_members
      where garden_id = ${gardenId} and user_id = ${user.id}
      limit 1
    `
    if (!membership?.length) {
      res.status(403).json({ ok: false, error: 'Access denied' })
      return
    }

    // Validate health status
    const validStatuses = ['thriving', 'healthy', 'okay', 'struggling', 'critical', null]
    if (healthStatus !== undefined && !validStatuses.includes(healthStatus)) {
      res.status(400).json({ ok: false, error: 'Invalid health status' })
      return
    }

    // Update plant
    await sql`
      update public.garden_plants
      set 
        health_status = ${healthStatus || null},
        notes = ${notes || null},
        last_health_update = now()
      where id = ${plantId} and garden_id = ${gardenId}
    `

    res.json({ ok: true })
  } catch (e) {
    console.error('[plant-health] Error:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to update plant health' })
  }
})

// Get plant details including health
app.get('/api/garden/:gardenId/plant/:plantId', async (req, res) => {
  try {
    const gardenId = String(req.params.gardenId || '').trim()
    const plantId = String(req.params.plantId || '').trim()
    if (!gardenId || !plantId) {
      res.status(400).json({ ok: false, error: 'garden id and plant id required' })
      return
    }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    // Verify membership
    const membership = await sql`
      select 1 from public.garden_members
      where garden_id = ${gardenId} and user_id = ${user.id}
      limit 1
    `
    if (!membership?.length) {
      res.status(403).json({ ok: false, error: 'Access denied' })
      return
    }

    // Get plant with health status
    const plants = await sql`
      select gp.id, gp.nickname, gp.plants_on_hand, gp.health_status, gp.notes, 
             gp.last_health_update, gp.planted_at, gp.expected_bloom_date,
             p.id as plant_id, p.name as plant_name, p.scientific_name,
             p.watering_type, p.level_sun, p.maintenance_level
      from public.garden_plants gp
      left join public.plants p on p.id = gp.plant_id
      where gp.id = ${plantId} and gp.garden_id = ${gardenId}
      limit 1
    `

    if (!plants?.length) {
      res.status(404).json({ ok: false, error: 'Plant not found' })
      return
    }

    const plant = plants[0]
    res.json({
      ok: true,
      plant: {
        id: plant.id,
        nickname: plant.nickname,
        plantsOnHand: plant.plants_on_hand,
        healthStatus: plant.health_status,
        notes: plant.notes,
        lastHealthUpdate: plant.last_health_update,
        plantedAt: plant.planted_at,
        expectedBloomDate: plant.expected_bloom_date,
        plantId: plant.plant_id,
        plantName: plant.plant_name,
        scientificName: plant.scientific_name,
        wateringType: plant.watering_type,
        levelSun: plant.level_sun,
        maintenanceLevel: plant.maintenance_level,
      }
    })
  } catch (e) {
    console.error('[plant-details] Error:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to get plant details' })
  }
})

// ============ JOURNAL ENDPOINTS ============

// Get journal entries for a garden
app.get('/api/garden/:id/journal', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    // Verify membership
    const membership = await sql`
      select 1 from public.garden_members
      where garden_id = ${gardenId} and user_id = ${user.id}
      limit 1
    `
    if (!membership?.length) {
      res.status(403).json({ ok: false, error: 'Access denied' })
      return
    }

    // Get entries (own entries + non-private entries from others)
    const entries = await sql`
      select 
        e.id, e.garden_id, e.user_id, e.entry_date, e.title, e.content, e.mood,
        e.weather_snapshot, e.plants_mentioned, e.tags, e.is_private,
        e.ai_feedback, e.ai_feedback_generated_at, e.created_at, e.updated_at,
        p.display_name as author_name
      from public.garden_journal_entries e
      left join public.profiles p on p.id = e.user_id
      where e.garden_id = ${gardenId}
        and (e.user_id = ${user.id} or e.is_private = false)
      order by e.entry_date desc, e.created_at desc
      limit 100
    `

    // Get photos for each entry
    const entryIds = entries.map(e => e.id)
    let photosMap = {}
    if (entryIds.length > 0) {
      const photos = await sql`
        select id, entry_id, garden_plant_id, image_url, thumbnail_url, caption,
               plant_health, observations, taken_at, uploaded_at
        from public.garden_journal_photos
        where entry_id = any(${entryIds})
        order by uploaded_at asc
      `
      for (const photo of photos) {
        if (!photosMap[photo.entry_id]) photosMap[photo.entry_id] = []
        photosMap[photo.entry_id].push({
          id: String(photo.id),
          entryId: String(photo.entry_id),
          gardenPlantId: photo.garden_plant_id ? String(photo.garden_plant_id) : null,
          imageUrl: photo.image_url,
          thumbnailUrl: photo.thumbnail_url,
          caption: photo.caption,
          plantHealth: photo.plant_health,
          observations: photo.observations,
          takenAt: photo.taken_at,
          uploadedAt: photo.uploaded_at,
        })
      }
    }

    const result = entries.map(e => ({
      id: String(e.id),
      gardenId: String(e.garden_id),
      userId: String(e.user_id),
      authorName: e.author_name,
      entryDate: e.entry_date,
      title: e.title,
      content: e.content,
      mood: e.mood,
      weatherSnapshot: e.weather_snapshot || {},
      plantsMentioned: e.plants_mentioned || [],
      tags: e.tags || [],
      isPrivate: e.is_private,
      aiFeedback: e.ai_feedback,
      aiFeedbackGeneratedAt: e.ai_feedback_generated_at,
      photos: photosMap[e.id] || [],
      createdAt: e.created_at,
      updatedAt: e.updated_at,
    }))

    res.json({ ok: true, entries: result })
  } catch (e) {
    console.error('[journal] Error fetching entries:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to fetch journal' })
  }
})

// Create journal entry
app.post('/api/garden/:id/journal', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }

    // Rate limit: 20 journal entries per hour per user
    if (await checkRateLimit('gardenJournal', req, res, user)) {
      return
    }

    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    const { title, content, mood, isPrivate, tags, photos } = req.body || {}
    if (!content?.trim()) {
      res.status(400).json({ ok: false, error: 'Content is required' })
      return
    }

    // Verify membership
    const membership = await sql`
      select 1 from public.garden_members
      where garden_id = ${gardenId} and user_id = ${user.id}
      limit 1
    `
    if (!membership?.length) {
      res.status(403).json({ ok: false, error: 'Access denied' })
      return
    }

    // Fetch weather for the entry
    let weatherSnapshot = {}
    try {
      const gardenRows = await sql`
        select location_city, location_lat, location_lon
        from public.gardens where id = ${gardenId} limit 1
      `
      const garden = gardenRows[0]
      if (garden?.location_city || garden?.location_lat) {
        const weather = await fetchWeatherForLocation(garden.location_lat, garden.location_lon, garden.location_city)
        if (weather?.current) {
          weatherSnapshot = weather.current
        }
      }
    } catch { }

    const today = new Date().toISOString().slice(0, 10)

    // Insert entry
    const insertResult = await sql`
      insert into public.garden_journal_entries (
        garden_id, user_id, entry_date, title, content, mood, is_private, tags, weather_snapshot
      ) values (
        ${gardenId}, ${user.id}, ${today}, ${title || null}, ${content.trim()},
        ${mood || null}, ${isPrivate || false}, ${JSON.stringify(tags || [])}::text[], ${JSON.stringify(weatherSnapshot)}::jsonb
      )
      returning id
    `
    const entryId = insertResult[0]?.id

    // Insert photos if any
    if (photos?.length && entryId) {
      for (const photoUrl of photos) {
        await sql`
          insert into public.garden_journal_photos (entry_id, image_url)
          values (${entryId}, ${photoUrl})
        `
      }
    }

    res.json({ ok: true, entryId: String(entryId) })
  } catch (e) {
    console.error('[journal] Error creating entry:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to create entry' })
  }
})

// Update journal entry
app.put('/api/garden/:id/journal', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    const { entryId, title, content, mood, isPrivate, tags, photos } = req.body || {}
    if (!entryId) {
      res.status(400).json({ ok: false, error: 'Entry ID is required' })
      return
    }

    // Verify ownership
    const entry = await sql`
      select id, user_id from public.garden_journal_entries
      where id = ${entryId} and garden_id = ${gardenId}
      limit 1
    `
    if (!entry?.length || entry[0].user_id !== user.id) {
      res.status(403).json({ ok: false, error: 'You can only edit your own entries' })
      return
    }

    await sql`
      update public.garden_journal_entries set
        title = ${title || null},
        content = ${content?.trim() || ''},
        mood = ${mood || null},
        is_private = ${isPrivate || false},
        tags = ${JSON.stringify(tags || [])}::text[],
        updated_at = now()
      where id = ${entryId}
    `

    // Add new photos if any
    if (photos?.length) {
      for (const photoUrl of photos) {
        await sql`
          insert into public.garden_journal_photos (entry_id, image_url)
          values (${entryId}, ${photoUrl})
        `
      }
    }

    res.json({ ok: true })
  } catch (e) {
    console.error('[journal] Error updating entry:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to update entry' })
  }
})

// Delete journal entry
app.delete('/api/garden/:id/journal/:entryId', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    const entryId = String(req.params.entryId || '').trim()
    if (!gardenId || !entryId) { res.status(400).json({ ok: false, error: 'garden id and entry id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    // Verify ownership or owner role
    const entry = await sql`
      select e.id, e.user_id, gm.role
      from public.garden_journal_entries e
      join public.garden_members gm on gm.garden_id = e.garden_id and gm.user_id = ${user.id}
      where e.id = ${entryId} and e.garden_id = ${gardenId}
      limit 1
    `
    if (!entry?.length) {
      res.status(404).json({ ok: false, error: 'Entry not found' })
      return
    }
    if (entry[0].user_id !== user.id && entry[0].role !== 'owner') {
      res.status(403).json({ ok: false, error: 'You can only delete your own entries' })
      return
    }

    // Photos will be cascade deleted
    await sql`delete from public.garden_journal_entries where id = ${entryId}`

    res.json({ ok: true })
  } catch (e) {
    console.error('[journal] Error deleting entry:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to delete entry' })
  }
})

// Generate AI feedback for a journal entry (with image analysis)
app.post('/api/garden/:id/journal/:entryId/feedback', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    const entryId = String(req.params.entryId || '').trim()
    if (!gardenId || !entryId) { res.status(400).json({ ok: false, error: 'garden id and entry id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }
    if (!openai) { res.status(500).json({ ok: false, error: 'AI not configured' }); return }

    // Get entry with photos
    const entries = await sql`
      select e.*, g.name as garden_name, g.location_city
      from public.garden_journal_entries e
      join public.gardens g on g.id = e.garden_id
      where e.id = ${entryId} and e.garden_id = ${gardenId} and e.user_id = ${user.id}
      limit 1
    `
    if (!entries?.length) {
      res.status(404).json({ ok: false, error: 'Entry not found' })
      return
    }
    const entry = entries[0]

    // Get photos for this entry
    const photos = await sql`
      select gjp.image_url, gjp.caption, gjp.plant_health, gjp.observations,
             gp.nickname, p.name as plant_name
      from public.garden_journal_photos gjp
      left join public.garden_plants gp on gp.id = gjp.garden_plant_id
      left join public.plants p on p.id = gp.plant_id
      where gjp.entry_id = ${entryId}
      order by gjp.uploaded_at desc
      limit 4
    `

    // Get plants in garden for context
    const plants = await sql`
      select gp.nickname, p.name as plant_name
      from public.garden_plants gp
      left join public.plants p on p.id = gp.plant_id
      where gp.garden_id = ${gardenId}
      limit 20
    `
    const plantList = plants.map(p => p.nickname || p.plant_name).filter(Boolean).join(', ')

    // Get weather context if available
    let weatherContext = ''
    if (entry.weather_snapshot?.temp) {
      weatherContext = `Weather when entry was written: ${entry.weather_snapshot.temp}Â°C, ${entry.weather_snapshot.condition || 'Unknown'}`
    }

    const moodLabels = {
      blooming: 'Garden is blooming beautifully',
      thriving: 'Garden is thriving and growing strong',
      sprouting: 'New growth is appearing',
      resting: 'Garden is in a resting/dormant phase',
      wilting: 'Some plants need attention'
    }

    // Build prompt
    const textPrompt = `You are a friendly, knowledgeable gardening expert providing personalized feedback on a gardener's journal entry.

Garden: "${entry.garden_name}"
${entry.location_city ? `Location: ${entry.location_city}` : ''}
Plants in garden: ${plantList || 'Not specified'}
${weatherContext}

Journal Entry Date: ${entry.entry_date}
${entry.mood ? `Garden Status: ${moodLabels[entry.mood] || entry.mood}` : ''}
${entry.title ? `Title: ${entry.title}` : ''}

Entry Content:
"${entry.content}"

${photos.length > 0 ? `The gardener has attached ${photos.length} photo(s) with this entry. Please analyze the images carefully and include observations about:
- Plant health and appearance
- Any signs of disease, pests, or nutrient deficiency
- Growth progress
- Care recommendations based on what you see` : ''}

Please provide detailed, warm, helpful feedback that:
1. ${photos.length > 0 ? 'Describes what you observe in the photos' : 'Acknowledges their observations'}
2. Identifies any issues or areas needing attention
3. Offers specific, actionable tips based on what you see
4. Celebrates any positive progress
5. Encourages their gardening journey

Be specific and reference what you actually see in the images. If you notice any concerning signs, explain what they might be and how to address them.`

    const journalInstructions = 'You are a friendly, expert gardener who can analyze plant photos and provide detailed, helpful feedback. When analyzing images, be specific about what you observe.'
    
    let feedback
    let tokensUsed = 0

    // Build input content for Responses API
    const inputContent = [{ type: 'input_text', text: textPrompt }]

    // Add images using Responses API format
    if (photos.length > 0) {
      for (const photo of photos) {
        const imageUrl = supabaseStorageToMediaProxy(photo.image_url) || photo.image_url
        inputContent.push({
          type: 'input_image',
          image_url: imageUrl
        })
      }
    }

    // Use Responses API for both text and vision
    const response = await openaiClient.responses.create(
      {
        model: photos.length > 0 ? openaiModel : openaiModelNano, // Use larger model for vision
        reasoning: { effort: photos.length > 0 ? 'medium' : 'low' },
        instructions: journalInstructions,
        input: [{ role: 'user', content: inputContent }],
      },
      { timeout: photos.length > 0 ? 120000 : 60000 }
    )

    feedback = typeof response?.output_text === 'string' ? response.output_text.trim() : ''
    tokensUsed = response.usage?.total_tokens || 0

    await sql`
      update public.garden_journal_entries
      set ai_feedback = ${feedback}, ai_feedback_generated_at = now()
      where id = ${entryId}
    `

    res.json({ ok: true, feedback, imagesAnalyzed: photos.length, tokensUsed })
  } catch (e) {
    console.error('[journal-feedback] Error:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to generate feedback' })
  }
})

// Export AI analysis as a formatted document
app.get('/api/garden/:id/advice/export', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }
    if (!sql) { res.status(500).json({ ok: false, error: 'Database not configured' }); return }

    const format = req.query.format || 'json' // json, txt, md

    // Verify membership
    const membership = await sql`
      select 1 from public.garden_members
      where garden_id = ${gardenId} and user_id = ${user.id}
      limit 1
    `
    if (!membership?.length) {
      res.status(403).json({ ok: false, error: 'Access denied' })
      return
    }

    // Get garden info
    const gardenRows = await sql`
      select name, location_city, location_country, created_at
      from public.gardens where id = ${gardenId} limit 1
    `
    const garden = gardenRows[0]
    if (!garden) {
      res.status(404).json({ ok: false, error: 'Garden not found' })
      return
    }

    // Get all AI advice history
    let adviceHistory
    const runAdviceHistoryBaseQuery = () => sql`
      select week_start, advice_text, advice_summary, focus_areas, plant_specific_tips,
             improvement_score, generated_at
      from public.garden_ai_advice
      where garden_id = ${gardenId}
      order by week_start desc
      limit 12
    `

    if (gardenAdviceContextColumnsSupported) {
      try {
        adviceHistory = await sql`
          select week_start, advice_text, advice_summary, focus_areas, plant_specific_tips,
                 improvement_score, weather_context, generated_at
          from public.garden_ai_advice
          where garden_id = ${gardenId}
          order by week_start desc
          limit 12
        `
      } catch (err) {
        if (isMissingColumnError(err)) {
          disableGardenAdviceContextColumns('export-select', err)
          adviceHistory = await runAdviceHistoryBaseQuery()
        } else {
          throw err
        }
      }
    } else {
      adviceHistory = await runAdviceHistoryBaseQuery()
    }

    // Get recent journal entries with AI feedback and photos
    const journalEntries = await sql`
      select gje.id, gje.entry_date, gje.title, gje.content, gje.mood, gje.ai_feedback, gje.ai_feedback_generated_at,
             (select json_agg(json_build_object(
               'url', gjp.image_url,
               'caption', gjp.caption,
               'observations', gjp.observations,
               'plantHealth', gjp.plant_health
             )) from public.garden_journal_photos gjp where gjp.entry_id = gje.id) as photos
      from public.garden_journal_entries gje
      where gje.garden_id = ${gardenId} and gje.ai_feedback is not null
      order by gje.entry_date desc
      limit 20
    `

    // Get plant info
    const plants = await sql`
      select gp.nickname, p.name as plant_name, gp.plants_on_hand
      from public.garden_plants gp
      left join public.plants p on p.id = gp.plant_id
      where gp.garden_id = ${gardenId}
      limit 50
    `

    const exportData = {
      garden: {
        name: garden.name,
        location: garden.location_city ? `${garden.location_city}${garden.location_country ? ', ' + garden.location_country : ''}` : null,
        createdAt: garden.created_at,
        plantsCount: plants.length,
      },
      plants: plants.map(p => ({
        name: p.nickname || p.plant_name,
        quantity: p.plants_on_hand || 1,
      })),
      weeklyAdvice: adviceHistory.map(a => ({
        weekStart: a.week_start,
        summary: a.advice_summary,
        focusAreas: a.focus_areas || [],
        plantTips: normalizeJsonArray(a.plant_specific_tips),
        score: a.improvement_score,
        weather: a.weather_context?.current ? `${a.weather_context.current.temp}Â°C, ${a.weather_context.current.condition}` : null,
        fullAdvice: a.advice_text,
        generatedAt: a.generated_at,
      })),
      journalFeedback: journalEntries.map(e => ({
        date: e.entry_date,
        title: e.title,
        mood: e.mood,
        yourEntry: e.content,
        aiFeedback: e.ai_feedback,
        feedbackGeneratedAt: e.ai_feedback_generated_at,
        photos: (e.photos || []).map(p => ({
          url: supabaseStorageToMediaProxy(p.url) || p.url,
          caption: p.caption,
          observations: p.observations,
          plantHealth: p.plantHealth,
        })),
        photosAnalyzed: Math.min((e.photos || []).length, 4),
      })),
      exportedAt: new Date().toISOString(),
    }

    if (format === 'json') {
      res.setHeader('Content-Type', 'application/json')
      res.setHeader('Content-Disposition', `attachment; filename="${garden.name}-garden-analysis.json"`)
      res.json(exportData)
    } else if (format === 'md' || format === 'txt') {
      // Generate markdown/text format
      let content = `# ${garden.name} - Garden Analysis Report\n\n`
      content += `**Exported:** ${new Date().toLocaleDateString()}\n`
      if (exportData.garden.location) content += `**Location:** ${exportData.garden.location}\n`
      content += `**Plants:** ${exportData.garden.plantsCount}\n\n`

      content += `---\n\n## Your Plants\n\n`
      exportData.plants.forEach(p => {
        content += `- ${p.name} (${p.quantity})\n`
      })

      content += `\n---\n\n## Weekly Gardener Advice\n\n`
      exportData.weeklyAdvice.forEach(a => {
        content += `### Week of ${a.weekStart}\n`
        if (a.score) content += `**Garden Score:** ${a.score}/100\n`
        if (a.weather) content += `**Weather:** ${a.weather}\n`
        content += `\n**Summary:** ${a.summary || 'N/A'}\n\n`
        if (a.focusAreas?.length) {
          content += `**Focus Areas:**\n`
          a.focusAreas.forEach((f, i) => content += `${i + 1}. ${f}\n`)
          content += `\n`
        }
        if (a.plantTips?.length) {
          content += `**Plant Tips:**\n`
          a.plantTips.forEach(t => {
            content += `- **${t.plantName}** (${t.priority}): ${t.tip}\n`
          })
          content += `\n`
        }
        if (a.fullAdvice) {
          content += `**Detailed Advice:**\n${a.fullAdvice}\n\n`
        }
        content += `---\n\n`
      })

      if (exportData.journalFeedback.length > 0) {
        content += `## Journal Entry Feedback\n\n`
        exportData.journalFeedback.forEach(e => {
          content += `### ${e.date}${e.title ? ' - ' + e.title : ''}\n`
          if (e.mood) content += `**Garden Status:** ${e.mood}\n`
          if (e.photosAnalyzed > 0) content += `**Photos Analyzed:** ${e.photosAnalyzed}\n`
          content += `\n**Your Entry:**\n${e.yourEntry}\n\n`
          if (e.photos && e.photos.length > 0) {
            content += `**Photos:**\n`
            e.photos.forEach((p, i) => {
              content += `- Photo ${i + 1}: ${p.url}\n`
              if (p.caption) content += `  Caption: ${p.caption}\n`
              if (p.observations) content += `  Observations: ${p.observations}\n`
              if (p.plantHealth) content += `  Plant Health: ${p.plantHealth}\n`
            })
            content += `\n`
          }
          content += `**AI Feedback:**\n${e.aiFeedback}\n\n`
          content += `---\n\n`
        })
      }

      const ext = format === 'md' ? 'md' : 'txt'
      res.setHeader('Content-Type', 'text/plain; charset=utf-8')
      res.setHeader('Content-Disposition', `attachment; filename="${garden.name}-garden-analysis.${ext}"`)
      res.send(content)
    } else {
      res.status(400).json({ ok: false, error: 'Invalid format. Use json, md, or txt' })
    }
  } catch (e) {
    console.error('[advice-export] Error:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to export analysis' })
  }
})

// Upload photo for garden (used by journal)
app.post('/api/garden/:id/upload', async (req, res) => {
  try {
    const gardenId = String(req.params.id || '').trim()
    if (!gardenId) { res.status(400).json({ ok: false, error: 'garden id required' }); return }
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) { res.status(401).json({ ok: false, error: 'Unauthorized' }); return }

    // Rate limit: 50 image uploads per hour per user (admins exempt)
    if (await checkRateLimit('imageUpload', req, res, user)) {
      return
    }

    // Verify membership
    if (sql) {
      const membership = await sql`
        select 1 from public.garden_members
        where garden_id = ${gardenId} and user_id = ${user.id}
        limit 1
      `
      if (!membership?.length) {
        res.status(403).json({ ok: false, error: 'Access denied' })
        return
      }
    }

    // Parse multipart form data
    const busboy = (await import('busboy')).default
    const bb = busboy({ headers: req.headers })

    let fileBuffer = null
    let fileName = ''
    let mimeType = ''
    let folder = 'journal'

    bb.on('file', (name, file, info) => {
      fileName = info.filename
      mimeType = info.mimeType
      const chunks = []
      file.on('data', (data) => chunks.push(data))
      file.on('end', () => { fileBuffer = Buffer.concat(chunks) })
    })

    bb.on('field', (name, val) => {
      if (name === 'folder') folder = val
    })

    bb.on('finish', async () => {
      if (!fileBuffer) {
        res.status(400).json({ ok: false, error: 'No file uploaded' })
        return
      }

      const originalSize = fileBuffer.length
      let finalBuffer = fileBuffer
      let finalMimeType = mimeType
      let finalExt = fileName.split('.').pop() || 'jpg'
      const gardenUploadQuality = 50 // Standard 50% quality for non-admin uploads

      // Optimize images (convert to WebP)
      const isOptimizableImage = ['image/jpeg', 'image/png', 'image/webp'].includes(mimeType.toLowerCase())
      if (isOptimizableImage) {
        try {
          finalBuffer = await sharp(fileBuffer)
            .rotate()
            .resize({
              width: 1920,
              height: 1920,
              fit: 'inside',
              withoutEnlargement: true,
            })
            .webp({ quality: gardenUploadQuality })
            .toBuffer()
          finalMimeType = 'image/webp'
          finalExt = 'webp'
        } catch (sharpErr) {
          console.error('[garden-upload] sharp optimization failed, using original', sharpErr)
          // Fall back to original if optimization fails
        }
      }

      // Generate unique filename
      const uniqueName = `${Date.now()}-${Math.random().toString(36).slice(2)}.${finalExt}`
      const storagePath = `gardens/${gardenId}/${folder}/${uniqueName}`

      // Upload to Supabase Storage (PHOTOS bucket)
      const { data, error } = await supabaseServiceClient.storage
        .from('PHOTOS')
        .upload(storagePath, finalBuffer, {
          contentType: finalMimeType,
          upsert: false,
        })

      if (error) {
        console.error('[upload] Storage error:', error)
        res.status(500).json({ ok: false, error: 'Failed to upload file' })
        return
      }

      // Get public URL and transform to media proxy
      const { data: urlData } = supabaseServiceClient.storage.from('PHOTOS').getPublicUrl(storagePath)
      const proxyUrl = supabaseStorageToMediaProxy(urlData?.publicUrl) || urlData?.publicUrl || ''

      // Record to global image database
      let uploaderDisplayName = null
      try {
        uploaderDisplayName = await getAdminProfileName(user.id)
      } catch { }
      
      const compressionPercent = originalSize > 0 && isOptimizableImage
        ? Math.max(0, Math.round(100 - (finalBuffer.length / originalSize) * 100))
        : 0

      try {
        await recordAdminMediaUpload({
          adminId: user.id,
          adminEmail: user.email || null,
          adminName: uploaderDisplayName,
          bucket: 'PHOTOS',
          path: storagePath,
          publicUrl: proxyUrl,
          mimeType: finalMimeType,
          originalMimeType: mimeType || 'image/jpeg',
          sizeBytes: finalBuffer.length,
          originalSizeBytes: originalSize,
          quality: isOptimizableImage ? gardenUploadQuality : null,
          compressionPercent,
          uploadSource: folder === 'journal' ? 'garden_journal' : 'garden_photo',
          metadata: {
            source: folder === 'journal' ? 'garden_journal' : 'garden_photo',
            originalName: fileName,
            gardenId: gardenId,
            folder: folder,
            userId: user.id,
          },
          createdAt: new Date().toISOString(),
        })
      } catch (recordErr) {
        console.error('[upload] failed to record media upload', recordErr)
      }

      res.json({ ok: true, url: proxyUrl, path: storagePath })
    })

    req.pipe(bb)
  } catch (e) {
    console.error('[upload] Error:', e)
    res.status(500).json({ ok: false, error: e?.message || 'Failed to upload' })
  }
})

// Serve environment config for admin frontend
app.get('/api/env.js', (req, res) => {
  const adminToken = process.env.ADMIN_STATIC_TOKEN || process.env.VITE_ADMIN_STATIC_TOKEN || ''
  const content = `window.__ENV__ = { VITE_ADMIN_STATIC_TOKEN: "${adminToken}" };`
  res.setHeader('Content-Type', 'application/javascript')
  res.send(content)
})

// Admin: Get all email templates
app.get('/api/admin/email-templates', async (req, res) => {
  try {
    const adminId = await ensureAdmin(req, res)
    if (!adminId) return
    if (!sql) { res.status(500).json({ error: 'Database not configured' }); return }

    const templates = await sql`
      select 
        id, title, subject, description, preview_text as "previewText",
        body_html as "bodyHtml", body_json as "bodyJson", variables,
        is_active as "isActive", version, last_used_at as "lastUsedAt",
        campaign_count as "campaignCount", created_at as "createdAt", updated_at as "updatedAt"
      from public.admin_email_templates
      where deleted_at is null
      order by updated_at desc
    `
    res.json({ ok: true, templates })
  } catch (e) {
    console.error('[email-templates] Error listing templates:', e)
    res.status(500).json({ ok: false, error: e.message })
  }
})

// Admin: Get single email template
app.get('/api/admin/email-templates/:id', async (req, res) => {
  try {
    const adminId = await ensureAdmin(req, res)
    if (!adminId) return
    if (!sql) { res.status(500).json({ error: 'Database not configured' }); return }

    const { id } = req.params
    const templates = await sql`
      select 
        id, title, subject, description, preview_text as "previewText",
        body_html as "bodyHtml", body_json as "bodyJson", variables,
        is_active as "isActive", version, last_used_at as "lastUsedAt",
        campaign_count as "campaignCount", created_at as "createdAt", updated_at as "updatedAt"
      from public.admin_email_templates
      where id = ${id}
    `

    if (!templates || templates.length === 0) {
      res.status(404).json({ ok: false, error: 'Template not found' })
      return
    }

    res.json(templates[0])
  } catch (e) {
    console.error('[email-templates] Error getting template:', e)
    res.status(500).json({ ok: false, error: e.message })
  }
})

// Admin: Create/Update email template
app.post('/api/admin/email-templates', async (req, res) => {
  try {
    const adminId = await ensureAdmin(req, res)
    if (!adminId) return
    if (!sql) { res.status(500).json({ error: 'Database not configured' }); return }

    const {
      id, title, subject, description, previewText,
      bodyHtml, bodyJson, variables, isActive
    } = req.body

    let result
    if (id) {
      // Update existing
      result = await sql`
        update public.admin_email_templates set
          title = ${title},
          subject = ${subject},
          description = ${description},
          preview_text = ${previewText},
          body_html = ${bodyHtml},
          body_json = ${bodyJson},
          variables = ${variables},
          is_active = ${isActive},
          updated_at = now(),
          version = version + 1
        where id = ${id}
        returning id
      `
    } else {
      // Create new
      result = await sql`
        insert into public.admin_email_templates (
          title, subject, description, preview_text, 
          body_html, body_json, variables, is_active
        ) values (
          ${title}, ${subject}, ${description}, ${previewText},
          ${bodyHtml}, ${bodyJson}, ${variables}, ${isActive}
        )
        returning id
      `
    }

    res.json({ ok: true, id: result?.[0]?.id })
  } catch (e) {
    console.error('[email-templates] Error saving template:', e)
    res.status(500).json({ ok: false, error: e.message })
  }
})


// Admin: create a new broadcast message
app.post('/api/admin/broadcast', async (req, res) => {
  try {
    // Require admin and ensure table
    const adminId = await ensureAdmin(req, res)
    if (!adminId) return
    if (!sql) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    await ensureBroadcastTable()

    const messageRaw = (req.body?.message || '').toString().trim()
    const severityRaw = (req.body?.severity || '').toString().trim().toLowerCase()
    const severity = (severityRaw === 'warning' || severityRaw === 'danger') ? severityRaw : 'info'
    const durationMsRaw = Number(req.body?.durationMs || req.body?.duration_ms || req.body?.duration || 0)
    if (!messageRaw) {
      res.status(400).json({ error: 'Message is required' })
      return
    }
    // Enforce single active message
    const active = await sql`
      select id from public.broadcast_messages
      where removed_at is null and (expires_at is null or expires_at > now())
      limit 1
    `
    if (Array.isArray(active) && active.length > 0) {
      res.status(409).json({ error: 'An active broadcast already exists' })
      return
    }
    let expiresAt = null
    if (Number.isFinite(durationMsRaw) && durationMsRaw > 0) {
      expiresAt = new Date(Date.now() + Math.floor(durationMsRaw)).toISOString()
    }
    const rows = await sql`
      insert into public.broadcast_messages (message, severity, created_by, expires_at)
      values (${messageRaw}, ${severity}, ${toAdminUuid(adminId)}, ${expiresAt ? expiresAt : null})
      returning id::text as id, message, severity, created_at, expires_at, created_by::text as created_by
    `
    const row = Array.isArray(rows) && rows[0] ? rows[0] : null
    // Resolve admin name for SSE payload convenience
    let adminName = null
    if (row?.created_by && sql) {
      try {
        const nameRows = await sql`select coalesce(display_name, username, '') as name from public.profiles where id = ${row.created_by} limit 1`
        adminName = nameRows?.[0]?.name || null
      } catch { }
    }
    const payload = row ? {
      id: String(row.id || ''),
      message: String(row.message || ''),
      severity: String(row.severity || 'info'),
      createdAt: row.created_at ? new Date(row.created_at).toISOString() : null,
      expiresAt: row.expires_at ? new Date(row.expires_at).toISOString() : null,
      createdBy: row.created_by ? String(row.created_by) : null,
      adminName: adminName ? String(adminName) : null,
      serverTime: new Date().toISOString(),
    } : null
    if (payload) broadcastToAll(payload)
    res.json({ ok: true, broadcast: payload })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to create broadcast' })
  }
})

// Admin: update current broadcast message (edit message or severity, optionally extend/shorten duration)
app.put('/api/admin/broadcast', async (req, res) => {
  try {
    const adminId = await ensureAdmin(req, res)
    if (!adminId) return
    if (!sql) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    await ensureBroadcastTable()
    // Find current active
    const rows = await sql`
      select id, message, severity, created_at, expires_at, created_by::text as created_by
      from public.broadcast_messages
      where removed_at is null and (expires_at is null or expires_at > now())
      order by created_at desc
      limit 1
    `
    const cur = Array.isArray(rows) && rows[0] ? rows[0] : null
    if (!cur) {
      res.status(404).json({ error: 'No active broadcast' })
      return
    }
    const nextMessage = (req.body?.message ?? cur.message)?.toString()?.trim()
    const sevRaw = (req.body?.severity ?? cur.severity)?.toString()?.trim()?.toLowerCase()
    const nextSeverity = (sevRaw === 'warning' || sevRaw === 'danger') ? sevRaw : 'info'
    const durationMsRaw = req.body?.durationMs ?? req.body?.duration_ms ?? null
    let nextExpires = cur.expires_at ? new Date(cur.expires_at) : null
    if (durationMsRaw === null) {
      // keep as is
    } else {
      const n = Number(durationMsRaw)
      if (Number.isFinite(n) && n > 0) nextExpires = new Date(Date.now() + Math.floor(n))
      else nextExpires = null
    }
    const upd = await sql`
      update public.broadcast_messages
      set message = ${nextMessage}, severity = ${nextSeverity}, expires_at = ${nextExpires ? nextExpires.toISOString() : null}
      where id = ${cur.id}
      returning id::text as id, message, severity, created_at, expires_at, created_by::text as created_by
    `
    const row = upd?.[0]
    let adminName = null
    if (row?.created_by && sql) {
      try {
        const nameRows = await sql`select coalesce(display_name, username, '') as name from public.profiles where id = ${row.created_by} limit 1`
        adminName = nameRows?.[0]?.name || null
      } catch { }
    }
    const payload = row ? {
      id: String(row.id || ''),
      message: String(row.message || ''),
      severity: String(row.severity || 'info'),
      createdAt: row.created_at ? new Date(row.created_at).toISOString() : null,
      expiresAt: row.expires_at ? new Date(row.expires_at).toISOString() : null,
      createdBy: row.created_by ? String(row.created_by) : null,
      adminName: adminName ? String(adminName) : null,
      serverTime: new Date().toISOString(),
    } : null
    if (payload) broadcastToAll(payload)
    res.json({ ok: true, broadcast: payload })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to update broadcast' })
  }
})

// Admin: remove current (or specified) broadcast message
app.delete('/api/admin/broadcast', async (req, res) => {
  try {
    const adminId = await ensureAdmin(req, res)
    if (!adminId) return
    if (!sql) {
      res.status(500).json({ error: 'Database not configured' })
      return
    }
    await ensureBroadcastTable()
    const idParam = (req.query?.id || req.body?.id || '').toString().trim()
    let rows
    if (idParam) {
      rows = await sql`
        update public.broadcast_messages
        set removed_at = now()
        where id = ${idParam} and removed_at is null
        returning id
      `
    } else {
      rows = await sql`
        update public.broadcast_messages
        set removed_at = now()
        where removed_at is null and (expires_at is null or expires_at > now())
        returning id
      `
    }
    const changed = Array.isArray(rows) && rows.length > 0
    if (changed) clearBroadcastForAll()
    res.json({ ok: true, removed: changed })
  } catch (e) {
    res.status(500).json({ error: e?.message || 'Failed to remove broadcast' })
  }
})

app.get('/api/notifications', async (req, res) => {
  const user = await getUserFromRequestOrToken(req)
  if (!user?.id) {
    res.status(401).json({ error: 'Unauthorized' })
    return
  }
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  try {
    const rows = await sql`
      select id::text as id, title, message, delivery_status, delivered_at, scheduled_for, seen_at, cta_url, payload
      from public.user_notifications
      where user_id = ${user.id}
      order by coalesce(delivered_at, scheduled_for) desc
      limit 50
    `
    const notifications = (rows || []).map((row) => ({
      id: row.id,
      title: row.title || null,
      message: row.message || null,
      status: row.delivery_status || 'pending',
      deliveredAt: isoOrNull(row.delivered_at),
      scheduledFor: isoOrNull(row.scheduled_for),
      seenAt: isoOrNull(row.seen_at),
      ctaUrl: row.cta_url || null,
      payload: row.payload && typeof row.payload === 'object' ? row.payload : {},
    }))
    res.json({ notifications })
  } catch (err) {
    console.error('[notifications] failed to load user notifications', err)
    res.status(500).json({ error: err?.message || 'Failed to load notifications' })
  }
})

app.post('/api/notifications/:id/read', async (req, res) => {
  const user = await getUserFromRequestOrToken(req)
  if (!user?.id) {
    res.status(401).json({ error: 'Unauthorized' })
    return
  }
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  const notificationId = String(req.params?.id || '').trim()
  if (!notificationId) {
    res.status(400).json({ error: 'Missing notification id' })
    return
  }
  try {
    await sql`
      update public.user_notifications
      set seen_at = now()
      where id = ${notificationId} and user_id = ${user.id}
    `
    res.json({ ok: true })
  } catch (err) {
    console.error('[notifications] failed to update notification', err)
    res.status(500).json({ error: err?.message || 'Failed to update notification' })
  }
})

app.post('/api/push/subscribe', async (req, res) => {
  const user = await getUserFromRequestOrToken(req)
  if (!user?.id) {
    res.status(401).json({ error: 'Unauthorized' })
    return
  }
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  const subscription = req.body?.subscription
  if (!subscription || typeof subscription !== 'object' || !subscription.endpoint) {
    res.status(400).json({ error: 'Invalid subscription payload' })
    return
  }
  const authKey = subscription.keys?.auth || subscription.auth_key || null
  const p256dhKey = subscription.keys?.p256dh || subscription.p256dh_key || null
  const userAgent = req.get('user-agent') || null
  
  // Extract endpoint domain for logging
  let endpointDomain = 'unknown'
  try {
    endpointDomain = new URL(subscription.endpoint).hostname
  } catch {}
  
  console.log(`[push/subscribe] Storing subscription for user ${user.id.slice(0, 8)}... (endpoint: ${endpointDomain})`)
  
  try {
    await sql`
      insert into public.user_push_subscriptions (user_id, endpoint, auth_key, p256dh_key, user_agent, subscription, updated_at, last_used_at)
      values (${user.id}, ${subscription.endpoint}, ${authKey}, ${p256dhKey}, ${userAgent}, ${subscription}, now(), now())
      on conflict (endpoint) do update
      set user_id = excluded.user_id,
          auth_key = excluded.auth_key,
          p256dh_key = excluded.p256dh_key,
          user_agent = excluded.user_agent,
          subscription = excluded.subscription,
          updated_at = now(),
          last_used_at = now()
    `
    console.log(`[push/subscribe] âœ“ Subscription stored successfully for user ${user.id.slice(0, 8)}...`)
    res.json({ ok: true, pushConfigured: pushNotificationsEnabled })
  } catch (err) {
    console.error('[push/subscribe] âœ— Failed to store subscription:', err?.message || err)
    res.status(500).json({ error: err?.message || 'Failed to store subscription' })
  }
})

app.delete('/api/push/subscribe', async (req, res) => {
  const user = await getUserFromRequestOrToken(req)
  if (!user?.id) {
    res.status(401).json({ error: 'Unauthorized' })
    return
  }
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  await ensureNotificationTables()
  const endpoint =
    (req.body?.endpoint || req.query?.endpoint || req.body?.subscription?.endpoint || '')
      .toString()
      .trim()
  if (!endpoint) {
    res.status(400).json({ error: 'Missing endpoint' })
    return
  }
  try {
    await sql`
      delete from public.user_push_subscriptions
      where endpoint = ${endpoint} or (user_id = ${user.id} and endpoint = ${endpoint})
    `
    res.json({ ok: true })
  } catch (err) {
    console.error('[notifications] failed to remove subscription', err)
    res.status(500).json({ error: err?.message || 'Failed to remove subscription' })
  }
})

// ========== Instant Push Notification API ==========
// Sends an immediate push notification for social events (friend requests, garden invites, messages)
// This is called internally when creating these events
app.post('/api/push/instant', async (req, res) => {
  const user = await getUserFromRequestOrToken(req)
  if (!user?.id) {
    res.status(401).json({ error: 'Unauthorized' })
    return
  }

  // Rate limit: 100 push notifications per hour per user (admins exempt)
  if (await checkRateLimit('pushNotify', req, res, user)) {
    return
  }

  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  
  const { recipientId, type, title, body, data, tag: clientTag, renotify } = req.body || {}
  
  if (!recipientId || !type || !title || !body) {
    res.status(400).json({ error: 'Missing required fields: recipientId, type, title, body' })
    return
  }
  
  // Validate notification type
  const validTypes = ['friend_request', 'garden_invite', 'friend_request_accepted', 'garden_invite_accepted', 'new_message']
  if (!validTypes.includes(type)) {
    res.status(400).json({ error: `Invalid notification type. Must be one of: ${validTypes.join(', ')}` })
    return
  }
  
  try {
    // Check if push notifications are enabled
    if (!pushNotificationsEnabled) {
      console.warn('[push/instant] Push notifications disabled (VAPID keys not configured)')
      res.json({ ok: true, sent: false, reason: 'PUSH_DISABLED' })
      return
    }
    
    // For message notifications, check if conversation is muted
    if (type === 'new_message' && data?.conversationId) {
      try {
        const conversation = await sql`
          select id, participant_1, participant_2, muted_by_1, muted_by_2
          from public.conversations
          where id = ${data.conversationId}::uuid
          limit 1
        `
        
        if (conversation && conversation.length > 0) {
          const conv = conversation[0]
          const isRecipientParticipant1 = conv.participant_1 === recipientId
          const isMuted = isRecipientParticipant1 ? conv.muted_by_1 : conv.muted_by_2
          
          if (isMuted) {
            console.log(`[push/instant] Conversation ${data.conversationId} is muted by recipient ${recipientId}, skipping notification`)
            res.json({ ok: true, sent: false, reason: 'CONVERSATION_MUTED' })
            return
          }
        }
      } catch (muteCheckErr) {
        // Don't fail the whole request if mute check fails, just log and continue
        console.warn('[push/instant] Failed to check conversation mute status:', muteCheckErr?.message)
      }
    }
    
    // Get recipient's push subscriptions
    const subscriptions = await sql`
      select id::text as id, user_id::text as user_id, endpoint, subscription
      from public.user_push_subscriptions
      where user_id = ${recipientId}::uuid
    `
    
    if (!subscriptions || subscriptions.length === 0) {
      console.log(`[push/instant] No push subscriptions found for user ${recipientId}`)
      res.json({ ok: true, sent: false, reason: 'NO_SUBSCRIPTION' })
      return
    }
    
    console.log(`[push/instant] Found ${subscriptions.length} subscription(s) for user ${recipientId}, sending ${type} notification`)
    
    // Use client-provided tag if available, otherwise generate one
    const notificationTag = clientTag || `${type}-${user.id}`
    
    // Determine the target URL based on notification type
    let targetUrl = '/'
    switch (type) {
      case 'friend_request':
      case 'friend_request_accepted':
        targetUrl = '/friends'
        break
      case 'garden_invite':
      case 'garden_invite_accepted':
        targetUrl = '/gardens'
        break
      case 'new_message':
        if (data?.conversationId) {
          targetUrl = `/messages?conversation=${data.conversationId}`
        } else {
          targetUrl = '/messages'
        }
        break
    }
    
    // Send notification to all of recipient's subscriptions
    let sent = false
    let successCount = 0
    const staleSubscriptionIds = []
    
    for (const sub of subscriptions) {
      try {
        const payload = sub.subscription && typeof sub.subscription === 'string'
          ? JSON.parse(sub.subscription)
          : sub.subscription
        
        // Build notification payload with all necessary fields
        const notificationPayload = {
          title,
          body,
          tag: notificationTag,
          renotify: renotify === true, // Ensure it's a boolean
          data: {
            type,
            senderId: user.id,
            url: targetUrl,
            ...data,
          },
        }
        
        // Add vibration pattern for message notifications
        if (type === 'new_message') {
          notificationPayload.vibrate = [200, 100, 200]
        }
          
        await webpush.sendNotification(
          payload,
          JSON.stringify(notificationPayload)
        )
        sent = true
        successCount++
        
        // Update last_used_at
        await sql`
          update public.user_push_subscriptions
          set last_used_at = now()
          where id = ${sub.id}::uuid
        `
      } catch (err) {
        const statusCode = err?.statusCode || err?.statuscode
        if (statusCode === 404 || statusCode === 410) {
          // Subscription expired, mark for cleanup
          staleSubscriptionIds.push(sub.id)
          console.log(`[push/instant] Subscription ${sub.id} expired (${statusCode}), marking for cleanup`)
        } else {
          console.warn(`[push/instant] Push delivery failed for subscription ${sub.id}:`, err?.message || err)
        }
      }
    }
    
    // Clean up stale subscriptions
    if (staleSubscriptionIds.length > 0) {
      await sql`
        delete from public.user_push_subscriptions
        where id = any(${staleSubscriptionIds}::uuid[])
      `
      console.log(`[push/instant] Cleaned up ${staleSubscriptionIds.length} expired subscription(s)`)
    }
    
    if (sent) {
      console.log(`[push/instant] Successfully sent ${type} notification to user ${recipientId} (${successCount}/${subscriptions.length} devices)`)
    } else {
      console.warn(`[push/instant] Failed to deliver ${type} notification to any device for user ${recipientId}`)
    }
    
    res.json({ ok: true, sent, type, devicesReached: successCount })
  } catch (err) {
    console.error('[push/instant] Failed to send notification:', err)
    res.status(500).json({ error: err?.message || 'Failed to send notification' })
  }
})

// ========== Push Notification Debug Endpoint ==========
// Returns info about the user's push notification setup for debugging
app.get('/api/push/debug', async (req, res) => {
  const user = await getUserFromRequestOrToken(req)
  if (!user?.id) {
    res.status(401).json({ error: 'Unauthorized' })
    return
  }
  if (!sql) {
    res.status(500).json({ error: 'Database not configured' })
    return
  }
  
  try {
    // Get user's push subscriptions
    const subscriptions = await sql`
      select 
        id::text as id,
        endpoint,
        created_at,
        updated_at,
        last_used_at,
        user_agent
      from public.user_push_subscriptions
      where user_id = ${user.id}::uuid
      order by updated_at desc
    `
    
    // Mask the endpoint for privacy (show only domain)
    const maskedSubscriptions = (subscriptions || []).map(sub => {
      let endpointDomain = 'unknown'
      try {
        const url = new URL(sub.endpoint)
        endpointDomain = url.hostname
      } catch {}
      
      return {
        id: sub.id,
        endpointDomain,
        endpointPreview: sub.endpoint ? sub.endpoint.slice(0, 50) + '...' : null,
        createdAt: sub.created_at,
        updatedAt: sub.updated_at,
        lastUsedAt: sub.last_used_at,
        userAgent: sub.user_agent ? sub.user_agent.slice(0, 100) : null
      }
    })
    
    res.json({
      ok: true,
      userId: user.id,
      serverPushEnabled: pushNotificationsEnabled,
      vapidConfigured: Boolean(vapidPublicKey && vapidPrivateKey),
      subscriptionCount: subscriptions?.length || 0,
      subscriptions: maskedSubscriptions,
      troubleshooting: {
        noSubscriptions: (subscriptions?.length || 0) === 0 
          ? 'No push subscriptions found. Enable notifications in the app settings.'
          : null,
        pushDisabled: !pushNotificationsEnabled 
          ? 'Push notifications are disabled on the server (VAPID keys not configured).'
          : null,
        staleSubscription: subscriptions?.some(s => {
          const lastUsed = new Date(s.last_used_at || s.updated_at)
          const daysSinceLastUse = (Date.now() - lastUsed.getTime()) / (1000 * 60 * 60 * 24)
          return daysSinceLastUse > 30
        }) ? 'Some subscriptions may be expired. Try disabling and re-enabling notifications.'
          : null
      }
    })
  } catch (err) {
    console.error('[push/debug] Failed to get debug info:', err)
    res.status(500).json({ error: err?.message || 'Failed to get debug info' })
  }
})

// ========== Aphylia Garden Chat AI ==========
// Streaming AI chat endpoint for in-app gardening assistant

// Ensure to_delete folder exists for ephemeral image uploads
const chatUploadDir = path.join(__dirname, 'uploads', 'to_delete')
try {
  if (!fsSync.existsSync(chatUploadDir)) {
    fsSync.mkdirSync(chatUploadDir, { recursive: true })
    console.log('[aphylia-chat] Created to_delete upload directory')
  }
} catch (err) {
  console.warn('[aphylia-chat] Failed to create to_delete directory:', err?.message)
}

// Multer storage for chat image uploads
const chatImageStorage = multer.diskStorage({
  destination: (_req, _file, cb) => {
    cb(null, chatUploadDir)
  },
  filename: (_req, file, cb) => {
    const timestamp = Date.now()
    const randomId = crypto.randomBytes(8).toString('hex')
    const ext = path.extname(file.originalname).toLowerCase() || '.jpg'
    cb(null, `chat_${timestamp}_${randomId}${ext}`)
  }
})

const chatImageUpload = multer({
  storage: chatImageStorage,
  limits: { fileSize: 10 * 1024 * 1024 }, // 10MB
  fileFilter: (_req, file, cb) => {
    const allowedTypes = ['image/jpeg', 'image/png', 'image/gif', 'image/webp']
    if (allowedTypes.includes(file.mimetype)) {
      cb(null, true)
    } else {
      cb(new Error('Invalid file type. Only JPEG, PNG, GIF, and WebP are allowed.'))
    }
  }
})

// Hourly cleanup of to_delete folder
cron.schedule('0 * * * *', async () => {
  try {
    const files = await fs.readdir(chatUploadDir)
    const now = Date.now()
    const oneHourMs = 60 * 60 * 1000
    let deletedCount = 0
    
    for (const file of files) {
      const filePath = path.join(chatUploadDir, file)
      try {
        const stats = await fs.stat(filePath)
        if (now - stats.mtimeMs > oneHourMs) {
          await fs.unlink(filePath)
          deletedCount++
        }
      } catch { }
    }
    
    if (deletedCount > 0) {
      console.log(`[aphylia-chat] Cleanup: deleted ${deletedCount} old file(s) from to_delete`)
    }
  } catch (err) {
    console.error('[aphylia-chat] Cleanup error:', err?.message)
  }
})

// Upload image for chat (ephemeral, stored in to_delete folder)
app.post('/api/ai/garden-chat/upload', chatImageUpload.single('image'), async (req, res) => {
  try {
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) {
      res.status(401).json({ error: 'Unauthorized' })
      return
    }
    
    // Rate limit: 50 image uploads per hour per user (admins exempt)
    if (await checkRateLimit('imageUpload', req, res, user)) {
      return
    }
    
    if (!req.file) {
      res.status(400).json({ error: 'No image uploaded' })
      return
    }
    
    // Build URL for the uploaded file
    const baseUrl = process.env.WEBSITE_URL || `http://localhost:${process.env.PORT || 3000}`
    const imageUrl = `${baseUrl}/api/ai/garden-chat/image/${req.file.filename}`
    
    res.json({
      success: true,
      url: imageUrl,
      filename: req.file.filename
    })
  } catch (err) {
    console.error('[aphylia-chat] Upload error:', err)
    res.status(500).json({ error: err?.message || 'Upload failed' })
  }
})

// Serve uploaded chat images
app.get('/api/ai/garden-chat/image/:filename', async (req, res) => {
  try {
    const filename = req.params.filename
    // Sanitize filename to prevent path traversal
    if (!filename || filename.includes('..') || filename.includes('/')) {
      res.status(400).json({ error: 'Invalid filename' })
      return
    }
    
    const filePath = path.join(chatUploadDir, filename)
    if (!fsSync.existsSync(filePath)) {
      res.status(404).json({ error: 'Image not found' })
      return
    }
    
    // Determine content type
    const ext = path.extname(filename).toLowerCase()
    const contentTypes = {
      '.jpg': 'image/jpeg',
      '.jpeg': 'image/jpeg',
      '.png': 'image/png',
      '.gif': 'image/gif',
      '.webp': 'image/webp'
    }
    
    res.setHeader('Content-Type', contentTypes[ext] || 'application/octet-stream')
    res.setHeader('Cache-Control', 'private, max-age=3600')
    res.sendFile(filePath)
  } catch (err) {
    console.error('[aphylia-chat] Image serve error:', err)
    res.status(500).json({ error: 'Failed to serve image' })
  }
})

// System prompt for Aphylia gardening assistant
const APHYLIA_SYSTEM_PROMPT = `You are Aphylia, a friendly and knowledgeable AI gardening assistant built into the Aphylia plant care app.

Your role is to provide expert, personalized gardening advice based on the user's specific garden, plants, and growing conditions.

## Key Capabilities:
- Plant diagnosis (pests, diseases, nutrient deficiencies)
- Watering and care schedules
- Seasonal gardening tips
- Companion planting advice
- Task planning and garden management
- Plant identification from photos
- Growing tips based on local climate
- **UPDATE plant health status** when you diagnose issues or improvements
- **CREATE, COMPLETE, and DELETE tasks** for plant care routines
- **RECORD care events** (watering, fertilizing, pruning, harvesting)
- **SET watering schedules** for plants
- **ADD journal entries** to record observations
- **UPDATE plant notes** with care instructions or observations
- **REMOVE plants** from the garden when needed

## ACTION CAPABILITIES - You Can Modify Garden Data!
You have the ability to take actions in the user's garden. When appropriate, USE THESE TOOLS:

1. **update_plant_health** - Update a plant's health status (thriving, healthy, okay, struggling, critical)
   - Use after diagnosing plant issues
   - Use when user reports improvements
   
2. **update_plant_notes** - Add or update notes on a plant
   - Use to record care instructions, observations, or diagnoses
   
3. **create_task** - Create a new care task for a plant
   - Use to set up watering schedules, fertilizing reminders, etc.
   
4. **complete_task** - Mark a task as complete
   - Use when user confirms they've done a task
   
5. **add_journal_entry** - Add a journal entry to the garden
   - Use to record significant observations, diagnoses, or milestones

6. **record_event** - Record a care event (water, fertilize, prune, harvest)
   - Use when the user says they watered/fed/pruned/harvested a plant
   - Use to log actions that just happened

7. **delete_task** - Delete a care task entirely
   - Use when the user wants to cancel or remove a task
   - Use when a recurring task is no longer needed

8. **update_watering_schedule** - Set or change a plant's watering schedule
   - Use to configure how often a plant should be watered (e.g., 3 times per week)
   - Use when recommending a new watering routine

9. **remove_plant** - Remove a plant from the garden
   - Use when a plant has died, been given away, or is no longer in the garden
   - This is irreversible â€” confirm with the user before using this tool

IMPORTANT: When you recommend changes (like updating health status or creating tasks), ACTUALLY DO IT using the tools. Don't just suggest - take action!

IMPORTANT: When removing a plant, ALWAYS confirm with the user first. This action deletes all tasks, events, and schedules associated with the plant.

## Communication Style:
- Warm, encouraging, and supportive
- Use emojis sparingly to add personality (ðŸŒ± ðŸª´ ðŸ’§ ðŸŒ¸ etc.)
- Provide practical, actionable advice
- Break down complex topics into simple steps
- Celebrate gardening successes with the user
- When you take actions, confirm what you did ("I've updated the health status to..." or "I've created a watering task for...")

## Important Guidelines:
- Base recommendations on the user's specific garden context (location, climate zone, existing plants)
- Consider seasonal timing when giving advice
- If you're unsure about something, say so and suggest how they might find more info
- When analyzing plant photos, be thorough but honest about uncertainty
- TAKE ACTION when appropriate - update statuses, create tasks, add notes

## When Helping with Tasks:
- Be specific about timing and frequency
- Consider the user's existing task load
- Prioritize based on plant health needs
- CREATE the tasks directly, don't just suggest them
- COMPLETE tasks when the user says they've done them
- DELETE tasks when the user wants to cancel them
- Task IDs are shown in the context as [task_id: ...] â€” use those IDs

## When Recording Events:
- If the user says "I just watered my basil", use record_event to log it
- Always record the event type accurately (water, fertilize, prune, harvest)
- Include helpful notes when relevant (amount, method, etc.)

## When Managing Watering Schedules:
- Use update_watering_schedule to set how often a plant should be watered
- Consider the plant species' needs, climate, and season when recommending
- Explain why you're recommending a specific schedule

## When Removing Plants:
- ALWAYS ask for confirmation before using remove_plant â€” this action is irreversible
- Log the reason for removal in the tool call
- Be empathetic if a plant died â€” it's a learning opportunity

Always aim to help the user become a more confident and successful gardener!`

// Define tools that the AI can use to modify garden data
// Note: Using OpenAI Responses API format (name/description/parameters at top level, not nested in function)
const APHYLIA_TOOLS = [
  {
    type: 'function',
    name: 'update_plant_health',
    description: 'Update the health status of a plant in the garden. Use this after diagnosing plant issues or when the user reports changes in plant health.',
    parameters: {
      type: 'object',
      properties: {
        garden_plant_id: {
          type: 'string',
          description: 'The ID of the garden plant to update (from the context provided)'
        },
        health_status: {
          type: 'string',
          enum: ['thriving', 'healthy', 'okay', 'struggling', 'critical'],
          description: 'The new health status for the plant'
        },
        reason: {
          type: 'string',
          description: 'Brief explanation for the health status change'
        }
      },
      required: ['garden_plant_id', 'health_status']
    }
  },
  {
    type: 'function',
    name: 'update_plant_notes',
    description: 'Update or append notes for a plant. Use this to record observations, care instructions, or diagnoses.',
    parameters: {
      type: 'object',
      properties: {
        garden_plant_id: {
          type: 'string',
          description: 'The ID of the garden plant to update'
        },
        notes: {
          type: 'string',
          description: 'The notes to add or update for this plant'
        },
        append: {
          type: 'boolean',
          description: 'If true, append to existing notes. If false, replace notes.',
          default: true
        }
      },
      required: ['garden_plant_id', 'notes']
    }
  },
  {
    type: 'function',
    name: 'create_task',
    description: 'Create a new care task for a plant. Use this to set up watering schedules, fertilizing reminders, pruning tasks, etc.',
    parameters: {
      type: 'object',
      properties: {
        garden_plant_id: {
          type: 'string',
          description: 'The ID of the garden plant this task is for'
        },
        task_type: {
          type: 'string',
          enum: ['water', 'fertilize', 'harvest', 'cut', 'custom'],
          description: 'The type of task'
        },
        custom_name: {
          type: 'string',
          description: 'Custom name for the task (required if task_type is custom)'
        },
        schedule_type: {
          type: 'string',
          enum: ['once', 'daily', 'weekly', 'biweekly', 'monthly'],
          description: 'How often this task should repeat'
        },
        due_date: {
          type: 'string',
          description: 'When the task is first due (ISO date string)'
        }
      },
      required: ['garden_plant_id', 'task_type', 'schedule_type']
    }
  },
  {
    type: 'function',
    name: 'complete_task',
    description: 'Mark a task occurrence as complete. Use when user confirms they have completed a task.',
    parameters: {
      type: 'object',
      properties: {
        task_id: {
          type: 'string',
          description: 'The ID of the task to complete'
        },
        notes: {
          type: 'string',
          description: 'Optional notes about completing this task'
        }
      },
      required: ['task_id']
    }
  },
  {
    type: 'function',
    name: 'add_journal_entry',
    description: 'Add a journal entry to the garden. Use to record significant observations, diagnoses, milestones, or summaries.',
    parameters: {
      type: 'object',
      properties: {
        title: {
          type: 'string',
          description: 'Title for the journal entry'
        },
        content: {
          type: 'string',
          description: 'The content/body of the journal entry'
        },
        mood: {
          type: 'string',
          enum: ['blooming', 'thriving', 'sprouting', 'resting', 'wilting'],
          description: 'The mood/sentiment for this entry'
        },
        plants_mentioned: {
          type: 'array',
          items: { type: 'string' },
          description: 'Array of garden_plant_ids mentioned in this entry'
        },
        tags: {
          type: 'array',
          items: { type: 'string' },
          description: 'Tags for this journal entry (e.g., diagnosis, milestone, observation)'
        }
      },
      required: ['title', 'content']
    }
  },
  {
    type: 'function',
    name: 'record_event',
    description: 'Record a plant care event (watering, fertilizing, pruning, or harvesting). Use this when the user says they watered, fed, pruned, or harvested a plant, or when you want to log an action that just happened.',
    parameters: {
      type: 'object',
      properties: {
        garden_plant_id: {
          type: 'string',
          description: 'The ID of the garden plant this event is for'
        },
        event_type: {
          type: 'string',
          enum: ['water', 'fertilize', 'prune', 'harvest', 'note'],
          description: 'The type of care event'
        },
        notes: {
          type: 'string',
          description: 'Optional notes about the event (e.g., amount of water, fertilizer type, what was harvested)'
        }
      },
      required: ['garden_plant_id', 'event_type']
    }
  },
  {
    type: 'function',
    name: 'delete_task',
    description: 'Delete a care task entirely. Use when the user wants to cancel or remove a recurring task or a one-time task they no longer need.',
    parameters: {
      type: 'object',
      properties: {
        task_id: {
          type: 'string',
          description: 'The ID of the task to delete (from the context provided)'
        }
      },
      required: ['task_id']
    }
  },
  {
    type: 'function',
    name: 'update_watering_schedule',
    description: 'Set or update the custom watering schedule for a plant. Use when the user wants to change how often a plant is watered.',
    parameters: {
      type: 'object',
      properties: {
        garden_plant_id: {
          type: 'string',
          description: 'The ID of the garden plant to update the schedule for'
        },
        period: {
          type: 'string',
          enum: ['week', 'month', 'year'],
          description: 'The time period for the schedule'
        },
        amount: {
          type: 'integer',
          description: 'How many times per period to water (e.g., 3 times per week)'
        },
        weekly_days: {
          type: 'array',
          items: { type: 'integer' },
          description: 'Optional: specific days of the week (0=Sunday, 1=Monday, ..., 6=Saturday)'
        }
      },
      required: ['garden_plant_id', 'period', 'amount']
    }
  },
  {
    type: 'function',
    name: 'remove_plant',
    description: 'Remove a plant from the garden. Use when the user says a plant died, they gave it away, or want to remove it from their garden. This action is irreversible and also removes all associated tasks, events, and schedules for this plant.',
    parameters: {
      type: 'object',
      properties: {
        garden_plant_id: {
          type: 'string',
          description: 'The ID of the garden plant to remove'
        },
        reason: {
          type: 'string',
          description: 'Reason for removal (e.g., died, gave away, harvested, moved)'
        }
      },
      required: ['garden_plant_id']
    }
  }
]

// Execute a tool call from the AI
async function executeAphyliaTool(toolName, args, gardenId, userId) {
  if (!sql) return { success: false, error: 'Database not available' }
  
  try {
    switch (toolName) {
      case 'update_plant_health': {
        const { garden_plant_id, health_status, reason } = args
        
        // Verify the plant belongs to this garden and user has access
        const checkRows = await sql`
          select gp.id from public.garden_plants gp
          join public.garden_members gm on gm.garden_id = gp.garden_id
          where gp.id = ${garden_plant_id}
            and gp.garden_id = ${gardenId}
            and gm.user_id = ${userId}
        `
        if (checkRows.length === 0) {
          return { success: false, error: 'Plant not found or access denied' }
        }
        
        // Update the health status
        await sql`
          update public.garden_plants
          set health_status = ${health_status},
              last_health_update = now()
          where id = ${garden_plant_id}
        `
        
        // Log the activity
        const logMsg = 'Health status updated to ' + health_status + (reason ? ': ' + reason : '')
        await sql`
          insert into public.garden_activity_logs (garden_id, actor_id, kind, message, plant_name)
          select ${gardenId}, ${userId}, 'plant_updated', 
                 ${logMsg},
                 coalesce(gp.nickname, p.name)
          from public.garden_plants gp
          left join public.plants p on p.id = gp.plant_id
          where gp.id = ${garden_plant_id}
        `
        
        return { success: true, message: 'Updated plant health to ' + health_status }
      }
      
      case 'update_plant_notes': {
        const { garden_plant_id, notes, append = true } = args
        
        // Verify access
        const checkRows = await sql`
          select gp.id, gp.notes as existing_notes from public.garden_plants gp
          join public.garden_members gm on gm.garden_id = gp.garden_id
          where gp.id = ${garden_plant_id}
            and gp.garden_id = ${gardenId}
            and gm.user_id = ${userId}
        `
        if (checkRows.length === 0) {
          return { success: false, error: 'Plant not found or access denied' }
        }
        
        const existingNotes = checkRows[0].existing_notes || ''
        const newNotes = append && existingNotes 
          ? existingNotes + '\n\n' + notes 
          : notes
        
        await sql`
          update public.garden_plants
          set notes = ${newNotes}
          where id = ${garden_plant_id}
        `
        
        return { success: true, message: 'Plant notes updated' }
      }
      
      case 'create_task': {
        const { garden_plant_id, task_type, custom_name, schedule_type, due_date } = args
        
        // Verify access
        const checkRows = await sql`
          select gp.id from public.garden_plants gp
          join public.garden_members gm on gm.garden_id = gp.garden_id
          where gp.id = ${garden_plant_id}
            and gp.garden_id = ${gardenId}
            and gm.user_id = ${userId}
        `
        if (checkRows.length === 0) {
          return { success: false, error: 'Plant not found or access denied' }
        }
        
        // Map schedule type to interval
        const intervalMap = {
          'once': { kind: 'one_time_date', amount: null, unit: null },
          'daily': { kind: 'repeat_duration', amount: 1, unit: 'day' },
          'weekly': { kind: 'repeat_duration', amount: 1, unit: 'week' },
          'biweekly': { kind: 'repeat_duration', amount: 2, unit: 'week' },
          'monthly': { kind: 'repeat_duration', amount: 1, unit: 'month' }
        }
        const schedule = intervalMap[schedule_type] || intervalMap['weekly']
        
        const dueAt = due_date ? new Date(due_date) : new Date()
        
        // Create the task
        const taskRows = await sql`
          insert into public.garden_plant_tasks 
            (garden_id, garden_plant_id, type, custom_name, schedule_kind, due_at, interval_amount, interval_unit)
          values 
            (${gardenId}, ${garden_plant_id}, ${task_type}, ${custom_name || null}, 
             ${schedule.kind}, ${dueAt}, ${schedule.amount}, ${schedule.unit})
          returning id
        `
        
        // Create first occurrence
        await sql`
          insert into public.garden_plant_task_occurrences (task_id, garden_plant_id, due_at)
          values (${taskRows[0].id}, ${garden_plant_id}, ${dueAt})
        `
        
        return { success: true, message: 'Created ' + task_type + ' task', taskId: taskRows[0].id }
      }
      
      case 'complete_task': {
        const { task_id } = args
        
        // Find the latest uncompleted occurrence for this task
        const occRows = await sql`
          select o.id, o.completed_count, o.required_count
          from public.garden_plant_task_occurrences o
          join public.garden_plant_tasks t on t.id = o.task_id
          join public.garden_members gm on gm.garden_id = t.garden_id
          where t.id = ${task_id}
            and t.garden_id = ${gardenId}
            and gm.user_id = ${userId}
            and o.completed_at is null
          order by o.due_at asc
          limit 1
        `
        
        if (occRows.length === 0) {
          return { success: false, error: 'No pending occurrence found for this task' }
        }
        
        const occ = occRows[0]
        const newCount = (occ.completed_count || 0) + 1
        const isComplete = newCount >= (occ.required_count || 1)
        
        await sql`
          update public.garden_plant_task_occurrences
          set completed_count = ${newCount},
              completed_at = ${isComplete ? new Date() : null}
          where id = ${occ.id}
        `
        
        // Record who completed it
        await sql`
          insert into public.garden_task_user_completions (occurrence_id, user_id, increment)
          values (${occ.id}, ${userId}, 1)
        `
        
        return { success: true, message: isComplete ? 'Task completed!' : 'Task progress: ' + newCount + '/' + (occ.required_count || 1) }
      }
      
      case 'add_journal_entry': {
        const { title, content, mood, plants_mentioned, tags } = args
        
        // Verify user has access to this garden
        const checkRows = await sql`
          select 1 from public.garden_members
          where garden_id = ${gardenId} and user_id = ${userId}
        `
        if (checkRows.length === 0) {
          return { success: false, error: 'Access denied' }
        }
        
        await sql`
          insert into public.garden_journal_entries 
            (garden_id, user_id, entry_date, title, content, mood, plants_mentioned, tags)
          values 
            (${gardenId}, ${userId}, current_date, ${title}, ${content}, 
             ${mood || null}, ${plants_mentioned || []}, ${tags || []})
        `
        
        return { success: true, message: 'Journal entry added' }
      }
      
      case 'record_event': {
        const { garden_plant_id, event_type, notes: eventNotes } = args
        
        // Validate event_type
        const validEventTypes = ['water', 'fertilize', 'prune', 'harvest', 'note']
        if (!validEventTypes.includes(event_type)) {
          return { success: false, error: 'Invalid event type. Must be one of: ' + validEventTypes.join(', ') }
        }
        
        // Verify access
        const checkRows = await sql`
          select gp.id from public.garden_plants gp
          join public.garden_members gm on gm.garden_id = gp.garden_id
          where gp.id = ${garden_plant_id}
            and gp.garden_id = ${gardenId}
            and gm.user_id = ${userId}
        `
        if (checkRows.length === 0) {
          return { success: false, error: 'Plant not found or access denied' }
        }
        
        // Insert the event
        await sql`
          insert into public.garden_plant_events (garden_plant_id, event_type, occurred_at, notes)
          values (${garden_plant_id}, ${event_type}, now(), ${eventNotes || null})
        `
        
        // Log the activity
        const eventLabel = event_type === 'water' ? 'Watered' : event_type === 'fertilize' ? 'Fertilized' : event_type === 'prune' ? 'Pruned' : event_type === 'harvest' ? 'Harvested' : 'Note added'
        const logMsg = eventLabel + (eventNotes ? ': ' + eventNotes : '')
        await sql`
          insert into public.garden_activity_logs (garden_id, actor_id, kind, message, plant_name)
          select ${gardenId}, ${userId}, 'plant_event', 
                 ${logMsg},
                 coalesce(gp.nickname, p.name)
          from public.garden_plants gp
          left join public.plants p on p.id = gp.plant_id
          where gp.id = ${garden_plant_id}
        `
        
        return { success: true, message: eventLabel + ' event recorded' }
      }
      
      case 'delete_task': {
        const { task_id } = args
        
        // Verify the task belongs to this garden and user has access
        const checkRows = await sql`
          select t.id, t.type, t.custom_name from public.garden_plant_tasks t
          join public.garden_members gm on gm.garden_id = t.garden_id
          where t.id = ${task_id}
            and t.garden_id = ${gardenId}
            and gm.user_id = ${userId}
        `
        if (checkRows.length === 0) {
          return { success: false, error: 'Task not found or access denied' }
        }
        
        const taskName = checkRows[0].custom_name || checkRows[0].type
        
        // Delete the task (cascade deletes occurrences and completions)
        await sql`
          delete from public.garden_plant_tasks where id = ${task_id}
        `
        
        return { success: true, message: 'Deleted task: ' + taskName }
      }
      
      case 'update_watering_schedule': {
        const { garden_plant_id, period, amount, weekly_days } = args
        
        // Validate period
        const validPeriods = ['week', 'month', 'year']
        if (!validPeriods.includes(period)) {
          return { success: false, error: 'Invalid period. Must be one of: ' + validPeriods.join(', ') }
        }
        if (!amount || amount < 1) {
          return { success: false, error: 'Amount must be at least 1' }
        }
        
        // Verify access
        const checkRows = await sql`
          select gp.id from public.garden_plants gp
          join public.garden_members gm on gm.garden_id = gp.garden_id
          where gp.id = ${garden_plant_id}
            and gp.garden_id = ${gardenId}
            and gm.user_id = ${userId}
        `
        if (checkRows.length === 0) {
          return { success: false, error: 'Plant not found or access denied' }
        }
        
        // Upsert the schedule (garden_plant_id is the primary key)
        await sql`
          insert into public.garden_plant_schedule (garden_plant_id, period, amount, weekly_days)
          values (${garden_plant_id}, ${period}, ${amount}, ${weekly_days || null})
          on conflict (garden_plant_id) do update
          set period = ${period}, amount = ${amount}, weekly_days = ${weekly_days || null}
        `
        
        return { success: true, message: 'Watering schedule set to ' + amount + ' time(s) per ' + period }
      }
      
      case 'remove_plant': {
        const { garden_plant_id, reason } = args
        
        // Verify access and get plant info for logging
        const checkRows = await sql`
          select gp.id, gp.nickname, p.name as plant_name from public.garden_plants gp
          join public.garden_members gm on gm.garden_id = gp.garden_id
          left join public.plants p on p.id = gp.plant_id
          where gp.id = ${garden_plant_id}
            and gp.garden_id = ${gardenId}
            and gm.user_id = ${userId}
        `
        if (checkRows.length === 0) {
          return { success: false, error: 'Plant not found or access denied' }
        }
        
        const plantName = checkRows[0].nickname || checkRows[0].plant_name || 'Unknown plant'
        
        // Log the removal before deleting (so we capture the plant_name)
        const logMsg = 'Plant removed' + (reason ? ': ' + reason : '')
        await sql`
          insert into public.garden_activity_logs (garden_id, actor_id, kind, message, plant_name)
          values (${gardenId}, ${userId}, 'plant_removed', ${logMsg}, ${plantName})
        `
        
        // Delete the garden plant (cascades to events, tasks, schedules, etc.)
        await sql`
          delete from public.garden_plants where id = ${garden_plant_id}
        `
        
        return { success: true, message: 'Removed "' + plantName + '" from the garden' }
      }
      
      default:
        return { success: false, error: 'Unknown tool: ' + toolName }
    }
  } catch (err) {
    console.error('[aphylia-chat] Tool execution error (' + toolName + '):', err)
    return { success: false, error: err.message || 'Tool execution failed' }
  }
}

// Build COMPREHENSIVE context string for the AI from ALL garden data
async function buildGardenContextString(context) {
  const parts = []
  
  // User context
  if (context.user) {
    parts.push(`## User Information`)
    if (context.user.displayName) parts.push(`- Name: ${context.user.displayName}`)
    if (context.user.language) parts.push(`- Preferred language: ${context.user.language}`)
    if (context.user.timezone) parts.push(`- Timezone: ${context.user.timezone}`)
    if (context.user.experienceYears) parts.push(`- Gardening experience: ${context.user.experienceYears} years`)
  }
  
  // Garden context with FULL details
  if (context.garden) {
    parts.push(`\n## Current Garden: "${context.garden.gardenName}"`)
    parts.push(`- Garden ID: ${context.garden.gardenId}`)
    if (context.garden.locationCity) {
      let location = context.garden.locationCity
      if (context.garden.locationCountry) location += `, ${context.garden.locationCountry}`
      parts.push(`- Location: ${location}`)
      if (context.garden.locationLat && context.garden.locationLon) {
        parts.push(`- Coordinates: ${context.garden.locationLat}, ${context.garden.locationLon}`)
      }
    }
    if (context.garden.locationTimezone) parts.push(`- Timezone: ${context.garden.locationTimezone}`)
    if (context.garden.adviceLanguage) parts.push(`- Advice language preference: ${context.garden.adviceLanguage}`)
    parts.push(`- Privacy setting: ${context.garden.privacy || 'public'}`)
    if (context.garden.createdAt) {
      const createdDate = new Date(context.garden.createdAt)
      const ageInDays = Math.floor((Date.now() - createdDate.getTime()) / (1000 * 60 * 60 * 24))
      parts.push(`- Garden created: ${createdDate.toLocaleDateString()} (${ageInDays} days ago)`)
    }
    
    // Garden summary counts - use frontend values as they're always up-to-date
    parts.push(`\n### Garden Summary`)
    parts.push(`- Total plant species: ${context.garden.plantCount || 0}`)
    parts.push(`- Total plants on hand: ${context.garden.totalPlantsOnHand || 0}`)
    parts.push(`- Total seeds planted: ${context.garden.totalSeedsPlanted || 0}`)
    parts.push(`- Total members: ${context.garden.memberCount || 0}`)
    
    // Calculate health distribution from frontend plants if available
    if (context.garden.plants && context.garden.plants.length > 0) {
      const healthCounts = {}
      for (const plant of context.garden.plants) {
        if (plant.healthStatus) {
          healthCounts[plant.healthStatus] = (healthCounts[plant.healthStatus] || 0) + 1
        }
      }
      if (Object.keys(healthCounts).length > 0) {
        const healthSummary = Object.entries(healthCounts)
          .map(([status, count]) => `${status}: ${count}`)
          .join(', ')
        parts.push(`- Plant health overview: ${healthSummary}`)
      }
    }
    
    // Garden streak info - handle both object (from DB) and number (from frontend) formats
    if (context.garden.streak) {
      if (typeof context.garden.streak === 'object') {
        parts.push(`- Current streak: ${context.garden.streak.currentStreak} days`)
        parts.push(`- Longest streak: ${context.garden.streak.longestStreak} days`)
        if (context.garden.streak.lastStreakDate) {
          parts.push(`- Last streak activity: ${new Date(context.garden.streak.lastStreakDate).toLocaleDateString()}`)
        }
      } else if (typeof context.garden.streak === 'number' && context.garden.streak > 0) {
        parts.push(`- Current streak: ${context.garden.streak} days`)
      }
    }
    
    // Task statistics from frontend context
    if (context.garden.taskStats) {
      const ts = context.garden.taskStats
      parts.push(`\n### Task Overview`)
      parts.push(`- Tasks due today: ${ts.totalTasksToday} (${ts.completedTasksToday} completed, ${ts.pendingTasksToday} pending)`)
      parts.push(`- Tasks this week: ${ts.totalTasksThisWeek} (${ts.completedTasksThisWeek} completed)`)
      if (ts.tasksByType && Object.keys(ts.tasksByType).length > 0) {
        const typeBreakdown = Object.entries(ts.tasksByType)
          .map(([type, count]) => `${type}: ${count}`)
          .join(', ')
        parts.push(`- Task types this week: ${typeBreakdown}`)
      }
    }
    
    // Today's tasks from frontend context
    if (context.garden.todayTasks && context.garden.todayTasks.length > 0) {
      parts.push(`\n### Today's Tasks (${context.garden.todayTasks.length} total)`)
      const pending = context.garden.todayTasks.filter(t => !t.isCompleted)
      const completed = context.garden.todayTasks.filter(t => t.isCompleted)
      
      if (pending.length > 0) {
        parts.push(`\n#### Pending Tasks:`)
        for (const task of pending) {
          let taskInfo = `- ${task.plantName}`
          if (task.requiredCount && task.requiredCount > 1) {
            taskInfo += ` (${task.completedCount || 0}/${task.requiredCount} done)`
          }
          parts.push(taskInfo)
        }
      }
      
      if (completed.length > 0) {
        parts.push(`\n#### âœ… Completed Today:`)
        for (const task of completed) {
          parts.push(`- ${task.plantName}`)
        }
      }
    }
    
    // Inventory summary
    if (context.garden.inventory) {
      parts.push(`\n### Inventory`)
      parts.push(`- Unique species in inventory: ${context.garden.inventory.uniqueSpecies || 0}`)
      parts.push(`- Total seeds in inventory: ${context.garden.inventory.totalSeedsInventory || 0}`)
      parts.push(`- Total plants in inventory: ${context.garden.inventory.totalPlantsInventory || 0}`)
    }
    
    // Garden members with FULL details
    if (context.garden.members && context.garden.members.length > 0) {
      parts.push(`\n### Garden Members (${context.garden.members.length} total)`)
      for (const member of context.garden.members) {
        parts.push(`\n#### ${member.displayName} (${member.role})`)
        if (member.experienceYears) parts.push(`- Gardening experience: ${member.experienceYears} years`)
        if (member.language) parts.push(`- Language: ${member.language}`)
        if (member.timezone) parts.push(`- Timezone: ${member.timezone}`)
        if (member.bio) parts.push(`- Bio: ${member.bio}`)
        if (member.joinedAt) {
          const joinDate = new Date(member.joinedAt)
          parts.push(`- Joined garden: ${joinDate.toLocaleDateString()}`)
        }
        parts.push(`- Tasks completed (last 30 days): ${member.tasksCompletedLast30Days || 0}`)
        parts.push(`- Journal entries (last 30 days): ${member.journalEntriesLast30Days || 0}`)
      }
    }
    
    // Recent activity with more detail
    if (context.garden.recentActivity && context.garden.recentActivity.length > 0) {
      parts.push(`\n### Recent Activity (last 14 days)`)
      const activitySummary = {}
      for (const activity of context.garden.recentActivity) {
        activitySummary[activity.kind] = (activitySummary[activity.kind] || 0) + 1
      }
      for (const [kind, count] of Object.entries(activitySummary)) {
        parts.push(`- ${kind}: ${count} occurrences`)
      }
      
      // Show last 10 specific activities
      parts.push(`\n#### Last 10 Activities:`)
      for (const activity of context.garden.recentActivity.slice(0, 10)) {
        let activityInfo = `- ${activity.kind}`
        if (activity.plantName) activityInfo += ` (${activity.plantName})`
        if (activity.taskName) activityInfo += `: ${activity.taskName}`
        if (activity.actorName) activityInfo += ` by ${activity.actorName}`
        if (activity.createdAt) {
          const actDate = new Date(activity.createdAt)
          activityInfo += ` - ${actDate.toLocaleDateString()}`
        }
        parts.push(activityInfo)
      }
    }
  }
  
  // ALL Plants with FULL details
  if (context.plants && context.plants.length > 0) {
    parts.push(`\n## Plants in Garden (${context.plants.length} total)`)
    for (const plant of context.plants) {
      let plantInfo = `\n### ${plant.plantName}`
      if (plant.nickname && plant.nickname !== plant.plantName) plantInfo += ` (nicknamed "${plant.nickname}")`
      parts.push(plantInfo)
      
      // Basic info
      parts.push(`- Plant ID: ${plant.gardenPlantId}`)
      if (plant.scientificName) parts.push(`- Scientific name: _${plant.scientificName}_`)
      if (plant.plantType) parts.push(`- Type: ${plant.plantType}`)
      if (plant.overview) parts.push(`- Overview: ${plant.overview.substring(0, 300)}${plant.overview.length > 300 ? '...' : ''}`)
      
      // Quantities
      if (plant.plantsOnHand > 0) parts.push(`- Plants on hand: ${plant.plantsOnHand}`)
      if (plant.seedsPlanted > 0) parts.push(`- Seeds planted: ${plant.seedsPlanted}`)
      
      // Health and status
      if (plant.healthStatus) {
        let healthInfo = `- Health status: ${plant.healthStatus}`
        if (plant.lastHealthUpdate) {
          const healthDate = new Date(plant.lastHealthUpdate)
          healthInfo += ` (updated ${healthDate.toLocaleDateString()})`
        }
        parts.push(healthInfo)
      }
      if (plant.notes) parts.push(`- User notes: ${plant.notes}`)
      
      // Dates
      if (plant.plantedAt) {
        const plantedDate = new Date(plant.plantedAt)
        parts.push(`- Planted: ${plantedDate.toLocaleDateString()}`)
      }
      if (plant.expectedBloomDate) {
        const bloomDate = new Date(plant.expectedBloomDate)
        parts.push(`- Expected bloom: ${bloomDate.toLocaleDateString()}`)
      }
      if (plant.addedAt) {
        const addedDate = new Date(plant.addedAt)
        parts.push(`- Added to garden: ${addedDate.toLocaleDateString()}`)
      }
      
      // Care requirements - only show section if there's care data
      const careRequirements = []
      if (plant.waterFrequency) careRequirements.push(`- Water frequency: ${plant.waterFrequency}`)
      if (plant.wateringType && plant.wateringType.length > 0) careRequirements.push(`- Watering methods: ${plant.wateringType.join(', ')}`)
      if (plant.lightLevel) careRequirements.push(`- Light needs: ${plant.lightLevel}`)
      if (plant.temperatureRange) {
        careRequirements.push(`- Temperature range: ${plant.temperatureRange.min}Â°C to ${plant.temperatureRange.max}Â°C (ideal: ${plant.temperatureRange.ideal}Â°C)`)
      }
      if (plant.humidity) careRequirements.push(`- Humidity needs: ${plant.humidity}%`)
      if (plant.soilType && plant.soilType.length > 0) careRequirements.push(`- Soil types: ${plant.soilType.join(', ')}`)
      if (plant.nutritionNeeds && plant.nutritionNeeds.length > 0) careRequirements.push(`- Nutrition needs: ${plant.nutritionNeeds.join(', ')}`)
      if (plant.fertilizerTypes && plant.fertilizerTypes.length > 0) careRequirements.push(`- Fertilizer types: ${plant.fertilizerTypes.join(', ')}`)
      
      if (careRequirements.length > 0) {
        parts.push(`\n#### Care Requirements:`)
        parts.push(...careRequirements)
      }
      
      // Growing info
      if (plant.sowingMonths && plant.sowingMonths.length > 0) parts.push(`- Sowing months: ${plant.sowingMonths.join(', ')}`)
      if (plant.floweringMonths && plant.floweringMonths.length > 0) parts.push(`- Flowering months: ${plant.floweringMonths.join(', ')}`)
      if (plant.fruitingMonths && plant.fruitingMonths.length > 0) parts.push(`- Fruiting months: ${plant.fruitingMonths.join(', ')}`)
      if (plant.heightCm) parts.push(`- Expected height: ${plant.heightCm}cm`)
      if (plant.wingspanCm) parts.push(`- Expected wingspan: ${plant.wingspanCm}cm`)
      if (plant.separationCm) parts.push(`- Plant separation: ${plant.separationCm}cm`)
      if (plant.needsTutoring) parts.push(`- Needs tutoring/staking: Yes`)
      if (plant.canTransplant) parts.push(`- Can be transplanted: Yes`)
      if (plant.sowType && plant.sowType.length > 0) parts.push(`- Sowing methods: ${plant.sowType.join(', ')}`)
      if (plant.propagationMethods && plant.propagationMethods.length > 0) parts.push(`- Propagation methods: ${plant.propagationMethods.join(', ')}`)
      
      // Characteristics
      const characteristics = []
      if (plant.isEdible) characteristics.push('Edible')
      if (plant.toxicityHuman === 'highly toxic' || plant.toxicityHuman === 'lethally toxic') characteristics.push('âš ï¸ Toxic to humans')
      if (plant.toxicityPets === 'highly toxic' || plant.toxicityPets === 'lethally toxic') characteristics.push('âš ï¸ Toxic to pets')
      if (plant.hasSpikes) characteristics.push('Has spikes')
      if (plant.hasScent) characteristics.push('Fragrant')
      if (plant.isMulticolor) characteristics.push('Multicolor')
      if (plant.isMelliferous) characteristics.push('Melliferous (attracts bees)')
      if (characteristics.length > 0) parts.push(`- Characteristics: ${characteristics.join(', ')}`)
      
      if (plant.edibleParts && plant.edibleParts.length > 0) parts.push(`- Edible parts: ${plant.edibleParts.join(', ')}`)
      if (plant.utility && plant.utility.length > 0) parts.push(`- Uses: ${plant.utility.join(', ')}`)
      if (plant.conservationStatus) parts.push(`- Conservation status: ${plant.conservationStatus}`)
      
      // Problems and companions
      if (plant.commonPests && plant.commonPests.length > 0) parts.push(`- Common pests: ${plant.commonPests.join(', ')}`)
      if (plant.commonDiseases && plant.commonDiseases.length > 0) parts.push(`- Common diseases: ${plant.commonDiseases.join(', ')}`)
      if (plant.companionPlants && plant.companionPlants.length > 0) parts.push(`- Companion plants: ${plant.companionPlants.join(', ')}`)
      
      // Schedule and tasks
      if (plant.schedule) {
        parts.push(`- Custom watering schedule: ${plant.schedule.amount}x per ${plant.schedule.period}`)
      }
      if (plant.taskCount > 0) {
        parts.push(`- Active tasks: ${plant.taskCount}`)
      }
      
      // Recent events
      if (plant.recentEvents && plant.recentEvents.length > 0) {
        parts.push(`- Recent events:`)
        for (const event of plant.recentEvents) {
          const eventDate = new Date(event.occurredAt)
          let eventInfo = `  - ${event.type} on ${eventDate.toLocaleDateString()}`
          if (event.notes) eventInfo += `: ${event.notes}`
          parts.push(eventInfo)
        }
      }
    }
  }
  
  // ALL Tasks with full details
  if (context.tasks && context.tasks.length > 0) {
    parts.push(`\n## Garden Tasks (${context.tasks.length} total)`)
    
    // Group by status
    const overdueTasks = []
    const dueTodayTasks = []
    const upcomingTasks = []
    const now = new Date()
    const todayStr = now.toISOString().split('T')[0]
    
    for (const task of context.tasks) {
      if (!task.occurrences || task.occurrences.length === 0) continue
      
      for (const occ of task.occurrences) {
        if (occ.completedAt) continue // Skip completed
        
        const dueDate = new Date(occ.dueAt)
        const dueDateStr = dueDate.toISOString().split('T')[0]
        
        const taskEntry = {
          ...task,
          dueAt: occ.dueAt,
          requiredCount: occ.requiredCount,
          completedCount: occ.completedCount
        }
        
        if (dueDate < now && dueDateStr !== todayStr) {
          overdueTasks.push(taskEntry)
        } else if (dueDateStr === todayStr) {
          dueTodayTasks.push(taskEntry)
        } else {
          upcomingTasks.push(taskEntry)
        }
      }
    }
    
    if (overdueTasks.length > 0) {
      parts.push(`\n### âš ï¸ Overdue Tasks (${overdueTasks.length})`)
      for (const task of overdueTasks.slice(0, 10)) {
        let taskInfo = `- [task_id: ${task.taskId}] ${task.customName || task.taskType}`
        if (task.plantName) taskInfo += ` for "${task.plantName}"`
        const dueDate = new Date(task.dueAt)
        taskInfo += ` (was due: ${dueDate.toLocaleDateString()})`
        if (task.frequency) taskInfo += ` â€” schedule: ${task.frequency}`
        parts.push(taskInfo)
      }
    }
    
    if (dueTodayTasks.length > 0) {
      parts.push(`\n### ðŸ“… Due Today (${dueTodayTasks.length})`)
      for (const task of dueTodayTasks) {
        let taskInfo = `- [task_id: ${task.taskId}] ${task.customName || task.taskType}`
        if (task.plantName) taskInfo += ` for "${task.plantName}"`
        if (task.requiredCount > 1) {
          taskInfo += ` (${task.completedCount || 0}/${task.requiredCount} done)`
        }
        parts.push(taskInfo)
      }
    }
    
    if (upcomingTasks.length > 0) {
      parts.push(`\n### ðŸ—“ï¸ Upcoming Tasks (${upcomingTasks.length})`)
      for (const task of upcomingTasks.slice(0, 15)) {
        let taskInfo = `- [task_id: ${task.taskId}] ${task.customName || task.taskType}`
        if (task.plantName) taskInfo += ` for "${task.plantName}"`
        const dueDate = new Date(task.dueAt)
        taskInfo += ` (due: ${dueDate.toLocaleDateString()})`
        if (task.frequency) taskInfo += ` â€” schedule: ${task.frequency}`
        parts.push(taskInfo)
      }
    }
  }
  
  // ALL Journal entries
  if (context.journal && context.journal.length > 0) {
    parts.push(`\n## Garden Journal (${context.journal.length} entries)`)
    for (const entry of context.journal.slice(0, 20)) {
      const createdDate = new Date(entry.createdAt)
      parts.push(`\n### ${entry.title || 'Journal Entry'} - ${createdDate.toLocaleDateString()}`)
      if (entry.authorName) parts.push(`- Author: ${entry.authorName}`)
      if (entry.mood) parts.push(`- Mood: ${entry.mood}`)
      if (entry.weather) parts.push(`- Weather: ${entry.weather}`)
      if (entry.temperature) parts.push(`- Temperature: ${entry.temperature}`)
      if (entry.content) {
        // Truncate very long entries
        const content = entry.content.length > 500 
          ? entry.content.substring(0, 500) + '...' 
          : entry.content
        parts.push(`- Content: ${content}`)
      }
      if (entry.plantsMentioned && entry.plantsMentioned.length > 0) {
        const plantNames = entry.plantsMentioned.map(p => p.plantName).filter(Boolean)
        if (plantNames.length > 0) {
          parts.push(`- Plants mentioned: ${plantNames.join(', ')}`)
        }
      }
    }
  }
  
  // COMPREHENSIVE Analytics and Statistics
  if (context.analytics) {
    parts.push(`\n## Garden Analytics & Statistics`)
    
    // Totals
    if (context.analytics.totals) {
      parts.push(`### Garden Totals`)
      parts.push(`- Total plants: ${context.analytics.totals.plants || 0}`)
      parts.push(`- Total tasks: ${context.analytics.totals.tasks || 0}`)
      parts.push(`- Total journal entries: ${context.analytics.totals.journalEntries || 0}`)
    }
    
    // Task completion stats
    if (context.analytics.taskStats) {
      const stats = context.analytics.taskStats
      parts.push(`\n### Task Completion (last 30 days)`)
      parts.push(`- Completed tasks: ${stats.completed_tasks || 0}`)
      parts.push(`- Overdue tasks: ${stats.overdue_tasks || 0}`)
      parts.push(`- Upcoming tasks (next 7 days): ${stats.upcoming_tasks || 0}`)
      parts.push(`- Future tasks (7-30 days): ${stats.future_tasks || 0}`)
      
      // Completion rate calculation
      const total = (stats.completed_tasks || 0) + (stats.overdue_tasks || 0)
      if (total > 0) {
        const completionRate = ((stats.completed_tasks || 0) / total * 100).toFixed(1)
        parts.push(`- Completion rate: ${completionRate}%`)
      }
    }
    
    // Task breakdown by type
    if (context.analytics.tasksByType && Object.keys(context.analytics.tasksByType).length > 0) {
      parts.push(`\n### Tasks by Type`)
      for (const [type, data] of Object.entries(context.analytics.tasksByType)) {
        parts.push(`- ${type}: ${data.total} total (${data.completed} completed, ${data.overdue} overdue)`)
      }
    }
    
    // Plant health distribution
    if (context.analytics.healthDistribution && Object.keys(context.analytics.healthDistribution).length > 0) {
      parts.push(`\n### Plant Health Distribution`)
      for (const [status, count] of Object.entries(context.analytics.healthDistribution)) {
        parts.push(`- ${status}: ${count} plants`)
      }
    }
    
    // Plant type distribution
    if (context.analytics.plantTypeDistribution && Object.keys(context.analytics.plantTypeDistribution).length > 0) {
      parts.push(`\n### Plant Types`)
      for (const [type, count] of Object.entries(context.analytics.plantTypeDistribution)) {
        parts.push(`- ${type || 'Unknown'}: ${count} plants`)
      }
    }
    
    // Daily activity
    if (context.analytics.dailyActivity && context.analytics.dailyActivity.length > 0) {
      const totalActivity = context.analytics.dailyActivity.reduce((sum, d) => sum + d.count, 0)
      const avgActivity = (totalActivity / context.analytics.dailyActivity.length).toFixed(1)
      parts.push(`\n### Activity (last 14 days)`)
      parts.push(`- Total activities: ${totalActivity}`)
      parts.push(`- Average per day: ${avgActivity}`)
      
      // Most active day
      const maxActivity = Math.max(...context.analytics.dailyActivity.map(d => d.count))
      const mostActiveDay = context.analytics.dailyActivity.find(d => d.count === maxActivity)
      if (mostActiveDay) {
        parts.push(`- Most active day: ${new Date(mostActiveDay.date).toLocaleDateString()} (${maxActivity} activities)`)
      }
    }
    
    // Activity breakdown by kind
    if (context.analytics.activityByKind && Object.keys(context.analytics.activityByKind).length > 0) {
      parts.push(`\n### Activity Types (last 30 days)`)
      for (const [kind, count] of Object.entries(context.analytics.activityByKind)) {
        parts.push(`- ${kind}: ${count}`)
      }
    }
    
    // Member contributions
    if (context.analytics.memberContributions && context.analytics.memberContributions.length > 0) {
      parts.push(`\n### Member Contributions (last 30 days)`)
      for (const member of context.analytics.memberContributions) {
        parts.push(`- ${member.displayName} (${member.role}): ${member.tasksCompleted} tasks completed, ${member.journalEntries} journal entries`)
      }
    }
    
    // Mood distribution
    if (context.analytics.moodDistribution && Object.keys(context.analytics.moodDistribution).length > 0) {
      parts.push(`\n### Journal Mood Distribution (last 30 days)`)
      for (const [mood, count] of Object.entries(context.analytics.moodDistribution)) {
        parts.push(`- ${mood}: ${count} entries`)
      }
    }
  }
  
  // Completed tasks with attribution (who did what)
  if (context.completedTasks && context.completedTasks.length > 0) {
    parts.push(`\n## Recently Completed Tasks (last 30 days)`)
    
    // Group by date
    const tasksByDate = {}
    for (const task of context.completedTasks) {
      const dateStr = new Date(task.completedAt).toLocaleDateString()
      if (!tasksByDate[dateStr]) tasksByDate[dateStr] = []
      tasksByDate[dateStr].push(task)
    }
    
    for (const [date, tasks] of Object.entries(tasksByDate).slice(0, 7)) {
      parts.push(`\n### ${date}`)
      for (const task of tasks.slice(0, 10)) {
        let taskInfo = `- âœ… ${task.customName || task.taskType}`
        if (task.plantName) taskInfo += ` for "${task.plantName}"`
        
        // Who completed it
        if (task.completedBy && task.completedBy.length > 0) {
          const names = task.completedBy.map(c => c.userName).filter(Boolean)
          if (names.length > 0) {
            taskInfo += ` (by ${names.join(', ')})`
          }
        }
        parts.push(taskInfo)
      }
    }
  }
  
  // Weekly AI gardening advice history
  if (context.weeklyAdvice && context.weeklyAdvice.length > 0) {
    parts.push(`\n## Weekly Gardening Advice History`)
    
    for (const advice of context.weeklyAdvice.slice(0, 4)) {
      const weekDate = new Date(advice.weekStart)
      parts.push(`\n### Week of ${weekDate.toLocaleDateString()}`)
      
      if (advice.summary) {
        parts.push(`**Summary:** ${advice.summary}`)
      }
      
      if (advice.focusAreas && advice.focusAreas.length > 0) {
        parts.push(`**Focus areas:** ${advice.focusAreas.join(', ')}`)
      }
      
      if (advice.improvementScore !== null && advice.improvementScore !== undefined) {
        parts.push(`**Improvement score:** ${advice.improvementScore}/100`)
      }
      
      if (advice.adviceText) {
        // Truncate very long advice
        const text = advice.adviceText.length > 600 
          ? advice.adviceText.substring(0, 600) + '...'
          : advice.adviceText
        parts.push(`**Advice:** ${text}`)
      }
      
      if (advice.plantTips && advice.plantTips.length > 0) {
        parts.push(`**Plant-specific tips:**`)
        for (const tip of advice.plantTips.slice(0, 5)) {
          if (tip.plantName && tip.tip) {
            parts.push(`  - ${tip.plantName}: ${tip.tip}`)
          }
        }
      }
    }
  }
  
  // Current date/time context
  const now = new Date()
  const month = now.toLocaleString('en', { month: 'long' })
  const season = getSeasonForMonth(now.getMonth())
  parts.push(`\n## Current Date & Time`)
  parts.push(`- Date: ${now.toLocaleDateString()} ${now.toLocaleTimeString()}`)
  parts.push(`- Month: ${month}`)
  parts.push(`- Season: ${season} (Northern Hemisphere)`)
  
  return parts.join('\n')
}

function getSeasonForMonth(month) {
  // Northern hemisphere seasons
  if (month >= 2 && month <= 4) return 'Spring'
  if (month >= 5 && month <= 7) return 'Summer'
  if (month >= 8 && month <= 10) return 'Autumn/Fall'
  return 'Winter'
}

// Fetch COMPREHENSIVE garden context from database - ALL DATA for AI
async function fetchGardenContext(gardenId, userId) {
  if (!sql || !gardenId) return null
  
  try {
    // Fetch garden details with ALL fields
    const gardenRows = await sql`
      select 
        g.id, g.name, g.location_city, g.location_country, 
        g.location_timezone, g.location_lat, g.location_lon,
        g.privacy, g.cover_image_url, g.created_at,
        g.advice_language, g.streak as base_streak,
        g.hide_ai_chat,
        -- Get plant count
        (select count(*)::int from public.garden_plants where garden_id = g.id) as plant_count,
        -- Get total seeds planted
        (select coalesce(sum(seeds_planted), 0)::int from public.garden_plants where garden_id = g.id) as total_seeds,
        -- Get total plants on hand
        (select coalesce(sum(plants_on_hand), 0)::int from public.garden_plants where garden_id = g.id) as total_plants_on_hand
      from public.gardens g
      join public.garden_members gm on gm.garden_id = g.id
      where g.id = ${gardenId} and gm.user_id = ${userId}
    `
    
    if (!gardenRows || gardenRows.length === 0) return null
    
    const garden = gardenRows[0]
    
    // Fetch ALL garden members with their FULL details
    const memberRows = await sql`
      select 
        gm.user_id, gm.role, gm.joined_at,
        p.display_name, p.experience_years, p.language, p.timezone,
        p.bio, p.avatar_url,
        -- Count tasks completed by this member in this garden (last 30 days)
        (
          select count(*)::int 
          from public.garden_task_user_completions c
          join public.garden_plant_task_occurrences o on o.id = c.occurrence_id
          join public.garden_plant_tasks t on t.id = o.task_id
          where t.garden_id = ${gardenId} 
            and c.user_id = gm.user_id 
            and c.occurred_at > now() - interval '30 days'
        ) as tasks_completed_30d,
        -- Count journal entries by this member (last 30 days)
        (
          select count(*)::int 
          from public.garden_journal_entries j
          where j.garden_id = ${gardenId} 
            and j.user_id = gm.user_id 
            and j.created_at > now() - interval '30 days'
        ) as journal_entries_30d
      from public.garden_members gm
      left join public.profiles p on p.id = gm.user_id
      where gm.garden_id = ${gardenId}
      order by gm.role desc, gm.joined_at asc
    `
    
    const members = memberRows.map(m => ({
      userId: m.user_id,
      role: m.role,
      displayName: m.display_name || 'Member',
      experienceYears: m.experience_years,
      language: m.language,
      timezone: m.timezone,
      bio: m.bio,
      avatarUrl: m.avatar_url,
      joinedAt: m.joined_at,
      tasksCompletedLast30Days: m.tasks_completed_30d || 0,
      journalEntriesLast30Days: m.journal_entries_30d || 0
    }))
    
    // Fetch garden streak and stats from dedicated table
    let streakInfo = null
    try {
      const streakRows = await sql`
        select current_streak, longest_streak, last_streak_date
        from public.garden_streaks
        where garden_id = ${gardenId}
      `
      if (streakRows[0]) {
        streakInfo = {
          currentStreak: streakRows[0].current_streak || 0,
          longestStreak: streakRows[0].longest_streak || 0,
          lastStreakDate: streakRows[0].last_streak_date
        }
      }
    } catch { }
    
    // Fetch recent activity logs (last 14 days for more context)
    let recentActivity = []
    try {
      const activityRows = await sql`
        select kind, message, plant_name, task_name, created_at, 
               user_id, actor_name
        from public.garden_activity_logs
        where garden_id = ${gardenId}
          and created_at > now() - interval '14 days'
        order by created_at desc
        limit 50
      `
      recentActivity = activityRows.map(a => ({
        kind: a.kind,
        message: a.message,
        plantName: a.plant_name,
        taskName: a.task_name,
        actorName: a.actor_name,
        createdAt: a.created_at
      }))
    } catch { }
    
    // Fetch inventory counts
    let inventorySummary = null
    try {
      const invRows = await sql`
        select 
          count(*)::int as unique_species,
          coalesce(sum(seeds_on_hand), 0)::int as total_seeds_inventory,
          coalesce(sum(plants_on_hand), 0)::int as total_plants_inventory
        from public.garden_inventory
        where garden_id = ${gardenId}
      `
      if (invRows[0]) {
        inventorySummary = {
          uniqueSpecies: invRows[0].unique_species || 0,
          totalSeedsInventory: invRows[0].total_seeds_inventory || 0,
          totalPlantsInventory: invRows[0].total_plants_inventory || 0
        }
      }
    } catch { }
    
    return {
      gardenId: garden.id,
      gardenName: garden.name,
      locationCity: garden.location_city,
      locationCountry: garden.location_country,
      locationTimezone: garden.location_timezone,
      locationLat: garden.location_lat,
      locationLon: garden.location_lon,
      privacy: garden.privacy,
      adviceLanguage: garden.advice_language,
      createdAt: garden.created_at,
      coverImageUrl: garden.cover_image_url,
      // Counts
      plantCount: garden.plant_count || 0,
      totalSeedsPlanted: garden.total_seeds || 0,
      totalPlantsOnHand: garden.total_plants_on_hand || 0,
      // Members
      members,
      memberCount: members.length,
      // Streaks
      streak: streakInfo,
      // Activity
      recentActivity,
      // Inventory
      inventory: inventorySummary
    }
  } catch (err) {
    console.error('[aphylia-chat] Error fetching garden context:', err)
    return null
  }
}

// Fetch ALL plants for a garden with FULL details - COMPREHENSIVE for AI context
async function fetchPlantsContext(gardenId, plantIds = null) {
  if (!sql || !gardenId) return []
  
  try {
    // Fetch ALL plants with COMPLETE info - base plant data, care requirements, and instance data
    const rows = await sql`
      select 
        gp.id as garden_plant_id, 
        gp.plant_id, 
        gp.nickname, 
        gp.health_status, 
        gp.notes,
        gp.plants_on_hand,
        gp.seeds_planted,
        gp.planted_at,
        gp.expected_bloom_date,
        gp.override_water_freq_unit,
        gp.override_water_freq_value,
        gp.last_health_update,
        gp.created_at as added_at,
        gp.sort_index as display_order,
        -- Base plant info
        p.name as plant_name,
        p.scientific_name,
        p.plant_type,
        p.utility as plant_utility,
        p.comestible_part,
        -- Care requirements
        p.level_sun,
        p.temperature_min,
        p.temperature_max,
        p.temperature_ideal,
        p.hygrometry,
        p.watering_type,
        p.soil,
        p.nutrition_need,
        p.fertilizer,
        -- Growing info
        p.sowing_month,
        p.flowering_month,
        p.fruiting_month,
        p.height_cm,
        p.wingspan_cm,
        p.separation_cm,
        p.tutoring,
        p.transplanting,
        p.sow_type,
        p.division,
        -- Characteristics
        ('comestible' = ANY(p.utility)) as is_edible,
        p.toxicity_human,
        p.toxicity_pets,
        p.spiked,
        p.scent,
        p.multicolor,
        p.melliferous,
        p.conservation_status,
        -- Companions (pests/diseases now in plant_translations)
        p.companions,
        -- Get translated fields including pests and diseases
        (
          select pt.overview 
          from public.plant_translations pt 
          where pt.plant_id = p.id and pt.language = 'en'
          limit 1
        ) as plant_overview,
        (
          select pt.pests 
          from public.plant_translations pt 
          where pt.plant_id = p.id and pt.language = 'en'
          limit 1
        ) as pests,
        (
          select pt.diseases 
          from public.plant_translations pt 
          where pt.plant_id = p.id and pt.language = 'en'
          limit 1
        ) as diseases
      from public.garden_plants gp
      left join public.plants p on p.id = gp.plant_id
      where gp.garden_id = ${gardenId}
      order by gp.sort_index asc nulls last, gp.created_at asc
      limit 150
    `
    
    // Fetch task counts, schedules, and recent events for each plant
    const plantIds2 = rows.map(r => r.garden_plant_id)
    let taskCounts = {}
    let schedules = {}
    let recentEvents = {}
    
    if (plantIds2.length > 0) {
      try {
        // Get active task counts per plant
        const taskCountRows = await sql`
          select garden_plant_id, count(*)::int as task_count
          from public.garden_plant_tasks
          where garden_plant_id = any(${plantIds2}::uuid[])
          group by garden_plant_id
        `
        for (const tc of taskCountRows) {
          taskCounts[tc.garden_plant_id] = tc.task_count
        }
        
        // Get schedules
        const scheduleRows = await sql`
          select garden_plant_id, period, amount
          from public.garden_plant_schedules
          where garden_plant_id = any(${plantIds2}::uuid[])
        `
        for (const s of scheduleRows) {
          schedules[s.garden_plant_id] = { period: s.period, amount: s.amount }
        }
        
        // Get recent events (last 30 days) for each plant
        const eventRows = await sql`
          select garden_plant_id, event_type, occurred_at, notes
          from public.garden_plant_events
          where garden_plant_id = any(${plantIds2}::uuid[])
            and occurred_at > now() - interval '30 days'
          order by occurred_at desc
        `
        for (const e of eventRows) {
          if (!recentEvents[e.garden_plant_id]) recentEvents[e.garden_plant_id] = []
          if (recentEvents[e.garden_plant_id].length < 5) {
            recentEvents[e.garden_plant_id].push({
              type: e.event_type,
              occurredAt: e.occurred_at,
              notes: e.notes
            })
          }
        }
      } catch { }
    }
    
    return rows.map(row => ({
      gardenPlantId: row.garden_plant_id,
      plantId: row.plant_id,
      plantName: row.plant_name || 'Unknown plant',
      scientificName: row.scientific_name,
      nickname: row.nickname,
      healthStatus: row.health_status,
      lastHealthUpdate: row.last_health_update,
      notes: row.notes,
      overview: row.plant_overview,
      plantsOnHand: row.plants_on_hand || 0,
      seedsPlanted: row.seeds_planted || 0,
      plantedAt: row.planted_at,
      expectedBloomDate: row.expected_bloom_date,
      addedAt: row.added_at,
      displayOrder: row.display_order,
      // Care info - including overrides
      waterFrequency: row.override_water_freq_value 
        ? `${row.override_water_freq_value}x per ${row.override_water_freq_unit || 'week'} (custom)`
        : null,
      lightLevel: row.level_sun,
      temperatureRange: row.temperature_min && row.temperature_max 
        ? { min: row.temperature_min, max: row.temperature_max, ideal: row.temperature_ideal }
        : null,
      humidity: row.hygrometry,
      wateringType: row.watering_type,
      soilType: row.soil,
      nutritionNeeds: row.nutrition_need,
      fertilizerTypes: row.fertilizer,
      // Growing info
      sowingMonths: row.sowing_month,
      floweringMonths: row.flowering_month,
      fruitingMonths: row.fruiting_month,
      heightCm: row.height_cm,
      wingspanCm: row.wingspan_cm,
      separationCm: row.separation_cm,
      needsTutoring: row.tutoring,
      canTransplant: row.transplanting,
      sowType: row.sow_type,
      propagationMethods: row.division,
      // Characteristics
      isEdible: row.is_edible,
      toxicityHuman: row.toxicity_human,
      toxicityPets: row.toxicity_pets,
      hasSpikes: row.spiked,
      hasScent: row.scent,
      isMulticolor: row.multicolor,
      isMelliferous: row.melliferous,
      conservationStatus: row.conservation_status,
      plantType: row.plant_type,
      utility: row.plant_utility,
      edibleParts: row.comestible_part,
      // Problems and companions
      commonPests: row.pests,
      commonDiseases: row.diseases,
      companionPlants: row.companions,
      // Instance data
      taskCount: taskCounts[row.garden_plant_id] || 0,
      schedule: schedules[row.garden_plant_id] || null,
      recentEvents: recentEvents[row.garden_plant_id] || []
    }))
  } catch (err) {
    console.error('[aphylia-chat] Error fetching plants context:', err)
    return []
  }
}

// Fetch ALL tasks for a garden with full details
async function fetchTasksContext(gardenId) {
  if (!sql || !gardenId) return []
  
  try {
    // Fetch all tasks with their occurrences
    // NOTE: Uses actual column names from garden_plant_tasks table:
    //   interval_amount, interval_unit, schedule_kind (not freq_amount/freq_period/enabled)
    const rows = await sql`
      select 
        t.id, 
        t.type, 
        t.custom_name, 
        t.garden_plant_id,
        t.schedule_kind,
        t.interval_amount,
        t.interval_unit,
        t.due_at as task_due_at,
        t.required_count as task_required_count,
        t.created_at,
        gp.nickname as plant_nickname,
        p.name as plant_name,
        (
          select json_agg(json_build_object(
            'dueAt', o.due_at,
            'completedAt', o.completed_at,
            'requiredCount', o.required_count,
            'completedCount', o.completed_count
          ) order by o.due_at)
          from public.garden_plant_task_occurrences o
          where o.task_id = t.id 
            and o.due_at > now() - interval '7 days'
            and o.due_at < now() + interval '14 days'
        ) as occurrences
      from public.garden_plant_tasks t
      left join public.garden_plants gp on gp.id = t.garden_plant_id
      left join public.plants p on p.id = gp.plant_id
      where t.garden_id = ${gardenId}
      order by t.created_at desc
      limit 100
    `
    
    return rows.map(row => ({
      taskId: row.id,
      taskType: row.type,
      customName: row.custom_name,
      gardenPlantId: row.garden_plant_id,
      plantName: row.plant_nickname || row.plant_name,
      scheduleKind: row.schedule_kind,
      frequency: row.interval_amount ? `every ${row.interval_amount} ${row.interval_unit || 'week'}(s)` : null,
      requiredCount: row.task_required_count || 1,
      occurrences: row.occurrences || []
    }))
  } catch (err) {
    console.error('[aphylia-chat] Error fetching tasks context:', err)
    return []
  }
}

// Fetch ALL journal entries for a garden (using correct table name)
async function fetchJournalContext(gardenId) {
  if (!sql || !gardenId) return []
  
  try {
    const rows = await sql`
      select 
        j.id,
        j.title,
        j.content,
        j.mood,
        j.weather_snapshot,
        j.entry_date,
        j.tags,
        j.ai_feedback,
        j.created_at,
        j.updated_at,
        j.plants_mentioned,
        p.display_name as author_name
      from public.garden_journal_entries j
      left join public.profiles p on p.id = j.user_id
      where j.garden_id = ${gardenId}
        and j.is_private = false
      order by j.entry_date desc, j.created_at desc
      limit 50
    `
    
    // Fetch plant names for mentioned plants
    const allPlantIds = rows.flatMap(r => r.plants_mentioned || []).filter(Boolean)
    let plantNameMap = {}
    if (allPlantIds.length > 0) {
      try {
        const plantRows = await sql`
          select gp.id, coalesce(gp.nickname, p.name) as name
          from public.garden_plants gp
          left join public.plants p on p.id = gp.plant_id
          where gp.id = any(${allPlantIds}::uuid[])
        `
        for (const pr of plantRows) {
          plantNameMap[pr.id] = pr.name
        }
      } catch { }
    }
    
    return rows.map(row => {
      const weather = row.weather_snapshot || {}
      return {
        id: row.id,
        title: row.title,
        content: row.content,
        mood: row.mood,
        weather: weather.description || weather.main,
        temperature: weather.temp_c ? `${weather.temp_c}Â°C` : null,
        entryDate: row.entry_date,
        tags: row.tags || [],
        aiFeedback: row.ai_feedback,
        authorName: row.author_name,
        createdAt: row.created_at,
        plantsMentioned: (row.plants_mentioned || []).map(id => ({
          plantId: id,
          plantName: plantNameMap[id] || 'Unknown plant'
        }))
      }
    })
  } catch (err) {
    console.error('[aphylia-chat] Error fetching journal context:', err)
    return []
  }
}

// Fetch weekly AI advice history for a garden
async function fetchWeeklyAdviceContext(gardenId) {
  if (!sql || !gardenId) return []
  
  try {
    const rows = await sql`
      select 
        week_start,
        advice_text,
        advice_summary,
        focus_areas,
        plant_specific_tips,
        improvement_score,
        generated_at
      from public.garden_ai_advice
      where garden_id = ${gardenId}
      order by week_start desc
      limit 8
    `
    
    return rows.map(row => ({
      weekStart: row.week_start,
      adviceText: row.advice_text,
      summary: row.advice_summary,
      focusAreas: row.focus_areas || [],
      plantTips: row.plant_specific_tips || [],
      improvementScore: row.improvement_score,
      generatedAt: row.generated_at
    }))
  } catch (err) {
    console.error('[aphylia-chat] Error fetching weekly advice:', err)
    return []
  }
}

// Fetch completed tasks with who completed them
async function fetchCompletedTasksContext(gardenId) {
  if (!sql || !gardenId) return []
  
  try {
    const rows = await sql`
      select 
        t.type as task_type,
        t.custom_name,
        o.completed_at,
        o.completed_count,
        o.required_count,
        coalesce(gp.nickname, p.name) as plant_name,
        (
          select json_agg(json_build_object(
            'userName', pr.display_name,
            'increment', c.increment,
            'occurredAt', c.occurred_at
          ) order by c.occurred_at desc)
          from public.garden_task_user_completions c
          left join public.profiles pr on pr.id = c.user_id
          where c.occurrence_id = o.id
        ) as completions
      from public.garden_plant_task_occurrences o
      join public.garden_plant_tasks t on t.id = o.task_id
      left join public.garden_plants gp on gp.id = t.garden_plant_id
      left join public.plants p on p.id = gp.plant_id
      where t.garden_id = ${gardenId}
        and o.completed_at is not null
        and o.completed_at > now() - interval '30 days'
      order by o.completed_at desc
      limit 50
    `
    
    return rows.map(row => ({
      taskType: row.task_type,
      customName: row.custom_name,
      plantName: row.plant_name,
      completedAt: row.completed_at,
      completedCount: row.completed_count,
      requiredCount: row.required_count,
      completedBy: row.completions || []
    }))
  } catch (err) {
    console.error('[aphylia-chat] Error fetching completed tasks:', err)
    return []
  }
}

// Fetch COMPREHENSIVE analytics/stats for a garden - ALL STATISTICS for AI
async function fetchAnalyticsContext(gardenId) {
  if (!sql || !gardenId) return null
  
  try {
    // Task completion stats for last 30 days
    const taskStatsRows = await sql`
      select 
        count(*) filter (where completed_at is not null)::int as completed_tasks,
        count(*) filter (where completed_at is null and due_at < now())::int as overdue_tasks,
        count(*) filter (where completed_at is null and due_at >= now() and due_at < now() + interval '7 days')::int as upcoming_tasks,
        count(*) filter (where completed_at is null and due_at >= now() + interval '7 days' and due_at < now() + interval '30 days')::int as future_tasks
      from public.garden_plant_task_occurrences o
      join public.garden_plant_tasks t on t.id = o.task_id
      where t.garden_id = ${gardenId}
        and o.due_at > now() - interval '30 days'
    `
    
    // Task breakdown by type
    const taskTypeRows = await sql`
      select 
        t.type as task_type,
        count(*)::int as total_tasks,
        count(*) filter (where o.completed_at is not null)::int as completed,
        count(*) filter (where o.completed_at is null and o.due_at < now())::int as overdue
      from public.garden_plant_tasks t
      left join public.garden_plant_task_occurrences o on o.task_id = t.id 
        and o.due_at > now() - interval '30 days'
      where t.garden_id = ${gardenId}
      group by t.type
    `
    
    // Plant health distribution
    const healthRows = await sql`
      select 
        health_status,
        count(*)::int as count
      from public.garden_plants
      where garden_id = ${gardenId} and health_status is not null
      group by health_status
    `
    
    // Plant type distribution
    const plantTypeRows = await sql`
      select 
        p.plant_type,
        count(*)::int as count
      from public.garden_plants gp
      left join public.plants p on p.id = gp.plant_id
      where gp.garden_id = ${gardenId}
      group by p.plant_type
    `
    
    // Activity frequency
    const activityRows = await sql`
      select 
        date_trunc('day', created_at)::date as day,
        count(*)::int as activity_count
      from public.garden_activity_logs
      where garden_id = ${gardenId}
        and created_at > now() - interval '14 days'
      group by date_trunc('day', created_at)
      order by day desc
    `
    
    // Activity breakdown by kind
    const activityByKindRows = await sql`
      select 
        kind,
        count(*)::int as count
      from public.garden_activity_logs
      where garden_id = ${gardenId}
        and created_at > now() - interval '30 days'
      group by kind
      order by count desc
    `
    
    // Member contribution stats
    const memberStatsRows = await sql`
      select 
        p.display_name,
        gm.role,
        count(distinct c.id)::int as tasks_completed,
        count(distinct j.id)::int as journal_entries
      from public.garden_members gm
      left join public.profiles p on p.id = gm.user_id
      left join public.garden_task_user_completions c on c.user_id = gm.user_id
      left join public.garden_plant_task_occurrences o on o.id = c.occurrence_id
      left join public.garden_plant_tasks t on t.id = o.task_id and t.garden_id = ${gardenId}
      left join public.garden_journal_entries j on j.user_id = gm.user_id 
        and j.garden_id = ${gardenId}
        and j.created_at > now() - interval '30 days'
      where gm.garden_id = ${gardenId}
        and (c.occurred_at is null or c.occurred_at > now() - interval '30 days')
      group by p.display_name, gm.role
    `
    
    // Journal mood distribution (last 30 days)
    const moodRows = await sql`
      select 
        mood,
        count(*)::int as count
      from public.garden_journal_entries
      where garden_id = ${gardenId}
        and created_at > now() - interval '30 days'
        and mood is not null
      group by mood
    `
    
    // Calculate totals
    const totalPlantCount = await sql`
      select count(*)::int as total from public.garden_plants where garden_id = ${gardenId}
    `
    
    const totalTaskCount = await sql`
      select count(*)::int as total from public.garden_plant_tasks where garden_id = ${gardenId}
    `
    
    const totalJournalCount = await sql`
      select count(*)::int as total from public.garden_journal_entries where garden_id = ${gardenId}
    `
    
    return {
      taskStats: taskStatsRows[0] || { completed_tasks: 0, overdue_tasks: 0, upcoming_tasks: 0, future_tasks: 0 },
      tasksByType: taskTypeRows.reduce((acc, t) => {
        acc[t.task_type] = { total: t.total_tasks, completed: t.completed, overdue: t.overdue }
        return acc
      }, {}),
      healthDistribution: healthRows.reduce((acc, h) => {
        acc[h.health_status] = h.count
        return acc
      }, {}),
      plantTypeDistribution: plantTypeRows.reduce((acc, p) => {
        acc[p.plant_type || 'unknown'] = p.count
        return acc
      }, {}),
      dailyActivity: activityRows.map(a => ({
        date: a.day,
        count: a.activity_count
      })),
      activityByKind: activityByKindRows.reduce((acc, a) => {
        acc[a.kind] = a.count
        return acc
      }, {}),
      memberContributions: memberStatsRows.map(m => ({
        displayName: m.display_name || 'Member',
        role: m.role,
        tasksCompleted: m.tasks_completed,
        journalEntries: m.journal_entries
      })),
      moodDistribution: moodRows.reduce((acc, m) => {
        acc[m.mood] = m.count
        return acc
      }, {}),
      totals: {
        plants: totalPlantCount[0]?.total || 0,
        tasks: totalTaskCount[0]?.total || 0,
        journalEntries: totalJournalCount[0]?.total || 0
      }
    }
  } catch (err) {
    console.error('[aphylia-chat] Error fetching analytics context:', err)
    return null
  }
}

// Main streaming chat endpoint
app.post('/api/ai/garden-chat', async (req, res) => {
  try {
    // Authenticate user
    const user = await getUserFromRequestOrToken(req)
    if (!user?.id) {
      res.status(401).json({ error: 'Unauthorized' })
      return
    }
    
    // Rate limit: 60 AI chat messages per hour per user (admins exempt)
    if (await checkRateLimit('aiChat', req, res, user)) {
      return
    }
    
    // Check if OpenAI is configured
    if (!openai) {
      res.status(503).json({ error: 'AI service not configured' })
      return
    }
    
    const body = req.body || {}
    const { messages = [], context = {}, quickAction, stream = true } = body
    
    if (!messages || messages.length === 0) {
      res.status(400).json({ error: 'Messages are required' })
      return
    }
    
    // Get user profile for context
    let userProfile = null
    if (sql) {
      try {
        const profileRows = await sql`
          select display_name, language, timezone, experience_years
          from public.profiles where id = ${user.id}
        `
        userProfile = profileRows[0] || null
      } catch { }
    }
    
    // Build user context
    const userContext = {
      userId: user.id,
      displayName: userProfile?.display_name || 'Gardener',
      language: context.user?.language || userProfile?.language || 'en',
      timezone: context.user?.timezone || userProfile?.timezone,
      experienceYears: context.user?.experienceYears || userProfile?.experience_years
    }
    
    // ALWAYS fetch COMPREHENSIVE garden context when gardenId is provided
    // Context is REQUIRED for the AI to provide accurate, personalized advice
    let gardenContext = context.garden || null
    let plantsContext = []
    let tasksContext = []
    let journalContext = []
    let analyticsContext = null
    let weeklyAdviceContext = []
    let completedTasksContext = []
    let contextLoadedSuccessfully = false
    
    if (context.garden?.gardenId) {
      // Fetch ALL data in parallel for performance - this is REQUIRED for good AI responses
      const gardenId = context.garden.gardenId
      
      console.log(`[aphylia-chat] Loading FULL context for garden ${gardenId}...`)
      
      const [
        fetchedGarden,
        fetchedPlants,
        fetchedTasks,
        fetchedJournal,
        fetchedAnalytics,
        fetchedWeeklyAdvice,
        fetchedCompletedTasks
      ] = await Promise.all([
        fetchGardenContext(gardenId, user.id),
        fetchPlantsContext(gardenId),
        fetchTasksContext(gardenId),
        fetchJournalContext(gardenId),
        fetchAnalyticsContext(gardenId),
        fetchWeeklyAdviceContext(gardenId),
        fetchCompletedTasksContext(gardenId)
      ])
      
      gardenContext = fetchedGarden || gardenContext
      plantsContext = fetchedPlants
      tasksContext = fetchedTasks
      journalContext = fetchedJournal
      analyticsContext = fetchedAnalytics
      weeklyAdviceContext = fetchedWeeklyAdvice
      completedTasksContext = fetchedCompletedTasks
      contextLoadedSuccessfully = !!fetchedGarden
      
      // Log comprehensive context summary
      console.log(`[aphylia-chat] âœ… Loaded FULL context for garden "${gardenContext?.gardenName || gardenId}":`)
      console.log(`  - Garden info: ${gardenContext ? 'YES' : 'NO'} (members: ${gardenContext?.members?.length || 0}, location: ${gardenContext?.locationCity || 'not set'})`)
      console.log(`  - Plants: ${plantsContext.length} (with full care info, health status, growing requirements)`)
      console.log(`  - Tasks: ${tasksContext.length} (with occurrences and schedules)`)
      console.log(`  - Journal entries: ${journalContext.length} (with mood, weather, plants mentioned)`)
      console.log(`  - Analytics: ${analyticsContext ? 'YES' : 'NO'} (task stats, health distribution, member contributions)`)
      console.log(`  - Weekly advice history: ${weeklyAdviceContext.length}`)
      console.log(`  - Completed tasks (30d): ${completedTasksContext.length}`)
    } else {
      // No garden context provided - warn in logs
      console.warn('[aphylia-chat] âš ï¸ No garden context provided! AI responses will be generic without garden-specific information.')
    }
    
    // Use frontend-provided plant summaries as fallback if backend fetch returned empty
    // This ensures the AI always has some plant context even if database queries fail
    let effectivePlantsContext = plantsContext
    if ((!plantsContext || plantsContext.length === 0) && gardenContext?.plants && gardenContext.plants.length > 0) {
      console.log(`[aphylia-chat] Using ${gardenContext.plants.length} plants from frontend context as fallback`)
      effectivePlantsContext = gardenContext.plants.map(p => ({
        gardenPlantId: p.gardenPlantId,
        plantId: p.plantId,
        plantName: p.plantName,
        nickname: p.nickname,
        healthStatus: p.healthStatus,
        plantsOnHand: p.plantsOnHand,
        seedsPlanted: p.seedsPlanted
      }))
    }
    
    // Build full context with ALL data
    const fullContext = {
      user: userContext,
      garden: gardenContext,
      plants: effectivePlantsContext,
      tasks: tasksContext,
      journal: journalContext,
      analytics: analyticsContext,
      weeklyAdvice: weeklyAdviceContext,
      completedTasks: completedTasksContext
    }
    
    // Build context string for AI - this MUST include ALL garden data
    const contextString = await buildGardenContextString(fullContext)
    
    // Build system prompt with context
    let systemPrompt = APHYLIA_SYSTEM_PROMPT
    if (contextString) {
      systemPrompt += `\n\n# Current Garden Context\n${contextString}`
    }
    
    // Add note about context availability to help AI respond appropriately
    if (!context.garden?.gardenId) {
      systemPrompt += `\n\n# Important Note\nNo garden context was provided for this conversation. The user may be asking a general gardening question. If they ask about specific plants, tasks, or garden details, politely ask them to make sure they are in a garden context or to provide more details.`
    } else if (!contextLoadedSuccessfully) {
      systemPrompt += `\n\n# Important Note\nGarden context could not be fully loaded. Some garden-specific information may be missing. Provide the best advice you can with the available information.`
    }
    
    // Add quick action specific instructions
    if (quickAction) {
      const quickActionPrompts = {
        'diagnose': '\n\n## Quick Action: Plant Diagnosis\nThe user wants help diagnosing a plant issue. Look carefully at any provided images and ask clarifying questions if needed. Focus on identifying the problem and providing treatment options.',
        'watering-schedule': '\n\n## Quick Action: Watering Schedule\nThe user wants help creating or optimizing a watering schedule. Consider the plants in their garden, local climate, and seasonal factors.',
        'weekly-plan': '\n\n## Quick Action: Weekly Garden Plan\nThe user wants a weekly plan for their garden tasks. Prioritize tasks by urgency and create a practical schedule.',
        'summarize-journal': '\n\n## Quick Action: Summarize Journal\nThe user wants a summary of their garden journal entries. Analyze all journal entries above and highlight: key observations, patterns over time, mood trends, weather correlations, plant health changes, and any notable events or achievements.',
        'plant-care': '\n\n## Quick Action: Plant Care Guide\nThe user wants comprehensive care advice for a specific plant. Cover watering, light, feeding, and seasonal care.',
        'pest-help': '\n\n## Quick Action: Pest & Disease Help\nThe user needs help with pest or disease issues. Help identify the problem and provide organic/natural solutions when possible.',
        'seasonal-tips': '\n\n## Quick Action: Seasonal Tips\nThe user wants seasonal gardening advice. Focus on what to plant, what tasks to prioritize, and how to prepare for the next season.',
        'companion-plants': '\n\n## Quick Action: Companion Planting\nThe user wants companion planting suggestions. Recommend plants that grow well together and explain the benefits.'
      }
      if (quickActionPrompts[quickAction]) {
        systemPrompt += quickActionPrompts[quickAction]
      }
    }
    
    // Format messages for OpenAI
    const openaiMessages = [
      { role: 'system', content: systemPrompt }
    ]
    
    for (const msg of messages) {
      const content = []
      
      // Add text content
      if (msg.content) {
        content.push({ type: 'text', text: msg.content })
      }
      
      // Add images if present
      if (msg.imageUrls && msg.imageUrls.length > 0) {
        for (const imageUrl of msg.imageUrls) {
          // For local images, we need to read and base64 encode them
          if (imageUrl.includes('/api/ai/garden-chat/image/')) {
            const filename = imageUrl.split('/').pop()
            const imagePath = path.join(chatUploadDir, filename)
            if (fsSync.existsSync(imagePath)) {
              try {
                const imageBuffer = await fs.readFile(imagePath)
                const base64 = imageBuffer.toString('base64')
                const ext = path.extname(filename).toLowerCase()
                const mimeTypes = { '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png', '.gif': 'image/gif', '.webp': 'image/webp' }
                const mimeType = mimeTypes[ext] || 'image/jpeg'
                content.push({
                  type: 'image_url',
                  image_url: { url: `data:${mimeType};base64,${base64}` }
                })
              } catch (imgErr) {
                console.warn('[aphylia-chat] Failed to read image:', imgErr?.message)
              }
            }
          } else {
            // External URL
            content.push({
              type: 'image_url',
              image_url: { url: imageUrl }
            })
          }
        }
      }
      
      openaiMessages.push({
        role: msg.role,
        content: content.length === 1 && content[0].type === 'text' ? content[0].text : content
      })
    }
    
    // Get garden ID for tool execution
    const gardenIdForTools = gardenContext?.gardenId || context.garden?.gardenId
    
    // Format conversation history as structured input items for the Responses API.
    // Returns an array of typed message objects instead of a plain text string,
    // which maintains clear separation between user content, assistant content,
    // and tool output â€” preventing prompt injection via content boundaries.
    const formatConversationForInput = (msgs) => {
      return msgs.slice(1).map(msg => { // Skip system message (handled via instructions)
        let content = msg.content
        // Convert Chat Completions content parts to Responses API format
        if (Array.isArray(content)) {
          content = content.map(part => {
            if (part.type === 'text') {
              return { type: 'input_text', text: part.text }
            }
            if (part.type === 'image_url') {
              return { type: 'input_image', image_url: part.image_url?.url || part.image_url }
            }
            return part
          })
        }
        return { role: msg.role, content }
      })
    }
    
    // Helper to execute tools and build structured result items for the Responses API.
    // Returns function_call_output items (keyed by call_id) instead of plain text strings,
    // so tool results are passed as typed objects â€” not concatenated into user content.
    // This prevents prompt injection if tool results contain adversarial content
    // (e.g. from user-controlled plant names, notes, or custom task names).
    const executeToolsIfNeeded = async (toolCalls) => {
      const toolCallsExecuted = []
      const toolResultItems = []
      
      for (const toolCall of toolCalls) {
        const toolName = toolCall.name || toolCall.function?.name
        let toolArgs = {}
        try {
          toolArgs = typeof toolCall.arguments === 'string' 
            ? JSON.parse(toolCall.arguments || '{}')
            : toolCall.arguments || {}
        } catch (e) {
          console.warn('[aphylia-chat] Failed to parse tool arguments:', e)
        }
        
        console.log(`[aphylia-chat] Executing tool: ${toolName}`, toolArgs)
        
        const result = await executeAphyliaTool(toolName, toolArgs, gardenIdForTools, user.id)
        
        toolCallsExecuted.push({
          tool: toolName,
          args: toolArgs,
          result: result
        })
        
        // Build structured function_call_output for the Responses API.
        // The call_id links this result back to the specific function_call
        // the model emitted, keeping tool output in its own typed lane.
        const callId = toolCall.call_id || toolCall.id
        if (callId) {
          toolResultItems.push({
            type: 'function_call_output',
            call_id: callId,
            output: JSON.stringify(result)
          })
        }
      }
      
      return { toolCallsExecuted, toolResultItems }
    }
    
    if (stream) {
      // Streaming response using SSE
      res.setHeader('Content-Type', 'text/event-stream')
      res.setHeader('Cache-Control', 'no-cache')
      res.setHeader('Connection', 'keep-alive')
      res.setHeader('X-Accel-Buffering', 'no')
      
      // Send start event
      res.write(`data: ${JSON.stringify({ type: 'start' })}\n\n`)
      
      try {
        let toolCallsExecuted = []
        let conversationInput = formatConversationForInput(openaiMessages)
        
        // First, check if AI wants to use tools (non-streaming call)
        if (gardenIdForTools) {
          const toolCheckResponse = await openaiClient.responses.create(
            {
              model: openaiModelNano,
              reasoning: { effort: 'low' },
              instructions: systemPrompt + '\n\nIf you need to perform actions like updating plant health, creating tasks, or recording watering, respond with a JSON object containing "tool_calls" array. Otherwise respond normally.',
              input: conversationInput,
              tools: APHYLIA_TOOLS,
            },
            { timeout: 60000 }
          )
          
          // Check if response contains tool calls
          if (toolCheckResponse.output && Array.isArray(toolCheckResponse.output)) {
            const toolUseOutputs = toolCheckResponse.output.filter(o => o.type === 'tool_use')
            if (toolUseOutputs.length > 0) {
              res.write(`data: ${JSON.stringify({ type: 'tool_start', tools: toolUseOutputs.map(t => t.name) })}\n\n`)
              
              const { toolCallsExecuted: executed, toolResultItems } = await executeToolsIfNeeded(toolUseOutputs)
              toolCallsExecuted = executed
              
              // Pass tool calls and results as structured Responses API input items.
              // The model's output (containing function_call items) is spread back into
              // the input, followed by our function_call_output items. This maintains
              // clear separation between user content and tool output, preventing
              // prompt injection via tool results that contain adversarial content.
              conversationInput = [
                ...conversationInput,
                ...toolCheckResponse.output,
                ...toolResultItems
              ]
              
              res.write(`data: ${JSON.stringify({ type: 'tool_end', results: toolCallsExecuted })}\n\n`)
            }
          }
        }
        
        // Stream the final response using Responses API
        const streamResponse = await openaiClient.responses.create(
          {
            model: openaiModelNano,
            reasoning: { effort: 'low' },
            instructions: systemPrompt,
            input: conversationInput,
            stream: true,
          },
          { timeout: 120000 }
        )
        
        let fullContent = ''
        let totalTokens = 0
        
        for await (const event of streamResponse) {
          // Handle different event types from the Responses API stream
          if (event.type === 'response.output_text.delta') {
            const delta = event.delta || ''
            if (delta) {
              fullContent += delta
              res.write(`data: ${JSON.stringify({ type: 'token', token: delta })}\n\n`)
            }
          } else if (event.type === 'response.completed' || event.type === 'response.done') {
            if (event.response?.usage) {
              totalTokens = event.response.usage.total_tokens || 0
            }
          }
        }
        
        // Send done event with complete message
        const messageId = crypto.randomUUID()
        res.write(`data: ${JSON.stringify({
          type: 'done',
          message: {
            id: messageId,
            role: 'assistant',
            content: fullContent,
            createdAt: new Date().toISOString(),
            toolCalls: toolCallsExecuted.length > 0 ? toolCallsExecuted : undefined
          },
          usage: {
            totalTokens
          }
        })}\n\n`)
        
      } catch (streamErr) {
        console.error('[aphylia-chat] Stream error:', streamErr)
        res.write(`data: ${JSON.stringify({ type: 'error', error: streamErr?.message || 'Stream failed' })}\n\n`)
      }
      
      res.end()
    } else {
      // Non-streaming response using Responses API
      let toolCallsExecuted = []
      let conversationInput = formatConversationForInput(openaiMessages)
      
      // First, check if AI wants to use tools
      if (gardenIdForTools) {
        const toolCheckResponse = await openaiClient.responses.create(
          {
            model: openaiModelNano,
            reasoning: { effort: 'low' },
            instructions: systemPrompt + '\n\nIf you need to perform actions like updating plant health, creating tasks, or recording watering, respond with a JSON object containing "tool_calls" array. Otherwise respond normally.',
            input: conversationInput,
            tools: APHYLIA_TOOLS,
          },
          { timeout: 60000 }
        )
        
        // Check if response contains tool calls
        if (toolCheckResponse.output && Array.isArray(toolCheckResponse.output)) {
          const toolUseOutputs = toolCheckResponse.output.filter(o => o.type === 'tool_use')
          if (toolUseOutputs.length > 0) {
            const { toolCallsExecuted: executed, toolResultItems } = await executeToolsIfNeeded(toolUseOutputs)
            toolCallsExecuted = executed
            
            // Pass tool calls and results as structured Responses API input items.
            // See streaming path comment for full rationale on why we avoid plain
            // text concatenation of tool results (prompt injection prevention).
            conversationInput = [
              ...conversationInput,
              ...toolCheckResponse.output,
              ...toolResultItems
            ]
          }
        }
      }
      
      // Final response using Responses API
      const response = await openaiClient.responses.create(
        {
          model: openaiModelNano,
          reasoning: { effort: 'low' },
          instructions: systemPrompt,
          input: conversationInput,
        },
        { timeout: 120000 }
      )
      
      const outputText = typeof response?.output_text === 'string' ? response.output_text.trim() : ''
      const messageId = crypto.randomUUID()
      
      res.json({
        message: {
          id: messageId,
          role: 'assistant',
          content: outputText,
          createdAt: new Date().toISOString(),
          toolCalls: toolCallsExecuted.length > 0 ? toolCallsExecuted : undefined
        },
        usage: {
          promptTokens: response.usage?.input_tokens || 0,
          completionTokens: response.usage?.output_tokens || 0,
          totalTokens: response.usage?.total_tokens || 0
        }
      })
    }
  } catch (err) {
    console.error('[aphylia-chat] Error:', err)
    if (!res.headersSent) {
      res.status(500).json({ error: err?.message || 'Chat failed' })
    }
  }
})

const notificationWorkerIntervalMs = Math.max(15000, Number(process.env.NOTIFICATION_WORKER_INTERVAL_MS || 60000))
const notificationDeliveryBatchSize = Math.min(
  Math.max(Number(process.env.NOTIFICATION_DELIVERY_BATCH_SIZE || 200), 25),
  500,
)

// Default timezone for users who haven't set one in their profile
// Falls back to server's system timezone if not configured via env
const getServerTimezone = () => {
  try {
    return Intl.DateTimeFormat().resolvedOptions().timeZone || 'UTC'
  } catch {
    return 'UTC'
  }
}
const DEFAULT_USER_TIMEZONE = process.env.DEFAULT_USER_TIMEZONE || getServerTimezone()
const DEFAULT_NOTIFICATION_HOUR = 10
console.log(`[notifications] Default user timezone: ${DEFAULT_USER_TIMEZONE}`)

let notificationWorkerTimer = null
let notificationWorkerBusy = false

function isoOrNull(value) {
  if (!value) return null
  try {
    const date = new Date(value)
    if (Number.isNaN(date.getTime())) return null
    return date.toISOString()
  } catch {
    return null
  }
}

function toStringArray(value) {
  if (!value) return []
  if (Array.isArray(value)) {
    return value
      .map((entry) => (entry == null ? null : String(entry)))
      .filter((entry) => entry && entry.trim().length > 0)
  }
  if (typeof value === 'string') {
    const trimmed = value.trim()
    return trimmed ? [trimmed] : []
  }
  return []
}

function toUuidArray(value) {
  return toStringArray(value)
}

function normalizeLanguageCode(value) {
  if (!value) return ''
  return String(value).trim().toLowerCase().replace('_', '-')
}

function normalizeTranslationMap(translations) {
  if (!translations || typeof translations !== 'object') return {}
  const normalized = {}
  for (const [lang, variants] of Object.entries(translations)) {
    const normalizedLang = normalizeLanguageCode(lang)
    if (!normalizedLang) continue
    const list = toStringArray(variants)
    if (list.length > 0) {
      normalized[normalizedLang] = list
    }
  }
  return normalized
}

function resolveMessageVariants(defaultVariants, translations, userLanguage) {
  const normalizedLang = normalizeLanguageCode(userLanguage)
  if (!normalizedLang || normalizedLang === 'en') return defaultVariants
  if (translations[normalizedLang]?.length) return translations[normalizedLang]
  const baseLang = normalizedLang.split('-')[0]
  if (baseLang && translations[baseLang]?.length) return translations[baseLang]
  return defaultVariants
}

function normalizeNotificationCampaign(row) {
  if (!row) return null
  const stats = {
    total: Number(row.total_recipients || 0),
    sent: Number(row.sent_count || 0),
    pending: Number(row.pending_count || 0),
    failed: Number(row.failed_count || 0),
  }
  const filters =
    row.filters && typeof row.filters === 'object' && !Array.isArray(row.filters)
      ? row.filters
      : {}
  return {
    id: row.id || null,
    title: row.title || '',
    description: row.description || null,
    audience: row.audience || 'all',
    deliveryMode: row.delivery_mode || 'send_now',
    state: row.state || 'draft',
    filters,
    templateId: row.template_id || null,
    templateTitle: row.template_title || null,
    messageVariants: toStringArray(row.message_variants),
    randomize: row.randomize !== false,
    timezone: row.timezone || DEFAULT_TIMEZONE,
    plannedFor: isoOrNull(row.planned_for),
    scheduleStartAt: isoOrNull(row.schedule_start_at),
    scheduleInterval: row.schedule_interval || null,
    ctaUrl: row.cta_url || null,
    customUserIds: toUuidArray(row.custom_user_ids),
    runCount: Number(row.run_count || 0),
    createdBy: row.created_by || null,
    createdByName: row.created_by_name || null,
    updatedBy: row.updated_by || null,
    lastRunAt: isoOrNull(row.last_run_at),
    nextRunAt: isoOrNull(row.next_run_at),
    lastRunSummary: row.last_run_summary || null,
    createdAt: isoOrNull(row.created_at),
    updatedAt: isoOrNull(row.updated_at),
    estimatedRecipients: Number(row.estimated_recipients || row.recipient_count || 0),
    stats,
  }
}

function normalizeNotificationTemplate(row, translations = null) {
  if (!row) return null
  // Parse translations if provided as JSON
  let parsedTranslations = {}
  if (translations) {
    parsedTranslations = translations
  } else if (row.translations && typeof row.translations === 'object') {
    parsedTranslations = row.translations
  }
  return {
    id: row.id || null,
    title: row.title || '',
    description: row.description || null,
    messageVariants: toStringArray(row.message_variants),
    randomize: row.randomize !== false,
    isActive: row.is_active !== false,
    usageCount: Number(row.usage_count || 0),
    campaignCount: Number(row.campaign_count || 0),
    automationCount: Number(row.automation_count || 0),
    createdBy: row.created_by || null,
    updatedBy: row.updated_by || null,
    createdAt: isoOrNull(row.created_at),
    updatedAt: isoOrNull(row.updated_at),
    translations: parsedTranslations,
  }
}

// Get message variants for a specific language (with fallback to default)
function getMessageVariantsForLanguage(template, userLanguage) {
  const defaultVariants = toStringArray(template.message_variants)
  const translations = normalizeTranslationMap(template.translations)
  return resolveMessageVariants(defaultVariants, translations, userLanguage)
}

function normalizeNotificationAutomation(row) {
  if (!row) return null
  return {
    id: row.id || null,
    triggerType: row.trigger_type || '',
    displayName: row.display_name || '',
    description: row.description || null,
    isEnabled: row.is_enabled === true,
    templateId: row.template_id || null,
    templateTitle: row.template_title || null,
    sendHour: typeof row.send_hour === 'number' ? row.send_hour : 9,
    ctaUrl: row.cta_url || null,
    lastRunAt: isoOrNull(row.last_run_at),
    lastRunSummary: row.last_run_summary || null,
    createdBy: row.created_by || null,
    updatedBy: row.updated_by || null,
    createdAt: isoOrNull(row.created_at),
    updatedAt: isoOrNull(row.updated_at),
    recipientCount: Number(row.recipient_count || 0),
    sentTodayCount: Number(row.sent_today_count || 0),
  }
}

function determineInitialNextRunAt(payload) {
  const now = new Date()
  if (!payload || !payload.deliveryMode) return now.toISOString()
  if (payload.deliveryMode === 'send_now') return now.toISOString()
  if (payload.deliveryMode === 'planned' && payload.plannedFor) {
    const date = new Date(payload.plannedFor)
    if (!Number.isNaN(date.getTime())) return date.toISOString()
  }
  if (payload.deliveryMode === 'scheduled' && payload.scheduleStartAt) {
    const date = new Date(payload.scheduleStartAt)
    if (!Number.isNaN(date.getTime())) return date.toISOString()
  }
  return now.toISOString()
}

function computeNextScheduledRun(campaign) {
  const interval = campaign.scheduleInterval || 'daily'
  const baseIso = campaign.nextRunAt || campaign.scheduleStartAt || new Date().toISOString()
  const base = new Date(baseIso)
  if (Number.isNaN(base.getTime())) return new Date(Date.now() + 24 * 3600 * 1000).toISOString()
  const next = new Date(base.getTime())
  if (interval === 'weekly') {
    next.setUTCDate(next.getUTCDate() + 7)
  } else if (interval === 'monthly') {
    const originalDay = base.getUTCDate()
    next.setUTCDate(1)
    next.setUTCMonth(next.getUTCMonth() + 1)
    const daysInMonth = new Date(next.getUTCFullYear(), next.getUTCMonth() + 1, 0).getUTCDate()
    next.setUTCDate(Math.min(originalDay, daysInMonth))
  } else {
    next.setUTCDate(next.getUTCDate() + 1)
  }
  return next.toISOString()
}

function pickNotificationMessage(campaign, index) {
  const variants =
    campaign.messageVariants && campaign.messageVariants.length > 0
      ? campaign.messageVariants
      : [campaign.description || 'You have a new update waiting in Aphylia.']
  if (variants.length === 1) return variants[0]
  if (campaign.randomize) {
    const randomIndex = Math.floor(Math.random() * variants.length)
    return variants[randomIndex]
  }
  const idx = index % variants.length
  return variants[idx]
}

function chunkArray(list, size) {
  const chunks = []
  for (let i = 0; i < list.length; i += size) {
    chunks.push(list.slice(i, i + size))
  }
  return chunks
}

async function resolveNotificationAudience(campaign) {
  if (!sql) return []
  const recipients = new Set()
  const addRows = (rows, field = 'id') => {
    for (const row of rows || []) {
      const value = row?.[field]
      if (value) recipients.add(String(value))
    }
  }
  // Only include users who have NOT explicitly disabled push notifications (notify_push defaults to true)
  if (campaign.audience === 'all') {
    const rows = await sql`select id::text as id from public.profiles where id is not null and (notify_push is null or notify_push = true)`
    addRows(rows, 'id')
  } else if (campaign.audience === 'tasks_open') {
    // Query live data directly from garden_plant_task_occurrences to find users with uncompleted tasks today.
    // This ensures we catch ALL users with remaining tasks, not just those whose cache was populated today.
    const today = new Date().toISOString().slice(0, 10)
    const startOfDay = `${today}T00:00:00.000Z`
    const endOfDay = `${today}T23:59:59.999Z`
    const rows = await sql`
      select distinct gm.user_id::text as user_id
      from public.garden_members gm
      join public.profiles p on p.id = gm.user_id
      where gm.user_id is not null
        and (p.notify_push is null or p.notify_push = true)
        and exists (
          select 1
          from public.garden_plant_tasks t
          join public.garden_plant_task_occurrences occ on occ.task_id = t.id
          where t.garden_id = gm.garden_id
            and occ.due_at >= ${startOfDay}::timestamptz
            and occ.due_at <= ${endOfDay}::timestamptz
            and occ.completed_count < greatest(1, occ.required_count)
        )
    `
    addRows(rows, 'user_id')
  } else if (campaign.audience === 'inactive_week') {
    const rows = await sql`
      select v.user_id::text as user_id
      from public.web_visits v
      join public.profiles p on p.id = v.user_id
      where v.user_id is not null
        and (p.notify_push is null or p.notify_push = true)
      group by v.user_id
      having max(v.occurred_at) < now() - interval '7 days'
    `
    addRows(rows, 'user_id')
  } else if (campaign.audience === 'admins') {
    const rows = await sql`select id::text as id from public.profiles where is_admin = true and (notify_push is null or notify_push = true)`
    addRows(rows, 'id')
  } else if (campaign.audience === 'custom') {
    // For custom audience, still filter by notify_push preference
    const customIds = (campaign.customUserIds || []).filter(Boolean)
    if (customIds.length > 0) {
      const rows = await sql`
        select id::text as id from public.profiles 
        where id = any(${sql.array(customIds)}::uuid[]) 
          and (notify_push is null or notify_push = true)
      `
      addRows(rows, 'id')
    }
  } else {
    const rows = await sql`select id::text as id from public.profiles where id is not null and (notify_push is null or notify_push = true)`
    addRows(rows, 'id')
  }
  return Array.from(recipients)
}

// Helper function to translate text using DeepL API
async function translateNotificationText(text, targetLang, sourceLang = 'EN') {
  if (!text || !targetLang || targetLang.toUpperCase() === sourceLang.toUpperCase()) {
    return text
  }

  const deeplApiKey = process.env.DEEPL_API_KEY
  if (!deeplApiKey) {
    console.warn('[notifications] DeepL API key not configured, skipping translation')
    return text
  }

  try {
    const deeplUrl = process.env.DEEPL_API_URL || 'https://api.deepl.com/v2/translate'
    const response = await fetch(deeplUrl, {
      method: 'POST',
      headers: {
        'Authorization': `DeepL-Auth-Key ${deeplApiKey}`,
        'Content-Type': 'application/x-www-form-urlencoded',
      },
      body: new URLSearchParams({
        text: text,
        source_lang: sourceLang.toUpperCase(),
        target_lang: targetLang.toUpperCase(),
      }),
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('[notifications] DeepL translation failed:', response.status, errorText)
      return text // Return original text on translation failure
    }

    const data = await response.json()
    return data.translations?.[0]?.text || text
  } catch (err) {
    console.error('[notifications] Translation error:', err)
    return text // Return original text on error
  }
}

// Get user language preferences for multiple users (batch fetch)
async function getUserLanguages(userIds) {
  if (!sql || !userIds.length) return new Map()

  const languageMap = new Map()

  try {
    // Try to get from profiles table (if preferred_language column exists)
    // This will fail gracefully if the column doesn't exist
    try {
      const profileLangs = await sql`
        select id::text as id, preferred_language
        from public.profiles
        where id = any(${sql.array(userIds)}::uuid[])
          and preferred_language is not null
      `
      for (const row of profileLangs || []) {
        const lang = String(row.preferred_language).toLowerCase()
        if (lang === 'fr' || lang === 'en') {
          languageMap.set(row.id, lang)
        }
      }
    } catch (err) {
      // Column doesn't exist or other error - continue to fallback
    }

    // Fallback: get most recent language from web visits for users we don't have yet
    const missingIds = userIds.filter(id => !languageMap.has(String(id)))
    if (missingIds.length > 0) {
      const visitLangs = await sql`
        select distinct on (user_id) user_id::text as user_id, language
        from public.web_visits
        where user_id = any(${sql.array(missingIds)}::uuid[])
          and language is not null
        order by user_id, occurred_at desc
      `.catch(() => null)

      for (const row of visitLangs || []) {
        if (!languageMap.has(row.user_id)) {
          const lang = String(row.language).toLowerCase()
          if (lang.startsWith('fr')) {
            languageMap.set(row.user_id, 'fr')
          } else if (lang.startsWith('en')) {
            languageMap.set(row.user_id, 'en')
          }
        }
      }
    }
  } catch (err) {
    console.error('[notifications] Error getting user languages:', err)
  }

  return languageMap
}

// Get user timezones for multiple users (batch fetch)
// Falls back to most recent timezone from web visits if not in profile
// Final fallback is Europe/London
async function getUserTimezones(userIds) {
  if (!sql || !userIds.length) return new Map()

  const timezoneMap = new Map()

  try {
    // First, get timezones from profiles
    const profiles = await sql`
      select id::text as id, timezone
      from public.profiles
      where id = any(${sql.array(userIds)}::uuid[])
        and timezone is not null
    `.catch(() => null)

    for (const row of profiles || []) {
      const tz = String(row.timezone).trim()
      if (tz) {
        timezoneMap.set(row.id, tz)
      }
    }

    // For users without timezone in profile, try to get from web visits
    const missingIds = userIds.filter(id => !timezoneMap.has(String(id)))
    if (missingIds.length > 0) {
      // Extract timezone from web visits extra JSONB field
      const visitTimezones = await sql`
        select distinct on (user_id) 
          user_id::text as user_id,
          (extra->>'timezone')::text as timezone
        from public.web_visits
        where user_id = any(${sql.array(missingIds)}::uuid[])
          and extra->>'timezone' is not null
          and (extra->>'timezone')::text != ''
        order by user_id, occurred_at desc
      `.catch(() => null)

      for (const row of visitTimezones || []) {
        if (!timezoneMap.has(row.user_id)) {
          const tz = String(row.timezone).trim()
          if (tz && tz !== 'null') {
            timezoneMap.set(row.user_id, tz)
          }
        }
      }
    }
  } catch (err) {
    console.error('[notifications] Error getting user timezones:', err)
  }

  return timezoneMap
}

// Convert a UTC timestamp to represent the same local time in user's timezone
// Example: Admin schedules "2024-01-15 09:00:00" in America/New_York timezone (stored as UTC)
//          User in Europe/Paris should receive it at "2024-01-15 09:00:00" Paris time
// Strategy: 
//   1. Extract the local time components (year, month, day, hour, minute) from the campaign timezone
//   2. Find the UTC timestamp that represents those same components in the user's timezone
function convertToUserTimezone(targetLocalTime, campaignTimezone, userTimezone) {
  try {
    const targetDate = new Date(targetLocalTime)
    if (Number.isNaN(targetDate.getTime())) {
      return targetLocalTime
    }

    // If same timezone, return as-is
    if (userTimezone === campaignTimezone || !userTimezone) {
      return targetLocalTime
    }

    // Extract local time components when displayed in campaign timezone
    const campaignFormatter = new Intl.DateTimeFormat('en-US', {
      timeZone: campaignTimezone,
      year: 'numeric',
      month: '2-digit',
      day: '2-digit',
      hour: '2-digit',
      minute: '2-digit',
      second: '2-digit',
      hour12: false
    })

    const campaignParts = campaignFormatter.formatToParts(targetDate)
    const getPart = (type) => parseInt(campaignParts.find(p => p.type === type)?.value || '0')

    const year = getPart('year')
    const month = getPart('month') - 1 // JavaScript months are 0-indexed
    const day = getPart('day')
    const hour = getPart('hour')
    const minute = getPart('minute')
    const second = getPart('second')

    // Now find the UTC timestamp that represents this same local time in user's timezone
    // We'll use a binary search-like approach: start with a reasonable guess and refine

    // Create an ISO string with the desired local time components
    // Format: "YYYY-MM-DDTHH:mm:ss"
    const dateStr = `${year}-${String(month + 1).padStart(2, '0')}-${String(day).padStart(2, '0')}T${String(hour).padStart(2, '0')}:${String(minute).padStart(2, '0')}:${String(second).padStart(2, '0')}`

    // Start with a guess: assume the date string represents UTC
    let candidateUtc = new Date(dateStr + 'Z') // 'Z' means UTC

    // Refine the guess by checking what local time this UTC represents in user's timezone
    // and adjusting until we get the right local time
    for (let iteration = 0; iteration < 10; iteration++) {
      const userFormatter = new Intl.DateTimeFormat('en-US', {
        timeZone: userTimezone,
        year: 'numeric',
        month: '2-digit',
        day: '2-digit',
        hour: '2-digit',
        minute: '2-digit',
        second: '2-digit',
        hour12: false
      })

      const userParts = userFormatter.formatToParts(candidateUtc)
      const getUserPart = (type) => parseInt(userParts.find(p => p.type === type)?.value || '0')

      const userYear = getUserPart('year')
      const userMonth = getUserPart('month') - 1
      const userDay = getUserPart('day')
      const userHour = getUserPart('hour')
      const userMinute = getUserPart('minute')
      const userSecond = getUserPart('second')

      // Check if we've found the exact match
      if (userYear === year && userMonth === month && userDay === day &&
        userHour === hour && userMinute === minute && Math.abs(userSecond - second) <= 1) {
        return candidateUtc.toISOString()
      }

      // Calculate how far off we are
      // Create Date objects in local time for comparison
      const desiredLocal = new Date(year, month, day, hour, minute, second)
      const actualLocal = new Date(userYear, userMonth, userDay, userHour, userMinute, userSecond)
      const diffMs = desiredLocal.getTime() - actualLocal.getTime()

      // If difference is very small, we're close enough
      if (Math.abs(diffMs) < 1000) {
        return candidateUtc.toISOString()
      }

      // Adjust candidate UTC by the difference
      candidateUtc = new Date(candidateUtc.getTime() + diffMs)
    }

    // Return the best guess we found
    return candidateUtc.toISOString()
  } catch (err) {
    console.error('[notifications] Error converting timezone:', err)
    return targetLocalTime
  }
}

// Calculate scheduled time for a user based on campaign and user timezone
function calculateUserScheduledTime(campaign, userTimezone) {
  const now = new Date()

  // For instant notifications, send immediately
  if (campaign.deliveryMode === 'send_now') {
    return now.toISOString()
  }

  // For planned notifications, convert planned time to user's timezone
  if (campaign.deliveryMode === 'planned' && campaign.plannedFor) {
    const plannedDate = new Date(campaign.plannedFor)
    if (Number.isNaN(plannedDate.getTime())) {
      return now.toISOString()
    }

    const campaignTz = campaign.timezone || DEFAULT_TIMEZONE
    return convertToUserTimezone(campaign.plannedFor, campaignTz, userTimezone || DEFAULT_TIMEZONE)
  }

  // For scheduled notifications, convert scheduled time to user's timezone
  if (campaign.deliveryMode === 'scheduled') {
    // Use next_run_at if available, otherwise schedule_start_at
    const baseTime = campaign.nextRunAt || campaign.scheduleStartAt
    if (!baseTime) {
      return now.toISOString()
    }

    const baseDate = new Date(baseTime)
    if (Number.isNaN(baseDate.getTime())) {
      return now.toISOString()
    }

    const campaignTz = campaign.timezone || DEFAULT_TIMEZONE
    return convertToUserTimezone(baseTime, campaignTz, userTimezone || DEFAULT_TIMEZONE)
  }

  return now.toISOString()
}

async function insertNotificationDeliveries(campaign, recipients, iteration, scheduledFor) {
  if (!sql || !recipients.length) return []
  const insertedRows = []
  let processedCount = 0
  const chunks = chunkArray(recipients, 200)

  // Detect source language from campaign title/message (assume English if not specified)
  const sourceLang = 'EN'

  for (const chunk of chunks) {
    // Fetch user display names, language preferences, and timezones for this chunk
    const userProfiles = await sql`
      select id::text as id, display_name, username, timezone
      from public.profiles
      where id = any(${sql.array(chunk)}::uuid[])
    `
    const userDisplayNames = new Map()
    const userLanguages = new Map()
    const userTimezones = new Map()

    // Get display names and timezones
    for (const profile of userProfiles || []) {
      const displayName = profile.display_name || profile.username || 'User'
      userDisplayNames.set(profile.id, displayName)
      if (profile.timezone) {
        userTimezones.set(profile.id, String(profile.timezone))
      }
    }

    // Get language preferences for all users in this chunk (batch fetch)
    const chunkLanguageMap = await getUserLanguages(chunk)
    for (const userId of chunk) {
      const lang = chunkLanguageMap.get(String(userId)) || 'en'
      userLanguages.set(String(userId), lang)
    }

    // Prepare payloads with personalized, translated messages, and timezone-adjusted scheduled times
    const payloadPromises = chunk.map(async (userId, index) => {
      const baseMessage = pickNotificationMessage(campaign, processedCount + index)
      const userDisplayName = userDisplayNames.get(String(userId)) || 'User'
      // Replace {{user}} with the actual user display name
      let personalizedMessage = baseMessage.replace(/\{\{user\}\}/g, userDisplayName)
      let personalizedTitle = (campaign.title || 'Aphylia').replace(/\{\{user\}\}/g, userDisplayName)

      // Translate message based on user's language preference
      const userLang = userLanguages.get(String(userId)) || 'en'
      const targetLang = userLang === 'fr' ? 'FR' : 'EN'

      if (targetLang !== sourceLang) {
        personalizedMessage = await translateNotificationText(personalizedMessage, targetLang, sourceLang)
      }

      // Translate title if needed
      let translatedTitle = personalizedTitle
      if (targetLang !== sourceLang) {
        translatedTitle = await translateNotificationText(campaign.title, targetLang, sourceLang)
      }

      // Calculate scheduled time based on user's timezone
      // For instant notifications, use provided scheduledFor (current time)
      // For planned/scheduled, calculate per-user timezone
      const userTimezone = userTimezones.get(String(userId)) || DEFAULT_TIMEZONE
      const userScheduledTime = campaign.deliveryMode === 'send_now'
        ? scheduledFor
        : calculateUserScheduledTime(campaign, userTimezone)

      return {
        campaign_id: campaign.id,
        iteration,
        user_id: userId,
        title: translatedTitle,
        message: personalizedMessage,
        payload: { ctaUrl: campaign.ctaUrl || null },
        cta_url: campaign.ctaUrl || null,
        scheduled_for: userScheduledTime,
        delivery_status: 'pending',
        delivery_attempts: 0,
        delivery_error: null,
      }
    })

    const payload = await Promise.all(payloadPromises)
    const inserted = await sql`
      insert into public.user_notifications ${sql(
      payload,
      'campaign_id',
      'iteration',
      'user_id',
      'title',
      'message',
      'payload',
      'cta_url',
      'scheduled_for',
      'delivery_status',
      'delivery_attempts',
      'delivery_error',
    )}
      on conflict (campaign_id, iteration, user_id)
      do update set
        title = excluded.title,
        message = excluded.message,
        payload = excluded.payload,
        cta_url = excluded.cta_url,
        scheduled_for = excluded.scheduled_for,
        delivery_status = 'pending',
        delivery_attempts = 0,
        delivery_error = null,
        delivered_at = null,
        seen_at = null,
        cancelled_at = null
      returning id::text as id, user_id::text as user_id, title, message, payload, cta_url
    `
    insertedRows.push(...inserted)
    processedCount += chunk.length
  }
  return insertedRows
}

async function deliverPushNotifications(notifications, campaign) {
  if (!sql || !notifications.length) return { sent: 0, failed: 0 }
  console.log(`[notifications] Delivering ${notifications.length} notification(s) for campaign: ${campaign?.id || 'adhoc'}`)
  if (!pushNotificationsEnabled) {
    console.warn('[notifications] Push notifications disabled (VAPID keys not configured)')
    const ids = notifications.map((row) => row.id)
    await sql`
      update public.user_notifications
      set delivery_status = 'failed',
          delivered_at = now(),
          delivery_attempts = delivery_attempts + 1,
          delivery_error = 'PUSH_DISABLED'
      where id = any(${ids}::uuid[])
    `
    return { sent: 0, failed: notifications.length }
  }
  const userIds = Array.from(new Set(notifications.map((row) => row.user_id).filter(Boolean)))
  if (!userIds.length) return { sent: 0, failed: notifications.length }
  const subscriptions = await sql`
    select id::text as id, user_id::text as user_id, endpoint, subscription
    from public.user_push_subscriptions
    where user_id = any(${userIds})
  `
  console.log(`[notifications] Found ${subscriptions?.length || 0} push subscription(s) for ${userIds.length} user(s)`)
  const subsByUser = new Map()
  for (const sub of subscriptions || []) {
    const list = subsByUser.get(sub.user_id) || []
    list.push(sub)
    subsByUser.set(sub.user_id, list)
  }
  const deliveredIds = []
  const failedWithReason = new Map() // Map<notificationId, errorReason>
  const staleSubscriptionIds = new Set()
  const usedSubscriptionIds = new Set()

  // Track users without subscriptions for better logging
  const usersWithoutSubs = []

  for (const notification of notifications) {
    const subs = subsByUser.get(notification.user_id) || []
    if (subs.length === 0) {
      failedWithReason.set(notification.id, 'NO_PUSH_SUBSCRIPTION')
      usersWithoutSubs.push(notification.user_id)
      continue
    }
    let delivered = false
    let lastError = null
    for (const sub of subs) {
      try {
        const payload =
          sub.subscription && typeof sub.subscription === 'string'
            ? JSON.parse(sub.subscription)
            : sub.subscription
        await webpush.sendNotification(
          payload,
          JSON.stringify({
            title: notification.title || campaign.title || 'Aphylia',
            body: notification.message,
            tag: campaign.id || `notification-${notification.id}`,
            data: {
              campaignId: campaign.id,
              notificationId: notification.id,
              url: notification.cta_url || null,
              ctaUrl: notification.cta_url || null,
            },
          }),
        )
        delivered = true
        usedSubscriptionIds.add(sub.id)
        break // Successfully sent, no need to try other subscriptions
      } catch (err) {
        const statusCode = err?.statusCode || err?.statuscode
        if (statusCode === 404 || statusCode === 410) {
          staleSubscriptionIds.add(sub.id)
          lastError = 'SUBSCRIPTION_EXPIRED'
        } else if (statusCode === 401 || statusCode === 403) {
          lastError = 'VAPID_AUTH_ERROR'
        } else {
          lastError = `PUSH_ERROR:${statusCode || 'UNKNOWN'}`
        }
        console.warn('[notifications] push delivery failed', err?.message || err)
      }
    }
    if (delivered) {
      deliveredIds.push(notification.id)
    } else {
      failedWithReason.set(notification.id, lastError || 'PUSH_FAILED')
    }
  }

  // Log summary of users without subscriptions
  if (usersWithoutSubs.length > 0) {
    console.warn(`[notifications] ${usersWithoutSubs.length} user(s) have no push subscriptions registered. They may need to enable notifications in their browser settings.`)
  }

  if (staleSubscriptionIds.size) {
    console.log(`[notifications] Cleaning up ${staleSubscriptionIds.size} expired subscription(s)`)
    await sql`
      delete from public.user_push_subscriptions
      where id = any(${Array.from(staleSubscriptionIds)}::uuid[])
    `
  }
  if (usedSubscriptionIds.size) {
    await sql`
      update public.user_push_subscriptions
      set last_used_at = now()
      where id = any(${Array.from(usedSubscriptionIds)}::uuid[])
    `
  }
  if (deliveredIds.length) {
    await sql`
      update public.user_notifications
      set delivery_status = 'sent',
          delivered_at = now(),
          delivery_attempts = delivery_attempts + 1,
          delivery_error = null
      where id = any(${deliveredIds}::uuid[])
    `
  }

  // Update failed notifications with specific error reasons
  for (const [notifId, errorReason] of failedWithReason.entries()) {
    await sql`
      update public.user_notifications
      set delivery_status = 'failed',
          delivered_at = now(),
          delivery_attempts = delivery_attempts + 1,
          delivery_error = ${errorReason}
      where id = ${notifId}::uuid
    `
  }

  // Log delivery summary
  const failureReasons = new Map()
  for (const [, reason] of failedWithReason.entries()) {
    failureReasons.set(reason, (failureReasons.get(reason) || 0) + 1)
  }
  if (deliveredIds.length > 0 || failedWithReason.size > 0) {
    let summary = `[notifications] Delivery complete: ${deliveredIds.length} sent, ${failedWithReason.size} failed`
    if (failureReasons.size > 0) {
      const reasons = Array.from(failureReasons.entries()).map(([r, c]) => `${r}=${c}`).join(', ')
      summary += ` (${reasons})`
    }
    console.log(summary)
  }

  return { sent: deliveredIds.length, failed: failedWithReason.size }
}

async function processDueUserNotifications() {
  if (!sql) return
  await ensureNotificationTables()
  while (true) {
    const pending = await sql`
      select
        un.id::text as id,
        un.user_id::text as user_id,
        un.title,
        un.message,
        un.payload,
        un.cta_url,
        un.campaign_id::text as campaign_id
      from public.user_notifications un
      where un.delivery_status = 'pending'
        and un.cancelled_at is null
        and un.scheduled_for <= now()
      order by un.scheduled_for asc
      limit ${notificationDeliveryBatchSize}
    `
    if (!pending || !pending.length) break

    const campaignIds = Array.from(
      new Set(pending.map((row) => row.campaign_id).filter((value) => value && value.length)),
    )
    const campaignMap = new Map()
    if (campaignIds.length) {
      const campaignRows = await sql`
        select *
        from public.notification_campaigns
        where id = any(${sql.array(campaignIds)}::uuid[])
      `
      for (const row of campaignRows || []) {
        const normalized = normalizeNotificationCampaign(row)
        if (normalized?.id) {
          campaignMap.set(normalized.id, normalized)
        }
      }
    }

    const grouped = new Map()
    for (const row of pending) {
      const key = row.campaign_id || '__adhoc__'
      const list = grouped.get(key) || []
      list.push(row)
      grouped.set(key, list)
    }

    for (const [campaignId, notifications] of grouped.entries()) {
      const fallbackCampaign =
        campaignMap.get(campaignId) || {
          id: campaignId === '__adhoc__' ? null : campaignId,
          title: notifications[0]?.title || 'Aphylia',
          ctaUrl: notifications[0]?.cta_url || null,
        }
      await deliverPushNotifications(notifications, fallbackCampaign)
    }

    if (pending.length < notificationDeliveryBatchSize) break
  }
}

async function runNotificationCampaign(row) {
  if (!sql) return
  // Store original state to restore on error
  const originalState = row.state || 'scheduled'
  const claimed = await sql`
    update public.notification_campaigns
    set state = 'processing', updated_at = now()
    where id = ${row.id}
      and deleted_at is null
      and state <> 'cancelled'
    returning *
  `
  if (!claimed || !claimed.length) {
    console.warn(`[notifications] Could not claim campaign ${row.id} - already processed or cancelled`)
    return
  }
  const campaign = normalizeNotificationCampaign(claimed[0])
  if (!campaign) return
  const iteration = (campaign.runCount || 0) + 1
  console.log(`[notifications] Running campaign "${campaign.title}" (id=${campaign.id}), iteration=${iteration}, audience=${campaign.audience}`)

  try {
    const recipients = await resolveNotificationAudience(campaign)
    console.log(`[notifications] Resolved ${recipients.length} recipient(s) for campaign ${campaign.id}`)

    if (recipients.length === 0) {
      console.warn(`[notifications] Campaign ${campaign.id} has no recipients matching audience "${campaign.audience}"`)
    }

    const scheduledFor = new Date().toISOString()
    const inserted = await insertNotificationDeliveries(campaign, recipients, iteration, scheduledFor)
    console.log(`[notifications] Queued ${inserted.length} notification(s) for delivery`)
    const summary = {
      recipients: recipients.length,
      queued: inserted.length,
      queuedAt: new Date().toISOString(),
    }
    let nextState = 'completed'
    let nextRunAt = null
    if (campaign.deliveryMode === 'scheduled') {
      nextRunAt = computeNextScheduledRun(campaign)
      nextState = campaign.state === 'paused' ? 'paused' : 'scheduled'
    }
    await sql`
      update public.notification_campaigns
      set state = ${nextState},
          run_count = run_count + 1,
          last_run_at = now(),
          next_run_at = ${nextRunAt},
          last_run_summary = ${summary},
          updated_at = now()
      where id = ${campaign.id}
    `
    console.log(`[notifications] Campaign ${campaign.id} completed. State=${nextState}, next_run_at=${nextRunAt || 'none'}`)
  } catch (err) {
    // Reset state on error so the campaign can be retried
    console.error(`[notifications] Campaign ${campaign.id} failed during processing:`, err)
    try {
      // Determine the appropriate fallback state
      let fallbackState = originalState
      if (originalState === 'processing' || originalState === 'draft') {
        fallbackState = campaign.deliveryMode === 'scheduled' ? 'scheduled' : 'draft'
      }
      const errorSummary = {
        error: err?.message || 'Unknown error during processing',
        failedAt: new Date().toISOString(),
      }
      await sql`
        update public.notification_campaigns
        set state = ${fallbackState},
            last_run_summary = ${errorSummary},
            updated_at = now()
        where id = ${campaign.id}
      `
      console.log(`[notifications] Campaign ${campaign.id} state reset to "${fallbackState}" after error`)
    } catch (resetErr) {
      console.error(`[notifications] Failed to reset campaign ${campaign.id} state:`, resetErr)
    }
    throw err // Re-throw to be caught by outer handler
  }
}

async function processDueNotificationCampaigns() {
  if (!sql) return
  await ensureNotificationTables()

  // First, recover any campaigns stuck in 'processing' for more than 5 minutes
  try {
    const resetAt = new Date().toISOString()
    const stuckCampaigns = await sql`
      update public.notification_campaigns
      set state = case 
            when delivery_mode = 'scheduled' then 'scheduled'
            when delivery_mode = 'planned' then 'draft'
            else 'draft'
          end,
          last_run_summary = jsonb_build_object(
            'error', 'Campaign was stuck in processing state and has been reset',
            'resetAt', ${resetAt}::text
          ),
          updated_at = now()
      where deleted_at is null
        and state = 'processing'
        and updated_at < now() - interval '5 minutes'
      returning id, title
    `
    if (stuckCampaigns && stuckCampaigns.length > 0) {
      console.warn(`[notifications] Recovered ${stuckCampaigns.length} stuck campaign(s):`, stuckCampaigns.map(c => c.id))
    }
  } catch (err) {
    console.error('[notifications] Failed to recover stuck campaigns:', err)
  }

  const due = await sql`
    select *
    from public.notification_campaigns
    where deleted_at is null
      and state not in ('cancelled','completed','paused','processing')
      and next_run_at is not null
      and next_run_at <= now()
    order by next_run_at asc
    limit 5
  `
  if (due && due.length > 0) {
    console.log(`[notifications] Found ${due.length} due campaign(s) to process`)
  }
  for (const row of due || []) {
    try {
      console.log(`[notifications] Processing campaign: id=${row.id}, title="${row.title}", state=${row.state}, delivery_mode=${row.delivery_mode}, next_run_at=${row.next_run_at}`)
      await runNotificationCampaign(row)
    } catch (err) {
      console.error('[notifications] campaign run failed', err)
    }
  }
}

async function runNotificationWorkerTick() {
  if (notificationWorkerBusy) return
  notificationWorkerBusy = true
  try {
    await processDueNotificationCampaigns()
    await processDueAutomations()
    await processDueUserNotifications()
  } catch (err) {
    console.error('[notifications] worker tick error', err)
  } finally {
    notificationWorkerBusy = false
  }
}

// Process due automations based on user timezone and send_hour
async function processDueAutomations() {
  if (!sql) return

  try {
    // Get all enabled automations with their templates and translations
    const automations = await sql`
      select a.*, t.message_variants, t.randomize, t.title as template_title, t.id as template_id,
             trans.translations
      from public.notification_automations a
      left join public.notification_templates t on t.id = a.template_id
      left join lateral (
        select jsonb_object_agg(ntt.language, ntt.message_variants) as translations
        from public.notification_template_translations ntt
        where ntt.template_id = t.id
      ) trans on true
      where a.is_enabled = true
        and a.template_id is not null
    `

    if (!automations || !automations.length) return

    const now = new Date()
    const currentHourUTC = now.getUTCHours()
    
    // Log current time info for debugging (every 15 minutes)
    const nowMinutes = now.getMinutes()
    if (nowMinutes < 1 || (nowMinutes >= 15 && nowMinutes < 16) || (nowMinutes >= 30 && nowMinutes < 31) || (nowMinutes >= 45 && nowMinutes < 46)) {
      const serverLocalHour = now.getHours()
      console.log(`[automations] Time check: serverLocalHour=${serverLocalHour}, UTC=${currentHourUTC}, defaultTimezone=${DEFAULT_USER_TIMEZONE}, enabled=${automations.length}`)
    }

    for (const automation of automations) {
      try {
        // Check if this automation should run based on current UTC hour
        // We check if any timezone would currently be at the target send_hour
        // This runs every hour, and we check all timezones where current local time = send_hour
        const sendHour = typeof automation.send_hour === 'number' ? automation.send_hour : 9
        const usesUserNotificationTime = automation.trigger_type === 'daily_task_reminder'

        // Parse translations from JSONB
        const translations = normalizeTranslationMap(automation.translations || {})

        // Get users eligible for this automation whose local time is at send_hour
        let recipientQuery

        if (automation.trigger_type === 'weekly_inactive_reminder') {
          recipientQuery = sql`
            select p.id as user_id, p.display_name, p.language, p.timezone
            from public.profiles p
            left join auth.users u on u.id = p.id
            where (p.notify_push is null or p.notify_push = true)
              and coalesce(u.last_sign_in_at, u.created_at, now() - interval '30 days') < now() - interval '7 days'
              and extract(hour from now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE})) = ${sendHour}
              and not exists (
                select 1 from public.user_notifications un
                where un.automation_id = ${automation.id}
                  and un.user_id = p.id
                  and (un.scheduled_for at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date
              )
            limit 1000
          `
        } else if (automation.trigger_type === 'daily_task_reminder') {
          // Use a bounded 2-hour window (preferred hour + 1) instead of unbounded >=.
          // This handles brief worker downtime without sending 8 AM notifications at 11 PM.
          // BETWEEN is inclusive, and extract(hour ...) returns 0-23, so BETWEEN 23 AND 24
          // only matches hour 23 (acceptable single-hour window for the last hour of day).
          recipientQuery = sql`
            select distinct p.id as user_id, p.display_name, p.language, p.timezone
            from public.profiles p
            join public.garden_members gm on gm.user_id = p.id
            join public.garden_plant_tasks t on t.garden_id = gm.garden_id
            join public.garden_plant_task_occurrences occ on occ.task_id = t.id
            where (p.notify_push is null or p.notify_push = true)
              and (p.push_task_reminders is null or p.push_task_reminders = true)
              and (occ.due_at at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date
              and coalesce(occ.completed_count, 0) < coalesce(occ.required_count, 1)
              and extract(hour from now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))
                between coalesce(nullif(regexp_replace(p.notification_time, '[^0-9]', '', 'g'), '')::int, ${DEFAULT_NOTIFICATION_HOUR})
                    and coalesce(nullif(regexp_replace(p.notification_time, '[^0-9]', '', 'g'), '')::int, ${DEFAULT_NOTIFICATION_HOUR}) + 1
              and not exists (
                select 1 from public.user_notifications un
                where un.automation_id = ${automation.id}
                  and un.user_id = p.id
                  and (un.scheduled_for at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date
              )
            limit 1000
          `
        } else if (automation.trigger_type === 'journal_continue_reminder') {
          recipientQuery = sql`
            select distinct p.id as user_id, p.display_name, p.language, p.timezone
            from public.profiles p
            join public.garden_members gm on gm.user_id = p.id
            join public.garden_activity_logs gal on gal.garden_id = gm.garden_id
            where (p.notify_push is null or p.notify_push = true)
              and gal.kind = 'note'
              and (gal.occurred_at at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date - interval '1 day'
              and extract(hour from now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE})) = ${sendHour}
              and not exists (
                select 1 from public.user_notifications un
                where un.automation_id = ${automation.id}
                  and un.user_id = p.id
                  and (un.scheduled_for at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date
              )
            limit 1000
          `
        } else {
          continue
        }

        const recipients = await recipientQuery
        
        // Log automation check even if no recipients (helps with debugging)
        if (!recipients || !recipients.length) {
          // Only log once per hour to avoid spam
          const lastLogKey = `automation_log_${automation.id}`
          const nowTs = Date.now()
          if (!global[lastLogKey] || nowTs - global[lastLogKey] > 3600000) {
            // Log debug info about why there might be no recipients
            const logDetail = usesUserNotificationTime
              ? 'No eligible recipients within preferred notification time window'
              : `No eligible recipients at send_hour=${sendHour}`
            console.log(`[automations] ${automation.trigger_type}: ${logDetail}`)
            
            // For daily_task_reminder, log how many users have incomplete tasks (without hour filter)
            if (automation.trigger_type === 'daily_task_reminder') {
              try {
                const debugCount = await sql`
                  select count(distinct p.id)::bigint as total_with_tasks,
                         count(distinct case
                          when extract(hour from now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))
                               between coalesce(nullif(regexp_replace(p.notification_time, '[^0-9]', '', 'g'), '')::int, ${DEFAULT_NOTIFICATION_HOUR})
                                   and coalesce(nullif(regexp_replace(p.notification_time, '[^0-9]', '', 'g'), '')::int, ${DEFAULT_NOTIFICATION_HOUR}) + 1
                           then p.id
                         end)::bigint as at_preferred_hour
                  from public.profiles p
                  join public.garden_members gm on gm.user_id = p.id
                  join public.garden_plant_tasks t on t.garden_id = gm.garden_id
                  join public.garden_plant_task_occurrences occ on occ.task_id = t.id
                  where (p.notify_push is null or p.notify_push = true)
                    and (p.push_task_reminders is null or p.push_task_reminders = true)
                    and (occ.due_at at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date = (now() at time zone coalesce(p.timezone, ${DEFAULT_USER_TIMEZONE}))::date
                    and coalesce(occ.completed_count, 0) < coalesce(occ.required_count, 1)
                `
                const totalWithTasks = Number(debugCount?.[0]?.total_with_tasks || 0)
                const atPreferredHour = Number(debugCount?.[0]?.at_preferred_hour || 0)
                console.log(`[automations] ${automation.trigger_type} debug: ${totalWithTasks} users with tasks, ${atPreferredHour} at preferred hour`)
              } catch (debugErr) {
                // Ignore debug query errors
              }
            }
            global[lastLogKey] = nowTs
          }
          continue
        }

        // Default message variants (English)
        const defaultVariants = toStringArray(automation.message_variants)
        if (!defaultVariants.length) {
          console.warn(`[automations] ${automation.trigger_type}: No message template configured, skipping`)
          continue
        }
        const notificationTitle = automation.template_title || automation.display_name || 'Reminder'

        console.log(`[automations] Processing ${automation.trigger_type}: ${recipients.length} recipients`)

        // Determine default URL based on automation type
        let defaultUrl = '/'
        switch (automation.trigger_type) {
          case 'daily_task_reminder':
            defaultUrl = '/gardens'
            break
          case 'journal_continue_reminder':
            defaultUrl = '/gardens'
            break
          case 'weekly_inactive_reminder':
            defaultUrl = '/'
            break
        }
        const targetUrl = automation.cta_url || defaultUrl

        let insertedCount = 0
        let skippedCount = 0
        for (const recipient of recipients) {
          // Get message variants for user's language (with fallback to default)
          const messageVariants = resolveMessageVariants(defaultVariants, translations, recipient.language)
          const shouldRandomize = automation.randomize !== false
          const messageIndex = shouldRandomize
            ? Math.floor(Math.random() * messageVariants.length)
            : 0
          const message = messageVariants[messageIndex]
            .replace(/\{\{user\}\}/gi, recipient.display_name || 'there')
          const personalizedTitle = notificationTitle.replace(/\{\{user\}\}/gi, recipient.display_name || 'there')

          try {
            // Insert notification with conflict handling for the unique automation constraint
            // The unique constraint is on (automation_id, user_id, scheduled_for::date)
            const insertResult = await sql`
              insert into public.user_notifications (
                automation_id, user_id, title, message, cta_url, scheduled_for, delivery_status
              )
              values (
                ${automation.id},
                ${recipient.user_id},
                ${personalizedTitle},
                ${message},
                ${targetUrl},
                now(),
                'pending'
              )
              on conflict (automation_id, user_id, (scheduled_for::date)) where automation_id is not null
              do nothing
              returning id
            `
            if (insertResult && insertResult.length > 0) {
              insertedCount++
            } else {
              skippedCount++
            }
          } catch (insertErr) {
            // Log errors for debugging (duplicate key violations expected if constraint triggered)
            if (!insertErr?.message?.includes('duplicate key') && !insertErr?.message?.includes('violates unique constraint')) {
              console.warn(`[automations] Failed to insert notification for user ${recipient.user_id}:`, insertErr?.message)
            }
            skippedCount++
          }
        }

        console.log(`[automations] ${automation.trigger_type}: Queued ${insertedCount} notifications (${skippedCount} skipped/duplicates)`)

        // Update last_run_at with detailed summary
        await sql`
          update public.notification_automations
          set last_run_at = now(),
              last_run_summary = ${sql.json({ 
                recipients: recipients.length, 
                queued: insertedCount,
                skipped: skippedCount,
                sentAt: new Date().toISOString() 
              })}
          where id = ${automation.id}
        `
      } catch (automationErr) {
        console.error('[automations] error processing', automation.trigger_type, automationErr)
      }
    }
  } catch (err) {
    console.error('[automations] processDueAutomations error', err)
  }
}

function scheduleNotificationWorker() {
  if (!sql) {
    console.log('[notifications] Worker not started - no database connection')
    return
  }
  if (notificationWorkerTimer) {
    console.log('[notifications] Worker already running')
    return
  }
  console.log(`[notifications] Starting notification worker (interval: ${notificationWorkerIntervalMs}ms)`)
  console.log('[notifications] Automations will be processed every tick based on user timezone and send_hour')
  const tick = () => {
    runNotificationWorkerTick().catch((err) => {
      console.error('[notifications] Worker tick error:', err?.message || err)
    })
    notificationWorkerTimer = setTimeout(tick, notificationWorkerIntervalMs)
  }
  notificationWorkerTimer = setTimeout(tick, 2000)
}

// Dynamic sitemap.xml generator
// Static pages: NO lastmod (tells Google these are evergreen, don't show dates)
// Dynamic pages: WITH lastmod (blog posts, plants get proper date indexing)
// Both EN (default) and FR locales get the same links with same priorities
const publicDir = path.resolve(__dirname, 'public')
app.get('/sitemap.xml', async (req, res) => {
  const siteUrl = process.env.PLANTSWIPE_SITE_URL || process.env.SITE_URL || 'https://aphylia.app'

  // Supported languages (en = default with no prefix, fr = with /fr prefix)
  const languages = ['en', 'fr']
  const defaultLang = 'en'

  // Helper to generate URL with language prefix
  const langUrl = (path, lang) => {
    if (lang === defaultLang) return `${siteUrl}${path}`
    return `${siteUrl}/${lang}${path}`
  }

  // Helper to generate alternate links for hreflang
  const alternateLinks = (path) => languages.map(lang =>
    `    <xhtml:link rel="alternate" hreflang="${lang}" href="${langUrl(path, lang)}" />`
  ).join('\n') + `\n    <xhtml:link rel="alternate" hreflang="x-default" href="${siteUrl}${path}" />`

  // Static pages - NO lastmod to prevent Google from showing dates
  // These are "evergreen" pages that shouldn't display modification dates in search
  const staticPages = [
    { loc: '/', priority: '1.0', changefreq: 'weekly' },
    { loc: '/blog', priority: '0.9', changefreq: 'daily' },
    { loc: '/discovery', priority: '0.9', changefreq: 'daily' },
    { loc: '/gardens', priority: '0.8', changefreq: 'daily' },
    { loc: '/contact', priority: '0.8', changefreq: 'monthly' },
    { loc: '/about', priority: '0.8', changefreq: 'monthly' },
    { loc: '/download', priority: '0.8', changefreq: 'monthly' },
    { loc: '/pricing', priority: '0.8', changefreq: 'monthly' },
    { loc: '/search', priority: '0.7', changefreq: 'weekly' },
    { loc: '/contact/business', priority: '0.6', changefreq: 'monthly' },
    { loc: '/terms', priority: '0.3', changefreq: 'yearly' },
  ]

  // Build sitemap XML - generate URLs for each language
  let urls = ''
  for (const lang of languages) {
    urls += staticPages.map(page => `  <url>
    <loc>${langUrl(page.loc, lang)}</loc>
    <changefreq>${page.changefreq}</changefreq>
    <priority>${page.priority}</priority>
${alternateLinks(page.loc)}
  </url>`).join('\n') + '\n'
  }

  // Add dynamic content WITH lastmod (blog posts, plants, profiles, gardens, bookmarks)
  // Use supabaseServiceClient (service role key) to bypass RLS and fetch ALL content including private
  const sitemapDb = supabaseServiceClient || supabaseServer
  if (sitemapDb) {
    try {
      // Recent blog posts (with lastmod)
      const { data: posts } = await sitemapDb
        .from('blog_posts')
        .select('slug, updated_at, published_at')
        .eq('is_published', true)
        .order('published_at', { ascending: false })
        .limit(100)

      if (posts?.length) {
        for (const lang of languages) {
          urls += posts.map(post => {
            const lastmod = post.updated_at || post.published_at
            const path = `/blog/${post.slug}`
            return `  <url>
    <loc>${langUrl(path, lang)}</loc>
    <lastmod>${new Date(lastmod).toISOString().split('T')[0]}</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.7</priority>
${alternateLinks(path)}
  </url>`
          }).join('\n') + '\n'
        }
      }

      // ALL plants (with lastmod based on when they were updated)
      // Approved plants get higher priority, other statuses get lower priority
      // Fetch in batches to get all plants
      const allPlants = []
      const plantBatchSize = 1000
      const maxPlants = 10000
      let plantOffset = 0

      while (allPlants.length < maxPlants) {
        const { data: plantBatch, error: plantError } = await sitemapDb
          .from('plants')
          .select('id, updated_time, created_time, status')
          .order('updated_time', { ascending: false, nullsFirst: false })
          .range(plantOffset, plantOffset + plantBatchSize - 1)

        if (plantError) {
          console.error('[sitemap] Error fetching plants batch:', plantError.message)
          break
        }

        if (!plantBatch || plantBatch.length === 0) break

        allPlants.push(...plantBatch)
        if (plantBatch.length < plantBatchSize) break
        plantOffset += plantBatchSize
      }

      if (allPlants.length) {
        for (const lang of languages) {
          urls += allPlants.map(plant => {
            const lastmod = plant.updated_time || plant.created_time
            const lastmodStr = lastmod ? `\n    <lastmod>${new Date(lastmod).toISOString().split('T')[0]}</lastmod>` : ''
            const path = `/plants/${plant.id}`
            // Approved plants get higher priority (0.7), other statuses get lower priority (0.4)
            const status = (plant.status || '').toLowerCase().trim()
            const isApproved = status === 'approved'
            const priority = isApproved ? '0.7' : '0.4'
            return `  <url>
    <loc>${langUrl(path, lang)}</loc>${lastmodStr}
    <changefreq>monthly</changefreq>
    <priority>${priority}</priority>
${alternateLinks(path)}
  </url>`
          }).join('\n') + '\n'
        }
      }

      // ALL user profiles (public and private) with different priorities
      // Public profiles: priority 0.5, Private profiles: priority 0.3
      // Fetch in batches to get all profiles
      const allProfiles = []
      const profileBatchSize = 1000
      const maxProfiles = 10000
      let profileOffset = 0

      while (allProfiles.length < maxProfiles) {
        const { data: profileBatch, error: profileError } = await sitemapDb
          .from('profiles')
          .select('id, display_name, username, is_private')
          .not('display_name', 'is', null)
          .order('is_private', { ascending: true }) // public first
          .order('display_name', { ascending: true })
          .range(profileOffset, profileOffset + profileBatchSize - 1)

        if (profileError) {
          console.error('[sitemap] Error fetching profiles batch:', profileError.message)
          break
        }

        if (!profileBatch || profileBatch.length === 0) break

        allProfiles.push(...profileBatch)
        if (profileBatch.length < profileBatchSize) break
        profileOffset += profileBatchSize
      }

      if (allProfiles.length) {
        for (const lang of languages) {
          urls += allProfiles.map(profile => {
            // Use username if available, otherwise display_name
            const urlPath = profile.username || profile.display_name
            const path = `/u/${encodeURIComponent(urlPath)}`
            // Public profiles get higher priority (0.5), private profiles get lower priority (0.3)
            const priority = profile.is_private ? '0.3' : '0.5'
            return `  <url>
    <loc>${langUrl(path, lang)}</loc>
    <changefreq>weekly</changefreq>
    <priority>${priority}</priority>
${alternateLinks(path)}
  </url>`
          }).join('\n') + '\n'
        }
      }

      // ALL gardens (public and private) with different priorities
      // Public gardens: priority 0.6, Private gardens: priority 0.4
      // Fetch in batches to get all gardens
      const allGardens = []
      const gardenBatchSize = 1000
      const maxGardens = 10000
      let gardenOffset = 0

      while (allGardens.length < maxGardens) {
        const { data: gardenBatch, error: gardenError } = await sitemapDb
          .from('gardens')
          .select('id, created_at, privacy')
          .order('created_at', { ascending: false })
          .range(gardenOffset, gardenOffset + gardenBatchSize - 1)

        if (gardenError) {
          console.error('[sitemap] Error fetching gardens batch:', gardenError.message)
          break
        }

        if (!gardenBatch || gardenBatch.length === 0) break

        allGardens.push(...gardenBatch)
        if (gardenBatch.length < gardenBatchSize) break
        gardenOffset += gardenBatchSize
      }

      if (allGardens.length) {
        for (const lang of languages) {
          urls += allGardens.map(garden => {
            // Use created_at for lastmod
            const lastmodStr = garden.created_at ? `\n    <lastmod>${new Date(garden.created_at).toISOString().split('T')[0]}</lastmod>` : ''

            const path = `/garden/${garden.id}`
            // Public gardens (privacy = 'public' or null) get higher priority (0.6)
            // Private gardens get lower priority (0.4)
            const isPrivate = garden.privacy === 'private'
            const priority = isPrivate ? '0.4' : '0.6'
            return `  <url>
    <loc>${langUrl(path, lang)}</loc>${lastmodStr}
    <changefreq>weekly</changefreq>
    <priority>${priority}</priority>
${alternateLinks(path)}
  </url>`
          }).join('\n') + '\n'
        }
      }

      // ALL bookmarks (public and private) with different priorities
      // Public bookmarks: priority 0.5, Private bookmarks: priority 0.3
      // Fetch in batches to get all bookmarks
      const allBookmarks = []
      const bookmarkBatchSize = 1000
      const maxBookmarks = 10000
      let bookmarkOffset = 0

      while (allBookmarks.length < maxBookmarks) {
        const { data: bookmarkBatch, error: bookmarkError } = await sitemapDb
          .from('bookmarks')
          .select('id, created_at, visibility')
          .order('created_at', { ascending: false })
          .range(bookmarkOffset, bookmarkOffset + bookmarkBatchSize - 1)

        if (bookmarkError) {
          console.error('[sitemap] Error fetching bookmarks batch:', bookmarkError.message)
          break
        }

        if (!bookmarkBatch || bookmarkBatch.length === 0) break

        allBookmarks.push(...bookmarkBatch)
        if (bookmarkBatch.length < bookmarkBatchSize) break
        bookmarkOffset += bookmarkBatchSize
      }

      if (allBookmarks.length) {
        for (const lang of languages) {
          urls += allBookmarks.map(bookmark => {
            // Use created_at for lastmod
            const lastmodStr = bookmark.created_at ? `\n    <lastmod>${new Date(bookmark.created_at).toISOString().split('T')[0]}</lastmod>` : ''

            const path = `/bookmarks/${bookmark.id}`
            // Public bookmarks get higher priority (0.5)
            // Private bookmarks get lower priority (0.3)
            const isPrivate = bookmark.visibility === 'private'
            const priority = isPrivate ? '0.3' : '0.5'
            return `  <url>
    <loc>${langUrl(path, lang)}</loc>${lastmodStr}
    <changefreq>weekly</changefreq>
    <priority>${priority}</priority>
${alternateLinks(path)}
  </url>`
          }).join('\n') + '\n'
        }
      }
    } catch (err) {
      console.error('[sitemap] Error fetching dynamic content:', err?.message)
    }
  }

  const sitemap = `<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9" xmlns:xhtml="http://www.w3.org/1999/xhtml">
${urls}
</urlset>`

  res.setHeader('Content-Type', 'application/xml; charset=utf-8')
  res.setHeader('Cache-Control', 'public, max-age=3600, stale-while-revalidate=86400')
  res.send(sitemap)
})

// Static assets
const distDir = path.resolve(__dirname, 'dist')
const ONE_YEAR_SECONDS = 60 * 60 * 24 * 365
const ONE_WEEK_SECONDS = 60 * 60 * 24 * 7
const ONE_DAY_SECONDS = 60 * 60 * 24
const DEFAULT_STALE_WHILE_REVALIDATE = ONE_WEEK_SECONDS
const EXTENDED_STALE_WHILE_REVALIDATE = ONE_WEEK_SECONDS * 4
const hashedAssetPattern =
  /assets\/.+[-.]([a-z0-9_\-]{8,})\.(?:js|mjs|cjs|css|json|png|jpe?g|webp|avif|svg|ttf|woff2?)$/i
app.use(
  express.static(distDir, {
    // CRITICAL: Disable index.html auto-serving so crawler detection in catch-all route works
    // Without this, express.static serves index.html for "/" before our SSR logic runs
    index: false,
    setHeaders: (res, filePath) => {
      const relativePath = path.relative(distDir, filePath).replace(/\\+/g, '/')
      if (relativePath === 'index.html') {
        res.setHeader('Cache-Control', 'public, max-age=0, must-revalidate')
        return
      }
      if (hashedAssetPattern.test(relativePath)) {
        res.setHeader('Cache-Control', `public, max-age=${ONE_YEAR_SECONDS}, immutable`)
        return
      }
      if (relativePath.startsWith('assets/')) {
        res.setHeader(
          'Cache-Control',
          `public, max-age=${ONE_WEEK_SECONDS}, stale-while-revalidate=${EXTENDED_STALE_WHILE_REVALIDATE}`,
        )
        return
      }
      if (
        relativePath.startsWith('locales/') ||
        relativePath.startsWith('icons/') ||
        relativePath === 'offline.html' ||
        relativePath === 'robots.txt' ||
        relativePath === 'env-loader.js' ||
        relativePath === 'env.js'
      ) {
        res.setHeader(
          'Cache-Control',
          `public, max-age=${ONE_WEEK_SECONDS}, stale-while-revalidate=${EXTENDED_STALE_WHILE_REVALIDATE}`,
        )
        return
      }
      res.setHeader(
        'Cache-Control',
        `public, max-age=${ONE_DAY_SECONDS}, stale-while-revalidate=${DEFAULT_STALE_WHILE_REVALIDATE}`,
      )
    },
  }),
)
// --- Crawler Detection and Server-Side Rendering for Web Archives ---
// Detects crawlers (Wayback Machine, Googlebot, etc.) and serves pre-rendered HTML
// This allows web archives to capture actual content instead of just a loading spinner

const CRAWLER_USER_AGENTS = [
  // Search engines
  'googlebot',
  'bingbot',
  'slurp',              // Yahoo
  'duckduckbot',
  'baiduspider',
  'yandexbot',
  'applebot',
  'seznambot',

  // Social media preview bots (IMPORTANT for link previews!)
  'discordbot',         // Discord link previews
  'facebookexternalhit', // Facebook/Meta
  'facebot',            // Facebook crawler
  'twitterbot',         // Twitter/X
  'linkedinbot',        // LinkedIn
  'slackbot',           // Slack
  'slack-imgproxy',     // Slack image proxy
  'whatsapp',           // WhatsApp
  'telegrambot',        // Telegram
  'vkshare',            // VK (Russian social network)
  'pinterestbot',       // Pinterest
  'redditbot',          // Reddit
  'skypeuripreview',    // Skype
  'embedly',            // Embedly (used by many platforms)
  'quora link preview', // Quora
  'outbrain',           // Outbrain
  'w3c_validator',      // W3C validator
  'viber',              // Viber
  'line-poker',         // LINE messenger
  'kakaotalk-scrap',    // KakaoTalk

  // OG Preview/Debug tools
  'opengraph',          // opengraph.xyz and similar
  'iframely',           // iframely.com
  'unfurl',             // Various unfurl services
  'preview',            // Generic preview bots
  'crawler',            // Generic crawlers
  'spider',             // Generic spiders
  'bot',                // Generic bots (catches most bots)
  'fetch',              // Generic fetch clients
  'http',               // Generic HTTP clients
  'link',               // Link preview services
  'card',               // Card validators
  'meta',               // Meta tag validators
  'og',                 // OG validators
  'scraper',            // Web scrapers
  'headless',           // Headless browsers
  'phantom',            // PhantomJS
  'puppeteer',          // Puppeteer
  'playwright',         // Playwright
  'selenium',           // Selenium
  'chrome-lighthouse',  // Lighthouse

  // Web archives
  'ia_archiver',        // Internet Archive / Wayback Machine
  'archive.org_bot',    // Internet Archive

  // SEO tools
  'ahrefsbot',
  'semrushbot',
  'mj12bot',
  'dotbot',
  'rogerbot',
  'screaming frog',
  'petalbot',
  'bytespider',
  'ccbot',

  // Generic HTTP clients (often used for unfurling)
  'wget',
  'curl',
  'python-requests',
  'python-urllib',
  'python/',
  'go-http-client',
  'axios',
  'node-fetch',
  'undici',
  'httpie',
  'insomnia',
  'postman',
  'java/',
  'okhttp',
  'apache-httpclient',
  'guzzle',
  'restsharp',
]

function isCrawler(userAgent) {
  if (!userAgent) return false
  const ua = userAgent.toLowerCase()
  return CRAWLER_USER_AGENTS.some(crawler => ua.includes(crawler))
}

// Generate pre-rendered HTML for crawlers
// Note: Uses existing escapeHtml function defined earlier in this file
// Returns: { html: string, statusCode: number } - statusCode is 200 for found pages, 404 for not-found
async function generateCrawlerHtml(req, pagePath) {
  const siteUrl = process.env.PLANTSWIPE_SITE_URL || process.env.SITE_URL || 'https://aphylia.app'
  const canonicalUrl = `${siteUrl.replace(/\/+$/, '')}${pagePath}`

  // Internal debug tracking (attached to req for debugging)
  req._ssrDebug = {
    pagePath,
    steps: [],
    errors: [],
    matchedRoute: null,
    queryResults: {}
  }
  const ssrDebug = (step, data) => {
    req._ssrDebug.steps.push({ step, data, time: Date.now() })
    console.log(`[ssr-debug] ${step}:`, JSON.stringify(data))
  }

  // SSR timeout for database queries (Discord/social bots typically timeout after 5-10 seconds)
  // Increased to 8 seconds to allow for slow database responses
  const SSR_QUERY_TIMEOUT = Number(process.env.SSR_QUERY_TIMEOUT_MS) || 8000

  // Helper to wrap Supabase queries with a timeout to prevent slow responses
  const ssrQuery = async (queryPromise, label = 'query') => {
    const startTime = Date.now()
    try {
      const result = await withTimeout(queryPromise, SSR_QUERY_TIMEOUT, `SSR_${label.toUpperCase()}_TIMEOUT`)
      console.log(`[ssr] ${label} completed in ${Date.now() - startTime}ms`)
      return result
    } catch (err) {
      const duration = Date.now() - startTime
      console.error(`[ssr] âœ— ${label} FAILED after ${duration}ms: ${err?.message || err}`)
      return { data: null, error: err }
    }
  }

  // Helper to ensure image URLs are absolute (required for og:image)
  const ensureAbsoluteUrl = (url) => {
    if (!url) return null
    // Already absolute
    if (url.startsWith('http://') || url.startsWith('https://')) return url
    // Protocol-relative URL
    if (url.startsWith('//')) return `https:${url}`
    // Relative URL - prepend site URL
    if (url.startsWith('/')) return `${siteUrl.replace(/\/+$/, '')}${url}`
    // No leading slash - treat as relative
    return `${siteUrl.replace(/\/+$/, '')}/${url}`
  }

  // Helper to check if an image URL is from our media domain (for Google image indexing)
  const isAphyliaMediaUrl = (url) => {
    if (!url) return false
    return url.includes('media.aphylia.app')
  }

  // Helper to generate an img tag for media.aphylia.app images (for Google image indexing)
  const generateImageTag = (url, alt, options = {}) => {
    if (!url || !isAphyliaMediaUrl(url)) return ''
    const { width, height, style = 'max-width: 100%; height: auto; border-radius: 12px; margin: 16px 0;' } = options
    const widthAttr = width ? ` width="${width}"` : ''
    const heightAttr = height ? ` height="${height}"` : ''
    return `<img src="${escapeHtml(url)}" alt="${escapeHtml(alt || 'Aphylia')}"${widthAttr}${heightAttr} style="${style}" loading="lazy" />`
  }

  // Default meta tags
  let title = 'Aphylia - Discover, Swipe and Manage Plants for Your Garden'
  let description = 'Discover, swipe and manage the perfect plants for every garden. Track growth, get care reminders, and build your dream garden.'
  
  // Banner image ONLY for landing page - other pages should use specific images or no image
  const LANDING_BANNER_IMAGE = 'https://media.aphylia.app/UTILITY/admin/uploads/png/baniere-logo-plus-titre-v2-54ef1ba8-2e4d-47fd-91bb-8bf4cbe01260.png'
  
  // Image settings - null means no image (don't show logo as fallback)
  // Only landing page gets the banner, other pages get specific images or nothing
  let image = null
  let imageWidth = null
  let imageHeight = null
  let imageAlt = 'Aphylia'
  let pageContent = ''
  
  // Track whether the requested resource was found (for proper 404 handling)
  // Default to true for static pages, set to false when a dynamic resource is not found
  let resourceFound = true
  // Flag to indicate if this route expects a dynamic resource
  let isDynamicRoute = false

  // Parse language from path BEFORE try block so it's always available for HTML template
  const pathParts = pagePath.split('/').filter(Boolean)
  // Supported languages with full translations
  const supportedLangs = ['en', 'fr']
  // All recognized 2-letter language codes (strip from path, default to 'en' if not fully supported)
  const allLangPrefixes = ['en', 'fr', 'de', 'es', 'it', 'pt', 'nl', 'pl', 'ru', 'ja', 'ko', 'zh', 'ar', 'hi', 'tr', 'vi', 'th', 'sv', 'da', 'no', 'fi', 'cs', 'hu', 'ro', 'uk', 'el', 'he', 'id', 'ms', 'tl']
  let detectedLang = 'en' // Default to English
  let effectivePath = pathParts
  if (pathParts.length > 0 && allLangPrefixes.includes(pathParts[0].toLowerCase())) {
    const langPrefix = pathParts[0].toLowerCase()
    // Use the language if fully supported, otherwise default to English
    detectedLang = supportedLangs.includes(langPrefix) ? langPrefix : 'en'
    effectivePath = pathParts.slice(1)
  }

  ssrDebug('path_parsed', { pathParts, effectivePath, detectedLang, firstPart: effectivePath[0], secondPart: effectivePath[1] })
  console.log(`[ssr] Generating HTML for: ${pagePath}, lang: ${detectedLang}`)

  try {
    console.log(`[ssr] Path parts: ${JSON.stringify(pathParts)}, effective: ${JSON.stringify(effectivePath)}`)

    // Translations for SSR previews
    const t = {
      en: {
        siteName: 'Aphylia',
        siteTagline: 'Discover, Swipe and Manage Plants for Your Garden',
        siteDesc: 'Discover, swipe and manage the perfect plants for every garden. Track growth, get care reminders, and build your dream garden.',
        // Plant page
        plantCareGuide: 'Care Guide & Growing Tips',
        plantAbout: 'About',
        plantQuickCare: 'Quick Care Guide',
        plantGreatFor: 'What It\'s Great For',
        plantViewFull: 'View complete care guide on Aphylia',
        plantLearnGrow: 'Learn how to grow and care for',
        plantExpertTips: 'Expert tips, watering guide, and everything you need!',
        plantType: { vegetable: 'Grow your own', herb: 'Fresh herbs at your fingertips', fruit: 'Homegrown delight', flower: 'Beautiful flowering plant', succulent: 'Low-maintenance beauty', cactus: 'Desert survivor', tree: 'Majestic addition to any garden' },
        difficulty: { easy: 'âœ… Easy', beginner: 'âœ… Beginner-friendly', moderate: 'âš¡ Moderate', medium: 'âš¡ Moderate', hard: 'ðŸ”¥ Advanced', difficult: 'ðŸ”¥ Advanced', expert: 'ðŸ’Ž Expert' },
        light: { 'full sun': 'â˜€ï¸ Full Sun', 'partial sun': 'ðŸŒ¤ï¸ Partial Sun', 'partial shade': 'â›… Partial Shade', 'full shade': 'ðŸŒ‘ Shade', 'low light': 'ðŸŒ‘ Low Light', 'bright indirect': 'ðŸ’¡ Bright Indirect' },
        blooms: 'Blooms',
        zones: 'Zones',
        family: 'Family',
        origin: 'Origin',
        tags: 'Tags',
        // Blog
        blogTitle: 'Aphylia Blog',
        blogTagline: 'Gardening Tips & Guides',
        blogDesc: 'Expert gardening advice, seasonal tips, plant care guides, and growing inspiration. Learn something new today!',
        blogBy: 'By',
        blogMinRead: 'min read',
        blogReadFull: 'Read full article on Aphylia',
        blogLatest: 'Latest Articles',
        blogReadAll: 'Read all articles',
        // Profile
        profileGardenProfile: 'Garden Profile',
        profileCheckOut: 'Check out',
        profileGrowingJourney: 'growing journey',
        profileGardens: 'garden(s)',
        profilePlants: 'plant(s)',
        profileMemberSince: 'Member since',
        profileExploreGardens: 'Explore gardens',
        profileOnAphylia: 'on Aphylia',
        profilePrivateAccount: 'This profile is private.',
        profileViewOn: 'View on',
        profilePlantEnthusiast: 'A passionate plant enthusiast growing their collection on Aphylia',
        // Garden
        gardenExplore: 'Explore Gardens',
        gardenBeautiful: 'A Beautiful Garden',
        gardenPlantsGrowing: 'plant(s) growing',
        gardenStartingFresh: 'Starting fresh',
        gardenBy: 'By',
        gardenOld: 'old',
        gardenNew: 'New garden!',
        gardenOnAphylia: 'on Aphylia',
        gardenPrivate: 'This garden is private.',
        gardenViewOn: 'View on',
        gardenWord: 'Garden',
        gardenMonths: 'month(s)',
        gardenYears: 'year(s)',
        gardenExploreThis: 'Explore this garden on Aphylia',
        gardenDiscover: 'Discover the plants growing here!',
        gardenFilled: 'A growing garden filled with beautiful plants',
        // Gardens listing
        gardensTitle: 'Explore Gardens',
        gardensDesc: 'Discover beautiful gardens from our community. Get inspired by what others are growing and share your own!',
        gardensCommunity: 'Community Gardens',
        gardensExploreWorld: 'Explore gardens from plant enthusiasts around the world.',
        gardensInspired: 'Get Inspired',
        gardensThrive: 'See what plants thrive together',
        gardensClimate: 'Discover gardens in your climate zone',
        gardensIdeas: 'Get layout and design ideas',
        gardensConnect: 'Connect with other gardeners',
        // Discovery
        discoveryTitle: 'Discover Plants | Swipe Your Way to a Dream Garden',
        discoveryDesc: 'Like Tinder, but for plants! Swipe right on plants you love, left on ones you don\'t. Build your perfect garden wishlist!',
        discoveryPlant: 'Plant Discovery',
        discoveryFind: 'Find your perfect plant matches by swiping!',
        discoveryHow: 'How It Works',
        discoveryRight: 'Swipe Right - Love it! Add to your wishlist',
        discoveryLeft: 'Swipe Left - Not for you? Skip it',
        discoveryUp: 'Swipe Up - Super like! Add to favorites',
        discoveryKeep: 'Keep Swiping - Discover your perfect matches',
        discoveryStart: 'Start swiping and build your dream garden collection!',
        // About
        aboutTitle: 'About Aphylia - Your Plant Companion',
        aboutDesc: 'Meet Aphylia: the app that helps you discover, grow, and nurture plants. Join gardeners on their growing journey!',
        aboutPersonal: 'Your personal plant companion, helping you discover, identify, and care for the perfect plants.',
        aboutMission: 'Our Mission',
        aboutBelieve: 'We believe everyone deserves access to plant knowledge. Whether you\'re a beginner with your first succulent or an expert with a botanical garden, Aphylia helps you grow.',
        aboutOffer: 'What We Offer',
        aboutDatabase: 'Extensive plant database with care guides',
        aboutGarden: 'Garden management and tracking',
        aboutReminders: 'Smart care reminders',
        aboutCommunity: 'Community of plant lovers',
        // Search
        searchTitle: 'Find Your Perfect Plants',
        searchDesc: 'Search plants by name, care level, light needs, or growing conditions. Find the perfect plants for YOUR space!',
        searchPlant: 'Plant Search',
        searchFind: 'Find your perfect plant match from our database of thousands of species.',
        searchBy: 'Search By',
        searchName: 'Plant name or scientific name',
        searchLight: 'Light requirements',
        searchWater: 'Watering needs',
        searchIndoor: 'Indoor or outdoor',
        searchClimate: 'Climate zone',
        searchDifficulty: 'Difficulty level',
        // Pricing
        pricingTitle: 'Aphylia Pricing - Free Forever & Premium Plans',
        pricingDesc: 'Aphylia is free to use! Discover plants, track your garden, get care reminders. Premium features available for power gardeners',
        pricingPlans: 'Pricing Plans',
        pricingFree: 'Free Forever',
        pricingEverything: 'Everything you need to start your gardening journey:',
        pricingDiscovery: 'Unlimited plant discovery',
        pricingTracking: 'Garden tracking',
        pricingCare: 'Care reminders',
        pricingIdentify: 'Plant identification',
        pricingAccess: 'Community access',
        pricingPremium: 'Premium (Coming Soon)',
        pricingSerious: 'For serious plant enthusiasts:',
        pricingAnalytics: 'Advanced analytics',
        pricingSupport: 'Priority support',
        pricingExclusive: 'Exclusive features',
        // Download
        downloadTitle: 'Download Aphylia - Your Plant Companion App',
        downloadDesc: 'Get Aphylia on your device! Available as a web app, PWA, and soon on iOS & Android. Start your plant journey today!',
        downloadGet: 'Download Aphylia',
        downloadWeb: 'Web App',
        downloadWebDesc: 'Use Aphylia directly in your browser - no download required!',
        downloadPwa: 'Install as PWA',
        downloadPwaDesc: 'Add to your home screen for an app-like experience:',
        downloadIos: 'iOS: Safari â†’ Share â†’ Add to Home Screen',
        downloadAndroid: 'Android: Chrome â†’ Menu â†’ Install App',
        downloadNative: 'Native Apps (Coming Soon)',
        downloadNativeDesc: 'iOS and Android apps are in development!',
        // Terms
        termsTitle: 'Terms of Service',
        termsDesc: 'Read Aphylia\'s Terms of Service. We keep it simple: be respectful, don\'t spam, and enjoy growing plants!',
        termsUpdated: 'Last updated',
        termsWelcome: 'Welcome to Aphylia! By using our service, you agree to these terms.',
        termsSimple: 'The Simple Version',
        termsRespect: 'Be respectful to others',
        termsSpam: 'Don\'t spam or abuse the service',
        termsSecure: 'Keep your account secure',
        termsEnjoy: 'Enjoy growing plants!',
        termsRead: 'Read full terms',
        // Contact
        contactTitle: 'Contact Aphylia - We\'d Love to Hear From You!',
        contactDesc: 'Have questions, feedback, or just want to say hi? Reach out to the Aphylia team. We typically respond within 24 hours!',
        contactGet: 'Get in Touch',
        contactLove: 'We\'d love to hear from you!',
        contactReach: 'Reach Out For',
        contactQuestions: 'Questions about Aphylia',
        contactFeatures: 'Feature suggestions',
        contactBugs: 'Bug reports',
        contactPartnership: 'Partnership inquiries',
        contactHello: 'Just saying hello!',
        contactRespond: 'We typically respond within 24 hours.',
        // Business contact
        businessTitle: 'Business Partnerships',
        businessDesc: 'Partner with Aphylia! We work with nurseries, garden centers, and plant brands. Let\'s grow together!',
        businessInterested: 'Interested in partnering with Aphylia? We love working with:',
        businessNurseries: 'Nurseries & Garden Centers',
        businessShops: 'Plant Shops',
        businessBrands: 'Garden Product Brands',
        businessCreators: 'Gardening Content Creators',
        businessExplore: 'Get in touch to explore collaboration opportunities!',
        // Bookmarks
        bookmarksCollection: 'Plant Collection',
        bookmarksCurated: 'Curated by',
        bookmarksCarefully: 'A carefully curated plant collection',
        bookmarksView: 'View this collection on Aphylia',
        bookmarkTitle: 'Plant Bookmark',
        bookmarkDesc: 'Bookmark',
        bookmarkMadeBy: 'made by',
        bookmarkSaved: 'saved',
        bookmarkPlant: 'plant',
        bookmarkPlants: 'plants',
        // Homepage
        homeTitle: 'Aphylia - Discover & Grow Your Perfect Garden',
        homeDesc: 'Swipe to discover plants, track your garden, get care reminders. Join gardeners growing their dream gardens!',
        homeWelcome: 'Welcome to Aphylia',
        homePersonal: 'Your personal plant companion for discovering, managing, and growing beautiful gardens.',
        homeWhy: 'Why Gardeners Love Us',
        homeSwipe: 'Swipe to Discover - Find your perfect plants, Tinder-style!',
        homeTracker: 'Garden Tracker - Manage all your plants in one place',
        homeReminders: 'Smart Reminders - Never forget to water again',
        homeCareGuides: 'Care Guides - Expert advice for',
        homePlants: 'plants',
        homeCommunityJoin: 'Community - Join',
        homePlantLovers: 'plant lovers',
        homeStart: 'Start Growing Today',
        homeFree: 'Free to use. No credit card required. Just plants!',
      },
      fr: {
        siteName: 'Aphylia',
        siteTagline: 'DÃ©couvrez, Swipez et GÃ©rez les Plantes de Votre Jardin',
        siteDesc: 'DÃ©couvrez et gÃ©rez les plantes parfaites pour votre jardin. Suivez la croissance, recevez des rappels d\'entretien et crÃ©ez le jardin de vos rÃªves.',
        plantCareGuide: 'Guide d\'Entretien & Conseils de Culture',
        plantAbout: 'Ã€ propos de',
        plantQuickCare: 'Guide d\'Entretien Rapide',
        plantGreatFor: 'IdÃ©al Pour',
        plantViewFull: 'Voir le guide complet sur Aphylia',
        plantLearnGrow: 'Apprenez Ã  cultiver et entretenir',
        plantExpertTips: 'Conseils d\'experts, guide d\'arrosage et tout ce dont vous avez besoin !',
        plantType: { vegetable: 'Cultivez vos propres', herb: 'Herbes fraÃ®ches Ã  portÃ©e de main', fruit: 'DÃ©lices du jardin', flower: 'Belle plante Ã  fleurs', succulent: 'BeautÃ© facile d\'entretien', cactus: 'Survivant du dÃ©sert', tree: 'Ajout majestueux Ã  tout jardin' },
        difficulty: { easy: 'âœ… Facile', beginner: 'âœ… DÃ©butant', moderate: 'âš¡ ModÃ©rÃ©', medium: 'âš¡ ModÃ©rÃ©', hard: 'ðŸ”¥ AvancÃ©', difficult: 'ðŸ”¥ AvancÃ©', expert: 'ðŸ’Ž Expert' },
        light: { 'full sun': 'â˜€ï¸ Plein Soleil', 'partial sun': 'ðŸŒ¤ï¸ Mi-Soleil', 'partial shade': 'â›… Mi-Ombre', 'full shade': 'ðŸŒ‘ Ombre', 'low light': 'ðŸŒ‘ Faible LumiÃ¨re', 'bright indirect': 'ðŸ’¡ LumiÃ¨re Indirecte' },
        blooms: 'Floraison',
        zones: 'Zones',
        family: 'Famille',
        origin: 'Origine',
        tags: 'Tags',
        blogTitle: 'Blog Aphylia',
        blogTagline: 'Conseils Jardinage & Guides',
        blogDesc: 'Conseils d\'experts en jardinage, astuces saisonniÃ¨res et guides d\'entretien. Apprenez quelque chose de nouveau aujourd\'hui !',
        blogBy: 'Par',
        blogMinRead: 'min de lecture',
        blogReadFull: 'Lire l\'article complet sur Aphylia',
        blogLatest: 'Derniers Articles',
        blogReadAll: 'Voir tous les articles',
        profileGardenProfile: 'Profil Jardinier',
        profileCheckOut: 'DÃ©couvrez',
        profileGrowingJourney: 'parcours de jardinage',
        profileGardens: 'jardin(s)',
        profilePlants: 'plante(s)',
        profileMemberSince: 'Membre depuis',
        profileExploreGardens: 'Explorer les jardins',
        profileOnAphylia: 'sur Aphylia',
        profilePrivateAccount: 'Ce profil est privÃ©.',
        profileViewOn: 'Voir sur',
        profilePlantEnthusiast: 'Un passionnÃ© de plantes qui agrandit sa collection sur Aphylia',
        gardenExplore: 'Explorer les Jardins',
        gardenBeautiful: 'Un Beau Jardin',
        gardenPlantsGrowing: 'plante(s) en culture',
        gardenStartingFresh: 'Nouveau dÃ©part',
        gardenBy: 'Par',
        gardenOld: 'd\'anciennetÃ©',
        gardenNew: 'Nouveau jardin !',
        gardenOnAphylia: 'sur Aphylia',
        gardenPrivate: 'Ce jardin est privÃ©.',
        gardenViewOn: 'Voir sur',
        gardenWord: 'Jardin',
        gardenMonths: 'mois',
        gardenYears: 'an(s)',
        gardenExploreThis: 'Explorer ce jardin sur Aphylia',
        gardenDiscover: 'DÃ©couvrez les plantes qui y poussent !',
        gardenFilled: 'Un jardin en croissance rempli de belles plantes',
        gardensTitle: 'Explorer les Jardins',
        gardensDesc: 'DÃ©couvrez les beaux jardins de notre communautÃ©. Inspirez-vous et partagez le vÃ´tre !',
        gardensCommunity: 'Jardins de la CommunautÃ©',
        gardensExploreWorld: 'Explorez les jardins des passionnÃ©s du monde entier.',
        gardensInspired: 'Inspirez-vous',
        gardensThrive: 'Voyez quelles plantes s\'Ã©panouissent ensemble',
        gardensClimate: 'DÃ©couvrez des jardins dans votre zone climatique',
        gardensIdeas: 'Trouvez des idÃ©es d\'amÃ©nagement',
        gardensConnect: 'Connectez-vous avec d\'autres jardiniers',
        discoveryTitle: 'DÃ©couvrir des Plantes | Swipez vers le Jardin de vos RÃªves',
        discoveryDesc: 'Comme Tinder, mais pour les plantes ! Swipez Ã  droite sur celles que vous aimez. CrÃ©ez votre liste de souhaits !',
        discoveryPlant: 'DÃ©couverte de Plantes',
        discoveryFind: 'Trouvez vos plantes idÃ©ales en swipant !',
        discoveryHow: 'Comment Ã§a marche',
        discoveryRight: 'Swipe Droite - J\'adore ! Ajouter Ã  ma liste',
        discoveryLeft: 'Swipe Gauche - Pas pour moi ? Passer',
        discoveryUp: 'Swipe Haut - Super like ! Ajouter aux favoris',
        discoveryKeep: 'Continuez Ã  swiper - DÃ©couvrez vos plantes parfaites',
        discoveryStart: 'Commencez Ã  swiper et crÃ©ez votre collection de rÃªve !',
        aboutTitle: 'Ã€ Propos d\'Aphylia - Votre Compagnon VÃ©gÃ©tal',
        aboutDesc: 'DÃ©couvrez Aphylia : l\'appli qui vous aide Ã  dÃ©couvrir et cultiver des plantes. Rejoignez les jardiniers !',
        aboutPersonal: 'Votre compagnon vÃ©gÃ©tal personnel pour dÃ©couvrir, identifier et prendre soin des plantes parfaites.',
        aboutMission: 'Notre Mission',
        aboutBelieve: 'Nous croyons que tout le monde mÃ©rite d\'accÃ©der aux connaissances vÃ©gÃ©tales. Que vous soyez dÃ©butant ou expert, Aphylia vous aide Ã  grandir.',
        aboutOffer: 'Ce Que Nous Offrons',
        aboutDatabase: 'Base de donnÃ©es de plantes avec guides d\'entretien',
        aboutGarden: 'Gestion et suivi de jardin',
        aboutReminders: 'Rappels d\'entretien intelligents',
        aboutCommunity: 'CommunautÃ© de passionnÃ©s de plantes',
        searchTitle: 'Trouvez Vos Plantes Parfaites',
        searchDesc: 'Recherchez des plantes par nom, niveau d\'entretien ou conditions de culture. Trouvez les plantes parfaites pour VOTRE espace !',
        searchPlant: 'Recherche de Plantes',
        searchFind: 'Trouvez votre plante idÃ©ale parmi des milliers d\'espÃ¨ces.',
        searchBy: 'Rechercher Par',
        searchName: 'Nom de la plante ou nom scientifique',
        searchLight: 'Besoins en lumiÃ¨re',
        searchWater: 'Besoins en eau',
        searchIndoor: 'IntÃ©rieur ou extÃ©rieur',
        searchClimate: 'Zone climatique',
        searchDifficulty: 'Niveau de difficultÃ©',
        pricingTitle: 'Tarifs Aphylia - Gratuit Pour Toujours',
        pricingDesc: 'Aphylia est gratuit ! DÃ©couvrez des plantes, suivez votre jardin, recevez des rappels. Fonctions premium disponibles',
        pricingPlans: 'Nos Forfaits',
        pricingFree: 'Gratuit Pour Toujours',
        pricingEverything: 'Tout ce dont vous avez besoin pour commencer :',
        pricingDiscovery: 'DÃ©couverte illimitÃ©e de plantes',
        pricingTracking: 'Suivi de jardin',
        pricingCare: 'Rappels d\'entretien',
        pricingIdentify: 'Identification de plantes',
        pricingAccess: 'AccÃ¨s Ã  la communautÃ©',
        pricingPremium: 'Premium (BientÃ´t)',
        pricingSerious: 'Pour les passionnÃ©s :',
        pricingAnalytics: 'Analyses avancÃ©es',
        pricingSupport: 'Support prioritaire',
        pricingExclusive: 'FonctionnalitÃ©s exclusives',
        downloadTitle: 'TÃ©lÃ©charger Aphylia - Votre Appli Jardinage',
        downloadDesc: 'Obtenez Aphylia ! Disponible en web app, PWA, et bientÃ´t sur iOS & Android. Commencez votre aventure vÃ©gÃ©tale !',
        downloadGet: 'TÃ©lÃ©charger Aphylia',
        downloadWeb: 'Application Web',
        downloadWebDesc: 'Utilisez Aphylia dans votre navigateur - aucun tÃ©lÃ©chargement requis !',
        downloadPwa: 'Installer en PWA',
        downloadPwaDesc: 'Ajoutez Ã  votre Ã©cran d\'accueil :',
        downloadIos: 'iOS : Safari â†’ Partager â†’ Sur l\'Ã©cran d\'accueil',
        downloadAndroid: 'Android : Chrome â†’ Menu â†’ Installer',
        downloadNative: 'Apps Natives (BientÃ´t)',
        downloadNativeDesc: 'Les apps iOS et Android sont en dÃ©veloppement !',
        termsTitle: 'Conditions d\'Utilisation',
        termsDesc: 'Lisez les conditions d\'Aphylia. C\'est simple : soyez respectueux et profitez des plantes !',
        termsUpdated: 'DerniÃ¨re mise Ã  jour',
        termsWelcome: 'Bienvenue sur Aphylia ! En utilisant notre service, vous acceptez ces conditions.',
        termsSimple: 'En RÃ©sumÃ©',
        termsRespect: 'Soyez respectueux envers les autres',
        termsSpam: 'Ne spammez pas',
        termsSecure: 'Gardez votre compte sÃ©curisÃ©',
        termsEnjoy: 'Profitez des plantes !',
        termsRead: 'Lire les conditions complÃ¨tes',
        contactTitle: 'Contactez Aphylia - On Adore Vous Entendre !',
        contactDesc: 'Des questions ou des commentaires ? Contactez l\'Ã©quipe Aphylia. Nous rÃ©pondons gÃ©nÃ©ralement sous 24h !',
        contactGet: 'Nous Contacter',
        contactLove: 'Nous serions ravis de vous entendre !',
        contactReach: 'Contactez-nous Pour',
        contactQuestions: 'Questions sur Aphylia',
        contactFeatures: 'Suggestions de fonctionnalitÃ©s',
        contactBugs: 'Signaler des bugs',
        contactPartnership: 'Demandes de partenariat',
        contactHello: 'Juste dire bonjour !',
        contactRespond: 'Nous rÃ©pondons gÃ©nÃ©ralement sous 24h.',
        businessTitle: 'Partenariats Professionnels',
        businessDesc: 'Partenaires avec Aphylia ! Nous travaillons avec pÃ©piniÃ¨res et jardineries. Grandissons ensemble !',
        businessInterested: 'IntÃ©ressÃ© par un partenariat ? Nous adorons travailler avec :',
        businessNurseries: 'PÃ©piniÃ¨res & Jardineries',
        businessShops: 'Boutiques de Plantes',
        businessBrands: 'Marques de Jardinage',
        businessCreators: 'CrÃ©ateurs de Contenu Jardinage',
        businessExplore: 'Contactez-nous pour explorer les opportunitÃ©s !',
        bookmarksCollection: 'Collection de Plantes',
        bookmarksCurated: 'SÃ©lectionnÃ© par',
        bookmarksCarefully: 'Une collection de plantes soigneusement sÃ©lectionnÃ©e',
        bookmarksView: 'Voir cette collection sur Aphylia',
        bookmarkTitle: 'Signet de Plantes',
        bookmarkDesc: 'Signet',
        bookmarkMadeBy: 'crÃ©Ã© par',
        bookmarkSaved: 'sauvegardÃ©es',
        bookmarkPlant: 'plante',
        bookmarkPlants: 'plantes',
        homeTitle: 'Aphylia - DÃ©couvrez & Cultivez Votre Jardin Parfait',
        homeDesc: 'Swipez pour dÃ©couvrir des plantes, suivez votre jardin, recevez des rappels. Rejoignez les jardiniers !',
        homeWelcome: 'Bienvenue sur Aphylia',
        homePersonal: 'Votre compagnon vÃ©gÃ©tal pour dÃ©couvrir, gÃ©rer et faire pousser de beaux jardins.',
        homeWhy: 'Pourquoi les Jardiniers Nous Adorent',
        homeSwipe: 'Swipez pour DÃ©couvrir - Trouvez vos plantes parfaites !',
        homeTracker: 'Suivi de Jardin - GÃ©rez toutes vos plantes en un seul endroit',
        homeReminders: 'Rappels Intelligents - N\'oubliez plus jamais d\'arroser',
        homeCareGuides: 'Guides d\'Entretien - Conseils d\'experts pour',
        homePlants: 'plantes',
        homeCommunityJoin: 'CommunautÃ© - Rejoignez',
        homePlantLovers: 'passionnÃ©s de plantes',
        homeStart: 'Commencez Ã  Jardiner',
        homeFree: 'Gratuit. Pas de carte bancaire. Juste des plantes !',
      },
    }

    // Get translations for detected language, fallback to English
    const tr = t[detectedLang] || t.en

    // Plant detail page: /plants/:id
    const isPlantRoute = effectivePath[0] === 'plants' && !!effectivePath[1]
    const isGardenRoute = (effectivePath[0] === 'garden' || effectivePath[0] === 'gardens') && !!effectivePath[1]
    const isBlogRoute = effectivePath[0] === 'blog' && !!effectivePath[1]
    const isProfileRoute = effectivePath[0] === 'u' && !!effectivePath[1]
    const isBookmarkRoute = effectivePath[0] === 'bookmarks' && !!effectivePath[1]

    ssrDebug('route_detection', {
      effectivePath0: effectivePath[0],
      effectivePath1: effectivePath[1],
      effectivePath2: effectivePath[2],
      isPlantRoute,
      isGardenRoute,
      isBlogRoute,
      isProfileRoute,
      isBookmarkRoute,
      supabaseAvailable: !!supabaseServer
    })
    console.log(`[ssr] Route detection: plant=${isPlantRoute}, garden=${isGardenRoute}, blog=${isBlogRoute}, profile=${isProfileRoute}, bookmark=${isBookmarkRoute}`)
    if (isPlantRoute) {
      isDynamicRoute = true
      req._ssrDebug.matchedRoute = 'plant'
      const plantId = decodeURIComponent(effectivePath[1])
      ssrDebug('plant_route_matched', { plantId, supabaseAvailable: !!supabaseServer })
      console.log(`[ssr] âœ“ Matched plant route! Looking up plant: ${plantId}, supabase available: ${!!supabaseServer}`)

      if (!supabaseServer) {
        console.log(`[ssr] WARNING: Supabase not available, using defaults`)
        resourceFound = false
      } else {
        // Query base plant data (non-translatable fields now include scientific_name, family, level_sun, maintenance_level, season)
        const { data: basePlant, error: plantError } = await ssrQuery(
          supabaseServer
            .from('plants')
            .select('id, name, plant_type, utility, watering_type, flowering_month, scientific_name, family, level_sun, maintenance_level, season')
            .eq('id', plantId)
            .maybeSingle(),
          'plant_lookup'
        )

        // Query translated fields from plant_translations for the detected language
        // Note: scientific_name, family, level_sun, maintenance_level, season were migrated to plants table
        const ssrLang = detectedLang || 'en'
        const { data: translation } = await ssrQuery(
          supabaseServer
            .from('plant_translations')
            .select('name, overview, tags, origin')
            .eq('plant_id', plantId)
            .eq('language', ssrLang)
            .maybeSingle(),
          'plant_translation_lookup'
        )

        // Also fetch English translation as fallback for empty fields
        let enTranslation = null
        if (ssrLang !== 'en') {
          const { data: enData } = await ssrQuery(
            supabaseServer
              .from('plant_translations')
              .select('name, overview, tags, origin')
              .eq('plant_id', plantId)
              .eq('language', 'en')
              .maybeSingle(),
            'plant_translation_en_fallback'
          )
          enTranslation = enData
        }

        // Use target language translation, falling back to English for empty fields
        const finalTranslation = translation || enTranslation

        // Merge base plant with translations, with field-level fallback to English
        // Non-translatable fields (scientific_name, family, level_sun, maintenance_level, season) come from basePlant
        const plant = basePlant ? {
          ...basePlant,
          name: translation?.name || enTranslation?.name || basePlant.name,
          // Non-translatable fields come from plants table
          scientific_name: basePlant.scientific_name,
          family: basePlant.family,
          level_sun: basePlant.level_sun,
          maintenance_level: basePlant.maintenance_level,
          season: basePlant.season,
          // Translatable fields come from plant_translations with fallback
          overview: translation?.overview || enTranslation?.overview,
          tags: (translation?.tags?.length ? translation.tags : null) || enTranslation?.tags,
          origin: (translation?.origin?.length ? translation.origin : null) || enTranslation?.origin,
        } : null

        ssrDebug('plant_query_result', {
          hasData: !!plant,
          hasError: !!plantError,
          plantName: plant?.name,
          errorMsg: plantError?.message
        })
        req._ssrDebug.queryResults.plant = { found: !!plant, name: plant?.name, error: plantError?.message }
        console.log(`[ssr] Plant query result: data=${plant ? 'found' : 'null'}, error=${plantError ? plantError.message || 'unknown error' : 'none'}`)
        if (plantError) {
          req._ssrDebug.errors.push({ type: 'plant_query', error: plantError.message || JSON.stringify(plantError) })
          console.log(`[ssr] âœ— Plant query error: ${plantError.message || JSON.stringify(plantError)}`)
          resourceFound = false
        } else if (!plant) {
          req._ssrDebug.errors.push({ type: 'plant_not_found', plantId })
          console.log(`[ssr] âœ— Plant not found in database: ${plantId}`)
          resourceFound = false
        }

        if (plant) {
          ssrDebug('plant_found', {
            name: plant.name,
            id: plant.id,
            type: plant.plant_type,
            hasOverview: !!plant.overview,
            overviewLength: plant.overview?.length || 0,
            tagsCount: plant.tags?.length || 0,
            lang: ssrLang
          })
          console.log(`[ssr] âœ“ Found plant: ${plant.name} (${plant.id}), overview=${plant.overview?.length || 0}chars, tags=${plant.tags?.length || 0}, lang=${ssrLang}`)

          // Simple, clean title format: "ðŸŒ± Lotus - Complete Care Guide | Aphylia"
          title = `ðŸŒ± ${plant.name} - ${tr.plantCareGuide} | Aphylia`

          // Use overview cropped to ~150 characters for description
          // Fallback to plant-specific info using tags, family, type
          if (plant.overview) {
            const overview = plant.overview.trim()
            description = overview.length > 150
              ? overview.slice(0, 150).trim() + '...'
              : overview
          } else {
            // Build a plant-specific description from available data
            const descParts = []
            if (plant.scientific_name) descParts.push(plant.scientific_name)
            if (plant.family) descParts.push(`${tr.family}: ${plant.family}`)
            if (plant.tags?.length) {
              const tagList = plant.tags.slice(0, 4).join(', ')
              descParts.push(tagList)
            }
            if (descParts.length > 0) {
              description = `${plant.name} - ${descParts.join(' â€¢ ')} ðŸŒ±`
            } else {
              description = `${tr.plantLearnGrow} ${plant.name}. ${tr.plantExpertTips} ðŸŒ±`
            }
          }

          // Keep these for pageContent structured data
          const plantEmoji = {
            'vegetable': 'ðŸ¥¬',
            'fruit': 'ðŸŽ',
            'herb': 'ðŸŒ¿',
            'flower': 'ðŸŒ¸',
            'tree': 'ðŸŒ³',
            'shrub': 'ðŸŒ²',
            'succulent': 'ðŸŒµ',
            'cactus': 'ðŸŒµ',
            'vine': 'ðŸ‡',
            'grass': 'ðŸŒ¾',
            'fern': 'ðŸŒ¿',
            'aquatic': 'ðŸª·',
            'bulb': 'ðŸŒ·',
            'palm': 'ðŸŒ´',
            'climber': 'ðŸ§—',
            'perennial': 'ðŸŒº',
            'annual': 'ðŸŒ»',
          }
          const typeKey = (plant.plant_type || '').toLowerCase()
          const emoji = plantEmoji[typeKey] || 'ðŸŒ±'

          // Care difficulty indicator - use translations (for pageContent)
          const difficulty = tr.difficulty[(plant.maintenance_level || '').toLowerCase()] || ''

          // Light requirement indicator - use translations (for pageContent)
          const light = tr.light[(plant.level_sun || '').toLowerCase()] || ''

          // Fetch primary image, fallback to discovery image (with timeout)
          const { data: images } = await ssrQuery(
            supabaseServer
              .from('plant_images')
              .select('link, use')
              .eq('plant_id', plantId)
              .in('use', ['primary', 'discovery', 'other'])
              .order('use', { ascending: true })
              .limit(3),
            'plant_images'
          )

          // Prefer primary, then discovery, then any other
          const primaryImg = images?.find(img => img.use === 'primary')
          const discoveryImg = images?.find(img => img.use === 'discovery')
          const anyImg = images?.[0]

          // Set plant image - don't specify dimensions to avoid squeezing
          // Let the platform render the image at its natural aspect ratio
          const selectedImg = primaryImg?.link || discoveryImg?.link || anyImg?.link
          if (selectedImg) {
            image = ensureAbsoluteUrl(selectedImg)
            // Don't set width/height - let the image display at natural dimensions
            // This prevents squeezing on platforms like Discord/Telegram
            imageAlt = `${plant.name} - Plant photo`
          }
          // If no image found, image stays null - no fallback to banner

          // Build structured content for the page
          const quickFacts = []
          if (plant.scientific_name) quickFacts.push(`ðŸ”¬ <em>${escapeHtml(plant.scientific_name)}</em>`)
          if (plant.family) quickFacts.push(`ðŸ‘¨â€ðŸ‘©â€ðŸ‘§ ${tr.family}: ${escapeHtml(plant.family)}`)
          if (plant.plant_type) quickFacts.push(`${emoji} ${escapeHtml(plant.plant_type)}`)
          if (plant.origin?.length) quickFacts.push(`ðŸŒ ${tr.origin}: ${plant.origin.slice(0, 2).map(o => escapeHtml(o)).join(', ')}`)

          const careInfo = []
          if (light) careInfo.push(light)
          if (plant.watering_type?.length) careInfo.push(`ðŸ’§ ${plant.watering_type.map(w => escapeHtml(w)).join(', ')}`)
          if (difficulty) careInfo.push(difficulty)
          if (plant.season?.length) careInfo.push(`ðŸŒ¿ ${plant.season.map(s => escapeHtml(s)).join(', ')}`)

          // Generate image tag if we have an image from media.aphylia.app
          const plantImageTag = generateImageTag(image, `${plant.name} - Plant photo on Aphylia`)

          pageContent = `
            <article itemscope itemtype="https://schema.org/Product">
              <h1 itemprop="name">${emoji} ${escapeHtml(plant.name)}</h1>
              ${quickFacts.length ? `<div class="plant-meta">${quickFacts.join(' Â· ')}</div>` : ''}
              
              ${plantImageTag ? `<figure itemprop="image" itemscope itemtype="https://schema.org/ImageObject">
                ${plantImageTag}
                <figcaption style="font-size: 12px; color: #6b7280; text-align: center;">${escapeHtml(plant.name)}</figcaption>
              </figure>` : ''}
              
              ${plant.overview ? `
                <div itemprop="description">
                  <h2>${tr.plantAbout} ${escapeHtml(plant.name)}</h2>
                  <p>${escapeHtml(plant.overview)}</p>
                </div>
              ` : ''}
              
              ${careInfo.length ? `
                <h2>ðŸŒ± ${tr.plantQuickCare}</h2>
                <div class="plant-meta">${careInfo.join(' Â· ')}</div>
              ` : ''}
              
              ${plant.utility?.length ? `
                <h2>âœ¨ ${tr.plantGreatFor}</h2>
                <ul>${plant.utility.slice(0, 5).map(u => `<li>${escapeHtml(u)}</li>`).join('')}</ul>
              ` : ''}
              
              ${plant.tags?.length ? `<p><strong>${tr.tags}:</strong> ${plant.tags.slice(0, 8).map(t => `#${escapeHtml(t)}`).join(' ')}</p>` : ''}
              
              <p style="margin-top: 20px;">
                <a href="${escapeHtml(canonicalUrl)}">ðŸ“– ${tr.plantViewFull} â†’</a>
              </p>
              
              <h2>ðŸ”— ${detectedLang === 'fr' ? 'DÃ©couvrir plus' : 'Discover More'}</h2>
              <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
                <a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher des plantes' : 'Search Plants'}</a>
                <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir' : 'Discover'}</a>
                <a href="/gardens">ðŸ¡ ${detectedLang === 'fr' ? 'Jardins' : 'Gardens'}</a>
                <a href="/blog">ðŸ“š Blog</a>
                <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
              </nav>
            </article>
          `

          console.log(`[ssr] Plant image: ${image}`)
        }
      }
    }

    // Blog post page: /blog/:slug
    else if (isBlogRoute && supabaseServer) {
      isDynamicRoute = true
      const slugOrId = decodeURIComponent(effectivePath[1])
      console.log(`[ssr] Looking up blog post: ${slugOrId}`)
      req._ssrDebug.matchedRoute = 'blog_post'

      // Check if it looks like a UUID (for ID-based lookup)
      const isUUID = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(slugOrId)
      ssrDebug('blog_route_matched', { slugOrId, isUUID })

      // Try slug lookup first, then ID if it's a UUID
      let post = null
      let postError = null

      // First try by slug
      const { data: postBySlug, error: slugError } = await ssrQuery(
        supabaseServer
          .from('blog_posts')
          .select('id, title, excerpt, body_html, cover_image_url, author_name, published_at')
          .eq('slug', slugOrId)
          .eq('is_published', true)
          .maybeSingle(),
        'blog_lookup_by_slug'
      )

      if (postBySlug) {
        post = postBySlug
      } else if (isUUID) {
        // If not found by slug and looks like UUID, try by ID
        console.log(`[ssr] Blog not found by slug, trying by ID: ${slugOrId}`)
        const { data: postById, error: idError } = await ssrQuery(
          supabaseServer
            .from('blog_posts')
            .select('id, title, excerpt, body_html, cover_image_url, author_name, published_at')
            .eq('id', slugOrId)
            .eq('is_published', true)
            .maybeSingle(),
          'blog_lookup_by_id'
        )
        post = postById
        postError = idError
      } else {
        postError = slugError
      }

      if (postError) {
        console.log(`[ssr] Blog query error: ${postError.message}`)
        resourceFound = false
      } else if (!post) {
        console.log(`[ssr] âœ— Blog post not found: ${slugOrId}`)
        resourceFound = false
      }
      
      if (post) {
        console.log(`[ssr] âœ“ Found blog post: ${post.title}`)

        // Estimate read time from body_html content
        const readTime = post.body_html ? Math.ceil(post.body_html.replace(/<[^>]*>/g, '').split(/\s+/).length / 200) : 5

        // Create engaging title
        title = `${post.title} | ${tr.blogTitle} ðŸ“–`

        // Create compelling description with read time
        const descParts = []
        if (post.excerpt) {
          descParts.push(post.excerpt.slice(0, 150))
        } else if (post.body_html) {
          const plainText = post.body_html.replace(/<[^>]*>/g, ' ').replace(/\s+/g, ' ').trim()
          descParts.push(plainText.slice(0, 150))
        }
        if (readTime > 0) descParts.push(`ðŸ“š ${readTime} ${tr.blogMinRead}`)
        if (post.author_name) descParts.push(`âœï¸ ${tr.blogBy} ${post.author_name}`)

        description = descParts.length > 0 ? descParts.join(' â€¢ ') : tr.blogDesc

        // Blog cover images - don't force dimensions
        if (post.cover_image_url) {
          image = ensureAbsoluteUrl(post.cover_image_url)
          imageAlt = `${post.title} - Aphylia Blog`
        }
        // If no cover image, image stays null - no fallback

        // Use locale-specific date format
        const dateLocales = { en: 'en-US', fr: 'fr-FR', es: 'es-ES', de: 'de-DE', it: 'it-IT', pt: 'pt-BR', nl: 'nl-NL', pl: 'pl-PL', ru: 'ru-RU', ja: 'ja-JP', ko: 'ko-KR', zh: 'zh-CN' }
        const publishDate = post.published_at ? new Date(post.published_at).toLocaleDateString(dateLocales[detectedLang] || 'en-US', {
          year: 'numeric',
          month: 'long',
          day: 'numeric'
        }) : null

        // Generate blog cover image tag if from media.aphylia.app
        const blogImageTag = generateImageTag(image, `${post.title} - Aphylia Blog`)

        pageContent = `
          <article itemscope itemtype="https://schema.org/BlogPosting">
            <h1 itemprop="headline">ðŸ“– ${escapeHtml(post.title)}</h1>
            <div class="plant-meta">
              ${post.author_name ? `âœï¸ ${tr.blogBy} <span itemprop="author">${escapeHtml(post.author_name)}</span>` : ''}
              ${publishDate ? ` Â· ðŸ“… <time itemprop="datePublished" datetime="${post.published_at}">${publishDate}</time>` : ''}
              ${readTime > 0 ? ` Â· ðŸ“š ${readTime} ${tr.blogMinRead}` : ''}
            </div>
            
            ${blogImageTag ? `<figure itemprop="image" itemscope itemtype="https://schema.org/ImageObject">
              ${blogImageTag}
              <figcaption style="font-size: 12px; color: #6b7280; text-align: center;">${escapeHtml(post.title)}</figcaption>
            </figure>` : ''}
            
            ${post.excerpt ? `<p itemprop="description" style="font-size: 1.1em; color: #444; font-style: italic;">"${escapeHtml(post.excerpt)}"</p>` : ''}
            <p style="margin-top: 20px;"><a href="${escapeHtml(canonicalUrl)}">${tr.blogReadFull} â†’</a></p>
            
            <h2>ðŸ”— ${detectedLang === 'fr' ? 'Plus d\'articles' : 'More Articles'}</h2>
            <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
              <a href="/blog">ðŸ“š ${detectedLang === 'fr' ? 'Tous les articles' : 'All Articles'}</a>
              <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir des plantes' : 'Discover Plants'}</a>
              <a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher' : 'Search'}</a>
              <a href="/gardens">ðŸ¡ ${detectedLang === 'fr' ? 'Jardins' : 'Gardens'}</a>
              <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
            </nav>
          </article>
        `
        console.log(`[ssr] Blog image: ${image}`)
      }
    }

    // User profile page: /u/:username
    else if (isProfileRoute && supabaseServer) {
      isDynamicRoute = true
      const username = decodeURIComponent(effectivePath[1])
      req._ssrDebug.matchedRoute = 'profile'
      ssrDebug('profile_route_matched', { username, supabaseAvailable: !!supabaseServer })
      console.log(`[ssr] Looking up user profile: ${username}`)

      // Use the same RPC function as the frontend for consistent results
      // This handles all the display_name/username matching logic in the database
      let profile = null
      let profileError = null

      // Try RPC function first (same as frontend)
      const { data: rpcResult, error: rpcErr } = await ssrQuery(
        supabaseServer.rpc('get_profile_public_by_display_name', { _name: username }),
        'profile_lookup_rpc'
      )

      if (rpcResult) {
        // RPC returns array or single object
        profile = Array.isArray(rpcResult) ? rpcResult[0] : rpcResult
      }

      // Fallback: direct query if RPC fails or doesn't exist
      // Search WITHOUT is_private filter first - we'll handle privacy after
      if (!profile && !rpcErr) {
        const { data: profileByDisplayName, error: err1 } = await ssrQuery(
          supabaseServer
            .from('profiles')
            .select('id, display_name, username, bio, avatar_url, is_private, country, favorite_plant, roles, is_admin')
            .ilike('display_name', username)
            .maybeSingle(),
          'profile_lookup_by_display_name'
        )

        if (profileByDisplayName) {
          profile = profileByDisplayName
        } else {
          // Try by username field (case-insensitive) if display_name didn't match
          const { data: profileByUsername, error: err2 } = await ssrQuery(
            supabaseServer
              .from('profiles')
              .select('id, display_name, username, bio, avatar_url, is_private, country, favorite_plant, roles, is_admin')
              .ilike('username', username)
              .maybeSingle(),
            'profile_lookup_by_username'
          )
          profile = profileByUsername
          profileError = err2
        }
      } else if (rpcErr) {
        profileError = rpcErr
      }

      ssrDebug('profile_query_result', { found: !!profile, displayName: profile?.display_name, isPrivate: profile?.is_private, error: profileError?.message })

      if (profileError) {
        console.log(`[ssr] Profile query error: ${profileError.message}`)
        resourceFound = false
      } else if (!profile) {
        console.log(`[ssr] âœ— Profile not found: ${username}`)
        resourceFound = false
      }
      
      if (profile) {
        const isPrivate = Boolean(profile.is_private)
        const displayName = profile.display_name || profile.username || username
        console.log(`[ssr] âœ“ Found profile: ${displayName} (private: ${isPrivate})`)

        // Always set the title with the user's name
        title = `ðŸŒ± ${displayName} | ${tr.profileGardenProfile} | Aphylia`

        // For private profiles, show limited info
        if (isPrivate) {
          description = `${displayName} ${tr.profileOnAphylia || 'on Aphylia'} ðŸŒ± ${tr.profilePrivateAccount || 'This is a private profile.'}`
          // Use avatar if available, otherwise no image
          if (profile.avatar_url) {
            image = ensureAbsoluteUrl(profile.avatar_url)
            imageAlt = `${displayName} - Profile on Aphylia`
          }
          // If no avatar, image stays null - no fallback

          pageContent = `
            <article itemscope itemtype="https://schema.org/Person">
              <h1 itemprop="name">ðŸŒ± ${escapeHtml(displayName)}</h1>
              <p>ðŸ”’ ${tr.profilePrivateAccount || 'This profile is private.'}</p>
              <p style="margin-top: 20px;"><a href="${escapeHtml(canonicalUrl)}">${tr.profileViewOn || 'View on'} Aphylia â†’</a></p>
            </article>
          `
          console.log(`[ssr] Private profile - showing limited preview`)
        } else {
          // Public profile - show full details
          // Get garden and plant counts (with timeouts to avoid blocking)
          let gardenCount = 0
          let plantCount = 0
          let currentStreak = 0
          let bestStreak = 0
          let friendsCount = 0
          let joinedDate = null
          let isOnline = false
          let lastSeen = null
          
          try {
            // Get stats using the same RPC as frontend
            const { data: statsData } = await ssrQuery(
              supabaseServer.rpc('get_user_profile_public_stats', { _user_id: profile.id }),
              'profile_stats'
            )
            if (statsData) {
              const statRow = Array.isArray(statsData) ? statsData[0] : statsData
              gardenCount = Number(statRow?.gardens_count || 0)
              plantCount = Number(statRow?.plants_total || 0)
              currentStreak = Number(statRow?.current_streak || 0)
              bestStreak = Number(statRow?.longest_streak || 0)
            }
            
            // Get friend count
            const { data: friendCountData } = await ssrQuery(
              supabaseServer.rpc('get_friend_count', { _user_id: profile.id }),
              'profile_friend_count'
            )
            if (typeof friendCountData === 'number') {
              friendsCount = friendCountData
            }

            // Fallback for garden/plant counts if RPC didn't return them
            if (gardenCount === 0) {
              const { count: gCount } = await ssrQuery(
                supabaseServer
                  .from('gardens')
                  .select('id', { count: 'exact', head: true })
                  .eq('created_by', profile.id),
                'profile_garden_count'
              )
              gardenCount = gCount || 0
            }

            if (plantCount === 0 && gardenCount > 0) {
              const { data: gardens } = await ssrQuery(
                supabaseServer
                  .from('gardens')
                  .select('id')
                  .eq('created_by', profile.id),
                'profile_gardens'
              )
              if (gardens?.length) {
                const gardenIds = gardens.map(g => g.id)
                const { count: pCount } = await ssrQuery(
                  supabaseServer
                    .from('garden_plants')
                    .select('id', { count: 'exact', head: true })
                    .in('garden_id', gardenIds),
                  'profile_plant_count'
                )
                plantCount = pCount || 0
              }
            }
          } catch { }

          // Extract joined date and online status from RPC result if available
          if (profile.joined_at) {
            joinedDate = profile.joined_at
          }
          if (profile.is_online !== undefined) {
            isOnline = Boolean(profile.is_online)
          }
          if (profile.last_seen_at) {
            lastSeen = profile.last_seen_at
          }

          // Fetch user's public gardens for internal links
          let userGardens = []
          try {
            const { data: gardens } = await ssrQuery(
              supabaseServer
                .from('gardens')
                .select('id, name')
                .eq('created_by', profile.id)
                .eq('privacy', 'public')
                .limit(6),
              'profile_user_gardens'
            )
            if (gardens) userGardens = gardens
          } catch { }

          // Create rich description with all stats
          const descParts = []
          if (profile.bio) {
            descParts.push(profile.bio.slice(0, 80))
          } else {
            descParts.push(`${tr.profileCheckOut} ${displayName}'s ${tr.profileGrowingJourney}`)
          }
          if (gardenCount > 0) descParts.push(`ðŸ¡ ${gardenCount} ${tr.profileGardens}`)
          if (plantCount > 0) descParts.push(`ðŸŒ¿ ${plantCount} ${tr.profilePlants}`)
          if (currentStreak > 0) descParts.push(`ðŸ”¥ ${currentStreak} ${detectedLang === 'fr' ? 'jours de sÃ©rie' : 'day streak'}`)
          if (friendsCount > 0) descParts.push(`ðŸ‘¥ ${friendsCount} ${detectedLang === 'fr' ? 'amis' : 'friends'}`)
          if (profile.country) descParts.push(`ðŸ“ ${profile.country}`)

          description = descParts.length > 0 ? descParts.join(' â€¢ ') : tr.profilePlantEnthusiast

          // Use avatar if available, otherwise no image
          if (profile.avatar_url) {
            image = ensureAbsoluteUrl(profile.avatar_url)
            imageAlt = `${displayName} - Garden Profile on Aphylia`
          }
          // If no avatar, image stays null - no fallback

          // Build role badges
          const roleBadges = []
          if (profile.is_admin) roleBadges.push('ðŸ‘‘ Admin')
          if (Array.isArray(profile.roles)) {
            if (profile.roles.includes('team_member')) roleBadges.push('ðŸŒŸ Team')
            if (profile.roles.includes('beta_tester')) roleBadges.push('ðŸ§ª Beta')
            if (profile.roles.includes('bug_catcher')) roleBadges.push('ðŸ› Bug Catcher')
            if (profile.roles.includes('early_adopter')) roleBadges.push('ðŸŒ± Early Adopter')
          }

          // Locale-specific date formatting
          const dateLocales = { en: 'en-US', fr: 'fr-FR' }
          const joinedDateFormatted = joinedDate ? new Date(joinedDate).toLocaleDateString(dateLocales[detectedLang] || 'en-US', {
            year: 'numeric',
            month: 'long',
          }) : null

          // Generate avatar image tag if from media.aphylia.app
          const profileImageTag = generateImageTag(image, `${displayName} - Profile on Aphylia`, { 
            width: 150, 
            height: 150, 
            style: 'border-radius: 50%; margin: 16px 0;' 
          })

          pageContent = `
            <article itemscope itemtype="https://schema.org/Person">
              <h1 itemprop="name">ðŸŒ± ${escapeHtml(displayName)}</h1>
              ${roleBadges.length > 0 ? `<div style="margin-bottom: 12px;">${roleBadges.join(' ')}</div>` : ''}
              
              ${profileImageTag ? `<figure itemprop="image" itemscope itemtype="https://schema.org/ImageObject" style="text-align: center;">
                ${profileImageTag}
              </figure>` : ''}
              
              <div class="profile-meta" style="display: flex; flex-wrap: wrap; gap: 8px; margin-bottom: 16px; color: #6b7280;">
                ${profile.country ? `<span>ðŸ“ ${escapeHtml(profile.country)}</span>` : ''}
                ${isOnline ? `<span>ðŸŸ¢ ${detectedLang === 'fr' ? 'En ligne' : 'Online'}</span>` : ''}
                ${joinedDateFormatted ? `<span>ðŸ“… ${detectedLang === 'fr' ? 'Membre depuis' : 'Member since'} ${joinedDateFormatted}</span>` : ''}
              </div>
              
              ${profile.bio ? `<p itemprop="description" style="font-style: italic; margin-bottom: 20px;">"${escapeHtml(profile.bio)}"</p>` : `<p>${tr.profilePlantEnthusiast} ðŸŒ±</p>`}
              
              <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(100px, 1fr)); gap: 12px; margin: 20px 0; padding: 16px; background: #f0fdf4; border-radius: 12px;">
                <div style="text-align: center;">
                  <div style="font-size: 24px; font-weight: bold; color: #059669;">ðŸŒ¿ ${plantCount}</div>
                  <div style="font-size: 12px; color: #6b7280;">${tr.profilePlants}</div>
                </div>
                <div style="text-align: center;">
                  <div style="font-size: 24px; font-weight: bold; color: #059669;">ðŸ¡ ${gardenCount}</div>
                  <div style="font-size: 12px; color: #6b7280;">${tr.profileGardens}</div>
                </div>
                <div style="text-align: center;">
                  <div style="font-size: 24px; font-weight: bold; color: #f97316;">ðŸ”¥ ${currentStreak}</div>
                  <div style="font-size: 12px; color: #6b7280;">${detectedLang === 'fr' ? 'SÃ©rie actuelle' : 'Current Streak'}</div>
                </div>
                <div style="text-align: center;">
                  <div style="font-size: 24px; font-weight: bold; color: #eab308;">ðŸ† ${bestStreak}</div>
                  <div style="font-size: 12px; color: #6b7280;">${detectedLang === 'fr' ? 'Meilleure sÃ©rie' : 'Best Streak'}</div>
                </div>
                ${friendsCount > 0 ? `
                <div style="text-align: center;">
                  <div style="font-size: 24px; font-weight: bold; color: #8b5cf6;">ðŸ‘¥ ${friendsCount}</div>
                  <div style="font-size: 12px; color: #6b7280;">${detectedLang === 'fr' ? 'Amis' : 'Friends'}</div>
                </div>
                ` : ''}
              </div>
              
              ${profile.favorite_plant ? `<p>â¤ï¸ ${detectedLang === 'fr' ? 'Plante prÃ©fÃ©rÃ©e' : 'Favorite plant'}: ${escapeHtml(profile.favorite_plant)}</p>` : ''}
              
              ${userGardens.length > 0 ? `
              <h2>ðŸ¡ ${detectedLang === 'fr' ? 'Jardins de' : 'Gardens by'} ${escapeHtml(displayName)}</h2>
              <ul>
                ${userGardens.map(g => `<li><a href="/garden/${encodeURIComponent(g.id)}">${escapeHtml(g.name || 'Garden')}</a></li>`).join('')}
              </ul>
              ` : ''}
              
              <h2>ðŸ”— ${detectedLang === 'fr' ? 'Explorer Aphylia' : 'Explore Aphylia'}</h2>
              <nav style="display: flex; flex-wrap: wrap; gap: 12px; margin-top: 12px;">
                <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
                <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir' : 'Discover'}</a>
                <a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher' : 'Search'}</a>
                <a href="/gardens">ðŸ¡ ${detectedLang === 'fr' ? 'Jardins' : 'Gardens'}</a>
                <a href="/blog">ðŸ“š Blog</a>
              </nav>
            </article>
          `
          console.log(`[ssr] Profile image: ${image}`)
        }
      }
    }

    // Garden page: /garden/:id or /gardens/:id or /garden/:id/overview etc.
    else if (isGardenRoute && supabaseServer) {
      isDynamicRoute = true
      const gardenId = decodeURIComponent(effectivePath[1])
      req._ssrDebug.matchedRoute = 'garden'
      ssrDebug('garden_route_matched', { gardenId, supabaseAvailable: !!supabaseServer, serviceClientAvailable: !!supabaseServiceClient })
      console.log(`[ssr] Looking up garden: ${gardenId}`)

      // Use service client to bypass RLS (gardens may have privacy restrictions)
      const dbClient = supabaseServiceClient || supabaseServer

      const { data: garden, error: gardenError } = await ssrQuery(
        dbClient
          .from('gardens')
          .select('id, name, created_by, created_at, privacy, location_city, location_country, cover_image_url')
          .eq('id', gardenId)
          .maybeSingle(),
        'garden_lookup'
      )

      ssrDebug('garden_query_result', { found: !!garden, name: garden?.name, privacy: garden?.privacy, error: gardenError?.message })

      if (gardenError) {
        console.log(`[ssr] Garden query error: ${gardenError.message}`)
        resourceFound = false
      } else if (!garden) {
        console.log(`[ssr] âœ— Garden not found: ${gardenId}`)
        resourceFound = false
      }
      
      if (garden) {
        const isPrivate = garden.privacy === 'private'
        const gardenName = garden.name || tr.gardenBeautiful
        console.log(`[ssr] âœ“ Found garden: ${gardenName} (privacy: ${garden.privacy || 'public'})`)

        // Get owner info (needed for both public and private gardens)
        let ownerName = null
        let ownerAvatarUrl = null
        if (garden.created_by) {
          const { data: owner } = await ssrQuery(
            dbClient
              .from('profiles')
              .select('display_name, avatar_url')
              .eq('id', garden.created_by)
              .maybeSingle(),
            'garden_owner'
          )
          if (owner) {
            ownerName = owner.display_name
            ownerAvatarUrl = owner.avatar_url
          }
        }

        // For private gardens, show limited info
        if (isPrivate) {
          const gardenEmoji = 'ðŸ¡'
          title = `${gardenEmoji} ${gardenName} - ${tr.gardenWord} | Aphylia`
          description = `${gardenName} ${tr.gardenOnAphylia || 'on Aphylia'} ðŸŒ± ${tr.gardenPrivate || 'This is a private garden.'}`
          // Use garden cover if available, otherwise no image
          if (garden.cover_image_url) {
            image = ensureAbsoluteUrl(garden.cover_image_url)
            imageAlt = `${gardenName} - Garden on Aphylia`
          }
          // If no cover, image stays null - no fallback

          pageContent = `
            <article itemscope itemtype="https://schema.org/Place">
              <h1 itemprop="name">${gardenEmoji} ${escapeHtml(gardenName)}</h1>
              ${ownerName ? `<p>ðŸ‘¤ ${tr.gardenBy} ${escapeHtml(ownerName)}</p>` : ''}
              <p>ðŸ”’ ${tr.gardenPrivate || 'This garden is private.'}</p>
              <p style="margin-top: 20px;"><a href="${escapeHtml(canonicalUrl)}">${tr.gardenViewOn || 'View on'} Aphylia â†’</a></p>
            </article>
          `
          console.log(`[ssr] Private garden - showing limited preview`)
        } else {
          // Public garden - show full details
          let plantCount = 0
          let speciesCount = 0
          let gardenImage = null
          let gardenStreak = 0
          let memberCount = 1
          let recentPlants = []
          let todayProgress = { due: 0, completed: 0 }

          try {
            // Use garden cover image if available
            if (garden.cover_image_url) {
              gardenImage = ensureAbsoluteUrl(garden.cover_image_url)
            }

            // Get owner avatar if no garden cover
            if (!gardenImage && ownerAvatarUrl) {
              gardenImage = ensureAbsoluteUrl(ownerAvatarUrl)
            }

            // Get plant count and species count
            const { data: gardenPlants } = await ssrQuery(
              dbClient
                .from('garden_plants')
                .select('id, plant_id, nickname')
                .eq('garden_id', gardenId),
              'garden_plants'
            )
            
            // Array to store plant details with IDs for linking
            let gardenPlantDetails = []
            
            if (gardenPlants?.length) {
              plantCount = gardenPlants.length
              // Count unique species
              const uniquePlantIds = new Set(gardenPlants.map(p => p.plant_id).filter(Boolean))
              speciesCount = uniquePlantIds.size
              
              // Get plant names and IDs for linking
              const plantIds = [...uniquePlantIds].slice(0, 8)
              if (plantIds.length > 0) {
                const { data: plantDetails } = await ssrQuery(
                  dbClient
                    .from('plants')
                    .select('id, name')
                    .in('id', plantIds),
                  'garden_plant_names'
                )
                if (plantDetails) {
                  gardenPlantDetails = plantDetails.filter(p => p.name)
                  recentPlants = plantDetails.map(p => p.name).filter(Boolean).slice(0, 4)
                }
              }
            }

            // Get garden streak
            const { data: gardenData } = await ssrQuery(
              dbClient
                .from('gardens')
                .select('current_streak')
                .eq('id', gardenId)
                .maybeSingle(),
              'garden_streak'
            )
            if (gardenData?.current_streak) {
              gardenStreak = gardenData.current_streak
            }

            // Get member count
            const { count: mCount } = await ssrQuery(
              dbClient
                .from('garden_members')
                .select('id', { count: 'exact', head: true })
                .eq('garden_id', gardenId),
              'garden_member_count'
            )
            memberCount = (mCount || 0) + 1 // +1 for owner

            // Try to get today's task progress
            try {
              const today = new Date().toISOString().slice(0, 10)
              const { data: taskOccs } = await ssrQuery(
                dbClient
                  .from('task_occurrences')
                  .select('required_count, completed_count')
                  .eq('garden_id', gardenId)
                  .gte('due_at', today)
                  .lt('due_at', today + 'T23:59:59'),
                'garden_today_tasks'
              )
              if (taskOccs?.length) {
                todayProgress.due = taskOccs.reduce((sum, t) => sum + (t.required_count || 0), 0)
                todayProgress.completed = taskOccs.reduce((sum, t) => sum + (t.completed_count || 0), 0)
              }
            } catch { }

            // Try to get a plant image from the garden (with timeout)
            if (!gardenImage && gardenPlants?.[0]?.plant_id) {
              const { data: plantImg } = await ssrQuery(
                dbClient
                  .from('plant_images')
                  .select('link')
                  .eq('plant_id', gardenPlants[0].plant_id)
                  .eq('use', 'primary')
                  .maybeSingle(),
                'garden_plant_img'
              )
              if (plantImg?.link) gardenImage = ensureAbsoluteUrl(plantImg.link)
            }
          } catch { }

          // Get garden age - with translations
          const createdDate = garden.created_at ? new Date(garden.created_at) : null
          const gardenAge = createdDate ? (() => {
            const months = Math.floor((Date.now() - createdDate.getTime()) / (1000 * 60 * 60 * 24 * 30))
            if (months < 1) return tr.gardenNew
            if (months < 12) return `${months} ${tr.gardenMonths} ${tr.gardenOld}`
            const years = Math.floor(months / 12)
            return `${years} ${tr.gardenYears} ${tr.gardenOld}`
          })() : null

          // Create engaging title
          const gardenEmoji = plantCount > 20 ? 'ðŸŒ³' : plantCount > 10 ? 'ðŸŒ¿' : plantCount > 0 ? 'ðŸŒ±' : 'ðŸ¡'
          title = `${gardenEmoji} ${gardenName} - ${tr.gardenWord} | Aphylia`

          // Create rich description with all stats
          const descParts = []
          // Build location string from city/country
          const locationParts = [garden.location_city, garden.location_country].filter(Boolean)
          const gardenLocation = locationParts.length > 0 ? locationParts.join(', ') : null

          if (plantCount > 0) descParts.push(`ðŸŒ¿ ${plantCount} ${tr.gardenPlantsGrowing}`)
          if (speciesCount > 0 && speciesCount !== plantCount) descParts.push(`ðŸŒ¸ ${speciesCount} ${detectedLang === 'fr' ? 'espÃ¨ces' : 'species'}`)
          if (gardenStreak > 0) descParts.push(`ðŸ”¥ ${gardenStreak} ${detectedLang === 'fr' ? 'jours de sÃ©rie' : 'day streak'}`)
          if (ownerName) descParts.push(`ðŸ‘¤ ${tr.gardenBy} ${ownerName}`)
          if (gardenLocation) descParts.push(`ðŸ“ ${gardenLocation}`)
          if (gardenAge) descParts.push(`ðŸ• ${gardenAge}`)

          description = descParts.length > 0
            ? descParts.join(' â€¢ ')
            : `${tr.gardenExploreThis}. ${tr.gardenDiscover}`

          // Use garden image if found, otherwise no image
          if (gardenImage) {
            image = gardenImage
            imageAlt = `${gardenName} - Garden on Aphylia`
          }
          // If no image found, image stays null - no fallback

          // Calculate task progress percentage
          const progressPercent = todayProgress.due > 0 ? Math.round((todayProgress.completed / todayProgress.due) * 100) : 100

          // Generate garden image tag if from media.aphylia.app
          const gardenImageTag = generateImageTag(image, `${gardenName} - Garden on Aphylia`)

          pageContent = `
            <article itemscope itemtype="https://schema.org/Place">
              <h1 itemprop="name">${gardenEmoji} ${escapeHtml(gardenName)}</h1>
              
              <div class="garden-meta" style="display: flex; flex-wrap: wrap; gap: 8px; margin-bottom: 16px; color: #6b7280;">
                ${ownerName ? `<span>ðŸ‘¤ ${tr.gardenBy} <a href="/u/${encodeURIComponent(ownerName)}">${escapeHtml(ownerName)}</a></span>` : ''}
                ${gardenLocation ? `<span>ðŸ“ ${escapeHtml(gardenLocation)}</span>` : ''}
                ${gardenAge ? `<span>ðŸ• ${gardenAge}</span>` : ''}
                ${memberCount > 1 ? `<span>ðŸ‘¥ ${memberCount} ${detectedLang === 'fr' ? 'membres' : 'members'}</span>` : ''}
              </div>
              
              ${gardenImageTag ? `<figure itemprop="image" itemscope itemtype="https://schema.org/ImageObject">
                ${gardenImageTag}
                <figcaption style="font-size: 12px; color: #6b7280; text-align: center;">${escapeHtml(gardenName)}</figcaption>
              </figure>` : ''}
              
              <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(100px, 1fr)); gap: 12px; margin: 20px 0; padding: 16px; background: #f0fdf4; border-radius: 12px;">
                <div style="text-align: center;">
                  <div style="font-size: 24px; font-weight: bold; color: #059669;">ðŸŒ¿ ${plantCount}</div>
                  <div style="font-size: 12px; color: #6b7280;">${tr.gardenPlantsGrowing}</div>
                </div>
                ${speciesCount > 0 ? `
                <div style="text-align: center;">
                  <div style="font-size: 24px; font-weight: bold; color: #059669;">ðŸŒ¸ ${speciesCount}</div>
                  <div style="font-size: 12px; color: #6b7280;">${detectedLang === 'fr' ? 'EspÃ¨ces' : 'Species'}</div>
                </div>
                ` : ''}
                <div style="text-align: center;">
                  <div style="font-size: 24px; font-weight: bold; color: #f97316;">ðŸ”¥ ${gardenStreak}</div>
                  <div style="font-size: 12px; color: #6b7280;">${detectedLang === 'fr' ? 'SÃ©rie' : 'Streak'}</div>
                </div>
                ${todayProgress.due > 0 ? `
                <div style="text-align: center;">
                  <div style="font-size: 24px; font-weight: bold; color: ${progressPercent >= 100 ? '#10b981' : '#f59e0b'};">âœ… ${progressPercent}%</div>
                  <div style="font-size: 12px; color: #6b7280;">${detectedLang === 'fr' ? 'Aujourd\'hui' : 'Today'}</div>
                </div>
                ` : ''}
              </div>
              
              ${gardenPlantDetails.length > 0 ? `
              <h2>ðŸŒ¿ ${detectedLang === 'fr' ? 'Plantes dans ce jardin' : 'Plants in this garden'}</h2>
              <ul style="display: flex; flex-wrap: wrap; gap: 8px; list-style: none; padding: 0;">
                ${gardenPlantDetails.map(p => `<li><a href="/plants/${encodeURIComponent(p.id)}" style="display: inline-block; padding: 6px 12px; background: #f0fdf4; border-radius: 20px; text-decoration: none; color: #065f46; font-size: 14px;">ðŸŒ± ${escapeHtml(p.name)}</a></li>`).join('')}
              </ul>
              ${plantCount > gardenPlantDetails.length ? `<p style="color: #6b7280; font-size: 14px;">${detectedLang === 'fr' ? `Et ${plantCount - gardenPlantDetails.length} autres plantes...` : `And ${plantCount - gardenPlantDetails.length} more plants...`}</p>` : ''}
              ` : ''}
              
              <p>${tr.gardenFilled} ðŸŒ¸</p>
              
              <h2>ðŸ”— ${detectedLang === 'fr' ? 'Explorer' : 'Explore'}</h2>
              <nav style="display: flex; flex-wrap: wrap; gap: 12px; margin-top: 12px;">
                ${ownerName ? `<a href="/u/${encodeURIComponent(ownerName)}">ðŸ‘¤ ${detectedLang === 'fr' ? 'Profil de' : 'Profile of'} ${escapeHtml(ownerName)}</a>` : ''}
                <a href="/gardens">ðŸ¡ ${detectedLang === 'fr' ? 'Tous les jardins' : 'All Gardens'}</a>
                <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir des plantes' : 'Discover Plants'}</a>
                <a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher' : 'Search'}</a>
                <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
              </nav>
            </article>
          `
          console.log(`[ssr] Garden image: ${image}`)
        }
      }
    }

    // Static pages with enhanced previews
    else if (effectivePath[0] === 'about' || pagePath === '/about') {
      title = `ðŸŒ± ${tr.aboutTitle}`
      description = tr.aboutDesc
      pageContent = `
        <article>
          <h1>ðŸŒ± ${tr.siteName}</h1>
          <p>${tr.aboutPersonal}</p>
          <h2>${tr.aboutMission}</h2>
          <p>${tr.aboutBelieve}</p>
          <h2>${tr.aboutOffer}</h2>
          <ul>
            <li>ðŸ” <a href="/search">${tr.aboutDatabase}</a></li>
            <li>ðŸ¡ <a href="/gardens">${tr.aboutGarden}</a></li>
            <li>â° ${tr.aboutReminders}</li>
            <li>ðŸ‘¥ ${tr.aboutCommunity}</li>
          </ul>
          <h2>ðŸ”— ${detectedLang === 'fr' ? 'En savoir plus' : 'Learn More'}</h2>
          <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
            <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
            <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir' : 'Discover'}</a>
            <a href="/blog">ðŸ“š Blog</a>
            <a href="/pricing">ðŸ’Ž ${detectedLang === 'fr' ? 'Tarifs' : 'Pricing'}</a>
            <a href="/download">ðŸ“² ${detectedLang === 'fr' ? 'TÃ©lÃ©charger' : 'Download'}</a>
            <a href="/contact">ðŸ’¬ Contact</a>
          </nav>
        </article>
      `
    }

    else if (effectivePath[0] === 'search' || pagePath === '/search') {
      // Fetch some popular plants to link from search page
      let searchPopularPlants = []
      try {
        if (supabaseServer) {
          const { data: plants } = await ssrQuery(
            supabaseServer
              .from('plants')
              .select('id, name')
              .limit(10),
            'search_popular_plants'
          )
          if (plants) searchPopularPlants = plants
        }
      } catch { }
      
      title = `ðŸ” ${tr.searchTitle} | Aphylia`
      description = tr.searchDesc
      pageContent = `
        <article>
          <h1>ðŸ” ${tr.searchPlant}</h1>
          <p>${tr.searchFind}</p>
          <h2>${tr.searchBy}</h2>
          <ul>
            <li>ðŸ·ï¸ ${tr.searchName}</li>
            <li>â˜€ï¸ ${tr.searchLight}</li>
            <li>ðŸ’§ ${tr.searchWater}</li>
            <li>ðŸ  ${tr.searchIndoor}</li>
            <li>ðŸŒ¡ï¸ ${tr.searchClimate}</li>
            <li>ðŸŽ¯ ${tr.searchDifficulty}</li>
          </ul>
          ${searchPopularPlants.length > 0 ? `
          <h2>ðŸŒ¿ ${detectedLang === 'fr' ? 'Plantes Populaires' : 'Popular Plants'}</h2>
          <ul style="display: flex; flex-wrap: wrap; gap: 8px; list-style: none; padding: 0;">
            ${searchPopularPlants.map(p => `<li><a href="/plants/${encodeURIComponent(p.id)}" style="display: inline-block; padding: 6px 12px; background: #f0fdf4; border-radius: 20px; text-decoration: none; color: #065f46; font-size: 14px;">ðŸŒ± ${escapeHtml(p.name)}</a></li>`).join('')}
          </ul>
          ` : ''}
          <h2>ðŸ”— ${detectedLang === 'fr' ? 'Explorer' : 'Explore'}</h2>
          <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
            <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
            <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir' : 'Discover'}</a>
            <a href="/gardens">ðŸ¡ ${detectedLang === 'fr' ? 'Jardins' : 'Gardens'}</a>
            <a href="/blog">ðŸ“š Blog</a>
          </nav>
        </article>
      `
    }

    else if (effectivePath[0] === 'blog' && !effectivePath[1]) {
      title = `ðŸ“š ${tr.blogTitle} - ${tr.blogTagline}`
      description = tr.blogDesc

      // Fetch recent blog posts for the listing
      if (supabaseServer) {
        const { data: posts } = await ssrQuery(
          supabaseServer
            .from('blog_posts')
            .select('title, slug, excerpt, published_at, cover_image_url')
            .eq('is_published', true)
            .order('published_at', { ascending: false })
            .limit(10),
          'blog_listing'
        )

        if (posts?.length) {
          // Use the most recent post's cover image if available
          const latestWithImage = posts.find(p => p.cover_image_url)
          if (latestWithImage) {
            image = ensureAbsoluteUrl(latestWithImage.cover_image_url)
            imageAlt = `${tr.blogTitle} - ${latestWithImage.title}`
          }
          // If no image found, image stays null - no fallback

          pageContent = `
            <article>
              <h1>ðŸ“š ${tr.blogTitle}</h1>
              <p>${tr.blogDesc}</p>
              <h2>${tr.blogLatest}</h2>
              <ul>
                ${posts.map(p => `
                  <li>
                    <a href="/blog/${escapeHtml(p.slug)}"><strong>${escapeHtml(p.title)}</strong></a>
                    ${p.excerpt ? `<br><em>${escapeHtml(p.excerpt.slice(0, 100))}...</em>` : ''}
                  </li>
                `).join('')}
              </ul>
              <h2>ðŸ”— ${detectedLang === 'fr' ? 'Explorer Aphylia' : 'Explore Aphylia'}</h2>
              <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
                <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
                <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir' : 'Discover'}</a>
                <a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher' : 'Search'}</a>
                <a href="/gardens">ðŸ¡ ${detectedLang === 'fr' ? 'Jardins' : 'Gardens'}</a>
                <a href="/about">â„¹ï¸ ${detectedLang === 'fr' ? 'Ã€ Propos' : 'About'}</a>
              </nav>
            </article>
          `
        } else {
          pageContent = `
            <article>
              <h1>ðŸ“š ${tr.blogTitle}</h1>
              <p>${tr.blogDesc}</p>
              <p>${detectedLang === 'fr' ? 'Les articles arrivent bientÃ´t!' : 'Articles coming soon!'}</p>
              <h2>ðŸ”— ${detectedLang === 'fr' ? 'Explorer Aphylia' : 'Explore Aphylia'}</h2>
              <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
                <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
                <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir' : 'Discover'}</a>
                <a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher' : 'Search'}</a>
                <a href="/gardens">ðŸ¡ ${detectedLang === 'fr' ? 'Jardins' : 'Gardens'}</a>
              </nav>
            </article>
          `
        }
      }
    }

    // Gardens listing page
    else if (effectivePath[0] === 'gardens' && !effectivePath[1]) {
      // Fetch some public gardens to list
      let listGardens = []
      try {
        if (supabaseServer) {
          const { data: gardens } = await ssrQuery(
            supabaseServer
              .from('gardens')
              .select('id, name')
              .eq('privacy', 'public')
              .limit(12),
            'gardens_list'
          )
          if (gardens) listGardens = gardens
        }
      } catch { }
      
      title = `ðŸ¡ ${tr.gardensTitle} | Aphylia`
      description = tr.gardensDesc
      pageContent = `
        <article>
          <h1>ðŸ¡ ${tr.gardensCommunity}</h1>
          <p>${tr.gardensExploreWorld}</p>
          <h2>${tr.gardensInspired}</h2>
          <ul>
            <li>ðŸŒ¸ ${tr.gardensThrive}</li>
            <li>ðŸ“ ${tr.gardensClimate}</li>
            <li>ðŸ’¡ ${tr.gardensIdeas}</li>
            <li>ðŸ¤ ${tr.gardensConnect}</li>
          </ul>
          ${listGardens.length > 0 ? `
          <h2>ðŸŒ³ ${detectedLang === 'fr' ? 'Jardins de la CommunautÃ©' : 'Community Gardens'}</h2>
          <ul>
            ${listGardens.map(g => `<li><a href="/garden/${encodeURIComponent(g.id)}">${escapeHtml(g.name || 'Garden')}</a></li>`).join('')}
          </ul>
          ` : ''}
          <h2>ðŸ”— ${detectedLang === 'fr' ? 'Explorer' : 'Explore'}</h2>
          <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
            <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
            <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir' : 'Discover'}</a>
            <a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher' : 'Search'}</a>
            <a href="/blog">ðŸ“š Blog</a>
          </nav>
        </article>
      `
    }

    // Discovery/Swipe page
    else if (effectivePath[0] === 'discovery') {
      // Fetch some featured plants for discovery page
      let discoveryPlants = []
      try {
        if (supabaseServer) {
          const { data: plants } = await ssrQuery(
            supabaseServer
              .from('plants')
              .select('id, name')
              .limit(8),
            'discovery_plants'
          )
          if (plants) discoveryPlants = plants
        }
      } catch { }
      
      title = `ðŸŽ´ ${tr.discoveryTitle}`
      description = tr.discoveryDesc
      pageContent = `
        <article>
          <h1>ðŸŽ´ ${tr.discoveryPlant}</h1>
          <p>${tr.discoveryFind}</p>
          <h2>${tr.discoveryHow}</h2>
          <ul>
            <li>ðŸ‘‰ ${tr.discoveryRight}</li>
            <li>ðŸ‘ˆ ${tr.discoveryLeft}</li>
            <li>â¬†ï¸ ${tr.discoveryUp}</li>
            <li>ðŸ”„ ${tr.discoveryKeep}</li>
          </ul>
          <p>${tr.discoveryStart} ðŸŒ¿</p>
          ${discoveryPlants.length > 0 ? `
          <h2>ðŸŒ¿ ${detectedLang === 'fr' ? 'Plantes Ã  DÃ©couvrir' : 'Plants to Discover'}</h2>
          <ul style="display: flex; flex-wrap: wrap; gap: 8px; list-style: none; padding: 0;">
            ${discoveryPlants.map(p => `<li><a href="/plants/${encodeURIComponent(p.id)}" style="display: inline-block; padding: 6px 12px; background: #f0fdf4; border-radius: 20px; text-decoration: none; color: #065f46; font-size: 14px;">ðŸŒ± ${escapeHtml(p.name)}</a></li>`).join('')}
          </ul>
          ` : ''}
          <h2>ðŸ”— ${detectedLang === 'fr' ? 'Explorer' : 'Explore'}</h2>
          <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
            <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
            <a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher' : 'Search'}</a>
            <a href="/gardens">ðŸ¡ ${detectedLang === 'fr' ? 'Jardins' : 'Gardens'}</a>
            <a href="/blog">ðŸ“š Blog</a>
            <a href="/download">ðŸ“² ${detectedLang === 'fr' ? 'TÃ©lÃ©charger' : 'Download'}</a>
          </nav>
        </article>
      `
    }

    // Pricing page
    else if (effectivePath[0] === 'pricing') {
      title = `ðŸ’Ž ${tr.pricingTitle}`
      description = tr.pricingDesc
      pageContent = `
        <article>
          <h1>ðŸ’Ž ${tr.pricingPlans}</h1>
          <h2>ðŸ†“ ${tr.pricingFree}</h2>
          <p>${tr.pricingEverything}</p>
          <ul>
            <li>âœ… <a href="/discovery">${tr.pricingDiscovery}</a></li>
            <li>âœ… <a href="/gardens">${tr.pricingTracking}</a></li>
            <li>âœ… ${tr.pricingCare}</li>
            <li>âœ… ${tr.pricingIdentify}</li>
            <li>âœ… ${tr.pricingAccess}</li>
          </ul>
          <h2>âœ¨ ${tr.pricingPremium}</h2>
          <p>${tr.pricingSerious}</p>
          <ul>
            <li>ðŸŒŸ ${tr.pricingAnalytics}</li>
            <li>ðŸŒŸ ${tr.pricingSupport}</li>
            <li>ðŸŒŸ ${tr.pricingExclusive}</li>
          </ul>
          <p style="margin-top: 20px;"><a href="/download" style="display: inline-block; padding: 12px 24px; background: #10b981; color: white; border-radius: 12px; text-decoration: none; font-weight: 600;">ðŸ“² ${detectedLang === 'fr' ? 'Commencer Gratuitement' : 'Get Started Free'}</a></p>
          <h2>ðŸ”— ${detectedLang === 'fr' ? 'En savoir plus' : 'Learn More'}</h2>
          <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
            <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
            <a href="/about">â„¹ï¸ ${detectedLang === 'fr' ? 'Ã€ Propos' : 'About'}</a>
            <a href="/contact">ðŸ’¬ Contact</a>
            <a href="/terms">ðŸ“œ ${detectedLang === 'fr' ? 'Conditions' : 'Terms'}</a>
          </nav>
        </article>
      `
    }

    // Download page
    else if (effectivePath[0] === 'download') {
      title = `ðŸ“² ${tr.downloadTitle}`
      description = tr.downloadDesc
      pageContent = `
        <article>
          <h1>ðŸ“² ${tr.downloadGet}</h1>
          <h2>ðŸŒ ${tr.downloadWeb}</h2>
          <p>${tr.downloadWebDesc}</p>
          <p><a href="/discovery" style="display: inline-block; padding: 10px 20px; background: #10b981; color: white; border-radius: 8px; text-decoration: none; font-weight: 600;">ðŸŽ´ ${detectedLang === 'fr' ? 'Lancer l\'App Web' : 'Launch Web App'}</a></p>
          <h2>ðŸ“± ${tr.downloadPwa}</h2>
          <p>${tr.downloadPwaDesc}</p>
          <ul>
            <li>${tr.downloadIos}</li>
            <li>${tr.downloadAndroid}</li>
          </ul>
          <h2>ðŸš€ ${tr.downloadNative}</h2>
          <p>${tr.downloadNativeDesc}</p>
          <h2>ðŸ”— ${detectedLang === 'fr' ? 'Explorer Aphylia' : 'Explore Aphylia'}</h2>
          <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
            <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
            <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir' : 'Discover'}</a>
            <a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher' : 'Search'}</a>
            <a href="/pricing">ðŸ’Ž ${detectedLang === 'fr' ? 'Tarifs' : 'Pricing'}</a>
            <a href="/about">â„¹ï¸ ${detectedLang === 'fr' ? 'Ã€ Propos' : 'About'}</a>
          </nav>
        </article>
      `
    }

    // Terms page
    else if (effectivePath[0] === 'terms') {
      const dateLocales = { en: 'en-US', fr: 'fr-FR', es: 'es-ES', de: 'de-DE', it: 'it-IT', pt: 'pt-BR', nl: 'nl-NL', pl: 'pl-PL', ru: 'ru-RU', ja: 'ja-JP', ko: 'ko-KR', zh: 'zh-CN' }
      title = `ðŸ“œ ${tr.termsTitle} | Aphylia`
      description = tr.termsDesc
      pageContent = `
        <article>
          <h1>ðŸ“œ ${tr.termsTitle}</h1>
          <p>${tr.termsUpdated}: ${new Date().toLocaleDateString(dateLocales[detectedLang] || 'en-US', { month: 'long', year: 'numeric' })}</p>
          <p>${tr.termsWelcome}</p>
          <h2>${tr.termsSimple}</h2>
          <ul>
            <li>âœ… ${tr.termsRespect}</li>
            <li>âœ… ${tr.termsSpam}</li>
            <li>âœ… ${tr.termsSecure}</li>
            <li>âœ… ${tr.termsEnjoy}</li>
          </ul>
          <h2>ðŸ”— ${detectedLang === 'fr' ? 'Liens Utiles' : 'Useful Links'}</h2>
          <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
            <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
            <a href="/about">â„¹ï¸ ${detectedLang === 'fr' ? 'Ã€ Propos' : 'About'}</a>
            <a href="/contact">ðŸ’¬ Contact</a>
            <a href="/pricing">ðŸ’Ž ${detectedLang === 'fr' ? 'Tarifs' : 'Pricing'}</a>
          </nav>
        </article>
      `
    }

    // Contact page
    else if (effectivePath[0] === 'contact' && effectivePath[1] === 'business') {
      title = `ðŸ¤ ${tr.businessTitle} | Aphylia`
      description = tr.businessDesc
      pageContent = `
        <article>
          <h1>ðŸ¤ ${tr.businessTitle}</h1>
          <p>${tr.businessInterested}</p>
          <ul>
            <li>ðŸŒ¿ ${tr.businessNurseries}</li>
            <li>ðŸª ${tr.businessShops}</li>
            <li>ðŸŽ¯ ${tr.businessBrands}</li>
            <li>ðŸ“š ${tr.businessCreators}</li>
          </ul>
          <p>${tr.businessExplore}</p>
          <h2>ðŸ”— ${detectedLang === 'fr' ? 'Liens Utiles' : 'Useful Links'}</h2>
          <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
            <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
            <a href="/contact">ðŸ’¬ ${detectedLang === 'fr' ? 'Contact GÃ©nÃ©ral' : 'General Contact'}</a>
            <a href="/about">â„¹ï¸ ${detectedLang === 'fr' ? 'Ã€ Propos' : 'About'}</a>
            <a href="/blog">ðŸ“š Blog</a>
          </nav>
        </article>
      `
    }

    else if (effectivePath[0] === 'contact') {
      title = `ðŸ’¬ ${tr.contactTitle}`
      description = tr.contactDesc
      pageContent = `
        <article>
          <h1>ðŸ’¬ ${tr.contactGet}</h1>
          <p>${tr.contactLove}</p>
          <h2>${tr.contactReach}</h2>
          <ul>
            <li>â“ ${tr.contactQuestions}</li>
            <li>ðŸ’¡ ${tr.contactFeatures}</li>
            <li>ðŸ› ${tr.contactBugs}</li>
            <li>ðŸ¤ <a href="/contact/business">${tr.contactPartnership}</a></li>
            <li>ðŸ‘‹ ${tr.contactHello}</li>
          </ul>
          <p>${tr.contactRespond} ðŸŒ±</p>
          <h2>ðŸ”— ${detectedLang === 'fr' ? 'Explorer Aphylia' : 'Explore Aphylia'}</h2>
          <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
            <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
            <a href="/about">â„¹ï¸ ${detectedLang === 'fr' ? 'Ã€ Propos' : 'About'}</a>
            <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir' : 'Discover'}</a>
            <a href="/blog">ðŸ“š Blog</a>
            <a href="/terms">ðŸ“œ ${detectedLang === 'fr' ? 'Conditions' : 'Terms'}</a>
          </nav>
        </article>
      `
    }

    // Bookmarks page
    // Bookmark list page: /bookmarks/:id
    else if (isBookmarkRoute && supabaseServer) {
      isDynamicRoute = true
      const listId = decodeURIComponent(effectivePath[1])
      console.log(`[ssr] Looking up bookmark list: ${listId}`)

      // Try to get the bookmark list info (using correct table name 'bookmarks')
      const { data: bookmarkList, error: bookmarkError } = await ssrQuery(
        supabaseServer
          .from('bookmarks')
          .select('id, name, user_id, visibility, created_at')
          .eq('id', listId)
          .eq('visibility', 'public')
          .maybeSingle(),
        'bookmark_lookup'
      )

      if (bookmarkError) {
        console.log(`[ssr] Bookmark list query error: ${bookmarkError.message}`)
        resourceFound = false
      } else if (!bookmarkList) {
        console.log(`[ssr] âœ— Bookmark list not found or private: ${listId}`)
        resourceFound = false
      }

      if (bookmarkList) {
        console.log(`[ssr] âœ“ Found bookmark list: ${bookmarkList.name}`)

        // Get owner and plant count
        let ownerName = null
        let plantCount = 0
        let listImage = null

        try {
          if (bookmarkList.user_id) {
            const { data: owner } = await ssrQuery(
              supabaseServer
                .from('profiles')
                .select('display_name')
                .eq('id', bookmarkList.user_id)
                .maybeSingle(),
              'bookmark_owner'
            )
            if (owner) ownerName = owner.display_name
          }

          // Get plant count (with timeout) - using correct table 'bookmark_items'
          const { count } = await ssrQuery(
            supabaseServer
              .from('bookmark_items')
              .select('id', { count: 'exact', head: true })
              .eq('bookmark_id', listId),
            'bookmark_plant_count'
          )
          plantCount = count || 0

          // Get first plant image (with timeout)
          const { data: listPlants } = await ssrQuery(
            supabaseServer
              .from('bookmark_items')
              .select('plant_id')
              .eq('bookmark_id', listId)
              .limit(1),
            'bookmark_plants_for_img'
          )
          if (listPlants?.[0]?.plant_id) {
            const { data: plantImg } = await ssrQuery(
              supabaseServer
                .from('plant_images')
                .select('link')
                .eq('plant_id', listPlants[0].plant_id)
                .eq('use', 'primary')
                .maybeSingle(),
              'bookmark_plant_img'
            )
            if (plantImg?.link) listImage = ensureAbsoluteUrl(plantImg.link)
          }
        } catch { }

        // Title: "ðŸ”– FAV_MTP - Plant Bookmark | Aphylia"
        title = `ðŸ”– ${bookmarkList.name || tr.bookmarksCollection} - ${tr.bookmarkTitle} | Aphylia`

        // Description: "ðŸ“Œ Bookmark "FAV_MTP" made by Username ðŸŒ¿ 4 plants saved ðŸŒ±"
        const bookmarkName = bookmarkList.name || tr.bookmarksCollection
        const plantWord = plantCount === 1 ? tr.bookmarkPlant : tr.bookmarkPlants

        if (ownerName) {
          description = `ðŸ“Œ ${tr.bookmarkDesc} "${bookmarkName}" ${tr.bookmarkMadeBy} ${ownerName} ðŸŒ¿ ${plantCount} ${plantWord} ${tr.bookmarkSaved} ðŸŒ±`
        } else {
          description = `ðŸ“Œ ${tr.bookmarkDesc} "${bookmarkName}" ðŸŒ¿ ${plantCount} ${plantWord} ${tr.bookmarkSaved} ðŸŒ±`
        }

        // Use plant image if found, otherwise no image
        if (listImage) {
          image = listImage
          imageAlt = `${bookmarkName} - Plant Collection on Aphylia`
        }
        // If no image found, image stays null - no fallback

        // Generate bookmark image tag if from media.aphylia.app
        const bookmarkImageTag = generateImageTag(listImage, `${bookmarkName} - Plant Collection on Aphylia`)

        pageContent = `
          <article>
            <h1>ðŸ”– ${escapeHtml(bookmarkName)} - ${tr.bookmarkTitle}</h1>
            <div class="plant-meta">
              ðŸŒ¿ ${plantCount} ${plantWord} ${tr.bookmarkSaved}
              ${ownerName ? ` Â· ðŸ‘¤ ${tr.bookmarkMadeBy} <a href="/u/${encodeURIComponent(ownerName)}">${escapeHtml(ownerName)}</a>` : ''}
            </div>
            
            ${bookmarkImageTag ? `<figure itemscope itemtype="https://schema.org/ImageObject">
              ${bookmarkImageTag}
              <figcaption style="font-size: 12px; color: #6b7280; text-align: center;">${escapeHtml(bookmarkName)}</figcaption>
            </figure>` : ''}
            
            <p>${tr.bookmarksCarefully} ðŸŒ±</p>
            <p style="margin-top: 20px;"><a href="${escapeHtml(canonicalUrl)}">${tr.bookmarksView} â†’</a></p>
            
            <h2>ðŸ”— ${detectedLang === 'fr' ? 'Explorer' : 'Explore'}</h2>
            <nav style="display: flex; flex-wrap: wrap; gap: 12px;">
              <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir des plantes' : 'Discover Plants'}</a>
              <a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher' : 'Search'}</a>
              <a href="/gardens">ðŸ¡ ${detectedLang === 'fr' ? 'Jardins' : 'Gardens'}</a>
              <a href="/">ðŸ  ${detectedLang === 'fr' ? 'Accueil' : 'Home'}</a>
            </nav>
          </article>
        `
      }
    }

    // Homepage with dynamic content - ONLY page that gets the banner image
    else if (pagePath === '/' || effectivePath.length === 0) {
      title = `ðŸŒ± ${tr.homeTitle}`
      description = tr.homeDesc
      
      // Landing page is the ONLY page that uses the banner image
      image = LANDING_BANNER_IMAGE
      imageAlt = 'Aphylia - Your Personal Plant Companion'

      // Try to get stats from landing_stats table first, fallback to counts
      let plantCountStat = '5,000+'
      let userCount = '10,000+'
      let taskCount = '50,000+'
      let ratingValue = '4.9'
      let ratingLabel = 'App Store Rating'
      try {
        if (supabaseServer) {
          // Try to get landing stats from admin-configured table
          const { data: landingStats } = await ssrQuery(
            supabaseServer
              .from('landing_stats')
              .select('plants_count, plants_label, users_count, users_label, tasks_count, tasks_label, rating_value, rating_label')
              .limit(1)
              .maybeSingle(),
            'landing_stats'
          )
          
          if (landingStats) {
            plantCountStat = landingStats.plants_count || plantCountStat
            userCount = landingStats.users_count || userCount
            taskCount = landingStats.tasks_count || taskCount
            ratingValue = landingStats.rating_value || ratingValue
            ratingLabel = landingStats.rating_label || ratingLabel
          } else {
            // Fallback: count from database
            const { count: pCount } = await ssrQuery(
              supabaseServer
                .from('plants')
                .select('id', { count: 'exact', head: true }),
              'home_plant_count'
            )
            if (pCount) plantCountStat = pCount.toLocaleString() + '+'
            
            // Count users
            const { count: uCount } = await ssrQuery(
              supabaseServer
                .from('profiles')
                .select('id', { count: 'exact', head: true }),
              'home_user_count'
            )
            if (uCount) userCount = uCount.toLocaleString() + '+'
          }
        }
      } catch { }

      // Features list for crawlers
      const features = detectedLang === 'fr' ? [
        { icon: 'ðŸŽ´', title: 'DÃ©couverte de Plantes', desc: 'Swipez pour dÃ©couvrir des plantes parfaites pour votre jardin' },
        { icon: 'ðŸ¡', title: 'Gestion de Jardin', desc: 'Suivez tous vos jardins et plantes en un seul endroit' },
        { icon: 'â°', title: 'Rappels Intelligents', desc: 'Ne manquez plus jamais l\'arrosage ou l\'entretien' },
        { icon: 'ðŸ“š', title: 'Guides d\'Entretien', desc: 'Conseils d\'experts pour chaque plante' },
        { icon: 'ðŸ“¸', title: 'Identification', desc: 'Identifiez les plantes avec votre camÃ©ra' },
        { icon: 'ðŸ‘¥', title: 'CommunautÃ©', desc: 'Connectez-vous avec d\'autres passionnÃ©s de jardinage' },
        { icon: 'ðŸ“Š', title: 'Analyses', desc: 'Suivez vos progrÃ¨s et accomplissements' },
        { icon: 'ðŸ¾', title: 'SÃ©curitÃ© Animaux', desc: 'VÃ©rifiez la toxicitÃ© des plantes pour vos animaux' },
      ] : [
        { icon: 'ðŸŽ´', title: 'Plant Discovery', desc: 'Swipe to discover perfect plants for your garden' },
        { icon: 'ðŸ¡', title: 'Garden Management', desc: 'Track all your gardens and plants in one place' },
        { icon: 'â°', title: 'Smart Reminders', desc: 'Never miss watering or care tasks again' },
        { icon: 'ðŸ“š', title: 'Care Guides', desc: 'Expert tips and advice for every plant' },
        { icon: 'ðŸ“¸', title: 'Plant ID', desc: 'Identify plants using your camera' },
        { icon: 'ðŸ‘¥', title: 'Community', desc: 'Connect with fellow gardening enthusiasts' },
        { icon: 'ðŸ“Š', title: 'Analytics', desc: 'Track your progress and achievements' },
        { icon: 'ðŸ¾', title: 'Pet Safety', desc: 'Check plant toxicity for your pets' },
      ]

      // How it works steps
      const howItWorks = detectedLang === 'fr' ? [
        { step: '1', title: 'TÃ©lÃ©chargez', desc: 'Installez Aphylia gratuitement' },
        { step: '2', title: 'CrÃ©ez votre Jardin', desc: 'Ajoutez vos plantes et configurez votre espace' },
        { step: '3', title: 'Recevez des Rappels', desc: 'Notifications intelligentes pour l\'entretien' },
        { step: '4', title: 'Regardez-le Grandir', desc: 'Suivez les progrÃ¨s et cÃ©lÃ©brez les succÃ¨s' },
      ] : [
        { step: '1', title: 'Download', desc: 'Install Aphylia for free' },
        { step: '2', title: 'Create Your Garden', desc: 'Add your plants and set up your space' },
        { step: '3', title: 'Get Reminders', desc: 'Smart notifications for care tasks' },
        { step: '4', title: 'Watch It Grow', desc: 'Track progress and celebrate success' },
      ]

      // Fetch popular plants for internal links
      let popularPlants = []
      let recentBlogPosts = []
      let publicGardens = []
      try {
        if (supabaseServer) {
          // Get popular plants (by name for linking)
          const { data: plants } = await ssrQuery(
            supabaseServer
              .from('plants')
              .select('id, name')
              .limit(12),
            'home_popular_plants'
          )
          if (plants) popularPlants = plants

          // Get recent blog posts
          const { data: posts } = await ssrQuery(
            supabaseServer
              .from('blog_posts')
              .select('slug, title')
              .eq('is_published', true)
              .order('published_at', { ascending: false })
              .limit(6),
            'home_recent_blog'
          )
          if (posts) recentBlogPosts = posts

          // Get public gardens with names
          const { data: gardens } = await ssrQuery(
            supabaseServer
              .from('gardens')
              .select('id, name')
              .eq('privacy', 'public')
              .limit(6),
            'home_public_gardens'
          )
          if (gardens) publicGardens = gardens
        }
      } catch { }

      // Generate landing banner image tag (always from media.aphylia.app)
      const landingBannerTag = generateImageTag(LANDING_BANNER_IMAGE, 'Aphylia - Your Personal Plant Companion', {
        style: 'width: 100%; max-width: 600px; height: auto; border-radius: 16px; margin: 20px auto; display: block;'
      })

      pageContent = `
        <article itemscope itemtype="https://schema.org/WebApplication">
          <h1 itemprop="name">ðŸŒ± ${tr.homeWelcome}</h1>
          <p itemprop="description">${tr.homePersonal}</p>
          
          ${landingBannerTag ? `<figure itemprop="image" itemscope itemtype="https://schema.org/ImageObject" style="text-align: center; margin: 24px 0;">
            ${landingBannerTag}
          </figure>` : ''}
          
          <div class="stats-banner" style="display: flex; flex-wrap: wrap; gap: 20px; margin: 24px 0; padding: 20px; background: #f0fdf4; border-radius: 12px;">
            <div style="text-align: center; flex: 1; min-width: 120px;">
              <div style="font-size: 24px; font-weight: bold; color: #059669;">ðŸŒ¿ ${plantCountStat}</div>
              <div style="font-size: 12px; color: #6b7280;">${detectedLang === 'fr' ? 'Plantes' : 'Plants'}</div>
            </div>
            <div style="text-align: center; flex: 1; min-width: 120px;">
              <div style="font-size: 24px; font-weight: bold; color: #059669;">ðŸ‘¥ ${userCount}</div>
              <div style="font-size: 12px; color: #6b7280;">${detectedLang === 'fr' ? 'Utilisateurs' : 'Users'}</div>
            </div>
            <div style="text-align: center; flex: 1; min-width: 120px;">
              <div style="font-size: 24px; font-weight: bold; color: #059669;">âœ… ${taskCount}</div>
              <div style="font-size: 12px; color: #6b7280;">${detectedLang === 'fr' ? 'TÃ¢ches complÃ©tÃ©es' : 'Tasks Completed'}</div>
            </div>
            <div style="text-align: center; flex: 1; min-width: 120px;">
              <div style="font-size: 24px; font-weight: bold; color: #f59e0b;">â­ ${ratingValue}</div>
              <div style="font-size: 12px; color: #6b7280;">${ratingLabel}</div>
            </div>
          </div>
          
          <h2>${tr.homeWhy}</h2>
          <ul>
            <li>ðŸŽ´ <a href="/discovery">${tr.homeSwipe}</a></li>
            <li>ðŸ¡ <a href="/gardens">${tr.homeTracker}</a></li>
            <li>â° ${tr.homeReminders}</li>
            <li>ðŸ“š <a href="/search">${tr.homeCareGuides} ${plantCountStat} ${tr.homePlants}</a></li>
            <li>ðŸ‘¥ ${tr.homeCommunityJoin} ${userCount} ${tr.homePlantLovers}</li>
          </ul>
          
          <h2>âœ¨ ${detectedLang === 'fr' ? 'FonctionnalitÃ©s' : 'Features'}</h2>
          <div style="display: grid; grid-template-columns: repeat(auto-fill, minmax(250px, 1fr)); gap: 16px;">
            ${features.map(f => `
              <div style="padding: 16px; border: 1px solid #e5e7eb; border-radius: 8px;">
                <div style="font-size: 24px; margin-bottom: 8px;">${f.icon}</div>
                <div style="font-weight: 600; margin-bottom: 4px;">${f.title}</div>
                <div style="font-size: 14px; color: #6b7280;">${f.desc}</div>
              </div>
            `).join('')}
          </div>
          
          <h2>ðŸš€ ${detectedLang === 'fr' ? 'Comment Ã§a marche' : 'How It Works'}</h2>
          <ol>
            ${howItWorks.map(step => `<li><strong>${step.title}</strong>: ${step.desc}</li>`).join('')}
          </ol>
          
          ${popularPlants.length > 0 ? `
          <h2>ðŸŒ¿ ${detectedLang === 'fr' ? 'Plantes Populaires' : 'Popular Plants'}</h2>
          <p>${detectedLang === 'fr' ? 'DÃ©couvrez nos guides de soins pour ces plantes:' : 'Explore our care guides for these plants:'}</p>
          <ul style="display: flex; flex-wrap: wrap; gap: 8px; list-style: none; padding: 0;">
            ${popularPlants.map(p => `<li><a href="/plants/${encodeURIComponent(p.id)}" style="display: inline-block; padding: 6px 12px; background: #f0fdf4; border-radius: 20px; text-decoration: none; color: #065f46; font-size: 14px;">ðŸŒ± ${escapeHtml(p.name)}</a></li>`).join('')}
          </ul>
          <p><a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher plus de plantes' : 'Search more plants'} â†’</a></p>
          ` : ''}
          
          ${recentBlogPosts.length > 0 ? `
          <h2>ðŸ“š ${detectedLang === 'fr' ? 'Articles RÃ©cents' : 'Recent Articles'}</h2>
          <ul>
            ${recentBlogPosts.map(post => `<li><a href="/blog/${escapeHtml(post.slug)}">${escapeHtml(post.title)}</a></li>`).join('')}
          </ul>
          <p><a href="/blog">ðŸ“– ${detectedLang === 'fr' ? 'Voir tous les articles' : 'View all articles'} â†’</a></p>
          ` : ''}
          
          ${publicGardens.length > 0 ? `
          <h2>ðŸ¡ ${detectedLang === 'fr' ? 'Jardins de la CommunautÃ©' : 'Community Gardens'}</h2>
          <p>${detectedLang === 'fr' ? 'DÃ©couvrez ce que les autres jardiniers cultivent:' : 'See what other gardeners are growing:'}</p>
          <ul>
            ${publicGardens.map(g => `<li><a href="/garden/${encodeURIComponent(g.id)}">${escapeHtml(g.name || 'Garden')}</a></li>`).join('')}
          </ul>
          <p><a href="/gardens">ðŸŒ³ ${detectedLang === 'fr' ? 'Explorer tous les jardins' : 'Explore all gardens'} â†’</a></p>
          ` : ''}
          
          <h2>${tr.homeStart}</h2>
          <p>${tr.homeFree} ðŸŒ¿</p>
          
          <div style="margin-top: 24px; display: flex; gap: 12px; flex-wrap: wrap;">
            <a href="/download" style="display: inline-flex; align-items: center; gap: 8px; padding: 12px 24px; background: #10b981; color: white; border-radius: 12px; text-decoration: none; font-weight: 600;">
              ðŸ“² ${detectedLang === 'fr' ? 'TÃ©lÃ©charger l\'App' : 'Download the App'}
            </a>
            <a href="/discovery" style="display: inline-flex; align-items: center; gap: 8px; padding: 12px 24px; background: white; color: #374151; border: 2px solid #e5e7eb; border-radius: 12px; text-decoration: none; font-weight: 600;">
              ðŸŒ ${detectedLang === 'fr' ? 'Essayer dans le navigateur' : 'Try in Browser'}
            </a>
          </div>
          
          <h2>ðŸ”— ${detectedLang === 'fr' ? 'Explorer Aphylia' : 'Explore Aphylia'}</h2>
          <nav style="display: flex; flex-wrap: wrap; gap: 16px; margin-top: 16px;">
            <a href="/discovery">ðŸŽ´ ${detectedLang === 'fr' ? 'DÃ©couvrir des Plantes' : 'Discover Plants'}</a>
            <a href="/search">ðŸ” ${detectedLang === 'fr' ? 'Rechercher' : 'Search'}</a>
            <a href="/gardens">ðŸ¡ ${detectedLang === 'fr' ? 'Jardins' : 'Gardens'}</a>
            <a href="/blog">ðŸ“š Blog</a>
            <a href="/about">â„¹ï¸ ${detectedLang === 'fr' ? 'Ã€ Propos' : 'About'}</a>
            <a href="/pricing">ðŸ’Ž ${detectedLang === 'fr' ? 'Tarifs' : 'Pricing'}</a>
            <a href="/download">ðŸ“² ${detectedLang === 'fr' ? 'TÃ©lÃ©charger' : 'Download'}</a>
            <a href="/contact">ðŸ’¬ Contact</a>
            <a href="/terms">ðŸ“œ ${detectedLang === 'fr' ? 'Conditions' : 'Terms'}</a>
          </nav>
        </article>
      `
    }

  } catch (err) {
    console.error('[ssr] Error generating crawler content:', err?.message || err)
    console.error('[ssr] Stack trace:', err?.stack || 'no stack')
  }

  // Build the full HTML page - completely self-contained, no external JS/CSS dependencies
  // This ensures web archives can display content without errors
  const html = `<!DOCTYPE html>
<html lang="${detectedLang}">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>${escapeHtml(title)}</title>
  <meta name="description" content="${escapeHtml(description)}">
  <meta name="robots" content="${(isDynamicRoute && !resourceFound) ? 'noindex, follow' : 'index, follow'}">
  <link rel="canonical" href="${escapeHtml(canonicalUrl)}">
  
  <!-- Open Graph / Facebook / Discord / Telegram / LinkedIn -->
  <meta property="og:type" content="website">
  <meta property="og:url" content="${escapeHtml(canonicalUrl)}">
  <meta property="og:title" content="${escapeHtml(title)}">
  <meta property="og:description" content="${escapeHtml(description)}">
  ${image ? `<meta property="og:image" content="${escapeHtml(image)}">
  <meta property="og:image:alt" content="${escapeHtml(imageAlt)}">` : '<!-- No image for this page -->'}
  <meta property="og:site_name" content="Aphylia">
  <meta property="og:locale" content="${detectedLang === 'fr' ? 'fr_FR' : 'en_US'}">
  
  <!-- Twitter -->
  <meta name="twitter:card" content="${image ? 'summary_large_image' : 'summary'}">
  <meta name="twitter:url" content="${escapeHtml(canonicalUrl)}">
  <meta name="twitter:title" content="${escapeHtml(title)}">
  <meta name="twitter:description" content="${escapeHtml(description)}">
  ${image ? `<meta name="twitter:image" content="${escapeHtml(image)}">
  <meta name="twitter:image:alt" content="${escapeHtml(imageAlt)}">` : ''}
  
  <!-- Theme -->
  <meta name="theme-color" content="#052e16">
  <meta name="application-name" content="Aphylia">
  
  <!-- Icons - Google requires 48x48+ favicon for search results -->
  <link rel="icon" type="image/svg+xml" href="${siteUrl}/icons/plant-swipe-icon-outline.svg">
  <link rel="icon" type="image/png" sizes="192x192" href="${siteUrl}/icons/icon-192x192.png">
  <link rel="icon" type="image/png" sizes="512x512" href="${siteUrl}/icons/icon-512x512.png">
  <link rel="apple-touch-icon" href="${siteUrl}/icons/icon-192x192.png">
  
  <style>
    * { box-sizing: border-box; }
    body { 
      font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      margin: 0;
      padding: 0;
      min-height: 100vh;
      background: linear-gradient(180deg, #f8faf7 0%, #eef2ed 45%, #e3e5df 100%);
      color: #1a1a1a;
      line-height: 1.6;
    }
    .container {
      max-width: 900px;
      margin: 0 auto;
      padding: 20px;
    }
    header {
      display: flex;
      align-items: center;
      gap: 12px;
      padding: 20px 0;
      border-bottom: 1px solid rgba(0,0,0,0.1);
      margin-bottom: 20px;
    }
    .logo {
      font-size: 2em;
    }
    .brand {
      font-size: 1.5em;
      font-weight: 600;
      color: #052e16;
      text-decoration: none;
    }
    nav {
      display: flex;
      flex-wrap: wrap;
      gap: 8px 20px;
      padding: 15px 0;
      margin-bottom: 20px;
    }
    nav a {
      color: #065f46;
      text-decoration: none;
      font-weight: 500;
      padding: 5px 0;
    }
    nav a:hover { color: #059669; text-decoration: underline; }
    h1 { color: #052e16; margin: 0 0 15px 0; font-size: 2em; }
    h2 { color: #065f46; margin: 30px 0 15px 0; }
    a { color: #059669; }
    article { margin: 20px 0; }
    .archive-notice {
      background: linear-gradient(135deg, #ecfdf5 0%, #d1fae5 100%);
      border: 1px solid #6ee7b7;
      border-radius: 12px;
      padding: 20px;
      margin: 20px 0;
    }
    .archive-notice strong { color: #065f46; }
    .archive-notice a {
      display: inline-block;
      margin-top: 10px;
      background: #059669;
      color: white;
      padding: 8px 16px;
      border-radius: 6px;
      text-decoration: none;
      font-weight: 500;
    }
    .archive-notice a:hover { background: #047857; }
    .plant-card {
      background: white;
      border-radius: 12px;
      padding: 20px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.08);
      margin: 20px 0;
    }
    .plant-card h1 { margin-top: 0; }
    .plant-meta { color: #666; font-size: 0.95em; margin: 10px 0; }
    .plant-meta em { color: #065f46; }
    ul { padding-left: 20px; }
    li { margin: 8px 0; }
    footer {
      margin-top: 60px;
      padding: 30px 0;
      border-top: 1px solid rgba(0,0,0,0.1);
      text-align: center;
      color: #666;
      font-size: 0.9em;
    }
    footer a { color: #059669; margin: 0 10px; }
    @media (max-width: 600px) {
      .container { padding: 15px; }
      h1 { font-size: 1.5em; }
      nav { gap: 5px 15px; }
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <span class="logo">ðŸŒ±</span>
      <a href="/" class="brand">Aphylia</a>
    </header>
    
    <nav>
      <a href="/">Home</a>
      <a href="/search">Search Plants</a>
      <a href="/blog">Blog</a>
      <a href="/gardens">Gardens</a>
      <a href="/about">About</a>
      <a href="/contact">Contact</a>
    </nav>
    
    <div class="archive-notice">
      <strong>ðŸ“š Static Content Version</strong><br>
      You're viewing a simplified version of this page optimized for web archives and search engines.
      For the full interactive experience with search, gardens, and personalized features:
      <br>
      <a href="https://aphylia.app${escapeHtml(pagePath)}">Visit Aphylia Live â†’</a>
    </div>
    
    <main>
      <div class="plant-card">
        ${pageContent || `
          <h1>${escapeHtml(title)}</h1>
          <p>${escapeHtml(description)}</p>
        `}
      </div>
    </main>
    
    <footer>
      <p>&copy; ${new Date().getFullYear()} Aphylia. Helping you grow your plant knowledge ðŸŒ±</p>
      <p>
        <a href="/terms">Terms</a>
        <a href="/about">About</a>
        <a href="/contact">Contact</a>
        <a href="/blog">Blog</a>
      </p>
      <p style="font-size: 0.85em; margin-top: 15px;">
        This is a pre-rendered version for web crawlers, archives, and accessibility.<br>
        Content archived on ${new Date().toISOString().split('T')[0]}
      </p>
    </footer>
  </div>
  
  <!-- No JavaScript dependencies - this page is fully static and self-contained -->
</body>
</html>`

  // Determine HTTP status code:
  // - 200 for static pages and found dynamic resources
  // - 404 for dynamic routes where the resource wasn't found
  const statusCode = (isDynamicRoute && !resourceFound) ? 404 : 200
  
  return { html, statusCode }
}

// Debug endpoint to test crawler detection and SSR
app.get('/api/debug-ssr', async (req, res) => {
  const userAgent = req.get('user-agent') || ''
  const testPath = req.query.path || '/plants/test'
  const isCrawlerResult = isCrawler(userAgent)

  // Test Supabase connection
  let supabaseTest = { ok: false, error: null }
  if (supabaseServer) {
    try {
      const { data, error } = await supabaseServer.from('plants').select('id').limit(1)
      supabaseTest = { ok: !error, error: error?.message || null, hasData: !!data?.length }
    } catch (e) {
      supabaseTest = { ok: false, error: e?.message || 'Connection failed' }
    }
  }

  res.json({
    userAgent,
    isCrawler: isCrawlerResult,
    testPath,
    supabaseAvailable: !!supabaseServer,
    supabaseUrl: supabaseUrlEnv ? 'configured' : 'NOT configured',
    supabaseTest,
    crawlerListSample: CRAWLER_USER_AGENTS.slice(0, 15),
    tips: [
      'Use /api/force-ssr?path=/plants/ID to test SSR output',
      'Use /api/preview-ssr?path=/plants/ID (simulates Discordbot)',
      'Add ?_ssr=1 to any URL to force SSR'
    ]
  })
})

// Force SSR endpoint - always returns SSR HTML for any path (for testing)
// Usage: /api/force-ssr?path=/plants/abc-123
// Add &json=1 to get JSON response with title/description/image
app.get('/api/force-ssr', async (req, res) => {
  const testPath = req.query.path || '/'
  const jsonMode = req.query.json === '1' || req.query.json === 'true'
  const debugMode = req.query.debug === '1' || req.query.debug === 'true'
  console.log(`[force-ssr] Generating SSR for: ${testPath} (json: ${jsonMode}, debug: ${debugMode})`)
  console.log(`[force-ssr] Supabase available: ${!!supabaseServer}, URL configured: ${!!supabaseUrlEnv}`)

  // If debug mode, test Supabase directly first
  let supabaseTestResult = null
  if (debugMode && supabaseServer) {
    try {
      const pathParts = testPath.split('/').filter(Boolean)
      const plantId = pathParts.find((_, i) => pathParts[i - 1] === 'plants' || pathParts[i - 1] === 'fr' && pathParts[i] === 'plants')
        ? pathParts[pathParts.indexOf('plants') + 1]
        : pathParts[1]
      if (plantId) {
        const { data, error } = await supabaseServer.from('plants').select('id, name').eq('id', plantId).maybeSingle()
        supabaseTestResult = { plantId, found: !!data, name: data?.name, error: error?.message }
      }
    } catch (e) {
      supabaseTestResult = { error: e.message }
    }
  }

  try {
    const fakeReq = {
      ...req,
      originalUrl: testPath,
      path: testPath,
      get: (header) => {
        if (header === 'user-agent') return 'Discordbot/2.0 (force-ssr-test)'
        return req.get(header)
      }
    }

    const ssrStartTime = Date.now()
    const { html, statusCode } = await generateCrawlerHtml(fakeReq, testPath)
    const ssrDuration = Date.now() - ssrStartTime

    if (jsonMode) {
      // Extract title, og:title, og:description, og:image from HTML
      const titleMatch = html.match(/<title>([^<]*)<\/title>/)
      const ogTitleMatch = html.match(/<meta property="og:title" content="([^"]*)"/)
      const ogDescMatch = html.match(/<meta property="og:description" content="([^"]*)"/)
      const ogImageMatch = html.match(/<meta property="og:image" content="([^"]*)"/)

      res.json({
        path: testPath,
        statusCode,
        title: titleMatch?.[1] || null,
        ogTitle: ogTitleMatch?.[1] || null,
        ogDescription: ogDescMatch?.[1] || null,
        ogImage: ogImageMatch?.[1] || null,
        htmlLength: html.length,
        ssrDurationMs: ssrDuration,
        ssrTimeoutMs: Number(process.env.SSR_QUERY_TIMEOUT_MS) || 8000,
        supabaseAvailable: !!supabaseServer,
        supabaseUrlConfigured: !!supabaseUrlEnv,
        supabaseDirectTest: supabaseTestResult,
        ssrInternalDebug: fakeReq._ssrDebug,
        debug: {
          pathParts: testPath.split('/').filter(Boolean),
          isPlantRoute: testPath.split('/').filter(Boolean)[0] === 'plants' || testPath.split('/').filter(Boolean)[1] === 'plants',
          isProfileRoute: testPath.split('/').filter(Boolean)[0] === 'u' && !!testPath.split('/').filter(Boolean)[1],
          isGardenRoute: ['garden', 'gardens'].includes(testPath.split('/').filter(Boolean)[0]) && !!testPath.split('/').filter(Boolean)[1]
        }
      })
    } else {
      res.setHeader('Content-Type', 'text/html; charset=utf-8')
      res.setHeader('X-SSR-Test', 'force-ssr')
      res.setHeader('X-SSR-Status', String(statusCode))
      res.status(statusCode).send(html)
    }
  } catch (err) {
    console.error('[force-ssr] Error:', err)
    res.status(500).json({
      error: err.message,
      stack: err.stack,
      supabaseAvailable: !!supabaseServer
    })
  }
})

// Test endpoint to preview what crawlers see
app.get('/api/preview-ssr', async (req, res) => {
  const testPath = req.query.path || '/'
  const fakeReq = {
    ...req,
    originalUrl: testPath,
    path: testPath,
    get: (header) => header === 'user-agent' ? 'Discordbot/2.0' : req.get(header)
  }

  try {
    const { html, statusCode } = await generateCrawlerHtml(fakeReq, testPath)
    res.setHeader('Content-Type', 'text/html; charset=utf-8')
    res.setHeader('X-SSR-Status', String(statusCode))
    res.status(statusCode).send(html)
  } catch (err) {
    res.status(500).json({ error: err.message })
  }
})

app.get('*', async (req, res) => {
  const userAgent = req.get('user-agent') || ''
  const pagePath = req.originalUrl || req.path || '/'

  // Strip query params from path for asset detection
  const pathWithoutQuery = pagePath.split('?')[0]

  // Check for force SSR query param (useful for testing)
  const forceSSR = req.query._ssr === '1' || req.query._ssr === 'true'

  // Always log incoming requests (first 100 chars of UA)
  const uaShort = userAgent.slice(0, 80)
  console.log(`[request] ${req.method} ${pagePath} | UA: ${uaShort}`)

  // Check if this is a crawler
  const detectedAsCrawler = isCrawler(userAgent) || forceSSR

  // Check if this is a crawler requesting a page (not an asset)
  const isAssetRequest = /\.(js|css|png|jpg|jpeg|gif|svg|webp|ico|woff|woff2|ttf|map|json|xml|txt|webmanifest)$/i.test(pathWithoutQuery)

  // Log crawler detection result
  if (detectedAsCrawler) {
    console.log(`[ssr] âœ“ Crawler DETECTED: ${uaShort} -> ${pagePath} (isAsset: ${isAssetRequest}, forced: ${forceSSR})`)
  }

  if (!isAssetRequest && detectedAsCrawler) {
    const ssrStartTime = Date.now()
    try {
      // Use path without query params for SSR
      const { html, statusCode } = await generateCrawlerHtml(req, pathWithoutQuery)
      const ssrDuration = Date.now() - ssrStartTime
      console.log(`[ssr] âœ“ Generated HTML for ${pathWithoutQuery} in ${ssrDuration}ms (${html.length} bytes) [status: ${statusCode}]`)
      res.setHeader('Content-Type', 'text/html; charset=utf-8')
      // Use shorter cache for 404 pages
      if (statusCode === 404) {
        res.setHeader('Cache-Control', 'public, max-age=300, stale-while-revalidate=600')
        res.setHeader('X-Robots-Tag', 'noindex, follow')
      } else {
        res.setHeader('Cache-Control', 'public, max-age=3600, stale-while-revalidate=86400')
        res.setHeader('X-Robots-Tag', 'index, follow')
      }
      res.setHeader('X-SSR-Duration', String(ssrDuration))
      res.setHeader('X-SSR-Status', String(statusCode))
      return res.status(statusCode).send(html)
    } catch (err) {
      const ssrDuration = Date.now() - ssrStartTime
      console.error(`[ssr] âœ— Crawler render FAILED after ${ssrDuration}ms, falling back to SPA:`, err?.message || err)
      console.error('[ssr] Full error stack:', err?.stack || 'no stack')
      console.error('[ssr] Request details:', { path: pathWithoutQuery, ua: uaShort })
      // Fall through to normal SPA serving
    }
  }

  // Record initial page load visit for SPA routes (non-crawlers)
  try {
    const sessionId = getOrSetSessionId(req, res)
    const referrer = req.get('referer') || req.get('referrer') || ''
    const ipAddress = getClientIp(req)
    const acceptLanguage = (req.get('accept-language') || '').split(',')[0] || null
    // Resolve geo asynchronously and do not block response rendering
    resolveGeo(req, ipAddress)
      .then((geo) => getUserIdFromRequest(req)
        .then((uid) => insertWebVisit({ sessionId, userId: uid || null, pagePath, referrer, userAgent, ipAddress, geo, extra: { source: 'initial_load' }, language: acceptLanguage }, req))
        .catch(() => { }))
      .catch(() => { })
  } catch { }
  res.setHeader('Cache-Control', 'public, max-age=0, must-revalidate')
  res.sendFile(path.join(distDir, 'index.html'))
})

// Sentry error handling middleware - must be after all routes
// This catches any errors thrown in route handlers
// GDPR Compliant: Does not send PII (headers, cookies, full request body)
app.use((err, req, res, next) => {
  // Log error for debugging (server-side only)
  console.error('[Server] Express error:', err?.message || err)
  
  // Capture error in Sentry with GDPR-compliant context
  Sentry.withScope((scope) => {
    // Only include path without query params (may contain tokens)
    const safePath = (req.originalUrl || req.path || '/').split('?')[0]
    scope.setExtra('path', safePath)
    scope.setExtra('method', req.method)
    
    // Only include safe headers (no auth, cookies, etc.)
    const safeHeaders = {
      'content-type': req.headers['content-type'],
      'accept': req.headers['accept'],
      'accept-language': req.headers['accept-language'],
    }
    scope.setExtra('headers', safeHeaders)
    
    // Don't include query params or body (may contain PII/tokens)
    // scope.setExtra('query', req.query) // GDPR: Removed
    // scope.setExtra('body', req.body)   // GDPR: Removed
    
    // Add error categorization for easier filtering
    if (err.statusCode === 400 || err.status === 400) {
      scope.setTag('error.type', 'client_error')
    } else if (err.statusCode === 401 || err.status === 401) {
      scope.setTag('error.type', 'auth_error')
    } else if (err.statusCode === 403 || err.status === 403) {
      scope.setTag('error.type', 'permission_error')
    } else if (err.statusCode === 404 || err.status === 404) {
      scope.setTag('error.type', 'not_found')
    } else {
      scope.setTag('error.type', 'server_error')
    }
    
    scope.setTag('route', safePath)
    Sentry.captureException(err)
  })
  
  // Send error response
  const statusCode = err.statusCode || err.status || 500
  res.status(statusCode).json({
    error: process.env.NODE_ENV === 'production' ? 'Internal server error' : err.message,
    ...(process.env.NODE_ENV !== 'production' && { stack: err.stack }),
  })
})

const shouldListen = String(process.env.DISABLE_LISTEN || 'false').toLowerCase() !== 'true'
if (shouldListen) {
  const port = process.env.PORT || 3000
  const host = process.env.HOST || '127.0.0.1' // Bind to localhost only for security
  const httpServer = app.listen(port, host, () => {
    console.log(`[server] listening on http://${host}:${port}`)
    // Best-effort ensure ban tables are present at startup
    ensureBanTables().catch(() => { })
    ensureBroadcastTable().catch(() => { })
    ensureNotificationTables().catch(() => { })
    scheduleNotificationWorker()
  })
  // Store reference for system-health endpoint to count connections
  app._httpServer = httpServer
} else {
  ensureNotificationTables().catch(() => { })
  scheduleNotificationWorker()
}

// Export app for testing and tooling
export { app }
